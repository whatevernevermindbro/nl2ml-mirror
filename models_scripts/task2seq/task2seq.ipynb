{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python385jvsc74a57bd0d0ddd292140de7144a2e52e7cfaaa287bc93c7991ea231311f4a8d4f39ae4756",
   "display_name": "Python 3.8.5 64-bit ('base': conda)"
  },
  "metadata": {
   "interpreter": {
    "hash": "0de36b31320ba4c88b4f85a74724f3d16c36a44df48581253710b1065e752d9e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import gc\n",
    "from datetime import datetime\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import backend as K\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import log_loss\n",
    "from sqlalchemy import create_engine\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('mode.chained_assignment', None)"
   ]
  },
  {
   "source": [
    "### Defining Methods"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_key(my_dict, val):\n",
    "    for key, value in my_dict.items():\n",
    "         if val == value:\n",
    "             return key\n",
    " \n",
    "    return \"key doesn't exist\""
   ]
  },
  {
   "source": [
    "### Reading Data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "---"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Index(['graph_vertex_id', 'graph_vertex', 'graph_vertex_subclass'], dtype='object')"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "graph_path = '../../data/actual_graph_2021-05-22.csv'\n",
    "graph = pd.read_csv(graph_path)\n",
    "graph.rename({'id':'graph_vertex_id'}, axis=1, inplace=True)\n",
    "graph.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(266, 8)"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "COMPETITIONS_PATH = \"../../data/competitions_info_cleaned_filled.csv\" #./data/competitions_info_cleaned.csv\n",
    "competitions_filled = pd.read_csv(COMPETITIONS_PATH)\n",
    "competitions_filled.drop_duplicates(inplace=True)\n",
    "competitions_filled.rename({'Description': 'description', 'Metric':'metric', 'DataType':'datatype', 'Subject':'subject', 'ProblemType':'problemtype'}\n",
    "                        , axis=1, inplace=True)\n",
    "competitions_filled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "ref             0\n",
       "comp_name       0\n",
       "comp_type       0\n",
       "description    21\n",
       "metric         19\n",
       "datatype       19\n",
       "subject        19\n",
       "problemtype    19\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "competitions_filled.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "competitions_filled['ref'] = competitions_filled['ref'].str.replace(\"'\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(5060, 10)"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "COMPETITIONS_PATH = \"../../data/competitions_2021-05-22.csv\" #./data/competitions_info_cleaned.csv\n",
    "competitions = pd.read_csv(COMPETITIONS_PATH)\n",
    "competitions.drop_duplicates(inplace=True)\n",
    "competitions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# competitions['ref'] = competitions['ref'].apply(lambda x: x.split(',')[0])\n",
    "# competitions['ref'] = competitions['ref'].str.replace(\"'\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# competitions['exists_in_comp_filled'] = competitions.apply(lambda x: x['ref'] in competitions_filled['ref'].unique(), axis=1)\n",
    "# competitions['exists_in_comp_filled'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# competitions_filled.merge(competitions[['id', 'ref']], on=['ref']).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(312, 10)"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "competitions = competitions_filled.merge(competitions[['id', 'ref_link']], how='inner', left_on=['ref'], right_on=['ref_link'])\n",
    "competitions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "ref             0\n",
       "comp_name       0\n",
       "comp_type       0\n",
       "description    26\n",
       "metric         23\n",
       "datatype       23\n",
       "subject        23\n",
       "problemtype    23\n",
       "id              0\n",
       "ref_link        0\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "competitions.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   code_block_id                                         code_block  \\\n",
       "0         570367  `# My forecasting COVID-19 confirmed cases and...   \n",
       "1         570367  `# My forecasting COVID-19 confirmed cases and...   \n",
       "2         570368  `# load training and testing data \\nsubm = pd....   \n",
       "3         570369                                             `subm`   \n",
       "4         570367  `# My forecasting COVID-19 confirmed cases and...   \n",
       "\n",
       "  data_format  graph_vertex_id errors  marks  kaggle_id  competition_id  \n",
       "0       Table               45     No      2    8591010            3868  \n",
       "1       Table               45     No      2    8591010            3868  \n",
       "2       Table               45     No      5    8591010            3868  \n",
       "3       Table               41     No      5    8591010            3868  \n",
       "4       Table               45     No      2    8591010            3868  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>code_block_id</th>\n      <th>code_block</th>\n      <th>data_format</th>\n      <th>graph_vertex_id</th>\n      <th>errors</th>\n      <th>marks</th>\n      <th>kaggle_id</th>\n      <th>competition_id</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>570367</td>\n      <td>`# My forecasting COVID-19 confirmed cases and...</td>\n      <td>Table</td>\n      <td>45</td>\n      <td>No</td>\n      <td>2</td>\n      <td>8591010</td>\n      <td>3868</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>570367</td>\n      <td>`# My forecasting COVID-19 confirmed cases and...</td>\n      <td>Table</td>\n      <td>45</td>\n      <td>No</td>\n      <td>2</td>\n      <td>8591010</td>\n      <td>3868</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>570368</td>\n      <td>`# load training and testing data \\nsubm = pd....</td>\n      <td>Table</td>\n      <td>45</td>\n      <td>No</td>\n      <td>5</td>\n      <td>8591010</td>\n      <td>3868</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>570369</td>\n      <td>`subm`</td>\n      <td>Table</td>\n      <td>41</td>\n      <td>No</td>\n      <td>5</td>\n      <td>8591010</td>\n      <td>3868</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>570367</td>\n      <td>`# My forecasting COVID-19 confirmed cases and...</td>\n      <td>Table</td>\n      <td>45</td>\n      <td>No</td>\n      <td>2</td>\n      <td>8591010</td>\n      <td>3868</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "NOTEBOOKS_PATH = '../../data/markup_data_2021-05-22.csv'\n",
    "notebooks = pd.read_csv(NOTEBOOKS_PATH)\n",
    "notebooks.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(5932, 10)"
      ]
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "source": [
    "notebooks = notebooks.merge(graph, on='graph_vertex_id', how='left')\n",
    "notebooks.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "3207\n3110\n"
     ]
    }
   ],
   "source": [
    "nl2ml = notebooks.merge(competitions, left_on=['competition_id'], right_on=['id'], how='inner')\n",
    "print(nl2ml.shape[0])\n",
    "nl2ml.drop_duplicates(inplace=True, subset=['code_block_id', 'kaggle_id'])\n",
    "print(nl2ml.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "113 7\n"
     ]
    }
   ],
   "source": [
    "print(nl2ml['kaggle_id'].nunique(), nl2ml['competition_id'].nunique())"
   ]
  },
  {
   "source": [
    "### Vertices Preprocessing"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Data_Transform          936\n",
       "EDA                     747\n",
       "Model_Train             287\n",
       "Visualization           281\n",
       "Environment             202\n",
       "Data_Extraction         167\n",
       "Other                   147\n",
       "Hyperparam_Tuning       120\n",
       "Data_Export             104\n",
       "Model_Evaluation         95\n",
       "Model_Interpretation     21\n",
       "Hypothesis                3\n",
       "Name: graph_vertex, dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "source": [
    "nl2ml['graph_vertex'].apply(lambda x: x.split(';')[0].split('.')[0]).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Index(['code_block_id', 'code_block', 'data_format', 'graph_vertex_id',\n",
       "       'errors', 'marks', 'kaggle_id', 'competition_id', 'graph_vertex',\n",
       "       'graph_vertex_subclass', 'ref', 'comp_name', 'comp_type', 'description',\n",
       "       'metric', 'datatype', 'subject', 'problemtype', 'id', 'ref_link'],\n",
       "      dtype='object')"
      ]
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "source": [
    "nl2ml.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "nl2ml['vertex_l1'], nl2ml['vertex_l2'] = nl2ml['graph_vertex'].apply(lambda x: x.split(';')[0].split('.')[0]), nl2ml['graph_vertex_subclass']#.apply(lambda x: x.split(';')[0].split('.')[1])"
   ]
  },
  {
   "source": [
    "### Missing Values"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "code_block_id            0\ncode_block               0\ndata_format              0\ngraph_vertex_id          0\nerrors                   0\nmarks                    0\nkaggle_id                0\ncompetition_id           0\ngraph_vertex             0\ngraph_vertex_subclass    0\nref                      0\ncomp_name                0\ncomp_type                0\ndescription              0\nmetric                   0\ndatatype                 0\nsubject                  0\nproblemtype              0\nid                       0\nref_link                 0\nvertex_l1                0\nvertex_l2                0\ndtype: int64\ncode_block_id            0\ncode_block               0\ndata_format              0\ngraph_vertex_id          0\nerrors                   0\nmarks                    0\nkaggle_id                0\ncompetition_id           0\ngraph_vertex             0\ngraph_vertex_subclass    0\nref                      0\ncomp_name                0\ncomp_type                0\ndescription              0\nmetric                   0\ndatatype                 0\nsubject                  0\nproblemtype              0\nid                       0\nref_link                 0\nvertex_l1                0\nvertex_l2                0\ndtype: int64\n"
     ]
    }
   ],
   "source": [
    "nl2ml.replace('-', -1, inplace=True)\n",
    "print(nl2ml.isna().sum())\n",
    "nl2ml.fillna(-1, inplace=True)\n",
    "print(nl2ml.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "TASK_FEATURES = ['comp_name', 'comp_type', 'description',\n",
    "                'metric', 'datatype', 'subject', 'problemtype']\n",
    "# TASK_FEATURES = ['ProblemType',\n",
    "#                 'number of columns (for tabular)', 'number of entries',\n",
    "#                 'LabelType', 'Number of classes', 'Loss Function/Metrics',\n",
    "#                 'Target Column(s) Name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET_COLUMN = 'vertex_l2'"
   ]
  },
  {
   "source": [
    "### Grouping chunks by notebooks"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "notebook_id_col = 'kaggle_id'\n",
    "competition_id_col = 'competition_id'\n",
    "def group_by_notebooks(data:pd.DataFrame, vertex_col:str='vertex_l1') -> pd.DataFrame:\n",
    "    notebook_cols = [[notebook_id_col, vertex_col, competition_id_col] + TASK_FEATURES]\n",
    "    df = pd.DataFrame(columns=notebook_cols)\n",
    "    for i, notebook_id in enumerate(data[notebook_id_col].unique()):\n",
    "        notebook = data[data[notebook_id_col] == notebook_id].reset_index(drop=True)\n",
    "        vertices_seq = \" \".join(notebook[vertex_col])\n",
    "        task_features = notebook[TASK_FEATURES].loc[0]\n",
    "        competition_id = notebook[competition_id_col].unique()[0]\n",
    "        row = [notebook_id, vertices_seq, competition_id] + task_features.tolist()\n",
    "        df.loc[i] = row\n",
    "        print('notebook #{} done'.format(notebook_id))\n",
    "    return df"
   ]
  },
  {
   "source": [
    "### Taking Train Features"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "notebook #8591010 done\n",
      "notebook #8592598 done\n",
      "notebook #8596735 done\n",
      "notebook #8606894 done\n",
      "notebook #8609050 done\n",
      "notebook #8611767 done\n",
      "notebook #8630977 done\n",
      "notebook #8634286 done\n",
      "notebook #8640194 done\n",
      "notebook #8660923 done\n",
      "notebook #8667455 done\n",
      "notebook #8668446 done\n",
      "notebook #8678201 done\n",
      "notebook #8687334 done\n",
      "notebook #8689318 done\n",
      "notebook #8699382 done\n",
      "notebook #8705213 done\n",
      "notebook #8706858 done\n",
      "notebook #8708118 done\n",
      "notebook #8710137 done\n",
      "notebook #8710362 done\n",
      "notebook #8604602 done\n",
      "notebook #8617043 done\n",
      "notebook #8620454 done\n",
      "notebook #8625834 done\n",
      "notebook #8628909 done\n",
      "notebook #8658083 done\n",
      "notebook #8663175 done\n",
      "notebook #8671133 done\n",
      "notebook #8679319 done\n",
      "notebook #8682800 done\n",
      "notebook #8687249 done\n",
      "notebook #8693806 done\n",
      "notebook #8701862 done\n",
      "notebook #8702904 done\n",
      "notebook #8706295 done\n",
      "notebook #8711165 done\n",
      "notebook #9326374 done\n",
      "notebook #9349764 done\n",
      "notebook #9463384 done\n",
      "notebook #138832 done\n",
      "notebook #2637869 done\n",
      "notebook #5466844 done\n",
      "notebook #5729566 done\n",
      "notebook #6470191 done\n",
      "notebook #8382140 done\n",
      "notebook #9655329 done\n",
      "notebook #10424951 done\n",
      "notebook #10522332 done\n",
      "notebook #10702707 done\n",
      "notebook #10913030 done\n",
      "notebook #11097956 done\n",
      "notebook #11410370 done\n",
      "notebook #11611498 done\n",
      "notebook #11656525 done\n",
      "notebook #12034947 done\n",
      "notebook #12343159 done\n",
      "notebook #13503938 done\n",
      "notebook #14177670 done\n",
      "notebook #171635 done\n",
      "notebook #2843645 done\n",
      "notebook #2846432 done\n",
      "notebook #2874738 done\n",
      "notebook #2894439 done\n",
      "notebook #2895967 done\n",
      "notebook #2897818 done\n",
      "notebook #2942474 done\n",
      "notebook #3001116 done\n",
      "notebook #3065122 done\n",
      "notebook #3127294 done\n",
      "notebook #3155308 done\n",
      "notebook #3308267 done\n",
      "notebook #3338077 done\n",
      "notebook #3412975 done\n",
      "notebook #3424825 done\n",
      "notebook #3544896 done\n",
      "notebook #3577796 done\n",
      "notebook #3640289 done\n",
      "notebook #3663832 done\n",
      "notebook #11400829 done\n",
      "notebook #24315 done\n",
      "notebook #242408 done\n",
      "notebook #243149 done\n",
      "notebook #244547 done\n",
      "notebook #244742 done\n",
      "notebook #244890 done\n",
      "notebook #244905 done\n",
      "notebook #244962 done\n",
      "notebook #245675 done\n",
      "notebook #874590 done\n",
      "notebook #1140262 done\n",
      "notebook #2095107 done\n",
      "notebook #3237641 done\n",
      "notebook #3674829 done\n",
      "notebook #4029935 done\n",
      "notebook #6511394 done\n",
      "notebook #6511397 done\n",
      "notebook #6511403 done\n",
      "notebook #6511414 done\n",
      "notebook #6511456 done\n",
      "notebook #6511492 done\n",
      "notebook #6518412 done\n",
      "notebook #7004483 done\n",
      "notebook #7465372 done\n",
      "notebook #7859060 done\n",
      "notebook #8648443 done\n",
      "notebook #9904611 done\n",
      "notebook #11013798 done\n",
      "notebook #3389306 done\n",
      "notebook #3414311 done\n",
      "notebook #4374092 done\n",
      "notebook #10307360 done\n",
      "notebook #3344044 done\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(113, 10)"
      ]
     },
     "metadata": {},
     "execution_count": 25
    }
   ],
   "source": [
    "# nl2ml = group_by_notebooks(nl2ml, TARGET_COLUMN)\n",
    "# X, y = train[TASK_FEATURES], train[TARGET_COLUMN]\n",
    "prepared_data = group_by_notebooks(nl2ml, TARGET_COLUMN)\n",
    "prepared_data.shape"
   ]
  },
  {
   "source": [
    "### Converting Dtypes"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def strip_recurrent_vertices(row):\n",
    "    # sequence = row['vertex_l2'].split(' ')\n",
    "    # result = []\n",
    "    # if len(sequence) > 1:\n",
    "    #     last_index = len(sequence) - 1\n",
    "    #     i = 0\n",
    "    #     while i < last_index:\n",
    "    #         # print(sequence[i], sequence[i+1])\n",
    "    #         if sequence[i].strip(' ') != sequence[i+1].strip(' '):\n",
    "    #             # print('not equal')\n",
    "    #             result.append(sequence[i])\n",
    "    #         else:\n",
    "    #             print('equal', sequence[i], sequence[i+1])\n",
    "    #         i =+ 1\n",
    "    # return \" \".join(result)\n",
    "    result = row['vertex_l2'].split(' ')[0] + \" \" + \" \".join([row['vertex_l2'].split(' ')[i] for i in range(1, len(row['vertex_l2'].split(' '))) if (row['vertex_l2'].split(' ')[i-1] != row['vertex_l2'].split(' ')[i])&(row['vertex_l2'].split(' ')[i] != ' ')&(row['vertex_l2'].split(' ')[i] != '')])\n",
    "    if result.split(' ')[1] == ' ':\n",
    "        result.pop(1)\n",
    "        return result\n",
    "    else:\n",
    "        return \" \".join(row['vertex_l2'].split(' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# prepared_data[TARGET_COLUMN] = prepared_data[TARGET_COLUMN].apply(strip_recurrent_vertices, axis=1)\n",
    "# prepared_data[TARGET_COLUMN] = prepared_data[TARGET_COLUMN].apply(lambda x: x.replace(' ', ''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'import_modules import_modules'"
      ]
     },
     "metadata": {},
     "execution_count": 28
    }
   ],
   "source": [
    "prepared_data[TARGET_COLUMN].loc[70]['vertex_l2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "('kaggle_id',)\n",
      "('competition_id',)\n",
      "('comp_name',)\n",
      "('comp_type',)\n",
      "('description',)\n",
      "('metric',)\n",
      "('datatype',)\n",
      "('subject',)\n",
      "('problemtype',)\n"
     ]
    }
   ],
   "source": [
    "cat_encodings = {}\n",
    "for i, col in enumerate(prepared_data):\n",
    "    if col[0] != TARGET_COLUMN:\n",
    "        print(col)\n",
    "        try:\n",
    "            prepared_data[col] =  prepared_data[col].astype('float32')\n",
    "        except:\n",
    "            prepared_data[col] = pd.Categorical(prepared_data[col])\n",
    "            cat_encodings.update({i:dict(enumerate(prepared_data[col].cat.categories))})\n",
    "            prepared_data[col] = prepared_data[col].cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "((54, 7), (59, 7))"
      ]
     },
     "metadata": {},
     "execution_count": 30
    }
   ],
   "source": [
    "competitions = prepared_data[competition_id_col].iloc[:, 0].unique()\n",
    "test_size = 0.25\n",
    "n_test_competitions = round(test_size * len(competitions))\n",
    "test_competitions, train_competitions = competitions[:n_test_competitions], competitions[n_test_competitions:]\n",
    "train = prepared_data[prepared_data['competition_id'].iloc[:, 0].isin(train_competitions)]\n",
    "test = prepared_data[prepared_data['competition_id'].iloc[:, 0].isin(test_competitions)]\n",
    "X_train, y_train = train[TASK_FEATURES], train[TARGET_COLUMN]\n",
    "X_test, y_test = test[TASK_FEATURES], test[TARGET_COLUMN]\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train, X_test, y_train, y_test = train_test_split(prepared_data[TASK_FEATURES], prepared_data[TARGET_COLUMN]\n",
    "#                                                     , test_size=0.25, shuffle=True, random_state=123)\n",
    "# X_train.shape, X_test.shape"
   ]
  },
  {
   "source": [
    "### Target Preprocessing: Encoding Vertices"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "lang = {vertice:i+2 for i, vertice in enumerate(nl2ml[TARGET_COLUMN].unique())} #TODO: save the dict as a local file\n",
    "lang.update({'<start>':1, '<end>':max(lang.values())+1})\n",
    "def encode_vertices(vertices_seq, lang:dict=lang):\n",
    "    # print(vertices_seq[0], type(vertices_seq[0]), vertices_seq[0].split(' '))\n",
    "    try:\n",
    "        encoded = np.append(np.flip(np.array([lang[vertex] for vertex in vertices_seq[0].split(' ')] + [lang['<end>']])), lang['<start>'])\n",
    "        # encoded = np.append(lang['<start>'], np.array([lang[vertex] for vertex in vertices_seq[0].split(' ')] + [lang['<end>']]))\n",
    "    except:\n",
    "        print(vertices_seq[0].split(' '))\n",
    "        raise Exception(\"Can't encode vertices\")\n",
    "    return encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_train.apply(encode_vertices, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X[TARGET_COLUMN] = y.apply(encode_vertices, axis=1)\n",
    "# X.to_csv('../data/nl2ml_train_example.csv', index=False)"
   ]
  },
  {
   "source": [
    "### Target Preprocessing: Padding Sequences"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length_targ, max_length_feat = prepared_data[TARGET_COLUMN].squeeze().str.split(' ').str.len().max() + 2, X_train.values.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train = tf.keras.preprocessing.sequence.pad_sequences(y_train.apply(encode_vertices, axis=1), maxlen=max_length_targ)\n",
    "Y_test = tf.keras.preprocessing.sequence.pad_sequences(y_test.apply(encode_vertices, axis=1), maxlen=max_length_targ)"
   ]
  },
  {
   "source": [
    "### Defining Constants"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_params = {\"Task\": \"train\"\n",
    "            , \"Model\": \"generative task2seq\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features = len(TASK_FEATURES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_params = {\"nrows\":X_train.shape[0]\n",
    "                , \"nfeatures\": n_features}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BUFFER_SIZE = len(input_tensor_train)\n",
    "BATCH_SIZE = 1\n",
    "LR = 0.001\n",
    "STEPS_PER_EPOCH = len(X_train)//BATCH_SIZE\n",
    "embedding_dim = 256\n",
    "gru_units = 512\n",
    "# vocab_inp_size = len(inp_lang.word_index) + 1\n",
    "# vocab_tar_size = len(targ_lang.word_index) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_params = {\"BATCH_SIZE\":BATCH_SIZE\n",
    "                , \"LR\":LR\n",
    "                , \"STEPS_PER_EPOCH\": STEPS_PER_EPOCH\n",
    "                , \"embedding_dim\": embedding_dim\n",
    "                , \"gru_units\": gru_units}"
   ]
  },
  {
   "source": [
    "### Creating tf.Dataset"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = tf.data.Dataset.from_tensor_slices((X_train.values, Y_train))\n",
    "train_dataset = train_dataset.batch(BATCH_SIZE, drop_remainder=True)"
   ]
  },
  {
   "source": [
    "### Building the Model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.Model):\n",
    "  def __init__(self, vocab_size, embedding_dim, dec_units, batch_sz):\n",
    "    super(Decoder, self).__init__()\n",
    "    self.batch_sz = batch_sz\n",
    "    self.dec_units = dec_units\n",
    "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "    # self.hidden_embedding = tf.keras.layers.Embedding(vocab_size, 1)\n",
    "    self.gru = tf.keras.layers.GRU(self.dec_units,\n",
    "                                   return_sequences=True,\n",
    "                                   return_state=True,\n",
    "                                   recurrent_initializer='glorot_uniform')\n",
    "    self.dropout = tf.keras.layers.Dropout(0.2)\n",
    "    self.fc = tf.keras.layers.Dense(vocab_size, activation='sigmoid')\n",
    "    # self.vec_input_layer = tf.keras.layers.InputLayer(input_shape=tf.TensorShape([n_features, 1]), batch_size=(BATCH_SIZE))\n",
    "    self.fc_vec = tf.keras.layers.Dense(dec_units, activation='sigmoid')\n",
    "    # self.fc_seq = tf.keras.layers.Dense(vocab_size, activation='sigmoid')\n",
    "    # used for attention\n",
    "    # self.attention = BahdanauAttention(self.dec_units)\n",
    "\n",
    "  def call(self, x, hidden, vec_input):#, enc_output):\n",
    "    # enc_output shape == (batch_size, max_length, hidden_size)\n",
    "    # context_vector, attention_weights = self.attention(hidden, enc_output)\n",
    "    # attention_weights = tf.ones(x.shape)\n",
    "    # context_vector = tf.ones(x.shape)\n",
    "    # print(\"X Vector has {} type and {} shape\".format(type(x), x.shape))\n",
    "    # print(\"Context Vector has {} type and {} shape\".format(type(context_vector), context_vector.shape))\n",
    "    # print(\"Attention Vector has {} type and {} shape\".format(type(context_vector), context_vector.shape))\n",
    "    # x shape after passing through embedding == (batch_size, 1, embedding_dim)\n",
    "    x = self.embedding(x)\n",
    "    # x = tf.squeeze(self.hidden_embedding(x), axis=-1)\n",
    "    # x shape after concatenation == (batch_size, 1, embedding_dim + hidden_size)\n",
    "    # x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1)\n",
    "\n",
    "    # passing the concatenated vector to the GRU\n",
    "    output, state = self.gru(x, initial_state=hidden)\n",
    "\n",
    "    # output shape == (batch_size * 1, hidden_size)\n",
    "    output = tf.reshape(output, (-1, output.shape[2]))\n",
    "    output = self.dropout(output)\n",
    "    # output shape == (batch_size, vocab)\n",
    "    # vec = self.vec_input_layer(vec_input)\n",
    "    # print(vec)\n",
    "    vec = self.fc_vec(vec_input)\n",
    "    # vec = self.embedding(vec)\n",
    "    concatenated = tf.keras.layers.concatenate([vec, output], axis=1)\n",
    "    x = self.fc(concatenated)\n",
    "    # x = self.fc(output)\n",
    "    return x, state#, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Decoder output shape: (batch_size, vocab size`) (1, 72)\nModel: \"decoder\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nembedding (Embedding)        multiple                  18432     \n_________________________________________________________________\ngru (GRU)                    multiple                  1182720   \n_________________________________________________________________\ndropout (Dropout)            multiple                  0         \n_________________________________________________________________\ndense (Dense)                multiple                  73800     \n_________________________________________________________________\ndense_1 (Dense)              multiple                  4096      \n=================================================================\nTotal params: 1,279,048\nTrainable params: 1,279,048\nNon-trainable params: 0\n_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "decoder = Decoder(len(lang)+2, embedding_dim, gru_units, BATCH_SIZE)\n",
    "sample_hidden = tf.zeros((BATCH_SIZE, gru_units))\n",
    "vec_input = np.ones((1, n_features))\n",
    "sample_decoder_output, state = decoder(tf.random.uniform((BATCH_SIZE, 1))\n",
    "                                          , sample_hidden\n",
    "                                          , vec_input\n",
    "                                          )\n",
    "print ('Decoder output shape: (batch_size, vocab size`) {}'.format(sample_decoder_output.shape))\n",
    "decoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(LR)\n",
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "                  from_logits=True, reduction='none')\n",
    "\n",
    "def loss_function(real, pred):\n",
    "  mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "  loss_ = loss_object(real, pred)\n",
    "\n",
    "  mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "  loss_ *= mask\n",
    "\n",
    "  return tf.reduce_mean(loss_)"
   ]
  },
  {
   "source": [
    "### Model Training or Loading Pre-Trained"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(inp, targ):#, enc_hidden):\n",
    "  loss = 0\n",
    "  # batch_perplexity = 1\n",
    "  with tf.GradientTape() as tape:\n",
    "    # enc_output, enc_hidden = encoder(inp, enc_hidden)\n",
    "\n",
    "    dec_hidden = tf.zeros((BATCH_SIZE, gru_units)) #enc_hidden\n",
    "\n",
    "    dec_input = tf.expand_dims([1] * BATCH_SIZE, 1)\n",
    "    # dec_input = tf.expand_dims(inp, 1)\n",
    "    # Teacher forcing - feeding the target as the next input\n",
    "    for t in range(1, targ.shape[1]): # for each vertex (token) from solution (sequence)\n",
    "      # passing enc_output to the decoder\n",
    "      predictions, dec_hidden = decoder(dec_input, dec_hidden, inp)#, enc_output)\n",
    "      loss += loss_function(targ[:, t], predictions)\n",
    "      # batch_perplexity *= tf.exp(loss)\n",
    "\n",
    "      # using teacher forcing\n",
    "      dec_input = tf.expand_dims(targ[:, t], 1)\n",
    "\n",
    "  batch_loss = (loss / int(targ.shape[1]))\n",
    "  variables = decoder.trainable_variables # + encoder.trainable_variables\n",
    "  gradients = tape.gradient(loss, variables)\n",
    "  optimizer.apply_gradients(zip(gradients, variables))\n",
    "  del inp, targ, gradients, variables\n",
    "  gc.collect()\n",
    "  return batch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_dir = './checkpoints/'\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
    "checkpoint = tf.train.Checkpoint(step=tf.Variable(1)\n",
    "                                , optimizer=optimizer\n",
    "                                # , metrics=perplexity_metric\n",
    "                                #  , encoder=encoder\n",
    "                                 , decoder=decoder)\n",
    "manager = tf.train.CheckpointManager(checkpoint, checkpoint_dir, max_to_keep=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "##TODO: validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if manager.latest_checkpoint:\n",
    "#     print(\"Restored from {}\".format(manager.latest_checkpoint))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# decoder.compile()\n",
    "# tf.saved_model.save(decoder, './checkpoints/model1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1 Batch 0 Loss 0.0066 Perplexity 1.0066\n",
      "Time taken for the epoch 92.43019604682922 sec\n",
      "\n",
      "Epoch 2 Batch 0 Loss 0.0070 Perplexity 1.0070\n",
      "Time taken for the epoch 14.37080979347229 sec\n",
      "\n",
      "Epoch 3 Batch 0 Loss 0.0093 Perplexity 1.0093\n",
      "Time taken for the epoch 14.33758807182312 sec\n",
      "\n",
      "Epoch 4 Batch 0 Loss 0.0060 Perplexity 1.0060\n",
      "Time taken for the epoch 14.438790798187256 sec\n",
      "\n",
      "Epoch 5 Batch 0 Loss 0.0040 Perplexity 1.0040\n",
      "saving\n",
      "saved\n",
      "Time taken for the epoch 14.428794145584106 sec\n",
      "\n",
      "Epoch 6 Batch 0 Loss 0.0043 Perplexity 1.0043\n",
      "Time taken for the epoch 14.792955875396729 sec\n",
      "\n",
      "Epoch 7 Batch 0 Loss 0.0045 Perplexity 1.0045\n",
      "Time taken for the epoch 14.423959255218506 sec\n",
      "\n",
      "Epoch 8 Batch 0 Loss 0.0042 Perplexity 1.0043\n",
      "Time taken for the epoch 14.056589603424072 sec\n",
      "\n",
      "Epoch 9 Batch 0 Loss 0.0046 Perplexity 1.0046\n",
      "Time taken for the epoch 14.034037113189697 sec\n",
      "\n",
      "Epoch 10 Batch 0 Loss 0.0043 Perplexity 1.0043\n",
      "saving\n",
      "saved\n",
      "Time taken for the epoch 14.104783773422241 sec\n",
      "\n",
      "Epoch 11 Batch 0 Loss 0.0045 Perplexity 1.0045\n",
      "Time taken for the epoch 14.333727598190308 sec\n",
      "\n",
      "Epoch 12 Batch 0 Loss 0.0132 Perplexity 1.0132\n",
      "Time taken for the epoch 14.111619234085083 sec\n",
      "\n",
      "Epoch 13 Batch 0 Loss 0.0180 Perplexity 1.0181\n",
      "Time taken for the epoch 14.143007040023804 sec\n",
      "\n",
      "Epoch 14 Batch 0 Loss 0.0064 Perplexity 1.0064\n",
      "Time taken for the epoch 14.181067705154419 sec\n",
      "\n",
      "Epoch 15 Batch 0 Loss 0.0238 Perplexity 1.0241\n",
      "saving\n",
      "saved\n",
      "Time taken for the epoch 14.378930568695068 sec\n",
      "\n",
      "Epoch 16 Batch 0 Loss 0.0054 Perplexity 1.0055\n",
      "Time taken for the epoch 15.032909870147705 sec\n",
      "\n",
      "Epoch 17 Batch 0 Loss 0.0044 Perplexity 1.0044\n",
      "Time taken for the epoch 14.335874795913696 sec\n",
      "\n",
      "Epoch 18 Batch 0 Loss 0.0032 Perplexity 1.0032\n",
      "Time taken for the epoch 15.02111554145813 sec\n",
      "\n",
      "Epoch 19 Batch 0 Loss 0.0124 Perplexity 1.0125\n",
      "Time taken for the epoch 14.456928491592407 sec\n",
      "\n",
      "Epoch 20 Batch 0 Loss 0.0364 Perplexity 1.0371\n",
      "saving\n",
      "saved\n",
      "Time taken for the epoch 14.567332744598389 sec\n",
      "\n",
      "Epoch 21 Batch 0 Loss 0.0059 Perplexity 1.0059\n",
      "Time taken for the epoch 15.70698070526123 sec\n",
      "\n",
      "Epoch 22 Batch 0 Loss 0.0082 Perplexity 1.0082\n",
      "Time taken for the epoch 15.94345736503601 sec\n",
      "\n",
      "Epoch 23 Batch 0 Loss 0.0062 Perplexity 1.0062\n",
      "Time taken for the epoch 15.791593551635742 sec\n",
      "\n",
      "Epoch 24 Batch 0 Loss 0.0053 Perplexity 1.0053\n",
      "Time taken for the epoch 15.074926614761353 sec\n",
      "\n",
      "Epoch 25 Batch 0 Loss 0.0075 Perplexity 1.0076\n",
      "saving\n",
      "saved\n",
      "Time taken for the epoch 15.311810731887817 sec\n",
      "\n",
      "Epoch 26 Batch 0 Loss 0.0061 Perplexity 1.0061\n",
      "Time taken for the epoch 15.82338571548462 sec\n",
      "\n",
      "Epoch 27 Batch 0 Loss 0.0085 Perplexity 1.0085\n",
      "Time taken for the epoch 15.382064580917358 sec\n",
      "\n",
      "Epoch 28 Batch 0 Loss 0.0087 Perplexity 1.0088\n",
      "Time taken for the epoch 14.939785242080688 sec\n",
      "\n",
      "Epoch 29 Batch 0 Loss 0.0104 Perplexity 1.0105\n",
      "Time taken for the epoch 14.932995080947876 sec\n",
      "\n",
      "Epoch 30 Batch 0 Loss 0.0556 Perplexity 1.0572\n",
      "saving\n",
      "saved\n",
      "Time taken for the epoch 15.720003128051758 sec\n",
      "\n",
      "Epoch 31 Batch 0 Loss 0.2195 Perplexity 1.2455\n",
      "Time taken for the epoch 15.733174562454224 sec\n",
      "\n",
      "Epoch 32 Batch 0 Loss 0.2584 Perplexity 1.2949\n",
      "Time taken for the epoch 15.31124496459961 sec\n",
      "\n",
      "Epoch 33 Batch 0 Loss 0.2910 Perplexity 1.3378\n",
      "Time taken for the epoch 15.562487125396729 sec\n",
      "\n",
      "Epoch 34 Batch 0 Loss 0.0961 Perplexity 1.1008\n",
      "Time taken for the epoch 15.308221101760864 sec\n",
      "\n",
      "Epoch 35 Batch 0 Loss 0.2484 Perplexity 1.2819\n",
      "saving\n",
      "saved\n",
      "Time taken for the epoch 16.465179204940796 sec\n",
      "\n",
      "Epoch 36 Batch 0 Loss 0.1447 Perplexity 1.1557\n",
      "Time taken for the epoch 16.053305625915527 sec\n",
      "\n",
      "Epoch 37 Batch 0 Loss 0.0266 Perplexity 1.0269\n",
      "Time taken for the epoch 15.519060850143433 sec\n",
      "\n",
      "Epoch 38 Batch 0 Loss 0.0509 Perplexity 1.0523\n",
      "Time taken for the epoch 15.55443549156189 sec\n",
      "\n",
      "Epoch 39 Batch 0 Loss 0.0122 Perplexity 1.0123\n",
      "Time taken for the epoch 15.526317596435547 sec\n",
      "\n",
      "Epoch 40 Batch 0 Loss 0.0048 Perplexity 1.0048\n",
      "saving\n",
      "saved\n",
      "Time taken for the epoch 15.610240697860718 sec\n",
      "\n",
      "Epoch 41 Batch 0 Loss 0.0045 Perplexity 1.0045\n",
      "Time taken for the epoch 15.862112760543823 sec\n",
      "\n",
      "Epoch 42 Batch 0 Loss 0.0035 Perplexity 1.0035\n",
      "Time taken for the epoch 15.582763195037842 sec\n",
      "\n",
      "Epoch 43 Batch 0 Loss 0.0037 Perplexity 1.0037\n",
      "Time taken for the epoch 16.43893551826477 sec\n",
      "\n",
      "Epoch 44 Batch 0 Loss 0.0032 Perplexity 1.0032\n",
      "Time taken for the epoch 18.033764600753784 sec\n",
      "\n",
      "Epoch 45 Batch 0 Loss 0.0029 Perplexity 1.0029\n",
      "saving\n",
      "saved\n",
      "Time taken for the epoch 16.27432680130005 sec\n",
      "\n",
      "Epoch 46 Batch 0 Loss 0.0030 Perplexity 1.0030\n",
      "Time taken for the epoch 18.93684148788452 sec\n",
      "\n",
      "Epoch 47 Batch 0 Loss 0.0031 Perplexity 1.0031\n",
      "Time taken for the epoch 19.79799175262451 sec\n",
      "\n",
      "Epoch 48 Batch 0 Loss 0.0031 Perplexity 1.0031\n",
      "Time taken for the epoch 18.718939781188965 sec\n",
      "\n",
      "Epoch 49 Batch 0 Loss 0.0033 Perplexity 1.0033\n",
      "Time taken for the epoch 17.318585872650146 sec\n",
      "\n",
      "Epoch 50 Batch 0 Loss 0.0057 Perplexity 1.0057\n",
      "saving\n",
      "saved\n",
      "Time taken for the epoch 17.095429182052612 sec\n",
      "\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x18c664524f0>]"
      ]
     },
     "metadata": {},
     "execution_count": 121
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\r\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\r\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\r\n<!-- Created with matplotlib (https://matplotlib.org/) -->\r\n<svg height=\"248.518125pt\" version=\"1.1\" viewBox=\"0 0 378.465625 248.518125\" width=\"378.465625pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\r\n <metadata>\r\n  <rdf:RDF xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\r\n   <cc:Work>\r\n    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\r\n    <dc:date>2021-05-29T12:14:31.124501</dc:date>\r\n    <dc:format>image/svg+xml</dc:format>\r\n    <dc:creator>\r\n     <cc:Agent>\r\n      <dc:title>Matplotlib v3.3.2, https://matplotlib.org/</dc:title>\r\n     </cc:Agent>\r\n    </dc:creator>\r\n   </cc:Work>\r\n  </rdf:RDF>\r\n </metadata>\r\n <defs>\r\n  <style type=\"text/css\">*{stroke-linecap:butt;stroke-linejoin:round;}</style>\r\n </defs>\r\n <g id=\"figure_1\">\r\n  <g id=\"patch_1\">\r\n   <path d=\"M 0 248.518125 \r\nL 378.465625 248.518125 \r\nL 378.465625 0 \r\nL 0 0 \r\nz\r\n\" style=\"fill:none;\"/>\r\n  </g>\r\n  <g id=\"axes_1\">\r\n   <g id=\"patch_2\">\r\n    <path d=\"M 36.465625 224.64 \r\nL 371.265625 224.64 \r\nL 371.265625 7.2 \r\nL 36.465625 7.2 \r\nz\r\n\" style=\"fill:#ffffff;\"/>\r\n   </g>\r\n   <g id=\"matplotlib.axis_1\">\r\n    <g id=\"xtick_1\">\r\n     <g id=\"line2d_1\">\r\n      <defs>\r\n       <path d=\"M 0 0 \r\nL 0 3.5 \r\n\" id=\"m306dc331a9\" style=\"stroke:#000000;stroke-width:0.8;\"/>\r\n      </defs>\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"51.683807\" xlink:href=\"#m306dc331a9\" y=\"224.64\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_1\">\r\n      <!-- 0 -->\r\n      <g transform=\"translate(48.502557 239.238438)scale(0.1 -0.1)\">\r\n       <defs>\r\n        <path d=\"M 31.78125 66.40625 \r\nQ 24.171875 66.40625 20.328125 58.90625 \r\nQ 16.5 51.421875 16.5 36.375 \r\nQ 16.5 21.390625 20.328125 13.890625 \r\nQ 24.171875 6.390625 31.78125 6.390625 \r\nQ 39.453125 6.390625 43.28125 13.890625 \r\nQ 47.125 21.390625 47.125 36.375 \r\nQ 47.125 51.421875 43.28125 58.90625 \r\nQ 39.453125 66.40625 31.78125 66.40625 \r\nz\r\nM 31.78125 74.21875 \r\nQ 44.046875 74.21875 50.515625 64.515625 \r\nQ 56.984375 54.828125 56.984375 36.375 \r\nQ 56.984375 17.96875 50.515625 8.265625 \r\nQ 44.046875 -1.421875 31.78125 -1.421875 \r\nQ 19.53125 -1.421875 13.0625 8.265625 \r\nQ 6.59375 17.96875 6.59375 36.375 \r\nQ 6.59375 54.828125 13.0625 64.515625 \r\nQ 19.53125 74.21875 31.78125 74.21875 \r\nz\r\n\" id=\"DejaVuSans-48\"/>\r\n       </defs>\r\n       <use xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_2\">\r\n     <g id=\"line2d_2\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"92.537986\" xlink:href=\"#m306dc331a9\" y=\"224.64\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_2\">\r\n      <!-- 20 -->\r\n      <g transform=\"translate(86.175486 239.238438)scale(0.1 -0.1)\">\r\n       <defs>\r\n        <path d=\"M 19.1875 8.296875 \r\nL 53.609375 8.296875 \r\nL 53.609375 0 \r\nL 7.328125 0 \r\nL 7.328125 8.296875 \r\nQ 12.9375 14.109375 22.625 23.890625 \r\nQ 32.328125 33.6875 34.8125 36.53125 \r\nQ 39.546875 41.84375 41.421875 45.53125 \r\nQ 43.3125 49.21875 43.3125 52.78125 \r\nQ 43.3125 58.59375 39.234375 62.25 \r\nQ 35.15625 65.921875 28.609375 65.921875 \r\nQ 23.96875 65.921875 18.8125 64.3125 \r\nQ 13.671875 62.703125 7.8125 59.421875 \r\nL 7.8125 69.390625 \r\nQ 13.765625 71.78125 18.9375 73 \r\nQ 24.125 74.21875 28.421875 74.21875 \r\nQ 39.75 74.21875 46.484375 68.546875 \r\nQ 53.21875 62.890625 53.21875 53.421875 \r\nQ 53.21875 48.921875 51.53125 44.890625 \r\nQ 49.859375 40.875 45.40625 35.40625 \r\nQ 44.1875 33.984375 37.640625 27.21875 \r\nQ 31.109375 20.453125 19.1875 8.296875 \r\nz\r\n\" id=\"DejaVuSans-50\"/>\r\n       </defs>\r\n       <use xlink:href=\"#DejaVuSans-50\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_3\">\r\n     <g id=\"line2d_3\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"133.392166\" xlink:href=\"#m306dc331a9\" y=\"224.64\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_3\">\r\n      <!-- 40 -->\r\n      <g transform=\"translate(127.029666 239.238438)scale(0.1 -0.1)\">\r\n       <defs>\r\n        <path d=\"M 37.796875 64.3125 \r\nL 12.890625 25.390625 \r\nL 37.796875 25.390625 \r\nz\r\nM 35.203125 72.90625 \r\nL 47.609375 72.90625 \r\nL 47.609375 25.390625 \r\nL 58.015625 25.390625 \r\nL 58.015625 17.1875 \r\nL 47.609375 17.1875 \r\nL 47.609375 0 \r\nL 37.796875 0 \r\nL 37.796875 17.1875 \r\nL 4.890625 17.1875 \r\nL 4.890625 26.703125 \r\nz\r\n\" id=\"DejaVuSans-52\"/>\r\n       </defs>\r\n       <use xlink:href=\"#DejaVuSans-52\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_4\">\r\n     <g id=\"line2d_4\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"174.246345\" xlink:href=\"#m306dc331a9\" y=\"224.64\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_4\">\r\n      <!-- 60 -->\r\n      <g transform=\"translate(167.883845 239.238438)scale(0.1 -0.1)\">\r\n       <defs>\r\n        <path d=\"M 33.015625 40.375 \r\nQ 26.375 40.375 22.484375 35.828125 \r\nQ 18.609375 31.296875 18.609375 23.390625 \r\nQ 18.609375 15.53125 22.484375 10.953125 \r\nQ 26.375 6.390625 33.015625 6.390625 \r\nQ 39.65625 6.390625 43.53125 10.953125 \r\nQ 47.40625 15.53125 47.40625 23.390625 \r\nQ 47.40625 31.296875 43.53125 35.828125 \r\nQ 39.65625 40.375 33.015625 40.375 \r\nz\r\nM 52.59375 71.296875 \r\nL 52.59375 62.3125 \r\nQ 48.875 64.0625 45.09375 64.984375 \r\nQ 41.3125 65.921875 37.59375 65.921875 \r\nQ 27.828125 65.921875 22.671875 59.328125 \r\nQ 17.53125 52.734375 16.796875 39.40625 \r\nQ 19.671875 43.65625 24.015625 45.921875 \r\nQ 28.375 48.1875 33.59375 48.1875 \r\nQ 44.578125 48.1875 50.953125 41.515625 \r\nQ 57.328125 34.859375 57.328125 23.390625 \r\nQ 57.328125 12.15625 50.6875 5.359375 \r\nQ 44.046875 -1.421875 33.015625 -1.421875 \r\nQ 20.359375 -1.421875 13.671875 8.265625 \r\nQ 6.984375 17.96875 6.984375 36.375 \r\nQ 6.984375 53.65625 15.1875 63.9375 \r\nQ 23.390625 74.21875 37.203125 74.21875 \r\nQ 40.921875 74.21875 44.703125 73.484375 \r\nQ 48.484375 72.75 52.59375 71.296875 \r\nz\r\n\" id=\"DejaVuSans-54\"/>\r\n       </defs>\r\n       <use xlink:href=\"#DejaVuSans-54\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_5\">\r\n     <g id=\"line2d_5\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"215.100524\" xlink:href=\"#m306dc331a9\" y=\"224.64\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_5\">\r\n      <!-- 80 -->\r\n      <g transform=\"translate(208.738024 239.238438)scale(0.1 -0.1)\">\r\n       <defs>\r\n        <path d=\"M 31.78125 34.625 \r\nQ 24.75 34.625 20.71875 30.859375 \r\nQ 16.703125 27.09375 16.703125 20.515625 \r\nQ 16.703125 13.921875 20.71875 10.15625 \r\nQ 24.75 6.390625 31.78125 6.390625 \r\nQ 38.8125 6.390625 42.859375 10.171875 \r\nQ 46.921875 13.96875 46.921875 20.515625 \r\nQ 46.921875 27.09375 42.890625 30.859375 \r\nQ 38.875 34.625 31.78125 34.625 \r\nz\r\nM 21.921875 38.8125 \r\nQ 15.578125 40.375 12.03125 44.71875 \r\nQ 8.5 49.078125 8.5 55.328125 \r\nQ 8.5 64.0625 14.71875 69.140625 \r\nQ 20.953125 74.21875 31.78125 74.21875 \r\nQ 42.671875 74.21875 48.875 69.140625 \r\nQ 55.078125 64.0625 55.078125 55.328125 \r\nQ 55.078125 49.078125 51.53125 44.71875 \r\nQ 48 40.375 41.703125 38.8125 \r\nQ 48.828125 37.15625 52.796875 32.3125 \r\nQ 56.78125 27.484375 56.78125 20.515625 \r\nQ 56.78125 9.90625 50.3125 4.234375 \r\nQ 43.84375 -1.421875 31.78125 -1.421875 \r\nQ 19.734375 -1.421875 13.25 4.234375 \r\nQ 6.78125 9.90625 6.78125 20.515625 \r\nQ 6.78125 27.484375 10.78125 32.3125 \r\nQ 14.796875 37.15625 21.921875 38.8125 \r\nz\r\nM 18.3125 54.390625 \r\nQ 18.3125 48.734375 21.84375 45.5625 \r\nQ 25.390625 42.390625 31.78125 42.390625 \r\nQ 38.140625 42.390625 41.71875 45.5625 \r\nQ 45.3125 48.734375 45.3125 54.390625 \r\nQ 45.3125 60.0625 41.71875 63.234375 \r\nQ 38.140625 66.40625 31.78125 66.40625 \r\nQ 25.390625 66.40625 21.84375 63.234375 \r\nQ 18.3125 60.0625 18.3125 54.390625 \r\nz\r\n\" id=\"DejaVuSans-56\"/>\r\n       </defs>\r\n       <use xlink:href=\"#DejaVuSans-56\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_6\">\r\n     <g id=\"line2d_6\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"255.954704\" xlink:href=\"#m306dc331a9\" y=\"224.64\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_6\">\r\n      <!-- 100 -->\r\n      <g transform=\"translate(246.410954 239.238438)scale(0.1 -0.1)\">\r\n       <defs>\r\n        <path d=\"M 12.40625 8.296875 \r\nL 28.515625 8.296875 \r\nL 28.515625 63.921875 \r\nL 10.984375 60.40625 \r\nL 10.984375 69.390625 \r\nL 28.421875 72.90625 \r\nL 38.28125 72.90625 \r\nL 38.28125 8.296875 \r\nL 54.390625 8.296875 \r\nL 54.390625 0 \r\nL 12.40625 0 \r\nz\r\n\" id=\"DejaVuSans-49\"/>\r\n       </defs>\r\n       <use xlink:href=\"#DejaVuSans-49\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_7\">\r\n     <g id=\"line2d_7\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"296.808883\" xlink:href=\"#m306dc331a9\" y=\"224.64\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_7\">\r\n      <!-- 120 -->\r\n      <g transform=\"translate(287.265133 239.238438)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-49\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-50\"/>\r\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_8\">\r\n     <g id=\"line2d_8\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"337.663062\" xlink:href=\"#m306dc331a9\" y=\"224.64\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_8\">\r\n      <!-- 140 -->\r\n      <g transform=\"translate(328.119312 239.238438)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-49\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-52\"/>\r\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n   </g>\r\n   <g id=\"matplotlib.axis_2\">\r\n    <g id=\"ytick_1\">\r\n     <g id=\"line2d_9\">\r\n      <defs>\r\n       <path d=\"M 0 0 \r\nL -3.5 0 \r\n\" id=\"md5fb6b1024\" style=\"stroke:#000000;stroke-width:0.8;\"/>\r\n      </defs>\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"36.465625\" xlink:href=\"#md5fb6b1024\" y=\"216.518319\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_9\">\r\n      <!-- 0.00 -->\r\n      <g transform=\"translate(7.2 220.317538)scale(0.1 -0.1)\">\r\n       <defs>\r\n        <path d=\"M 10.6875 12.40625 \r\nL 21 12.40625 \r\nL 21 0 \r\nL 10.6875 0 \r\nz\r\n\" id=\"DejaVuSans-46\"/>\r\n       </defs>\r\n       <use xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\r\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_2\">\r\n     <g id=\"line2d_10\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"36.465625\" xlink:href=\"#md5fb6b1024\" y=\"173.024812\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_10\">\r\n      <!-- 0.05 -->\r\n      <g transform=\"translate(7.2 176.824031)scale(0.1 -0.1)\">\r\n       <defs>\r\n        <path d=\"M 10.796875 72.90625 \r\nL 49.515625 72.90625 \r\nL 49.515625 64.59375 \r\nL 19.828125 64.59375 \r\nL 19.828125 46.734375 \r\nQ 21.96875 47.46875 24.109375 47.828125 \r\nQ 26.265625 48.1875 28.421875 48.1875 \r\nQ 40.625 48.1875 47.75 41.5 \r\nQ 54.890625 34.8125 54.890625 23.390625 \r\nQ 54.890625 11.625 47.5625 5.09375 \r\nQ 40.234375 -1.421875 26.90625 -1.421875 \r\nQ 22.3125 -1.421875 17.546875 -0.640625 \r\nQ 12.796875 0.140625 7.71875 1.703125 \r\nL 7.71875 11.625 \r\nQ 12.109375 9.234375 16.796875 8.0625 \r\nQ 21.484375 6.890625 26.703125 6.890625 \r\nQ 35.15625 6.890625 40.078125 11.328125 \r\nQ 45.015625 15.765625 45.015625 23.390625 \r\nQ 45.015625 31 40.078125 35.4375 \r\nQ 35.15625 39.890625 26.703125 39.890625 \r\nQ 22.75 39.890625 18.8125 39.015625 \r\nQ 14.890625 38.140625 10.796875 36.28125 \r\nz\r\n\" id=\"DejaVuSans-53\"/>\r\n       </defs>\r\n       <use xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\r\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-53\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_3\">\r\n     <g id=\"line2d_11\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"36.465625\" xlink:href=\"#md5fb6b1024\" y=\"129.531305\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_11\">\r\n      <!-- 0.10 -->\r\n      <g transform=\"translate(7.2 133.330524)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\r\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-49\"/>\r\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_4\">\r\n     <g id=\"line2d_12\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"36.465625\" xlink:href=\"#md5fb6b1024\" y=\"86.037798\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_12\">\r\n      <!-- 0.15 -->\r\n      <g transform=\"translate(7.2 89.837017)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\r\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-49\"/>\r\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-53\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_5\">\r\n     <g id=\"line2d_13\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"36.465625\" xlink:href=\"#md5fb6b1024\" y=\"42.544291\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_13\">\r\n      <!-- 0.20 -->\r\n      <g transform=\"translate(7.2 46.34351)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\r\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-50\"/>\r\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n   </g>\r\n   <g id=\"line2d_14\">\r\n    <path clip-path=\"url(#pdcb32814eb)\" d=\"M 51.683807 17.083636 \r\nL 53.726516 52.352095 \r\nL 55.769225 82.141562 \r\nL 57.811934 75.140356 \r\nL 59.854643 79.798408 \r\nL 61.897352 76.969616 \r\nL 63.940061 72.582304 \r\nL 65.98277 84.354409 \r\nL 68.025479 63.718966 \r\nL 70.068188 85.319046 \r\nL 72.110897 87.330682 \r\nL 74.153605 87.963854 \r\nL 76.196314 108.79468 \r\nL 78.239023 131.562857 \r\nL 80.281732 133.761834 \r\nL 82.324441 137.569722 \r\nL 84.36715 146.450759 \r\nL 86.409859 158.623885 \r\nL 88.452568 162.241243 \r\nL 90.495277 168.228915 \r\nL 92.537986 174.836369 \r\nL 94.580695 181.939628 \r\nL 96.623404 171.677715 \r\nL 98.666113 186.452443 \r\nL 100.708822 178.528804 \r\nL 102.751531 184.076358 \r\nL 104.79424 185.51324 \r\nL 106.836949 185.747357 \r\nL 108.879658 185.700921 \r\nL 110.922367 187.059758 \r\nL 112.965076 186.975514 \r\nL 117.050494 187.316307 \r\nL 119.093203 188.021255 \r\nL 121.135912 187.466786 \r\nL 123.178621 189.653315 \r\nL 125.22133 187.509898 \r\nL 127.264039 189.220021 \r\nL 129.306748 188.80946 \r\nL 131.349457 190.778451 \r\nL 133.392166 189.267899 \r\nL 135.434875 189.970658 \r\nL 137.477584 192.207967 \r\nL 139.520292 192.068812 \r\nL 141.563001 192.472729 \r\nL 143.60571 184.647467 \r\nL 145.648419 185.835046 \r\nL 147.691128 189.729025 \r\nL 149.733837 190.281402 \r\nL 151.776546 184.955757 \r\nL 153.819255 185.967418 \r\nL 155.861964 189.924018 \r\nL 157.904673 185.248664 \r\nL 159.947382 192.144801 \r\nL 161.990091 189.426464 \r\nL 164.0328 189.685912 \r\nL 166.075509 190.454804 \r\nL 168.118218 191.537538 \r\nL 170.160927 194.07594 \r\nL 172.203636 194.529277 \r\nL 174.246345 192.998153 \r\nL 176.289054 196.009035 \r\nL 178.331763 195.352915 \r\nL 180.374472 196.111591 \r\nL 182.417181 195.343298 \r\nL 184.45989 196.822707 \r\nL 186.502599 190.428899 \r\nL 188.545308 195.105762 \r\nL 192.630726 186.222985 \r\nL 194.673435 200.024584 \r\nL 196.716144 192.490112 \r\nL 198.758853 196.374404 \r\nL 200.801562 196.898406 \r\nL 202.844271 197.584415 \r\nL 204.886979 198.028984 \r\nL 206.929688 198.944636 \r\nL 208.972397 199.330527 \r\nL 211.015106 196.545403 \r\nL 213.057815 197.496304 \r\nL 215.100524 199.359382 \r\nL 217.143233 201.934881 \r\nL 219.185942 201.000035 \r\nL 221.228651 184.21257 \r\nL 223.27136 189.273479 \r\nL 225.314069 192.473301 \r\nL 227.356778 199.596972 \r\nL 229.399487 199.119407 \r\nL 231.442196 200.295872 \r\nL 233.484905 200.881975 \r\nL 235.527614 201.221888 \r\nL 237.570323 202.300326 \r\nL 239.613032 202.322104 \r\nL 241.655741 203.914125 \r\nL 245.741159 204.430461 \r\nL 247.783868 205.023999 \r\nL 249.826577 204.495515 \r\nL 251.869286 207.50866 \r\nL 253.911995 206.029265 \r\nL 255.954704 207.378654 \r\nL 260.040122 208.107419 \r\nL 262.082831 209.898159 \r\nL 264.12554 209.574566 \r\nL 266.168249 208.889268 \r\nL 268.210958 211.042362 \r\nL 270.253666 210.284255 \r\nL 272.296375 212.5746 \r\nL 274.339084 211.458029 \r\nL 278.424502 212.1491 \r\nL 280.467211 210.253632 \r\nL 282.50992 212.253257 \r\nL 284.552629 211.749253 \r\nL 286.595338 212.531025 \r\nL 288.638047 213.754476 \r\nL 292.723465 213.279164 \r\nL 294.766174 210.694799 \r\nL 296.808883 210.934155 \r\nL 298.851592 210.456846 \r\nL 300.894301 210.119812 \r\nL 302.93701 211.576839 \r\nL 304.979719 212.773251 \r\nL 307.022428 213.755717 \r\nL 309.065137 209.240358 \r\nL 311.107846 209.606831 \r\nL 313.150555 211.811268 \r\nL 315.193264 211.339895 \r\nL 317.235973 190.238723 \r\nL 319.278682 200.059627 \r\nL 321.321391 212.302069 \r\nL 323.3641 209.063927 \r\nL 325.406809 208.082817 \r\nL 329.492227 210.954074 \r\nL 331.534936 209.706 \r\nL 333.577645 211.280123 \r\nL 335.620353 212.540616 \r\nL 337.663062 213.132706 \r\nL 343.791189 213.729693 \r\nL 345.833898 214.34863 \r\nL 347.876607 214.300958 \r\nL 349.919316 214.630232 \r\nL 351.962025 214.403747 \r\nL 354.004734 214.756364 \r\nL 356.047443 213.041442 \r\nL 356.047443 213.041442 \r\n\" style=\"fill:none;stroke:#1f77b4;stroke-linecap:square;stroke-width:1.5;\"/>\r\n   </g>\r\n   <g id=\"patch_3\">\r\n    <path d=\"M 36.465625 224.64 \r\nL 36.465625 7.2 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_4\">\r\n    <path d=\"M 371.265625 224.64 \r\nL 371.265625 7.2 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_5\">\r\n    <path d=\"M 36.465625 224.64 \r\nL 371.265625 224.64 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_6\">\r\n    <path d=\"M 36.465625 7.2 \r\nL 371.265625 7.2 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n  </g>\r\n </g>\r\n <defs>\r\n  <clipPath id=\"pdcb32814eb\">\r\n   <rect height=\"217.44\" width=\"334.8\" x=\"36.465625\" y=\"7.2\"/>\r\n  </clipPath>\r\n </defs>\r\n</svg>\r\n",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "source": [
    "EPOCHS = 50\n",
    "for epoch in range(EPOCHS):\n",
    "    gc.collect()\n",
    "    start = time.time()\n",
    "    # enc_hidden = encoder.initialize_hidden_state()\n",
    "    total_loss = 0\n",
    "    total_batch_perplexity = 0\n",
    "    for (batch, (feat, targ)) in enumerate(train_dataset.take(STEPS_PER_EPOCH)):\n",
    "        # print ('Features: {}, Target: {}'.format(feat, targ))\n",
    "        batch_loss = train_step(feat, targ)#, enc_hidden)\n",
    "        batch_perplexity = tf.exp(batch_loss)\n",
    "\n",
    "        total_loss += batch_loss\n",
    "        total_batch_perplexity += batch_perplexity #perplexity_metric.result()\n",
    "        if batch % 100 == 0:\n",
    "            print('Epoch {} Batch {} Loss {:.4f}'.format(epoch + 1,\n",
    "                                                            batch,\n",
    "                                                            batch_loss.numpy()), end=' ')\n",
    "            print('Perplexity {:.4f}'.format(batch_perplexity))\n",
    "    train_losses.append(batch_loss)\n",
    "    if (epoch + 1) % 5 == 0:\n",
    "        print('saving')\n",
    "        # checkpoint.write(file_prefix=checkpoint_prefix)\n",
    "        checkpoint.step.assign_add(5)\n",
    "        manager.save()\n",
    "        print('saved')\n",
    "    print('Time taken for the epoch {} sec\\n'.format(time.time() - start))\n",
    "plt.plot(train_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))"
   ]
  },
  {
   "source": [
    "### Sequence Generation"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_task(task_vector):\n",
    "    # either convert to float32 or encode to categoricals\n",
    "    for i, el in enumerate(task_vector):\n",
    "        try:\n",
    "            task_vector[i] = float(task_vector[i])\n",
    "        except:\n",
    "            task_vector[i] = get_key(cat_encodings[i], task_vector[i])\n",
    "    return task_vector.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_solution(task_vector, save_outputs:bool=False):\n",
    "  attention_plot = np.zeros((max_length_targ, max_length_feat))\n",
    "  task_vector = preprocess_task(task_vector)\n",
    "  inputs = tf.expand_dims(tf.convert_to_tensor(task_vector), axis=0)\n",
    "  result = ''\n",
    "\n",
    "  dec_hidden = tf.zeros((BATCH_SIZE, gru_units))\n",
    "  dec_input = tf.expand_dims([1], 0)\n",
    "  loss = 0\n",
    "  for t in range(max_length_targ):\n",
    "    predictions, dec_hidden = decoder(dec_input\n",
    "                                      , dec_hidden\n",
    "                                      , inputs)\n",
    "    # storing the attention weights to plot later on\n",
    "    # attention_weights = tf.reshape(attention_weights, (-1, ))\n",
    "    # attention_plot[t] = attention_weights.numpy()\n",
    "    predicted_id = tf.argmax(predictions[0]).numpy()\n",
    "    predicted_vertice = get_key(lang, predicted_id)\n",
    "    if (predicted_vertice != ' ')&(predicted_vertice != ''):\n",
    "      # loss += loss_function(true_vector, predictions)\n",
    "      # print(loss)\n",
    "      result = predicted_vertice + ' ' + result #targ_lang.index_word[predicted_id] + ' '\n",
    "    elif (predicted_vertice == '<start>')&(predicted_vertice == '<end>'):\n",
    "      print('Evaluation: found start/end, ending')\n",
    "      return result, task_vector#, attention_plot\n",
    "    \n",
    "    # the predicted ID is fed back into the model\n",
    "    dec_input = tf.expand_dims([predicted_id], 0)\n",
    "  if save_outputs:\n",
    "    OUTPUT_FILE = './task2seq/outputs/output.py'\n",
    "    with open(OUTPUT_FILE, 'w') as f:\n",
    "        last_vertice = ''\n",
    "        for vertice in result.split(' '):\n",
    "            if vertice:\n",
    "                if (vertice!='<start>')&(vertice!='<end>')&(vertice!=last_vertice):\n",
    "                    line = '#@ {} \\n\\n'.format(vertice)\n",
    "                    f.write(line)\n",
    "                    last_vertice = vertice\n",
    "  return result, task_vector#, attention_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# i = 0\n",
    "# example_task_vector = X_test.reset_index(drop=True).loc[i]\n",
    "# example_true_vector = Y_test[i]\n",
    "# example_true_sequence = y_test.loc[i][0]\n",
    "# print('task vector: {} \\n'.format(example_task_vector.values))\n",
    "# print('true sequence is: {}\\n'.format(example_true_sequence))\n",
    "# result, task_vector = generate_solution(example_task_vector)\n",
    "# print(result, '\\n')\n",
    "# print('length of the result sequence is: {} \\n'.format(len(result.split(' '))))"
   ]
  },
  {
   "source": [
    "### Model Evaluation"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rouge_recall(true_string_vector:list, predicted_string_vector:list) -> float:\n",
    "    n_overlapping_words = len(set(true_string_vector).intersection(set(predicted_string_vector)))\n",
    "    total_words_in_output = len(predicted_string_vector)\n",
    "    return n_overlapping_words / total_words_in_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rouge_precision(true_string_vector:list, predicted_string_vector:list) -> float:\n",
    "    n_overlapping_words = len(set(true_string_vector).intersection(set(predicted_string_vector)))\n",
    "    total_words_in_reference = len(true_string_vector)\n",
    "    return n_overlapping_words / total_words_in_reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_generated_sequence(generated_sequence_string:str, output_path:str):\n",
    "    # OUTPUT_FILE = './task2seq/outputs/output.py'\n",
    "    with open(output_path, 'w') as f:\n",
    "        last_vertice = ''\n",
    "        for vertice in generated_sequence_string.split(' '):\n",
    "            if vertice:\n",
    "                if (vertice!='<start>')&(vertice!='<end>')&(vertice!=last_vertice):\n",
    "                    line = '#@ {} \\n\\n'.format(vertice)\n",
    "                    f.write(line)\n",
    "                    last_vertice = vertice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_solution_with_evaluation(task_vector, true_sequence:np.array, save_outputs:bool=False):\n",
    "  task_vector = preprocess_task(task_vector)\n",
    "  inputs = tf.expand_dims(tf.convert_to_tensor(task_vector), axis=0)\n",
    "  generated_sequence_string = ''\n",
    "  generated_sequence_array = []\n",
    "  metrics = {}\n",
    "\n",
    "  dec_hidden = tf.zeros((BATCH_SIZE, gru_units))\n",
    "  dec_input = tf.expand_dims([1], 0)\n",
    "  loss = 0\n",
    "  for t in range(max_length_targ):\n",
    "    predictions, dec_hidden = decoder(dec_input\n",
    "                                      , dec_hidden\n",
    "                                      , inputs)\n",
    "    predicted_id = tf.argmax(predictions[0]).numpy()\n",
    "    generated_sequence_array.append(predicted_id)\n",
    "\n",
    "    predicted_vertice = get_key(lang, predicted_id)\n",
    "    if (predicted_vertice != ' ')&(predicted_vertice != ''):\n",
    "        loss += loss_function(true_sequence[t], predictions)\n",
    "        generated_sequence_string = predicted_vertice + ' ' + generated_sequence_string\n",
    "    elif (predicted_vertice == '<start>')&(predicted_vertice == '<end>'):\n",
    "        print('Evaluation: found start/end, ending')\n",
    "        return generated_sequence_string, metrics\n",
    "\n",
    "    dec_input = tf.expand_dims([predicted_id], 0)\n",
    "  metrics.update({\"Cross-Entropy\":loss.numpy(),\n",
    "                \"Perplexity\":tf.exp(loss).numpy(),\n",
    "                \"ROUGE-Recall\":rouge_recall(true_sequence, generated_sequence_array),\n",
    "                \"ROUGE-Precision\": rouge_precision(true_sequence, generated_sequence_array)})\n",
    "  if save_outputs:\n",
    "      TODAY_NOW = datetime.now().strftime(\"%d-%m-%y_%H-%M\")\n",
    "      save_generated_sequence(generated_sequence_string, output_path='./outputs/output_{}.py'.format(TODAY_NOW))\n",
    "  return generated_sequence_string, metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# i = 0\n",
    "# example_task_vector = X_test.reset_index(drop=True).loc[i]\n",
    "# example_true_vector = Y_test[i]\n",
    "# example_true_sequence = y_test.loc[i][0]\n",
    "# print('task vector: {} \\n'.format(example_task_vector.values))\n",
    "# print('true sequence is: {}\\n'.format(example_true_sequence))\n",
    "# result, metrics = generate_solution_with_evaluation(example_task_vector, example_true_vector, save_outputs=True)\n",
    "# print('predicted sequence is: {}\\n'.format(result))\n",
    "# print('predicted unique sequence is: {}\\n'.format(\" \".join(list(set(result.split(' ')))))) #[el for i, el in enumerate(result.split(' ')) if result.split(' ')[i-1] != el])\n",
    "# print('length of the result sequence is: {} \\n'.format(len(result.split(' '))))\n",
    "# print('Metrics:', metrics)"
   ]
  },
  {
   "source": [],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_on_test(X_test, Y_test):\n",
    "    y_pred = []\n",
    "    losses_ce = []\n",
    "    rouge_recalls = []\n",
    "    rouge_precisions = []\n",
    "    print('predicting..', end=' ')\n",
    "    for i, task_vector in X_test.reset_index(drop=True).iterrows():\n",
    "        print('{:.2%}'.format(i/X_test.shape[0]), end=' ')\n",
    "        true_vector = Y_test[i]\n",
    "        result, metrics = generate_solution_with_evaluation(task_vector, true_vector)\n",
    "        # print(loss.numpy())\n",
    "        y_pred.append(result[:-1])\n",
    "        losses_ce.append(metrics['Cross-Entropy'])\n",
    "        rouge_recalls.append(metrics['ROUGE-Recall'])\n",
    "        rouge_precisions.append(metrics['ROUGE-Precision'])\n",
    "    y_pred = pd.DataFrame(y_pred, columns=[TARGET_COLUMN])\n",
    "    print('Cross-Entropy: {}'.format(np.mean(losses_ce)))\n",
    "    print('Perplexity: {}'.format(np.mean(np.exp(losses_ce))))\n",
    "    print('ROUGE-Recall: {}'.format(np.mean(rouge_recalls)))\n",
    "    print('ROUGE-Precision: {}'.format(np.mean(rouge_precisions)))\n",
    "    print('Unique answers: {}'.format(y_pred[TARGET_COLUMN].nunique()))\n",
    "    return y_pred, losses_ce, rouge_recalls, rouge_precisions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "predicting.. 0.00% 1.85% 3.70% 5.56% 7.41% 9.26% 11.11% 12.96% 14.81% 16.67% 18.52% 20.37% 22.22% 24.07% 25.93% 27.78% 29.63% 31.48% 33.33% 35.19% 37.04% 38.89% 40.74% 42.59% 44.44% 46.30% 48.15% 50.00% 51.85% 53.70% 55.56% 57.41% 59.26% 61.11% 62.96% 64.81% 66.67% 68.52% 70.37% 72.22% 74.07% 75.93% 77.78% 79.63% 81.48% 83.33% 85.19% 87.04% 88.89% 90.74% 92.59% 94.44% 96.30% 98.15% Cross-Entropy: 403.538330078125\n",
      "ROUGE-Recall: 0.08205619412515965\n",
      "ROUGE-Precision: 0.08205619412515965\n",
      "Unique answers: 5\n"
     ]
    }
   ],
   "source": [
    "## Predict on Train\n",
    "predict_on_test(X_train[TASK_FEATURES], Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "predicting.. 0.00% 1.69% 3.39% 5.08% 6.78% 8.47% 10.17% 11.86% 13.56% 15.25% 16.95% 18.64% 20.34% 22.03% 23.73% 25.42% 27.12% 28.81% 30.51% 32.20% 33.90% 35.59% 37.29% 38.98% 40.68% 42.37% 44.07% 45.76% 47.46% 49.15% 50.85% 52.54% 54.24% 55.93% 57.63% 59.32% 61.02% 62.71% 64.41% 66.10% 67.80% 69.49% 71.19% 72.88% 74.58% 76.27% 77.97% 79.66% 81.36% 83.05% 84.75% 86.44% 88.14% 89.83% 91.53% 93.22% 94.92% 96.61% 98.31% Cross-Entropy: 403.538330078125\n",
      "Unique answers: 2\n"
     ]
    }
   ],
   "source": [
    "## Predict on Test\n",
    "predict_on_test(X_test[TASK_FEATURES], Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred[TARGET_COLUMN].unique()"
   ]
  },
  {
   "source": [
    "---\n",
    "## To Do"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##TODO: To py and argparse"
   ]
  },
  {
   "source": [
    "### To DAGsHub"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##TODO: Export to DAGsHub\n",
    "experiment_params = run_params.update(model_params).update(data_params)\n",
    "print(experiment_params)\n",
    "# experiment_results = {}"
   ]
  }
 ]
}