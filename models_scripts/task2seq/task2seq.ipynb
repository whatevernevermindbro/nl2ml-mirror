{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python385jvsc74a57bd0d0ddd292140de7144a2e52e7cfaaa287bc93c7991ea231311f4a8d4f39ae4756",
   "display_name": "Python 3.8.5 64-bit ('base': conda)"
  },
  "metadata": {
   "interpreter": {
    "hash": "0de36b31320ba4c88b4f85a74724f3d16c36a44df48581253710b1065e752d9e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import gc\n",
    "from datetime import datetime\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import backend as K\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import log_loss\n",
    "from sqlalchemy import create_engine\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('mode.chained_assignment', None)"
   ]
  },
  {
   "source": [
    "### Defining Methods"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_key(my_dict, val):\n",
    "    for key, value in my_dict.items():\n",
    "         if val == value:\n",
    "             return key\n",
    " \n",
    "    return \"key doesn't exist\""
   ]
  },
  {
   "source": [
    "### Reading Data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "---"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Index(['graph_vertex_id', 'graph_vertex', 'graph_vertex_subclass'], dtype='object')"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "graph_path = '../../data/actual_graph_2021-05-22.csv'\n",
    "graph = pd.read_csv(graph_path)\n",
    "graph.rename({'id':'graph_vertex_id'}, axis=1, inplace=True)\n",
    "graph.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(266, 8)"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "COMPETITIONS_PATH = \"../../data/competitions_info_cleaned_filled.csv\" #./data/competitions_info_cleaned.csv\n",
    "competitions_filled = pd.read_csv(COMPETITIONS_PATH)\n",
    "competitions_filled.drop_duplicates(inplace=True)\n",
    "competitions_filled.rename({'Description': 'description', 'Metric':'metric', 'DataType':'datatype', 'Subject':'subject', 'ProblemType':'problemtype'}\n",
    "                        , axis=1, inplace=True)\n",
    "competitions_filled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "ref             0\n",
       "comp_name       0\n",
       "comp_type       0\n",
       "description    21\n",
       "metric         19\n",
       "datatype       19\n",
       "subject        19\n",
       "problemtype    19\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "competitions_filled.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "competitions_filled['ref'] = competitions_filled['ref'].str.replace(\"'\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(5060, 10)"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "COMPETITIONS_PATH = \"../../data/competitions_2021-05-22.csv\" #./data/competitions_info_cleaned.csv\n",
    "competitions = pd.read_csv(COMPETITIONS_PATH)\n",
    "competitions.drop_duplicates(inplace=True)\n",
    "competitions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# competitions['ref'] = competitions['ref'].apply(lambda x: x.split(',')[0])\n",
    "# competitions['ref'] = competitions['ref'].str.replace(\"'\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# competitions['exists_in_comp_filled'] = competitions.apply(lambda x: x['ref'] in competitions_filled['ref'].unique(), axis=1)\n",
    "# competitions['exists_in_comp_filled'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# competitions_filled.merge(competitions[['id', 'ref']], on=['ref']).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(312, 10)"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "competitions = competitions_filled.merge(competitions[['id', 'ref_link']], how='inner', left_on=['ref'], right_on=['ref_link'])\n",
    "competitions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "ref             0\n",
       "comp_name       0\n",
       "comp_type       0\n",
       "description    26\n",
       "metric         23\n",
       "datatype       23\n",
       "subject        23\n",
       "problemtype    23\n",
       "id              0\n",
       "ref_link        0\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "competitions.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   code_block_id                                         code_block  \\\n",
       "0         570367  `# My forecasting COVID-19 confirmed cases and...   \n",
       "1         570367  `# My forecasting COVID-19 confirmed cases and...   \n",
       "2         570368  `# load training and testing data \\nsubm = pd....   \n",
       "3         570369                                             `subm`   \n",
       "4         570367  `# My forecasting COVID-19 confirmed cases and...   \n",
       "\n",
       "  data_format  graph_vertex_id errors  marks  kaggle_id  competition_id  \n",
       "0       Table               45     No      2    8591010            3868  \n",
       "1       Table               45     No      2    8591010            3868  \n",
       "2       Table               45     No      5    8591010            3868  \n",
       "3       Table               41     No      5    8591010            3868  \n",
       "4       Table               45     No      2    8591010            3868  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>code_block_id</th>\n      <th>code_block</th>\n      <th>data_format</th>\n      <th>graph_vertex_id</th>\n      <th>errors</th>\n      <th>marks</th>\n      <th>kaggle_id</th>\n      <th>competition_id</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>570367</td>\n      <td>`# My forecasting COVID-19 confirmed cases and...</td>\n      <td>Table</td>\n      <td>45</td>\n      <td>No</td>\n      <td>2</td>\n      <td>8591010</td>\n      <td>3868</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>570367</td>\n      <td>`# My forecasting COVID-19 confirmed cases and...</td>\n      <td>Table</td>\n      <td>45</td>\n      <td>No</td>\n      <td>2</td>\n      <td>8591010</td>\n      <td>3868</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>570368</td>\n      <td>`# load training and testing data \\nsubm = pd....</td>\n      <td>Table</td>\n      <td>45</td>\n      <td>No</td>\n      <td>5</td>\n      <td>8591010</td>\n      <td>3868</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>570369</td>\n      <td>`subm`</td>\n      <td>Table</td>\n      <td>41</td>\n      <td>No</td>\n      <td>5</td>\n      <td>8591010</td>\n      <td>3868</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>570367</td>\n      <td>`# My forecasting COVID-19 confirmed cases and...</td>\n      <td>Table</td>\n      <td>45</td>\n      <td>No</td>\n      <td>2</td>\n      <td>8591010</td>\n      <td>3868</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "NOTEBOOKS_PATH = '../../data/markup_data_2021-05-22.csv'\n",
    "notebooks = pd.read_csv(NOTEBOOKS_PATH)\n",
    "notebooks.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(5932, 10)"
      ]
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "source": [
    "notebooks = notebooks.merge(graph, on='graph_vertex_id', how='left')\n",
    "notebooks.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "3207\n3110\n"
     ]
    }
   ],
   "source": [
    "nl2ml = notebooks.merge(competitions, left_on=['competition_id'], right_on=['id'], how='inner')\n",
    "print(nl2ml.shape[0])\n",
    "nl2ml.drop_duplicates(inplace=True, subset=['code_block_id', 'kaggle_id'])\n",
    "print(nl2ml.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "113 7\n"
     ]
    }
   ],
   "source": [
    "print(nl2ml['kaggle_id'].nunique(), nl2ml['competition_id'].nunique())"
   ]
  },
  {
   "source": [
    "### Vertices Preprocessing"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Data_Transform          936\n",
       "EDA                     747\n",
       "Model_Train             287\n",
       "Visualization           281\n",
       "Environment             202\n",
       "Data_Extraction         167\n",
       "Other                   147\n",
       "Hyperparam_Tuning       120\n",
       "Data_Export             104\n",
       "Model_Evaluation         95\n",
       "Model_Interpretation     21\n",
       "Hypothesis                3\n",
       "Name: graph_vertex, dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "source": [
    "nl2ml['graph_vertex'].apply(lambda x: x.split(';')[0].split('.')[0]).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Index(['code_block_id', 'code_block', 'data_format', 'graph_vertex_id',\n",
       "       'errors', 'marks', 'kaggle_id', 'competition_id', 'graph_vertex',\n",
       "       'graph_vertex_subclass', 'ref', 'comp_name', 'comp_type', 'description',\n",
       "       'metric', 'datatype', 'subject', 'problemtype', 'id', 'ref_link'],\n",
       "      dtype='object')"
      ]
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "source": [
    "nl2ml.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "nl2ml['vertex_l1'], nl2ml['vertex_l2'] = nl2ml['graph_vertex'].apply(lambda x: x.split(';')[0].split('.')[0]), nl2ml['graph_vertex_subclass']#.apply(lambda x: x.split(';')[0].split('.')[1])"
   ]
  },
  {
   "source": [
    "### Missing Values"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "code_block_id            0\ncode_block               0\ndata_format              0\ngraph_vertex_id          0\nerrors                   0\nmarks                    0\nkaggle_id                0\ncompetition_id           0\ngraph_vertex             0\ngraph_vertex_subclass    0\nref                      0\ncomp_name                0\ncomp_type                0\ndescription              0\nmetric                   0\ndatatype                 0\nsubject                  0\nproblemtype              0\nid                       0\nref_link                 0\nvertex_l1                0\nvertex_l2                0\ndtype: int64\ncode_block_id            0\ncode_block               0\ndata_format              0\ngraph_vertex_id          0\nerrors                   0\nmarks                    0\nkaggle_id                0\ncompetition_id           0\ngraph_vertex             0\ngraph_vertex_subclass    0\nref                      0\ncomp_name                0\ncomp_type                0\ndescription              0\nmetric                   0\ndatatype                 0\nsubject                  0\nproblemtype              0\nid                       0\nref_link                 0\nvertex_l1                0\nvertex_l2                0\ndtype: int64\n"
     ]
    }
   ],
   "source": [
    "nl2ml.replace('-', -1, inplace=True)\n",
    "print(nl2ml.isna().sum())\n",
    "nl2ml.fillna(-1, inplace=True)\n",
    "print(nl2ml.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "TASK_FEATURES = ['comp_name', 'comp_type', 'description',\n",
    "                'metric', 'datatype', 'subject', 'problemtype']\n",
    "# TASK_FEATURES = ['ProblemType',\n",
    "#                 'number of columns (for tabular)', 'number of entries',\n",
    "#                 'LabelType', 'Number of classes', 'Loss Function/Metrics',\n",
    "#                 'Target Column(s) Name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET_COLUMN = 'vertex_l2'"
   ]
  },
  {
   "source": [
    "### Grouping chunks by notebooks"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "notebook_id_col = 'kaggle_id'\n",
    "competition_id_col = 'competition_id'\n",
    "def group_by_notebooks(data:pd.DataFrame, vertex_col:str='vertex_l1') -> pd.DataFrame:\n",
    "    notebook_cols = [[notebook_id_col, vertex_col, competition_id_col] + TASK_FEATURES]\n",
    "    df = pd.DataFrame(columns=notebook_cols)\n",
    "    for i, notebook_id in enumerate(data[notebook_id_col].unique()):\n",
    "        notebook = data[data[notebook_id_col] == notebook_id].reset_index(drop=True)\n",
    "        vertices_seq = \" \".join(notebook[vertex_col])\n",
    "        task_features = notebook[TASK_FEATURES].loc[0]\n",
    "        competition_id = notebook[competition_id_col].unique()[0]\n",
    "        row = [notebook_id, vertices_seq, competition_id] + task_features.tolist()\n",
    "        df.loc[i] = row\n",
    "        print('notebook #{} done'.format(notebook_id))\n",
    "    return df"
   ]
  },
  {
   "source": [
    "### Taking Train Features"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "notebook #8591010 done\n",
      "notebook #8592598 done\n",
      "notebook #8596735 done\n",
      "notebook #8606894 done\n",
      "notebook #8609050 done\n",
      "notebook #8611767 done\n",
      "notebook #8630977 done\n",
      "notebook #8634286 done\n",
      "notebook #8640194 done\n",
      "notebook #8660923 done\n",
      "notebook #8667455 done\n",
      "notebook #8668446 done\n",
      "notebook #8678201 done\n",
      "notebook #8687334 done\n",
      "notebook #8689318 done\n",
      "notebook #8699382 done\n",
      "notebook #8705213 done\n",
      "notebook #8706858 done\n",
      "notebook #8708118 done\n",
      "notebook #8710137 done\n",
      "notebook #8710362 done\n",
      "notebook #8604602 done\n",
      "notebook #8617043 done\n",
      "notebook #8620454 done\n",
      "notebook #8625834 done\n",
      "notebook #8628909 done\n",
      "notebook #8658083 done\n",
      "notebook #8663175 done\n",
      "notebook #8671133 done\n",
      "notebook #8679319 done\n",
      "notebook #8682800 done\n",
      "notebook #8687249 done\n",
      "notebook #8693806 done\n",
      "notebook #8701862 done\n",
      "notebook #8702904 done\n",
      "notebook #8706295 done\n",
      "notebook #8711165 done\n",
      "notebook #9326374 done\n",
      "notebook #9349764 done\n",
      "notebook #9463384 done\n",
      "notebook #138832 done\n",
      "notebook #2637869 done\n",
      "notebook #5466844 done\n",
      "notebook #5729566 done\n",
      "notebook #6470191 done\n",
      "notebook #8382140 done\n",
      "notebook #9655329 done\n",
      "notebook #10424951 done\n",
      "notebook #10522332 done\n",
      "notebook #10702707 done\n",
      "notebook #10913030 done\n",
      "notebook #11097956 done\n",
      "notebook #11410370 done\n",
      "notebook #11611498 done\n",
      "notebook #11656525 done\n",
      "notebook #12034947 done\n",
      "notebook #12343159 done\n",
      "notebook #13503938 done\n",
      "notebook #14177670 done\n",
      "notebook #171635 done\n",
      "notebook #2843645 done\n",
      "notebook #2846432 done\n",
      "notebook #2874738 done\n",
      "notebook #2894439 done\n",
      "notebook #2895967 done\n",
      "notebook #2897818 done\n",
      "notebook #2942474 done\n",
      "notebook #3001116 done\n",
      "notebook #3065122 done\n",
      "notebook #3127294 done\n",
      "notebook #3155308 done\n",
      "notebook #3308267 done\n",
      "notebook #3338077 done\n",
      "notebook #3412975 done\n",
      "notebook #3424825 done\n",
      "notebook #3544896 done\n",
      "notebook #3577796 done\n",
      "notebook #3640289 done\n",
      "notebook #3663832 done\n",
      "notebook #11400829 done\n",
      "notebook #24315 done\n",
      "notebook #242408 done\n",
      "notebook #243149 done\n",
      "notebook #244547 done\n",
      "notebook #244742 done\n",
      "notebook #244890 done\n",
      "notebook #244905 done\n",
      "notebook #244962 done\n",
      "notebook #245675 done\n",
      "notebook #874590 done\n",
      "notebook #1140262 done\n",
      "notebook #2095107 done\n",
      "notebook #3237641 done\n",
      "notebook #3674829 done\n",
      "notebook #4029935 done\n",
      "notebook #6511394 done\n",
      "notebook #6511397 done\n",
      "notebook #6511403 done\n",
      "notebook #6511414 done\n",
      "notebook #6511456 done\n",
      "notebook #6511492 done\n",
      "notebook #6518412 done\n",
      "notebook #7004483 done\n",
      "notebook #7465372 done\n",
      "notebook #7859060 done\n",
      "notebook #8648443 done\n",
      "notebook #9904611 done\n",
      "notebook #11013798 done\n",
      "notebook #3389306 done\n",
      "notebook #3414311 done\n",
      "notebook #4374092 done\n",
      "notebook #10307360 done\n",
      "notebook #3344044 done\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(113, 10)"
      ]
     },
     "metadata": {},
     "execution_count": 25
    }
   ],
   "source": [
    "# nl2ml = group_by_notebooks(nl2ml, TARGET_COLUMN)\n",
    "# X, y = train[TASK_FEATURES], train[TARGET_COLUMN]\n",
    "prepared_data = group_by_notebooks(nl2ml, TARGET_COLUMN)\n",
    "prepared_data.shape"
   ]
  },
  {
   "source": [
    "### Converting Dtypes"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def strip_recurrent_vertices(row):\n",
    "    # sequence = row['vertex_l2'].split(' ')\n",
    "    # result = []\n",
    "    # if len(sequence) > 1:\n",
    "    #     last_index = len(sequence) - 1\n",
    "    #     i = 0\n",
    "    #     while i < last_index:\n",
    "    #         # print(sequence[i], sequence[i+1])\n",
    "    #         if sequence[i].strip(' ') != sequence[i+1].strip(' '):\n",
    "    #             # print('not equal')\n",
    "    #             result.append(sequence[i])\n",
    "    #         else:\n",
    "    #             print('equal', sequence[i], sequence[i+1])\n",
    "    #         i =+ 1\n",
    "    # return \" \".join(result)\n",
    "    result = row['vertex_l2'].split(' ')[0] + \" \" + \" \".join([row['vertex_l2'].split(' ')[i] for i in range(1, len(row['vertex_l2'].split(' '))) if (row['vertex_l2'].split(' ')[i-1] != row['vertex_l2'].split(' ')[i])&(row['vertex_l2'].split(' ')[i] != ' ')&(row['vertex_l2'].split(' ')[i] != '')])\n",
    "    if result.split(' ')[1] == ' ':\n",
    "        result.pop(1)\n",
    "        return result\n",
    "    else:\n",
    "        return \" \".join(row['vertex_l2'].split(' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# prepared_data[TARGET_COLUMN] = prepared_data[TARGET_COLUMN].apply(strip_recurrent_vertices, axis=1)\n",
    "# prepared_data[TARGET_COLUMN] = prepared_data[TARGET_COLUMN].apply(lambda x: x.replace(' ', ''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'import_modules import_modules'"
      ]
     },
     "metadata": {},
     "execution_count": 28
    }
   ],
   "source": [
    "prepared_data[TARGET_COLUMN].loc[70]['vertex_l2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "('kaggle_id',)\n",
      "('competition_id',)\n",
      "('comp_name',)\n",
      "('comp_type',)\n",
      "('description',)\n",
      "('metric',)\n",
      "('datatype',)\n",
      "('subject',)\n",
      "('problemtype',)\n"
     ]
    }
   ],
   "source": [
    "cat_encodings = {}\n",
    "for i, col in enumerate(prepared_data):\n",
    "    if col[0] != TARGET_COLUMN:\n",
    "        print(col)\n",
    "        try:\n",
    "            prepared_data[col] =  prepared_data[col].astype('float32')\n",
    "        except:\n",
    "            prepared_data[col] = pd.Categorical(prepared_data[col])\n",
    "            cat_encodings.update({i:dict(enumerate(prepared_data[col].cat.categories))})\n",
    "            prepared_data[col] = prepared_data[col].cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "((54, 7), (59, 7))"
      ]
     },
     "metadata": {},
     "execution_count": 30
    }
   ],
   "source": [
    "competitions = prepared_data[competition_id_col].iloc[:, 0].unique()\n",
    "test_size = 0.25\n",
    "n_test_competitions = round(test_size * len(competitions))\n",
    "test_competitions, train_competitions = competitions[:n_test_competitions], competitions[n_test_competitions:]\n",
    "train = prepared_data[prepared_data['competition_id'].iloc[:, 0].isin(train_competitions)]\n",
    "test = prepared_data[prepared_data['competition_id'].iloc[:, 0].isin(test_competitions)]\n",
    "X_train, y_train = train[TASK_FEATURES], train[TARGET_COLUMN]\n",
    "X_test, y_test = test[TASK_FEATURES], test[TARGET_COLUMN]\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train, X_test, y_train, y_test = train_test_split(prepared_data[TASK_FEATURES], prepared_data[TARGET_COLUMN]\n",
    "#                                                     , test_size=0.25, shuffle=True, random_state=123)\n",
    "# X_train.shape, X_test.shape"
   ]
  },
  {
   "source": [
    "### Target Preprocessing: Encoding Vertices"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "lang = {vertice:i+2 for i, vertice in enumerate(nl2ml[TARGET_COLUMN].unique())} #TODO: save the dict as a local file\n",
    "lang.update({'<start>':1, '<end>':max(lang.values())+1})\n",
    "def encode_vertices(vertices_seq, lang:dict=lang):\n",
    "    # print(vertices_seq[0], type(vertices_seq[0]), vertices_seq[0].split(' '))\n",
    "    try:\n",
    "        encoded = np.append(np.flip(np.array([lang[vertex] for vertex in vertices_seq[0].split(' ')] + [lang['<end>']])), lang['<start>'])\n",
    "        # encoded = np.append(lang['<start>'], np.array([lang[vertex] for vertex in vertices_seq[0].split(' ')] + [lang['<end>']]))\n",
    "    except:\n",
    "        print(vertices_seq[0].split(' '))\n",
    "        raise Exception(\"Can't encode vertices\")\n",
    "    return encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_train.apply(encode_vertices, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X[TARGET_COLUMN] = y.apply(encode_vertices, axis=1)\n",
    "# X.to_csv('../data/nl2ml_train_example.csv', index=False)"
   ]
  },
  {
   "source": [
    "### Target Preprocessing: Padding Sequences"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length_targ, max_length_feat = prepared_data[TARGET_COLUMN].squeeze().str.split(' ').str.len().max() + 2, X_train.values.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train = tf.keras.preprocessing.sequence.pad_sequences(y_train.apply(encode_vertices, axis=1), maxlen=max_length_targ)\n",
    "Y_test = tf.keras.preprocessing.sequence.pad_sequences(y_test.apply(encode_vertices, axis=1), maxlen=max_length_targ)"
   ]
  },
  {
   "source": [
    "### Defining Constants"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_params = {\"Task\": \"train\"\n",
    "            , \"Model\": \"generative task2seq\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features = len(TASK_FEATURES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_params = {\"nrows\":X_train.shape[0]\n",
    "                , \"nfeatures\": n_features}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BUFFER_SIZE = len(input_tensor_train)\n",
    "BATCH_SIZE = 1\n",
    "LR = 0.001\n",
    "STEPS_PER_EPOCH = len(X_train)//BATCH_SIZE\n",
    "embedding_dim = 256\n",
    "gru_units = 512\n",
    "# vocab_inp_size = len(inp_lang.word_index) + 1\n",
    "# vocab_tar_size = len(targ_lang.word_index) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_params = {\"BATCH_SIZE\":BATCH_SIZE\n",
    "                , \"LR\":LR\n",
    "                , \"STEPS_PER_EPOCH\": STEPS_PER_EPOCH\n",
    "                , \"embedding_dim\": embedding_dim\n",
    "                , \"gru_units\": gru_units}"
   ]
  },
  {
   "source": [
    "### Creating tf.Dataset"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = tf.data.Dataset.from_tensor_slices((X_train.values, Y_train))\n",
    "train_dataset = train_dataset.batch(BATCH_SIZE, drop_remainder=True)"
   ]
  },
  {
   "source": [
    "### Building the Model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.Model):\n",
    "  def __init__(self, vocab_size, embedding_dim, dec_units, batch_sz):\n",
    "    super(Decoder, self).__init__()\n",
    "    self.batch_sz = batch_sz\n",
    "    self.dec_units = dec_units\n",
    "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "    # self.hidden_embedding = tf.keras.layers.Embedding(vocab_size, 1)\n",
    "    self.gru = tf.keras.layers.GRU(self.dec_units,\n",
    "                                   return_sequences=True,\n",
    "                                   return_state=True,\n",
    "                                   recurrent_initializer='glorot_uniform')\n",
    "    self.dropout = tf.keras.layers.Dropout(0.2)\n",
    "    self.fc = tf.keras.layers.Dense(vocab_size, activation='sigmoid')\n",
    "    # self.vec_input_layer = tf.keras.layers.InputLayer(input_shape=tf.TensorShape([n_features, 1]), batch_size=(BATCH_SIZE))\n",
    "    self.fc_vec = tf.keras.layers.Dense(dec_units, activation='sigmoid')\n",
    "    # self.fc_seq = tf.keras.layers.Dense(vocab_size, activation='sigmoid')\n",
    "    # used for attention\n",
    "    # self.attention = BahdanauAttention(self.dec_units)\n",
    "\n",
    "  def call(self, x, hidden, vec_input):#, enc_output):\n",
    "    # enc_output shape == (batch_size, max_length, hidden_size)\n",
    "    # context_vector, attention_weights = self.attention(hidden, enc_output)\n",
    "    # attention_weights = tf.ones(x.shape)\n",
    "    # context_vector = tf.ones(x.shape)\n",
    "    # print(\"X Vector has {} type and {} shape\".format(type(x), x.shape))\n",
    "    # print(\"Context Vector has {} type and {} shape\".format(type(context_vector), context_vector.shape))\n",
    "    # print(\"Attention Vector has {} type and {} shape\".format(type(context_vector), context_vector.shape))\n",
    "    # x shape after passing through embedding == (batch_size, 1, embedding_dim)\n",
    "    x = self.embedding(x)\n",
    "    # x = tf.squeeze(self.hidden_embedding(x), axis=-1)\n",
    "    # x shape after concatenation == (batch_size, 1, embedding_dim + hidden_size)\n",
    "    # x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1)\n",
    "\n",
    "    # passing the concatenated vector to the GRU\n",
    "    output, state = self.gru(x, initial_state=hidden)\n",
    "\n",
    "    # output shape == (batch_size * 1, hidden_size)\n",
    "    output = tf.reshape(output, (-1, output.shape[2]))\n",
    "    output = self.dropout(output)\n",
    "    # output shape == (batch_size, vocab)\n",
    "    # vec = self.vec_input_layer(vec_input)\n",
    "    # print(vec)\n",
    "    vec = self.fc_vec(vec_input)\n",
    "    # vec = self.embedding(vec)\n",
    "    concatenated = tf.keras.layers.concatenate([vec, output], axis=1)\n",
    "    x = self.fc(concatenated)\n",
    "    # x = self.fc(output)\n",
    "    return x, state#, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Decoder output shape: (batch_size, vocab size`) (1, 72)\nModel: \"decoder\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nembedding (Embedding)        multiple                  18432     \n_________________________________________________________________\ngru (GRU)                    multiple                  1182720   \n_________________________________________________________________\ndropout (Dropout)            multiple                  0         \n_________________________________________________________________\ndense (Dense)                multiple                  73800     \n_________________________________________________________________\ndense_1 (Dense)              multiple                  4096      \n=================================================================\nTotal params: 1,279,048\nTrainable params: 1,279,048\nNon-trainable params: 0\n_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "decoder = Decoder(len(lang)+2, embedding_dim, gru_units, BATCH_SIZE)\n",
    "sample_hidden = tf.zeros((BATCH_SIZE, gru_units))\n",
    "vec_input = np.ones((1, n_features))\n",
    "sample_decoder_output, state = decoder(tf.random.uniform((BATCH_SIZE, 1))\n",
    "                                          , sample_hidden\n",
    "                                          , vec_input\n",
    "                                          )\n",
    "print ('Decoder output shape: (batch_size, vocab size`) {}'.format(sample_decoder_output.shape))\n",
    "decoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(LR)\n",
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "                  from_logits=True, reduction='none')\n",
    "\n",
    "def loss_function(real, pred):\n",
    "  mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "  loss_ = loss_object(real, pred)\n",
    "\n",
    "  mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "  loss_ *= mask\n",
    "\n",
    "  return tf.reduce_mean(loss_)"
   ]
  },
  {
   "source": [
    "### Model Training or Loading Pre-Trained"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(inp, targ):#, enc_hidden):\n",
    "  loss = 0\n",
    "  # batch_perplexity = 1\n",
    "  with tf.GradientTape() as tape:\n",
    "    # enc_output, enc_hidden = encoder(inp, enc_hidden)\n",
    "\n",
    "    dec_hidden = tf.zeros((BATCH_SIZE, gru_units)) #enc_hidden\n",
    "\n",
    "    dec_input = tf.expand_dims([1] * BATCH_SIZE, 1)\n",
    "    # dec_input = tf.expand_dims(inp, 1)\n",
    "    # Teacher forcing - feeding the target as the next input\n",
    "    for t in range(1, targ.shape[1]): # for each vertex (token) from solution (sequence)\n",
    "      # passing enc_output to the decoder\n",
    "      predictions, dec_hidden = decoder(dec_input, dec_hidden, inp)#, enc_output)\n",
    "      loss += loss_function(targ[:, t], predictions)\n",
    "      # batch_perplexity *= tf.exp(loss)\n",
    "\n",
    "      # using teacher forcing\n",
    "      dec_input = tf.expand_dims(targ[:, t], 1)\n",
    "\n",
    "  batch_loss = (loss / int(targ.shape[1]))\n",
    "  variables = decoder.trainable_variables # + encoder.trainable_variables\n",
    "  gradients = tape.gradient(loss, variables)\n",
    "  optimizer.apply_gradients(zip(gradients, variables))\n",
    "  del inp, targ, gradients, variables\n",
    "  gc.collect()\n",
    "  return batch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_dir = './checkpoints/'\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
    "checkpoint = tf.train.Checkpoint(step=tf.Variable(1)\n",
    "                                , optimizer=optimizer\n",
    "                                # , metrics=perplexity_metric\n",
    "                                #  , encoder=encoder\n",
    "                                 , decoder=decoder)\n",
    "manager = tf.train.CheckpointManager(checkpoint, checkpoint_dir, max_to_keep=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "##TODO: validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if manager.latest_checkpoint:\n",
    "#     print(\"Restored from {}\".format(manager.latest_checkpoint))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# decoder.compile()\n",
    "# tf.saved_model.save(decoder, './checkpoints/model1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1 Batch 0 Loss 0.0046 Perplexity 1.0046\n",
      "Time taken for the epoch 14.539703130722046 sec\n",
      "\n",
      "Epoch 2 Batch 0 Loss 0.0032 Perplexity 1.0032\n",
      "Time taken for the epoch 15.140742301940918 sec\n",
      "\n",
      "Epoch 3 Batch 0 Loss 0.0033 Perplexity 1.0033\n",
      "Time taken for the epoch 15.921015739440918 sec\n",
      "\n",
      "Epoch 4 Batch 0 Loss 0.0035 Perplexity 1.0035\n",
      "Time taken for the epoch 15.684227228164673 sec\n",
      "\n",
      "Epoch 5 Batch 0 Loss 0.0034 Perplexity 1.0034\n",
      "saving\n",
      "saved\n",
      "Time taken for the epoch 17.27472996711731 sec\n",
      "\n",
      "Epoch 6 Batch 0 Loss 0.0032 Perplexity 1.0032\n",
      "Time taken for the epoch 17.04537320137024 sec\n",
      "\n",
      "Epoch 7 Batch 0 Loss 0.0033 Perplexity 1.0033\n",
      "Time taken for the epoch 17.002867698669434 sec\n",
      "\n",
      "Epoch 8 Batch 0 Loss 0.2413 Perplexity 1.2729\n",
      "Time taken for the epoch 16.833014726638794 sec\n",
      "\n",
      "Epoch 9 Batch 0 Loss 0.0547 Perplexity 1.0563\n",
      "Time taken for the epoch 17.52511692047119 sec\n",
      "\n",
      "Epoch 10 Batch 0 Loss 0.0639 Perplexity 1.0660\n",
      "saving\n",
      "saved\n",
      "Time taken for the epoch 15.613655090332031 sec\n",
      "\n",
      "Epoch 11 Batch 0 Loss 0.0685 Perplexity 1.0709\n",
      "Time taken for the epoch 18.25195574760437 sec\n",
      "\n",
      "Epoch 12 Batch 0 Loss 0.0202 Perplexity 1.0204\n",
      "Time taken for the epoch 17.203026056289673 sec\n",
      "\n",
      "Epoch 13 Batch 0 Loss 0.0071 Perplexity 1.0071\n",
      "Time taken for the epoch 18.92949080467224 sec\n",
      "\n",
      "Epoch 14 Batch 0 Loss 0.0057 Perplexity 1.0057\n",
      "Time taken for the epoch 15.686974287033081 sec\n",
      "\n",
      "Epoch 15 Batch 0 Loss 0.0052 Perplexity 1.0052\n",
      "saving\n",
      "saved\n",
      "Time taken for the epoch 16.6375253200531 sec\n",
      "\n",
      "Epoch 16 Batch 0 Loss 0.0044 Perplexity 1.0044\n",
      "Time taken for the epoch 16.141462802886963 sec\n",
      "\n",
      "Epoch 17 Batch 0 Loss 0.0045 Perplexity 1.0046\n",
      "Time taken for the epoch 15.45930290222168 sec\n",
      "\n",
      "Epoch 18 Batch 0 Loss 0.0039 Perplexity 1.0039\n",
      "Time taken for the epoch 15.592086553573608 sec\n",
      "\n",
      "Epoch 19 Batch 0 Loss 0.0043 Perplexity 1.0043\n",
      "Time taken for the epoch 16.027289867401123 sec\n",
      "\n",
      "Epoch 20 Batch 0 Loss 0.0037 Perplexity 1.0037\n",
      "saving\n",
      "saved\n",
      "Time taken for the epoch 15.763507604598999 sec\n",
      "\n",
      "Epoch 21 Batch 0 Loss 0.0039 Perplexity 1.0039\n",
      "Time taken for the epoch 15.844887495040894 sec\n",
      "\n",
      "Epoch 22 Batch 0 Loss 0.0032 Perplexity 1.0032\n",
      "Time taken for the epoch 15.468451023101807 sec\n",
      "\n",
      "Epoch 23 Batch 0 Loss 0.0023 Perplexity 1.0024\n",
      "Time taken for the epoch 15.432855129241943 sec\n",
      "\n",
      "Epoch 24 Batch 0 Loss 0.0085 Perplexity 1.0085\n",
      "Time taken for the epoch 15.419967412948608 sec\n",
      "\n",
      "Epoch 25 Batch 0 Loss 0.0031 Perplexity 1.0031\n",
      "saving\n",
      "saved\n",
      "Time taken for the epoch 16.532781839370728 sec\n",
      "\n",
      "Epoch 26 Batch 0 Loss 0.0026 Perplexity 1.0026\n",
      "Time taken for the epoch 16.686260223388672 sec\n",
      "\n",
      "Epoch 27 Batch 0 Loss 0.0030 Perplexity 1.0030\n",
      "Time taken for the epoch 15.762433767318726 sec\n",
      "\n",
      "Epoch 28 Batch 0 Loss 0.0050 Perplexity 1.0050\n",
      "Time taken for the epoch 15.40428876876831 sec\n",
      "\n",
      "Epoch 29 Batch 0 Loss 0.0032 Perplexity 1.0032\n",
      "Time taken for the epoch 15.580792665481567 sec\n",
      "\n",
      "Epoch 30 Batch 0 Loss 0.0019 Perplexity 1.0019\n",
      "saving\n",
      "saved\n",
      "Time taken for the epoch 16.91806125640869 sec\n",
      "\n",
      "Epoch 31 Batch 0 Loss 0.0019 Perplexity 1.0019\n",
      "Time taken for the epoch 15.916118621826172 sec\n",
      "\n",
      "Epoch 32 Batch 0 Loss 0.0034 Perplexity 1.0034\n",
      "Time taken for the epoch 15.509272813796997 sec\n",
      "\n",
      "Epoch 33 Batch 0 Loss 0.0014 Perplexity 1.0014\n",
      "Time taken for the epoch 15.443961143493652 sec\n",
      "\n",
      "Epoch 34 Batch 0 Loss 0.0014 Perplexity 1.0014\n",
      "Time taken for the epoch 15.43169379234314 sec\n",
      "\n",
      "Epoch 35 Batch 0 Loss 0.0015 Perplexity 1.0015\n",
      "saving\n",
      "saved\n",
      "Time taken for the epoch 15.908545732498169 sec\n",
      "\n",
      "Epoch 36 Batch 0 Loss 0.0024 Perplexity 1.0024\n",
      "Time taken for the epoch 16.072318077087402 sec\n",
      "\n",
      "Epoch 37 Batch 0 Loss 0.0029 Perplexity 1.0029\n",
      "Time taken for the epoch 15.392452001571655 sec\n",
      "\n",
      "Epoch 38 Batch 0 Loss 0.0017 Perplexity 1.0017\n",
      "Time taken for the epoch 15.458017587661743 sec\n",
      "\n",
      "Epoch 39 Batch 0 Loss 0.0054 Perplexity 1.0055\n",
      "Time taken for the epoch 15.525058269500732 sec\n",
      "\n",
      "Epoch 40 Batch 0 Loss 0.0014 Perplexity 1.0014\n",
      "saving\n",
      "saved\n",
      "Time taken for the epoch 15.50243330001831 sec\n",
      "\n",
      "Epoch 41 Batch 0 Loss 0.0014 Perplexity 1.0014\n",
      "Time taken for the epoch 16.142848014831543 sec\n",
      "\n",
      "Epoch 42 Batch 0 Loss 0.0016 Perplexity 1.0016\n",
      "Time taken for the epoch 15.904842376708984 sec\n",
      "\n",
      "Epoch 43 Batch 0 Loss 0.0087 Perplexity 1.0087\n",
      "Time taken for the epoch 15.454330682754517 sec\n",
      "\n",
      "Epoch 44 Batch 0 Loss 0.0210 Perplexity 1.0213\n",
      "Time taken for the epoch 15.457037210464478 sec\n",
      "\n",
      "Epoch 45 Batch 0 Loss 0.0020 Perplexity 1.0020\n",
      "saving\n",
      "saved\n",
      "Time taken for the epoch 15.567164421081543 sec\n",
      "\n",
      "Epoch 46 Batch 0 Loss 0.0021 Perplexity 1.0021\n",
      "Time taken for the epoch 16.730222463607788 sec\n",
      "\n",
      "Epoch 47 Batch 0 Loss 0.0016 Perplexity 1.0016\n",
      "Time taken for the epoch 15.507352590560913 sec\n",
      "\n",
      "Epoch 48 Batch 0 Loss 0.0012 Perplexity 1.0012\n",
      "Time taken for the epoch 15.35028624534607 sec\n",
      "\n",
      "Epoch 49 Batch 0 Loss 0.0016 Perplexity 1.0016\n",
      "Time taken for the epoch 15.409761905670166 sec\n",
      "\n",
      "Epoch 50 Batch 0 Loss 0.0014 Perplexity 1.0014\n",
      "saving\n",
      "saved\n",
      "Time taken for the epoch 15.48838472366333 sec\n",
      "\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x18c77d9ea00>]"
      ]
     },
     "metadata": {},
     "execution_count": 163
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\r\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\r\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\r\n<!-- Created with matplotlib (https://matplotlib.org/) -->\r\n<svg height=\"248.518125pt\" version=\"1.1\" viewBox=\"0 0 378.465625 248.518125\" width=\"378.465625pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\r\n <metadata>\r\n  <rdf:RDF xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\r\n   <cc:Work>\r\n    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\r\n    <dc:date>2021-05-29T12:48:09.395172</dc:date>\r\n    <dc:format>image/svg+xml</dc:format>\r\n    <dc:creator>\r\n     <cc:Agent>\r\n      <dc:title>Matplotlib v3.3.2, https://matplotlib.org/</dc:title>\r\n     </cc:Agent>\r\n    </dc:creator>\r\n   </cc:Work>\r\n  </rdf:RDF>\r\n </metadata>\r\n <defs>\r\n  <style type=\"text/css\">*{stroke-linecap:butt;stroke-linejoin:round;}</style>\r\n </defs>\r\n <g id=\"figure_1\">\r\n  <g id=\"patch_1\">\r\n   <path d=\"M 0 248.518125 \r\nL 378.465625 248.518125 \r\nL 378.465625 0 \r\nL 0 0 \r\nz\r\n\" style=\"fill:none;\"/>\r\n  </g>\r\n  <g id=\"axes_1\">\r\n   <g id=\"patch_2\">\r\n    <path d=\"M 36.465625 224.64 \r\nL 371.265625 224.64 \r\nL 371.265625 7.2 \r\nL 36.465625 7.2 \r\nz\r\n\" style=\"fill:#ffffff;\"/>\r\n   </g>\r\n   <g id=\"matplotlib.axis_1\">\r\n    <g id=\"xtick_1\">\r\n     <g id=\"line2d_1\">\r\n      <defs>\r\n       <path d=\"M 0 0 \r\nL 0 3.5 \r\n\" id=\"m01244b474f\" style=\"stroke:#000000;stroke-width:0.8;\"/>\r\n      </defs>\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"51.683807\" xlink:href=\"#m01244b474f\" y=\"224.64\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_1\">\r\n      <!-- 0 -->\r\n      <g transform=\"translate(48.502557 239.238437)scale(0.1 -0.1)\">\r\n       <defs>\r\n        <path d=\"M 31.78125 66.40625 \r\nQ 24.171875 66.40625 20.328125 58.90625 \r\nQ 16.5 51.421875 16.5 36.375 \r\nQ 16.5 21.390625 20.328125 13.890625 \r\nQ 24.171875 6.390625 31.78125 6.390625 \r\nQ 39.453125 6.390625 43.28125 13.890625 \r\nQ 47.125 21.390625 47.125 36.375 \r\nQ 47.125 51.421875 43.28125 58.90625 \r\nQ 39.453125 66.40625 31.78125 66.40625 \r\nz\r\nM 31.78125 74.21875 \r\nQ 44.046875 74.21875 50.515625 64.515625 \r\nQ 56.984375 54.828125 56.984375 36.375 \r\nQ 56.984375 17.96875 50.515625 8.265625 \r\nQ 44.046875 -1.421875 31.78125 -1.421875 \r\nQ 19.53125 -1.421875 13.0625 8.265625 \r\nQ 6.59375 17.96875 6.59375 36.375 \r\nQ 6.59375 54.828125 13.0625 64.515625 \r\nQ 19.53125 74.21875 31.78125 74.21875 \r\nz\r\n\" id=\"DejaVuSans-48\"/>\r\n       </defs>\r\n       <use xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_2\">\r\n     <g id=\"line2d_2\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"89.920445\" xlink:href=\"#m01244b474f\" y=\"224.64\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_2\">\r\n      <!-- 25 -->\r\n      <g transform=\"translate(83.557945 239.238437)scale(0.1 -0.1)\">\r\n       <defs>\r\n        <path d=\"M 19.1875 8.296875 \r\nL 53.609375 8.296875 \r\nL 53.609375 0 \r\nL 7.328125 0 \r\nL 7.328125 8.296875 \r\nQ 12.9375 14.109375 22.625 23.890625 \r\nQ 32.328125 33.6875 34.8125 36.53125 \r\nQ 39.546875 41.84375 41.421875 45.53125 \r\nQ 43.3125 49.21875 43.3125 52.78125 \r\nQ 43.3125 58.59375 39.234375 62.25 \r\nQ 35.15625 65.921875 28.609375 65.921875 \r\nQ 23.96875 65.921875 18.8125 64.3125 \r\nQ 13.671875 62.703125 7.8125 59.421875 \r\nL 7.8125 69.390625 \r\nQ 13.765625 71.78125 18.9375 73 \r\nQ 24.125 74.21875 28.421875 74.21875 \r\nQ 39.75 74.21875 46.484375 68.546875 \r\nQ 53.21875 62.890625 53.21875 53.421875 \r\nQ 53.21875 48.921875 51.53125 44.890625 \r\nQ 49.859375 40.875 45.40625 35.40625 \r\nQ 44.1875 33.984375 37.640625 27.21875 \r\nQ 31.109375 20.453125 19.1875 8.296875 \r\nz\r\n\" id=\"DejaVuSans-50\"/>\r\n        <path d=\"M 10.796875 72.90625 \r\nL 49.515625 72.90625 \r\nL 49.515625 64.59375 \r\nL 19.828125 64.59375 \r\nL 19.828125 46.734375 \r\nQ 21.96875 47.46875 24.109375 47.828125 \r\nQ 26.265625 48.1875 28.421875 48.1875 \r\nQ 40.625 48.1875 47.75 41.5 \r\nQ 54.890625 34.8125 54.890625 23.390625 \r\nQ 54.890625 11.625 47.5625 5.09375 \r\nQ 40.234375 -1.421875 26.90625 -1.421875 \r\nQ 22.3125 -1.421875 17.546875 -0.640625 \r\nQ 12.796875 0.140625 7.71875 1.703125 \r\nL 7.71875 11.625 \r\nQ 12.109375 9.234375 16.796875 8.0625 \r\nQ 21.484375 6.890625 26.703125 6.890625 \r\nQ 35.15625 6.890625 40.078125 11.328125 \r\nQ 45.015625 15.765625 45.015625 23.390625 \r\nQ 45.015625 31 40.078125 35.4375 \r\nQ 35.15625 39.890625 26.703125 39.890625 \r\nQ 22.75 39.890625 18.8125 39.015625 \r\nQ 14.890625 38.140625 10.796875 36.28125 \r\nz\r\n\" id=\"DejaVuSans-53\"/>\r\n       </defs>\r\n       <use xlink:href=\"#DejaVuSans-50\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_3\">\r\n     <g id=\"line2d_3\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"128.157082\" xlink:href=\"#m01244b474f\" y=\"224.64\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_3\">\r\n      <!-- 50 -->\r\n      <g transform=\"translate(121.794582 239.238437)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-53\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_4\">\r\n     <g id=\"line2d_4\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"166.39372\" xlink:href=\"#m01244b474f\" y=\"224.64\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_4\">\r\n      <!-- 75 -->\r\n      <g transform=\"translate(160.03122 239.238437)scale(0.1 -0.1)\">\r\n       <defs>\r\n        <path d=\"M 8.203125 72.90625 \r\nL 55.078125 72.90625 \r\nL 55.078125 68.703125 \r\nL 28.609375 0 \r\nL 18.3125 0 \r\nL 43.21875 64.59375 \r\nL 8.203125 64.59375 \r\nz\r\n\" id=\"DejaVuSans-55\"/>\r\n       </defs>\r\n       <use xlink:href=\"#DejaVuSans-55\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_5\">\r\n     <g id=\"line2d_5\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"204.630358\" xlink:href=\"#m01244b474f\" y=\"224.64\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_5\">\r\n      <!-- 100 -->\r\n      <g transform=\"translate(195.086608 239.238437)scale(0.1 -0.1)\">\r\n       <defs>\r\n        <path d=\"M 12.40625 8.296875 \r\nL 28.515625 8.296875 \r\nL 28.515625 63.921875 \r\nL 10.984375 60.40625 \r\nL 10.984375 69.390625 \r\nL 28.421875 72.90625 \r\nL 38.28125 72.90625 \r\nL 38.28125 8.296875 \r\nL 54.390625 8.296875 \r\nL 54.390625 0 \r\nL 12.40625 0 \r\nz\r\n\" id=\"DejaVuSans-49\"/>\r\n       </defs>\r\n       <use xlink:href=\"#DejaVuSans-49\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_6\">\r\n     <g id=\"line2d_6\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"242.866995\" xlink:href=\"#m01244b474f\" y=\"224.64\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_6\">\r\n      <!-- 125 -->\r\n      <g transform=\"translate(233.323245 239.238437)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-49\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-50\"/>\r\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-53\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_7\">\r\n     <g id=\"line2d_7\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"281.103633\" xlink:href=\"#m01244b474f\" y=\"224.64\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_7\">\r\n      <!-- 150 -->\r\n      <g transform=\"translate(271.559883 239.238437)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-49\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\r\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_8\">\r\n     <g id=\"line2d_8\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"319.340271\" xlink:href=\"#m01244b474f\" y=\"224.64\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_8\">\r\n      <!-- 175 -->\r\n      <g transform=\"translate(309.796521 239.238437)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-49\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-55\"/>\r\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-53\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_9\">\r\n     <g id=\"line2d_9\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"357.576909\" xlink:href=\"#m01244b474f\" y=\"224.64\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_9\">\r\n      <!-- 200 -->\r\n      <g transform=\"translate(348.033159 239.238437)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-50\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n   </g>\r\n   <g id=\"matplotlib.axis_2\">\r\n    <g id=\"ytick_1\">\r\n     <g id=\"line2d_10\">\r\n      <defs>\r\n       <path d=\"M 0 0 \r\nL -3.5 0 \r\n\" id=\"m4525930d4e\" style=\"stroke:#000000;stroke-width:0.8;\"/>\r\n      </defs>\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"36.465625\" xlink:href=\"#m4525930d4e\" y=\"215.274613\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_10\">\r\n      <!-- 0.00 -->\r\n      <g transform=\"translate(7.2 219.073832)scale(0.1 -0.1)\">\r\n       <defs>\r\n        <path d=\"M 10.6875 12.40625 \r\nL 21 12.40625 \r\nL 21 0 \r\nL 10.6875 0 \r\nz\r\n\" id=\"DejaVuSans-46\"/>\r\n       </defs>\r\n       <use xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\r\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_2\">\r\n     <g id=\"line2d_11\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"36.465625\" xlink:href=\"#m4525930d4e\" y=\"172.052339\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_11\">\r\n      <!-- 0.05 -->\r\n      <g transform=\"translate(7.2 175.851557)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\r\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-53\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_3\">\r\n     <g id=\"line2d_12\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"36.465625\" xlink:href=\"#m4525930d4e\" y=\"128.830064\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_12\">\r\n      <!-- 0.10 -->\r\n      <g transform=\"translate(7.2 132.629283)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\r\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-49\"/>\r\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_4\">\r\n     <g id=\"line2d_13\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"36.465625\" xlink:href=\"#m4525930d4e\" y=\"85.607789\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_13\">\r\n      <!-- 0.15 -->\r\n      <g transform=\"translate(7.2 89.407008)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\r\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-49\"/>\r\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-53\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_5\">\r\n     <g id=\"line2d_14\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"36.465625\" xlink:href=\"#m4525930d4e\" y=\"42.385515\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_14\">\r\n      <!-- 0.20 -->\r\n      <g transform=\"translate(7.2 46.184733)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\r\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-50\"/>\r\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n   </g>\r\n   <g id=\"line2d_15\">\r\n    <path clip-path=\"url(#pa6c25018eb)\" d=\"M 51.683807 17.083636 \r\nL 53.213272 52.132155 \r\nL 54.742738 81.73585 \r\nL 56.272203 74.778305 \r\nL 57.801669 79.407308 \r\nL 59.331134 76.596158 \r\nL 60.8606 72.236205 \r\nL 62.390065 83.934897 \r\nL 63.919531 63.428141 \r\nL 65.448996 84.893519 \r\nL 66.978462 86.892611 \r\nL 68.507927 87.521834 \r\nL 70.037393 108.222755 \r\nL 71.566858 130.848946 \r\nL 73.096324 133.03421 \r\nL 74.625789 136.818352 \r\nL 76.155255 145.644005 \r\nL 77.68472 157.741217 \r\nL 79.214186 161.336018 \r\nL 80.743651 167.286349 \r\nL 82.273117 173.852598 \r\nL 83.802583 180.91156 \r\nL 85.332048 170.713642 \r\nL 86.861514 185.396232 \r\nL 88.390979 177.522006 \r\nL 89.920445 183.034965 \r\nL 91.44991 184.462886 \r\nL 92.979376 184.695544 \r\nL 94.508841 184.649397 \r\nL 96.038307 185.99976 \r\nL 97.567772 185.916041 \r\nL 100.626703 186.254709 \r\nL 102.156169 186.955261 \r\nL 103.685634 186.40425 \r\nL 105.2151 188.577143 \r\nL 106.744565 186.447093 \r\nL 108.274031 188.146551 \r\nL 109.803496 187.73855 \r\nL 111.332962 189.695262 \r\nL 112.862427 188.194131 \r\nL 114.391893 188.892507 \r\nL 115.921358 191.115864 \r\nL 117.450824 190.977577 \r\nL 118.980289 191.378974 \r\nL 120.509755 183.602512 \r\nL 122.03922 184.782685 \r\nL 123.568686 188.652381 \r\nL 125.098151 189.201314 \r\nL 126.627617 183.90888 \r\nL 128.157082 184.914232 \r\nL 129.686548 188.846158 \r\nL 131.216013 184.199961 \r\nL 132.745479 191.053092 \r\nL 134.274944 188.351707 \r\nL 135.80441 188.609536 \r\nL 137.333875 189.373634 \r\nL 138.863341 190.449615 \r\nL 140.392806 192.972188 \r\nL 141.922272 193.422698 \r\nL 143.451737 191.901122 \r\nL 144.981203 194.893228 \r\nL 146.510668 194.241199 \r\nL 148.040134 194.995145 \r\nL 149.569599 194.231643 \r\nL 151.099065 195.701826 \r\nL 152.62853 189.347891 \r\nL 154.157996 193.995588 \r\nL 157.216927 185.168205 \r\nL 158.746392 198.883736 \r\nL 160.275858 191.39625 \r\nL 161.805323 195.256318 \r\nL 163.334789 195.777052 \r\nL 164.864255 196.458784 \r\nL 166.39372 196.90058 \r\nL 167.923186 197.810522 \r\nL 169.452651 198.194006 \r\nL 170.982117 195.426251 \r\nL 172.511582 196.371222 \r\nL 174.041048 198.222681 \r\nL 175.570513 200.78212 \r\nL 177.099979 199.853104 \r\nL 178.629444 183.170328 \r\nL 180.15891 188.199676 \r\nL 181.688375 191.379543 \r\nL 183.217841 198.45879 \r\nL 184.747306 197.984203 \r\nL 186.276772 199.153332 \r\nL 187.806237 199.73578 \r\nL 189.335703 200.073573 \r\nL 190.865168 201.145285 \r\nL 192.394634 201.166928 \r\nL 193.924099 202.74902 \r\nL 196.98303 203.262136 \r\nL 198.512496 203.851973 \r\nL 200.041961 203.326785 \r\nL 201.571427 206.321139 \r\nL 203.100892 204.85097 \r\nL 204.630358 206.191944 \r\nL 207.689289 206.916165 \r\nL 209.218754 208.695738 \r\nL 210.74822 208.374163 \r\nL 212.277685 207.693138 \r\nL 213.807151 209.832804 \r\nL 215.336616 209.079425 \r\nL 216.866082 211.355488 \r\nL 218.395547 210.245879 \r\nL 221.454478 210.932641 \r\nL 222.983944 209.048993 \r\nL 224.513409 211.036148 \r\nL 226.042875 210.535287 \r\nL 227.57234 211.312184 \r\nL 229.101806 212.528006 \r\nL 232.160737 212.055657 \r\nL 233.690202 209.487409 \r\nL 235.219668 209.725272 \r\nL 236.749133 209.25094 \r\nL 238.278599 208.916008 \r\nL 239.808064 210.363949 \r\nL 241.33753 211.5529 \r\nL 242.866995 212.529238 \r\nL 244.396461 208.042038 \r\nL 245.925927 208.406226 \r\nL 247.455392 210.596915 \r\nL 248.984858 210.128483 \r\nL 250.514323 189.1589 \r\nL 252.043789 198.91856 \r\nL 253.573254 211.084656 \r\nL 255.10272 207.866708 \r\nL 256.632185 206.891716 \r\nL 259.691116 209.745067 \r\nL 261.220582 208.504776 \r\nL 262.750047 210.069083 \r\nL 264.279513 211.321715 \r\nL 265.808978 211.910113 \r\nL 270.397375 212.503377 \r\nL 271.92684 213.118454 \r\nL 273.456306 213.07108 \r\nL 274.985771 213.3983 \r\nL 276.515237 213.173228 \r\nL 278.044702 213.523645 \r\nL 279.574168 211.819419 \r\nL 281.103633 212.802699 \r\nL 282.633099 212.646203 \r\nL 284.162564 213.050272 \r\nL 285.69203 212.995061 \r\nL 287.221495 213.598214 \r\nL 288.750961 213.191864 \r\nL 290.280426 103.550568 \r\nL 291.809892 211.907948 \r\nL 293.339357 213.202053 \r\nL 294.868823 213.104602 \r\nL 296.398288 213.268516 \r\nL 297.927754 212.635373 \r\nL 299.457219 212.790309 \r\nL 300.986685 212.645198 \r\nL 302.51615 212.907329 \r\nL 304.045616 213.284339 \r\nL 307.104547 213.27832 \r\nL 310.163478 213.178844 \r\nL 311.692943 213.5318 \r\nL 313.222409 211.756032 \r\nL 314.751874 213.831527 \r\nL 316.28134 213.653281 \r\nL 317.810805 213.942611 \r\nL 319.340271 213.622975 \r\nL 320.869736 213.857923 \r\nL 323.928667 213.820407 \r\nL 325.458133 213.809097 \r\nL 326.987599 213.987656 \r\nL 330.04653 214.196376 \r\nL 331.575995 214.430638 \r\nL 333.105461 214.217529 \r\nL 334.634926 213.493838 \r\nL 336.164392 214.013106 \r\nL 337.693857 214.31126 \r\nL 339.223323 214.256446 \r\nL 340.752788 213.996947 \r\nL 342.282254 213.446782 \r\nL 343.811719 214.43873 \r\nL 346.87065 214.669607 \r\nL 348.400116 214.533897 \r\nL 349.929581 214.554131 \r\nL 351.459047 214.045537 \r\nL 352.988512 214.589995 \r\nL 354.517978 213.927703 \r\nL 356.047443 214.756364 \r\nL 356.047443 214.756364 \r\n\" style=\"fill:none;stroke:#1f77b4;stroke-linecap:square;stroke-width:1.5;\"/>\r\n   </g>\r\n   <g id=\"patch_3\">\r\n    <path d=\"M 36.465625 224.64 \r\nL 36.465625 7.2 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_4\">\r\n    <path d=\"M 371.265625 224.64 \r\nL 371.265625 7.2 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_5\">\r\n    <path d=\"M 36.465625 224.64 \r\nL 371.265625 224.64 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_6\">\r\n    <path d=\"M 36.465625 7.2 \r\nL 371.265625 7.2 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n  </g>\r\n </g>\r\n <defs>\r\n  <clipPath id=\"pa6c25018eb\">\r\n   <rect height=\"217.44\" width=\"334.8\" x=\"36.465625\" y=\"7.2\"/>\r\n  </clipPath>\r\n </defs>\r\n</svg>\r\n",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "source": [
    "EPOCHS = 50\n",
    "for epoch in range(EPOCHS):\n",
    "    gc.collect()\n",
    "    start = time.time()\n",
    "    # enc_hidden = encoder.initialize_hidden_state()\n",
    "    total_loss = 0\n",
    "    total_batch_perplexity = 0\n",
    "    for (batch, (feat, targ)) in enumerate(train_dataset.take(STEPS_PER_EPOCH)):\n",
    "        # print ('Features: {}, Target: {}'.format(feat, targ))\n",
    "        batch_loss = train_step(feat, targ)#, enc_hidden)\n",
    "        batch_perplexity = tf.exp(batch_loss)\n",
    "\n",
    "        total_loss += batch_loss\n",
    "        total_batch_perplexity += batch_perplexity #perplexity_metric.result()\n",
    "        if batch % 100 == 0:\n",
    "            print('Epoch {} Batch {} Loss {:.4f}'.format(epoch + 1,\n",
    "                                                            batch,\n",
    "                                                            batch_loss.numpy()), end=' ')\n",
    "            print('Perplexity {:.4f}'.format(batch_perplexity))\n",
    "    train_losses.append(batch_loss)\n",
    "    if (epoch + 1) % 5 == 0:\n",
    "        print('saving')\n",
    "        # checkpoint.write(file_prefix=checkpoint_prefix)\n",
    "        checkpoint.step.assign_add(5)\n",
    "        manager.save()\n",
    "        print('saved')\n",
    "    print('Time taken for the epoch {} sec\\n'.format(time.time() - start))\n",
    "best_epoch = np.argmin(train_losses)\n",
    "print('The best epoch is {}'.format(best_epoch))\n",
    "plt.plot(train_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.0005995167"
      ]
     },
     "metadata": {},
     "execution_count": 180
    }
   ],
   "source": [
    "np.min(train_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))"
   ]
  },
  {
   "source": [
    "### Sequence Generation"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_task(task_vector):\n",
    "    # either convert to float32 or encode to categoricals\n",
    "    for i, el in enumerate(task_vector):\n",
    "        try:\n",
    "            task_vector[i] = float(task_vector[i])\n",
    "        except:\n",
    "            task_vector[i] = get_key(cat_encodings[i], task_vector[i])\n",
    "    return task_vector.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_solution(task_vector, save_outputs:bool=False):\n",
    "  attention_plot = np.zeros((max_length_targ, max_length_feat))\n",
    "  task_vector = preprocess_task(task_vector)\n",
    "  inputs = tf.expand_dims(tf.convert_to_tensor(task_vector), axis=0)\n",
    "  result = ''\n",
    "\n",
    "  dec_hidden = tf.zeros((BATCH_SIZE, gru_units))\n",
    "  dec_input = tf.expand_dims([1], 0)\n",
    "  loss = 0\n",
    "  for t in range(max_length_targ):\n",
    "    predictions, dec_hidden = decoder(dec_input\n",
    "                                      , dec_hidden\n",
    "                                      , inputs)\n",
    "    # storing the attention weights to plot later on\n",
    "    # attention_weights = tf.reshape(attention_weights, (-1, ))\n",
    "    # attention_plot[t] = attention_weights.numpy()\n",
    "    predicted_id = tf.argmax(predictions[0]).numpy()\n",
    "    predicted_vertice = get_key(lang, predicted_id)\n",
    "    if (predicted_vertice != ' ')&(predicted_vertice != ''):\n",
    "      # loss += loss_function(true_vector, predictions)\n",
    "      # print(loss)\n",
    "      result = predicted_vertice + ' ' + result #targ_lang.index_word[predicted_id] + ' '\n",
    "    elif (predicted_vertice == '<start>')&(predicted_vertice == '<end>'):\n",
    "      print('Evaluation: found start/end, ending')\n",
    "      return result, task_vector#, attention_plot\n",
    "    \n",
    "    # the predicted ID is fed back into the model\n",
    "    dec_input = tf.expand_dims([predicted_id], 0)\n",
    "  if save_outputs:\n",
    "    OUTPUT_FILE = './task2seq/outputs/output.py'\n",
    "    with open(OUTPUT_FILE, 'w') as f:\n",
    "        last_vertice = ''\n",
    "        for vertice in result.split(' '):\n",
    "            if vertice:\n",
    "                if (vertice!='<start>')&(vertice!='<end>')&(vertice!=last_vertice):\n",
    "                    line = '#@ {} \\n\\n'.format(vertice)\n",
    "                    f.write(line)\n",
    "                    last_vertice = vertice\n",
    "  return result, task_vector#, attention_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# i = 0\n",
    "# example_task_vector = X_test.reset_index(drop=True).loc[i]\n",
    "# example_true_vector = Y_test[i]\n",
    "# example_true_sequence = y_test.loc[i][0]\n",
    "# print('task vector: {} \\n'.format(example_task_vector.values))\n",
    "# print('true sequence is: {}\\n'.format(example_true_sequence))\n",
    "# result, task_vector = generate_solution(example_task_vector)\n",
    "# print(result, '\\n')\n",
    "# print('length of the result sequence is: {} \\n'.format(len(result.split(' '))))"
   ]
  },
  {
   "source": [
    "### Model Evaluation"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rouge_recall(true_string_vector:list, predicted_string_vector:list) -> float:\n",
    "    true_string_vector = [el for el in true_string_vector if el != 0]\n",
    "    # predicted_string_vector = [el for el in predicted_string_vector if el != 0]\n",
    "    n_overlapping_words = len(set(true_string_vector).intersection(set(predicted_string_vector)))\n",
    "    total_words_in_output = len(predicted_string_vector)\n",
    "    return n_overlapping_words / total_words_in_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rouge_precision(true_string_vector:list, predicted_string_vector:list) -> float:\n",
    "    true_string_vector = [el for el in true_string_vector if el != 0]\n",
    "    n_overlapping_words = len(set(true_string_vector).intersection(set(predicted_string_vector)))\n",
    "    total_words_in_reference = len(true_string_vector)\n",
    "    return n_overlapping_words / total_words_in_reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_generated_sequence(generated_sequence_string:str, output_path:str):\n",
    "    # OUTPUT_FILE = './task2seq/outputs/output.py'\n",
    "    with open(output_path, 'w') as f:\n",
    "        last_vertice = ''\n",
    "        for vertice in generated_sequence_string.split(' '):\n",
    "            if vertice:\n",
    "                if (vertice!='<start>')&(vertice!='<end>')&(vertice!=last_vertice):\n",
    "                    line = '#@ {} \\n\\n'.format(vertice)\n",
    "                    f.write(line)\n",
    "                    last_vertice = vertice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_solution_with_evaluation(task_vector, true_sequence:np.array, save_outputs:bool=False):\n",
    "  task_vector = preprocess_task(task_vector)\n",
    "  inputs = tf.expand_dims(tf.convert_to_tensor(task_vector), axis=0)\n",
    "  generated_sequence_string = ''\n",
    "  generated_sequence_array = []\n",
    "  metrics = {}\n",
    "\n",
    "  dec_hidden = tf.zeros((BATCH_SIZE, gru_units))\n",
    "  dec_input = tf.expand_dims([1], 0)\n",
    "  loss = 0\n",
    "  for t in range(max_length_targ):\n",
    "    predictions, dec_hidden = decoder(dec_input\n",
    "                                      , dec_hidden\n",
    "                                      , inputs)\n",
    "    predicted_id = tf.argmax(predictions[0]).numpy()\n",
    "    generated_sequence_array.append(predicted_id)\n",
    "\n",
    "    predicted_vertice = get_key(lang, predicted_id)\n",
    "    if (predicted_vertice != ' ')&(predicted_vertice != ''):\n",
    "        loss += loss_function(true_sequence[t], predictions)\n",
    "        generated_sequence_string = predicted_vertice + ' ' + generated_sequence_string\n",
    "    elif (predicted_vertice == '<start>')&(predicted_vertice == '<end>'):\n",
    "        print('Evaluation: found start/end, ending')\n",
    "        return generated_sequence_string, metrics\n",
    "\n",
    "    dec_input = tf.expand_dims([predicted_id], 0)\n",
    "  metrics.update({\"Cross-Entropy\":loss.numpy(),\n",
    "                \"Perplexity\":tf.exp(loss).numpy(),\n",
    "                \"ROUGE-Recall\":rouge_recall(true_sequence, generated_sequence_array),\n",
    "                \"ROUGE-Precision\": rouge_precision(true_sequence, generated_sequence_array)})\n",
    "  if save_outputs:\n",
    "      TODAY_NOW = datetime.now().strftime(\"%d-%m-%y_%H-%M\")\n",
    "      save_generated_sequence(generated_sequence_string, output_path='./outputs/output_{}.py'.format(TODAY_NOW))\n",
    "  return generated_sequence_string, metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "task vector: [1 2 0 1 1 0 3] \n",
      "\n",
      "true sequence is: load_from_csv load_from_csv show_table show_table show_table show_table_attributes show_table_attributes show_table_attributes show_table_attributes show_table_attributes show_table_attributes count_missing_values count_missing_values data_type_conversions show_table_attributes correct_missing_values categorify correct_missing_values show_table_attributes train_model prepare_x_and_y compute_train_metric compute_test_metric choose_model_class train_model predict_on_train predict_on_train compute_test_metric predict_on_train prepare_x_and_y train_model predict_on_train predict_on_train compute_test_metric predict_on_train save_to_csv show_table show_table_attributes\n",
      "\n",
      "predicted sequence is: train_model train_model train_model train_model train_model train_model train_model train_model train_model train_model train_model train_model train_model train_model train_model train_model train_model train_model train_model train_model train_model train_model train_model train_model train_model train_model train_model train_model train_model train_model train_model train_model train_model train_model train_model train_model train_model train_model train_model train_model train_model train_model train_model train_model train_model train_model train_model train_model train_model train_model train_model train_model train_model train_model train_model train_model train_model train_model train_model train_model train_model train_model train_model train_model train_model train_model train_model train_model train_model train_model train_model train_model train_model train_model train_model train_model train_model train_model train_model train_model train_model train_model train_model train_model train_model train_model <start> <start> import_modules load_from_csv load_from_csv load_from_csv feature_engineering feature_engineering show_table create_dataframe feature_engineering feature_engineering feature_engineering show_table save_to_csv show_table save_to_csv show_table save_to_csv show_table save_to_csv show_table show_table save_to_csv show_table save_to_csv show_table save_to_csv import_modules train_model \n",
      "\n",
      "predicted unique sequence is:  import_modules load_from_csv create_dataframe <start> feature_engineering save_to_csv show_table train_model\n",
      "\n",
      "length of the result sequence is: 117 \n",
      "\n",
      "Metrics: {'Cross-Entropy': 531.2148, 'Perplexity': inf, 'ROUGE-Recall': 0.04310344827586207, 'ROUGE-Precision': 0.125}\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "example_task_vector = X_test.reset_index(drop=True).loc[i]\n",
    "example_true_vector = Y_test[i]\n",
    "example_true_sequence = y_test.loc[i][0]\n",
    "print('task vector: {} \\n'.format(example_task_vector.values))\n",
    "print('true sequence is: {}\\n'.format(example_true_sequence))\n",
    "result, metrics = generate_solution_with_evaluation(example_task_vector, example_true_vector, save_outputs=True)\n",
    "print('predicted sequence is: {}\\n'.format(result))\n",
    "print('predicted unique sequence is: {}\\n'.format(\" \".join(list(set(result.split(' ')))))) #[el for i, el in enumerate(result.split(' ')) if result.split(' ')[i-1] != el])\n",
    "print('length of the result sequence is: {} \\n'.format(len(result.split(' '))))\n",
    "print('Metrics:', metrics)"
   ]
  },
  {
   "source": [],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_on_test(X_test, Y_test):\n",
    "    y_pred = []\n",
    "    losses_ce = []\n",
    "    rouge_recalls = []\n",
    "    rouge_precisions = []\n",
    "    print('predicting..', end=' ')\n",
    "    for i, task_vector in X_test.reset_index(drop=True).iterrows():\n",
    "        print('{:.2%}'.format(i/X_test.shape[0]), end=' ')\n",
    "        true_vector = Y_test[i]\n",
    "        result, metrics = generate_solution_with_evaluation(task_vector, true_vector)\n",
    "        # print(loss.numpy())\n",
    "        y_pred.append(result[:-1])\n",
    "        losses_ce.append(metrics['Cross-Entropy'])\n",
    "        rouge_recalls.append(metrics['ROUGE-Recall'])\n",
    "        rouge_precisions.append(metrics['ROUGE-Precision'])\n",
    "    y_pred = pd.DataFrame(y_pred, columns=[TARGET_COLUMN])\n",
    "    print('Cross-Entropy: {}'.format(np.mean(losses_ce)))\n",
    "    print('Perplexity: {}'.format(np.mean(np.exp(losses_ce))))\n",
    "    print('ROUGE-Recall: {}'.format(np.mean(rouge_recalls)))\n",
    "    print('ROUGE-Precision: {}'.format(np.mean(rouge_precisions)))\n",
    "    print('Unique answers: {}'.format(y_pred[TARGET_COLUMN].nunique()))\n",
    "    return y_pred, losses_ce, rouge_recalls, rouge_precisions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "predicting.. 0.00% 1.85% 3.70% 5.56% 7.41% 9.26% 11.11% 12.96% 14.81% 16.67% 18.52% 20.37% 22.22% 24.07% 25.93% 27.78% 29.63% 31.48% 33.33% 35.19% 37.04% 38.89% 40.74% 42.59% 44.44% 46.30% 48.15% 50.00% 51.85% 53.70% 55.56% 57.41% 59.26% 61.11% 62.96% 64.81% 66.67% 68.52% 70.37% 72.22% 74.07% 75.93% 77.78% 79.63% 81.48% 83.33% 85.19% 87.04% 88.89% 90.74% 92.59% 94.44% 96.30% 98.15% [0.20689655172413793, 0.08620689655172414, 0.017241379310344827, 0.034482758620689655, 0.034482758620689655, 0.06896551724137931, 0.02586206896551724, 0.034482758620689655, 0.04310344827586207, 0.0603448275862069, 0.07758620689655173, 0.017241379310344827, 0.017241379310344827, 0.008620689655172414, 0.02586206896551724, 0.017241379310344827, 0.07758620689655173, 0.017241379310344827, 0.02586206896551724, 0.06896551724137931, 0.05172413793103448, 0.09482758620689655, 0.1896551724137931, 0.12931034482758622, 0.09482758620689655, 0.11206896551724138, 0.09482758620689655, 0.12931034482758622, 0.1206896551724138, 0.04310344827586207, 0.13793103448275862, 0.19827586206896552, 0.13793103448275862, 0.15517241379310345, 0.13793103448275862, 0.04310344827586207, 0.14655172413793102, 0.19827586206896552, 0.16379310344827586, 0.04310344827586207, 0.05172413793103448, 0.3103448275862069, 0.19827586206896552, 0.1724137931034483, 0.19827586206896552, 0.14655172413793102, 0.12931034482758622, 0.0603448275862069, 0.12931034482758622, 0.008620689655172414, 0.008620689655172414, 0.008620689655172414, 0.008620689655172414, 0.05172413793103448] [0.20689655172413793, 0.08620689655172414, 0.017241379310344827, 0.034482758620689655, 0.034482758620689655, 0.06896551724137931, 0.02586206896551724, 0.034482758620689655, 0.04310344827586207, 0.0603448275862069, 0.07758620689655173, 0.017241379310344827, 0.017241379310344827, 0.008620689655172414, 0.02586206896551724, 0.017241379310344827, 0.07758620689655173, 0.017241379310344827, 0.02586206896551724, 0.06896551724137931, 0.05172413793103448, 0.09482758620689655, 0.1896551724137931, 0.12931034482758622, 0.09482758620689655, 0.11206896551724138, 0.09482758620689655, 0.12931034482758622, 0.1206896551724138, 0.04310344827586207, 0.13793103448275862, 0.19827586206896552, 0.13793103448275862, 0.15517241379310345, 0.13793103448275862, 0.04310344827586207, 0.14655172413793102, 0.19827586206896552, 0.16379310344827586, 0.04310344827586207, 0.05172413793103448, 0.3103448275862069, 0.19827586206896552, 0.1724137931034483, 0.19827586206896552, 0.14655172413793102, 0.12931034482758622, 0.0603448275862069, 0.12931034482758622, 0.008620689655172414, 0.008620689655172414, 0.008620689655172414, 0.008620689655172414, 0.05172413793103448]\n",
      "Cross-Entropy: 343.96038818359375\n",
      "Perplexity: inf\n",
      "ROUGE-Recall: 0.09019795657726694\n",
      "ROUGE-Precision: 0.09019795657726694\n",
      "Unique answers: 5\n",
      "<ipython-input-181-2f6d9089d73b>:19: RuntimeWarning: overflow encountered in exp\n",
      "  print('Perplexity: {}'.format(np.mean(np.exp(losses_ce))))\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(                                            vertex_l2\n",
       " 0   <start> <start> find_best_score show_shape sho...\n",
       " 1   load_from_csv show_shape show_table save_to_cs...\n",
       " 2   load_from_csv show_shape show_table save_to_cs...\n",
       " 3   load_from_csv show_shape show_table save_to_cs...\n",
       " 4   load_from_csv show_shape show_table save_to_cs...\n",
       " 5   load_from_csv show_shape show_table save_to_cs...\n",
       " 6   load_from_csv show_shape show_table save_to_cs...\n",
       " 7   load_from_csv show_shape show_table save_to_cs...\n",
       " 8   load_from_csv show_shape show_table save_to_cs...\n",
       " 9   load_from_csv show_shape show_table save_to_cs...\n",
       " 10  load_from_csv show_shape show_table save_to_cs...\n",
       " 11  load_from_csv show_shape show_table save_to_cs...\n",
       " 12  load_from_csv show_shape show_table save_to_cs...\n",
       " 13  load_from_csv show_shape show_table save_to_cs...\n",
       " 14  load_from_csv show_shape show_table save_to_cs...\n",
       " 15  load_from_csv show_shape show_table save_to_cs...\n",
       " 16  load_from_csv show_shape show_table save_to_cs...\n",
       " 17  load_from_csv show_shape show_table save_to_cs...\n",
       " 18  load_from_csv show_shape show_table save_to_cs...\n",
       " 19  load_from_csv show_shape show_table save_to_cs...\n",
       " 20  load_from_csv show_shape show_table save_to_cs...\n",
       " 21  <start> find_best_score show_shape show_table ...\n",
       " 22  <start> find_best_score show_shape show_table ...\n",
       " 23  <start> find_best_score show_shape show_table ...\n",
       " 24  <start> find_best_score show_shape show_table ...\n",
       " 25  <start> find_best_score show_shape show_table ...\n",
       " 26  <start> find_best_score show_shape show_table ...\n",
       " 27  <start> find_best_score show_shape show_table ...\n",
       " 28  <start> find_best_score show_shape show_table ...\n",
       " 29  <start> find_best_score show_shape show_table ...\n",
       " 30  <start> find_best_score show_shape show_table ...\n",
       " 31  <start> find_best_score show_shape show_table ...\n",
       " 32  <start> find_best_score show_shape show_table ...\n",
       " 33  <start> find_best_score show_shape show_table ...\n",
       " 34  <start> find_best_score show_shape show_table ...\n",
       " 35  <start> find_best_score show_shape show_table ...\n",
       " 36  <start> find_best_score show_shape show_table ...\n",
       " 37  <start> find_best_score show_shape show_table ...\n",
       " 38  <start> find_best_score show_shape show_table ...\n",
       " 39  <start> find_best_score show_shape show_table ...\n",
       " 40  <start> find_best_score show_shape show_table ...\n",
       " 41  <start> find_best_score show_shape show_table ...\n",
       " 42  <start> find_best_score show_shape show_table ...\n",
       " 43  <start> find_best_score show_shape show_table ...\n",
       " 44  <start> find_best_score show_shape show_table ...\n",
       " 45  <start> find_best_score show_shape show_table ...\n",
       " 46  <start> find_best_score show_shape show_table ...\n",
       " 47  <start> find_best_score show_shape show_table ...\n",
       " 48  <start> find_best_score show_shape show_table ...\n",
       " 49  train_model train_model train_model train_mode...\n",
       " 50  train_model train_model train_model train_mode...\n",
       " 51  train_model train_model train_model train_mode...\n",
       " 52  train_model train_model train_model train_mode...\n",
       " 53  distribution distribution distribution prepare...,\n",
       " [952.03314,\n",
       "  197.89444,\n",
       "  39.321144,\n",
       "  91.642914,\n",
       "  88.00485,\n",
       "  380.08588,\n",
       "  121.21387,\n",
       "  194.52138,\n",
       "  171.69191,\n",
       "  483.71115,\n",
       "  453.18658,\n",
       "  63.68406,\n",
       "  316.8298,\n",
       "  91.58274,\n",
       "  104.37561,\n",
       "  50.438484,\n",
       "  208.7148,\n",
       "  78.04946,\n",
       "  48.7191,\n",
       "  178.51593,\n",
       "  167.9986,\n",
       "  389.66483,\n",
       "  1390.206,\n",
       "  421.90607,\n",
       "  200.35564,\n",
       "  252.1656,\n",
       "  321.14032,\n",
       "  600.459,\n",
       "  748.11,\n",
       "  130.21548,\n",
       "  569.74023,\n",
       "  1114.4742,\n",
       "  675.6986,\n",
       "  960.76074,\n",
       "  430.70206,\n",
       "  233.16454,\n",
       "  363.11893,\n",
       "  760.58905,\n",
       "  586.4523,\n",
       "  79.51807,\n",
       "  52.74024,\n",
       "  1.9489123,\n",
       "  640.1099,\n",
       "  540.12494,\n",
       "  759.77313,\n",
       "  325.76248,\n",
       "  330.0816,\n",
       "  197.89917,\n",
       "  327.8409,\n",
       "  113.993,\n",
       "  136.24304,\n",
       "  222.67148,\n",
       "  104.263626,\n",
       "  109.75239],\n",
       " [0.20689655172413793,\n",
       "  0.08620689655172414,\n",
       "  0.017241379310344827,\n",
       "  0.034482758620689655,\n",
       "  0.034482758620689655,\n",
       "  0.06896551724137931,\n",
       "  0.02586206896551724,\n",
       "  0.034482758620689655,\n",
       "  0.04310344827586207,\n",
       "  0.0603448275862069,\n",
       "  0.07758620689655173,\n",
       "  0.017241379310344827,\n",
       "  0.017241379310344827,\n",
       "  0.008620689655172414,\n",
       "  0.02586206896551724,\n",
       "  0.017241379310344827,\n",
       "  0.07758620689655173,\n",
       "  0.017241379310344827,\n",
       "  0.02586206896551724,\n",
       "  0.06896551724137931,\n",
       "  0.05172413793103448,\n",
       "  0.09482758620689655,\n",
       "  0.1896551724137931,\n",
       "  0.12931034482758622,\n",
       "  0.09482758620689655,\n",
       "  0.11206896551724138,\n",
       "  0.09482758620689655,\n",
       "  0.12931034482758622,\n",
       "  0.1206896551724138,\n",
       "  0.04310344827586207,\n",
       "  0.13793103448275862,\n",
       "  0.19827586206896552,\n",
       "  0.13793103448275862,\n",
       "  0.15517241379310345,\n",
       "  0.13793103448275862,\n",
       "  0.04310344827586207,\n",
       "  0.14655172413793102,\n",
       "  0.19827586206896552,\n",
       "  0.16379310344827586,\n",
       "  0.04310344827586207,\n",
       "  0.05172413793103448,\n",
       "  0.3103448275862069,\n",
       "  0.19827586206896552,\n",
       "  0.1724137931034483,\n",
       "  0.19827586206896552,\n",
       "  0.14655172413793102,\n",
       "  0.12931034482758622,\n",
       "  0.0603448275862069,\n",
       "  0.12931034482758622,\n",
       "  0.008620689655172414,\n",
       "  0.008620689655172414,\n",
       "  0.008620689655172414,\n",
       "  0.008620689655172414,\n",
       "  0.05172413793103448],\n",
       " [0.20689655172413793,\n",
       "  0.08620689655172414,\n",
       "  0.017241379310344827,\n",
       "  0.034482758620689655,\n",
       "  0.034482758620689655,\n",
       "  0.06896551724137931,\n",
       "  0.02586206896551724,\n",
       "  0.034482758620689655,\n",
       "  0.04310344827586207,\n",
       "  0.0603448275862069,\n",
       "  0.07758620689655173,\n",
       "  0.017241379310344827,\n",
       "  0.017241379310344827,\n",
       "  0.008620689655172414,\n",
       "  0.02586206896551724,\n",
       "  0.017241379310344827,\n",
       "  0.07758620689655173,\n",
       "  0.017241379310344827,\n",
       "  0.02586206896551724,\n",
       "  0.06896551724137931,\n",
       "  0.05172413793103448,\n",
       "  0.09482758620689655,\n",
       "  0.1896551724137931,\n",
       "  0.12931034482758622,\n",
       "  0.09482758620689655,\n",
       "  0.11206896551724138,\n",
       "  0.09482758620689655,\n",
       "  0.12931034482758622,\n",
       "  0.1206896551724138,\n",
       "  0.04310344827586207,\n",
       "  0.13793103448275862,\n",
       "  0.19827586206896552,\n",
       "  0.13793103448275862,\n",
       "  0.15517241379310345,\n",
       "  0.13793103448275862,\n",
       "  0.04310344827586207,\n",
       "  0.14655172413793102,\n",
       "  0.19827586206896552,\n",
       "  0.16379310344827586,\n",
       "  0.04310344827586207,\n",
       "  0.05172413793103448,\n",
       "  0.3103448275862069,\n",
       "  0.19827586206896552,\n",
       "  0.1724137931034483,\n",
       "  0.19827586206896552,\n",
       "  0.14655172413793102,\n",
       "  0.12931034482758622,\n",
       "  0.0603448275862069,\n",
       "  0.12931034482758622,\n",
       "  0.008620689655172414,\n",
       "  0.008620689655172414,\n",
       "  0.008620689655172414,\n",
       "  0.008620689655172414,\n",
       "  0.05172413793103448])"
      ]
     },
     "metadata": {},
     "execution_count": 182
    }
   ],
   "source": [
    "## Predict on Train\n",
    "predict_on_test(X_train[TASK_FEATURES], Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "predicting.. 0.00% 1.69% 3.39% 5.08% 6.78% 8.47% 10.17% 11.86% 13.56% 15.25% 16.95% 18.64% 20.34% 22.03% 23.73% 25.42% 27.12% 28.81% 30.51% 32.20% 33.90% 35.59% 37.29% 38.98% 40.68% 42.37% 44.07% 45.76% 47.46% 49.15% 50.85% 52.54% 54.24% 55.93% 57.63% 59.32% 61.02% 62.71% 64.41% 66.10% 67.80% 69.49% 71.19% 72.88% 74.58% 76.27% 77.97% 79.66% 81.36% 83.05% 84.75% 86.44% 88.14% 89.83% 91.53% 93.22% 94.92% 96.61% 98.31% [0.04310344827586207, 0.02586206896551724, 0.05172413793103448, 0.02586206896551724, 0.05172413793103448, 0.017241379310344827, 0.04310344827586207, 0.034482758620689655, 0.06896551724137931, 0.0603448275862069, 0.0603448275862069, 0.04310344827586207, 0.06896551724137931, 0.05172413793103448, 0.04310344827586207, 0.034482758620689655, 0.0603448275862069, 0.05172413793103448, 0.06896551724137931, 0.02586206896551724, 0.034482758620689655, 0.04310344827586207, 0.05172413793103448, 0.06896551724137931, 0.04310344827586207, 0.04310344827586207, 0.06896551724137931, 0.017241379310344827, 0.05172413793103448, 0.06896551724137931, 0.0603448275862069, 0.06896551724137931, 0.034482758620689655, 0.06896551724137931, 0.02586206896551724, 0.04310344827586207, 0.05172413793103448, 0.017241379310344827, 0.02586206896551724, 0.017241379310344827, 0.0603448275862069, 0.07758620689655173, 0.08620689655172414, 0.10344827586206896, 0.09482758620689655, 0.1206896551724138, 0.07758620689655173, 0.06896551724137931, 0.08620689655172414, 0.1206896551724138, 0.09482758620689655, 0.11206896551724138, 0.11206896551724138, 0.09482758620689655, 0.11206896551724138, 0.11206896551724138, 0.12931034482758622, 0.1206896551724138, 0.06896551724137931] [0.04310344827586207, 0.02586206896551724, 0.05172413793103448, 0.02586206896551724, 0.05172413793103448, 0.017241379310344827, 0.04310344827586207, 0.034482758620689655, 0.06896551724137931, 0.0603448275862069, 0.0603448275862069, 0.04310344827586207, 0.06896551724137931, 0.05172413793103448, 0.04310344827586207, 0.034482758620689655, 0.0603448275862069, 0.05172413793103448, 0.06896551724137931, 0.02586206896551724, 0.034482758620689655, 0.04310344827586207, 0.05172413793103448, 0.06896551724137931, 0.04310344827586207, 0.04310344827586207, 0.06896551724137931, 0.017241379310344827, 0.05172413793103448, 0.06896551724137931, 0.0603448275862069, 0.06896551724137931, 0.034482758620689655, 0.06896551724137931, 0.02586206896551724, 0.04310344827586207, 0.05172413793103448, 0.017241379310344827, 0.02586206896551724, 0.017241379310344827, 0.0603448275862069, 0.07758620689655173, 0.08620689655172414, 0.10344827586206896, 0.09482758620689655, 0.1206896551724138, 0.07758620689655173, 0.06896551724137931, 0.08620689655172414, 0.1206896551724138, 0.09482758620689655, 0.11206896551724138, 0.11206896551724138, 0.09482758620689655, 0.11206896551724138, 0.11206896551724138, 0.12931034482758622, 0.1206896551724138, 0.06896551724137931]\n",
      "Cross-Entropy: 375.2212219238281\n",
      "Perplexity: inf\n",
      "ROUGE-Recall: 0.0625365283459965\n",
      "ROUGE-Precision: 0.0625365283459965\n",
      "Unique answers: 2\n",
      "<ipython-input-181-2f6d9089d73b>:19: RuntimeWarning: overflow encountered in exp\n",
      "  print('Perplexity: {}'.format(np.mean(np.exp(losses_ce))))\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(                                            vertex_l2\n",
       " 0   train_model train_model train_model train_mode...\n",
       " 1   train_model train_model train_model train_mode...\n",
       " 2   train_model train_model train_model train_mode...\n",
       " 3   train_model train_model train_model train_mode...\n",
       " 4   train_model train_model train_model train_mode...\n",
       " 5   train_model train_model train_model train_mode...\n",
       " 6   train_model train_model train_model train_mode...\n",
       " 7   train_model train_model train_model train_mode...\n",
       " 8   train_model train_model train_model train_mode...\n",
       " 9   train_model train_model train_model train_mode...\n",
       " 10  train_model train_model train_model train_mode...\n",
       " 11  train_model train_model train_model train_mode...\n",
       " 12  train_model train_model train_model train_mode...\n",
       " 13  train_model train_model train_model train_mode...\n",
       " 14  train_model train_model train_model train_mode...\n",
       " 15  train_model train_model train_model train_mode...\n",
       " 16  train_model train_model train_model train_mode...\n",
       " 17  train_model train_model train_model train_mode...\n",
       " 18  train_model train_model train_model train_mode...\n",
       " 19  train_model train_model train_model train_mode...\n",
       " 20  train_model train_model train_model train_mode...\n",
       " 21  train_model train_model train_model train_mode...\n",
       " 22  train_model train_model train_model train_mode...\n",
       " 23  train_model train_model train_model train_mode...\n",
       " 24  train_model train_model train_model train_mode...\n",
       " 25  train_model train_model train_model train_mode...\n",
       " 26  train_model train_model train_model train_mode...\n",
       " 27  train_model train_model train_model train_mode...\n",
       " 28  train_model train_model train_model train_mode...\n",
       " 29  train_model train_model train_model train_mode...\n",
       " 30  train_model train_model train_model train_mode...\n",
       " 31  train_model train_model train_model train_mode...\n",
       " 32  train_model train_model train_model train_mode...\n",
       " 33  train_model train_model train_model train_mode...\n",
       " 34  train_model train_model train_model train_mode...\n",
       " 35  train_model train_model train_model train_mode...\n",
       " 36  train_model train_model train_model train_mode...\n",
       " 37  train_model train_model train_model train_mode...\n",
       " 38  train_model train_model train_model train_mode...\n",
       " 39  train_model train_model train_model train_mode...\n",
       " 40  count_values categorify count_values categorif...\n",
       " 41  count_values categorify count_values categorif...\n",
       " 42  count_values categorify count_values categorif...\n",
       " 43  count_values categorify count_values categorif...\n",
       " 44  count_values categorify count_values categorif...\n",
       " 45  count_values categorify count_values categorif...\n",
       " 46  count_values categorify count_values categorif...\n",
       " 47  count_values categorify count_values categorif...\n",
       " 48  count_values categorify count_values categorif...\n",
       " 49  count_values categorify count_values categorif...\n",
       " 50  count_values categorify count_values categorif...\n",
       " 51  count_values categorify count_values categorif...\n",
       " 52  count_values categorify count_values categorif...\n",
       " 53  count_values categorify count_values categorif...\n",
       " 54  count_values categorify count_values categorif...\n",
       " 55  count_values categorify count_values categorif...\n",
       " 56  count_values categorify count_values categorif...\n",
       " 57  count_values categorify count_values categorif...\n",
       " 58  count_values categorify count_values categorif...,\n",
       " [531.2148,\n",
       "  53.39046,\n",
       "  330.3352,\n",
       "  32.748077,\n",
       "  585.54315,\n",
       "  20.57131,\n",
       "  131.3067,\n",
       "  72.72957,\n",
       "  299.26636,\n",
       "  560.88,\n",
       "  120.391815,\n",
       "  180.45978,\n",
       "  390.8477,\n",
       "  698.17664,\n",
       "  290.7346,\n",
       "  153.60907,\n",
       "  315.72266,\n",
       "  560.8147,\n",
       "  499.77682,\n",
       "  97.540085,\n",
       "  31.732553,\n",
       "  383.47614,\n",
       "  865.70233,\n",
       "  545.70105,\n",
       "  138.22406,\n",
       "  585.0104,\n",
       "  951.1064,\n",
       "  20.57131,\n",
       "  228.26352,\n",
       "  848.9294,\n",
       "  1024.6034,\n",
       "  942.84863,\n",
       "  109.26875,\n",
       "  563.7438,\n",
       "  23.597767,\n",
       "  165.0914,\n",
       "  379.557,\n",
       "  20.57131,\n",
       "  27.760576,\n",
       "  20.57131,\n",
       "  144.0764,\n",
       "  178.58282,\n",
       "  266.68732,\n",
       "  573.1706,\n",
       "  340.10165,\n",
       "  447.89746,\n",
       "  428.84247,\n",
       "  317.85107,\n",
       "  210.00961,\n",
       "  470.76688,\n",
       "  261.42477,\n",
       "  434.95685,\n",
       "  238.97105,\n",
       "  493.7919,\n",
       "  529.3928,\n",
       "  1089.407,\n",
       "  742.8516,\n",
       "  603.21893,\n",
       "  563.6612],\n",
       " [0.04310344827586207,\n",
       "  0.02586206896551724,\n",
       "  0.05172413793103448,\n",
       "  0.02586206896551724,\n",
       "  0.05172413793103448,\n",
       "  0.017241379310344827,\n",
       "  0.04310344827586207,\n",
       "  0.034482758620689655,\n",
       "  0.06896551724137931,\n",
       "  0.0603448275862069,\n",
       "  0.0603448275862069,\n",
       "  0.04310344827586207,\n",
       "  0.06896551724137931,\n",
       "  0.05172413793103448,\n",
       "  0.04310344827586207,\n",
       "  0.034482758620689655,\n",
       "  0.0603448275862069,\n",
       "  0.05172413793103448,\n",
       "  0.06896551724137931,\n",
       "  0.02586206896551724,\n",
       "  0.034482758620689655,\n",
       "  0.04310344827586207,\n",
       "  0.05172413793103448,\n",
       "  0.06896551724137931,\n",
       "  0.04310344827586207,\n",
       "  0.04310344827586207,\n",
       "  0.06896551724137931,\n",
       "  0.017241379310344827,\n",
       "  0.05172413793103448,\n",
       "  0.06896551724137931,\n",
       "  0.0603448275862069,\n",
       "  0.06896551724137931,\n",
       "  0.034482758620689655,\n",
       "  0.06896551724137931,\n",
       "  0.02586206896551724,\n",
       "  0.04310344827586207,\n",
       "  0.05172413793103448,\n",
       "  0.017241379310344827,\n",
       "  0.02586206896551724,\n",
       "  0.017241379310344827,\n",
       "  0.0603448275862069,\n",
       "  0.07758620689655173,\n",
       "  0.08620689655172414,\n",
       "  0.10344827586206896,\n",
       "  0.09482758620689655,\n",
       "  0.1206896551724138,\n",
       "  0.07758620689655173,\n",
       "  0.06896551724137931,\n",
       "  0.08620689655172414,\n",
       "  0.1206896551724138,\n",
       "  0.09482758620689655,\n",
       "  0.11206896551724138,\n",
       "  0.11206896551724138,\n",
       "  0.09482758620689655,\n",
       "  0.11206896551724138,\n",
       "  0.11206896551724138,\n",
       "  0.12931034482758622,\n",
       "  0.1206896551724138,\n",
       "  0.06896551724137931],\n",
       " [0.04310344827586207,\n",
       "  0.02586206896551724,\n",
       "  0.05172413793103448,\n",
       "  0.02586206896551724,\n",
       "  0.05172413793103448,\n",
       "  0.017241379310344827,\n",
       "  0.04310344827586207,\n",
       "  0.034482758620689655,\n",
       "  0.06896551724137931,\n",
       "  0.0603448275862069,\n",
       "  0.0603448275862069,\n",
       "  0.04310344827586207,\n",
       "  0.06896551724137931,\n",
       "  0.05172413793103448,\n",
       "  0.04310344827586207,\n",
       "  0.034482758620689655,\n",
       "  0.0603448275862069,\n",
       "  0.05172413793103448,\n",
       "  0.06896551724137931,\n",
       "  0.02586206896551724,\n",
       "  0.034482758620689655,\n",
       "  0.04310344827586207,\n",
       "  0.05172413793103448,\n",
       "  0.06896551724137931,\n",
       "  0.04310344827586207,\n",
       "  0.04310344827586207,\n",
       "  0.06896551724137931,\n",
       "  0.017241379310344827,\n",
       "  0.05172413793103448,\n",
       "  0.06896551724137931,\n",
       "  0.0603448275862069,\n",
       "  0.06896551724137931,\n",
       "  0.034482758620689655,\n",
       "  0.06896551724137931,\n",
       "  0.02586206896551724,\n",
       "  0.04310344827586207,\n",
       "  0.05172413793103448,\n",
       "  0.017241379310344827,\n",
       "  0.02586206896551724,\n",
       "  0.017241379310344827,\n",
       "  0.0603448275862069,\n",
       "  0.07758620689655173,\n",
       "  0.08620689655172414,\n",
       "  0.10344827586206896,\n",
       "  0.09482758620689655,\n",
       "  0.1206896551724138,\n",
       "  0.07758620689655173,\n",
       "  0.06896551724137931,\n",
       "  0.08620689655172414,\n",
       "  0.1206896551724138,\n",
       "  0.09482758620689655,\n",
       "  0.11206896551724138,\n",
       "  0.11206896551724138,\n",
       "  0.09482758620689655,\n",
       "  0.11206896551724138,\n",
       "  0.11206896551724138,\n",
       "  0.12931034482758622,\n",
       "  0.1206896551724138,\n",
       "  0.06896551724137931])"
      ]
     },
     "metadata": {},
     "execution_count": 183
    }
   ],
   "source": [
    "## Predict on Test\n",
    "predict_on_test(X_test[TASK_FEATURES], Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred[TARGET_COLUMN].unique()"
   ]
  },
  {
   "source": [
    "---\n",
    "## To Do"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##TODO: To py and argparse"
   ]
  },
  {
   "source": [
    "### To DAGsHub"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##TODO: Export to DAGsHub\n",
    "experiment_params = run_params.update(model_params).update(data_params)\n",
    "print(experiment_params)\n",
    "# experiment_results = {}"
   ]
  }
 ]
}