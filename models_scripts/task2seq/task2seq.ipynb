{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python385jvsc74a57bd0d0ddd292140de7144a2e52e7cfaaa287bc93c7991ea231311f4a8d4f39ae4756",
   "display_name": "Python 3.8.5 64-bit ('base': conda)"
  },
  "metadata": {
   "interpreter": {
    "hash": "0de36b31320ba4c88b4f85a74724f3d16c36a44df48581253710b1065e752d9e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import gc\n",
    "from datetime import datetime\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import backend as K\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import log_loss\n",
    "from sqlalchemy import create_engine\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('mode.chained_assignment', None)"
   ]
  },
  {
   "source": [
    "### Defining Methods"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_key(my_dict, val):\n",
    "    for key, value in my_dict.items():\n",
    "         if val == value:\n",
    "             return key\n",
    " \n",
    "    return \"key doesn't exist\""
   ]
  },
  {
   "source": [
    "### Reading Data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "---"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Index(['graph_vertex_id', 'graph_vertex', 'graph_vertex_subclass'], dtype='object')"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "graph_path = '../../data/actual_graph_2021-05-22.csv'\n",
    "graph = pd.read_csv(graph_path)\n",
    "graph.rename({'id':'graph_vertex_id'}, axis=1, inplace=True)\n",
    "graph.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(266, 8)"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "COMPETITIONS_PATH = \"../../data/competitions_info_cleaned_filled.csv\" #./data/competitions_info_cleaned.csv\n",
    "competitions_filled = pd.read_csv(COMPETITIONS_PATH)\n",
    "competitions_filled.drop_duplicates(inplace=True)\n",
    "competitions_filled.rename({'Description': 'description', 'Metric':'metric', 'DataType':'datatype', 'Subject':'subject', 'ProblemType':'problemtype'}\n",
    "                        , axis=1, inplace=True)\n",
    "competitions_filled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "ref             0\n",
       "comp_name       0\n",
       "comp_type       0\n",
       "description    21\n",
       "metric         19\n",
       "datatype       19\n",
       "subject        19\n",
       "problemtype    19\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "competitions_filled.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "competitions_filled['ref'] = competitions_filled['ref'].str.replace(\"'\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(5060, 10)"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "COMPETITIONS_PATH = \"../../data/competitions_2021-05-22.csv\" #./data/competitions_info_cleaned.csv\n",
    "competitions = pd.read_csv(COMPETITIONS_PATH)\n",
    "competitions.drop_duplicates(inplace=True)\n",
    "competitions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# competitions['ref'] = competitions['ref'].apply(lambda x: x.split(',')[0])\n",
    "# competitions['ref'] = competitions['ref'].str.replace(\"'\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# competitions['exists_in_comp_filled'] = competitions.apply(lambda x: x['ref'] in competitions_filled['ref'].unique(), axis=1)\n",
    "# competitions['exists_in_comp_filled'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# competitions_filled.merge(competitions[['id', 'ref']], on=['ref']).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(312, 10)"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "competitions = competitions_filled.merge(competitions[['id', 'ref_link']], how='inner', left_on=['ref'], right_on=['ref_link'])\n",
    "competitions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "ref             0\n",
       "comp_name       0\n",
       "comp_type       0\n",
       "description    26\n",
       "metric         23\n",
       "datatype       23\n",
       "subject        23\n",
       "problemtype    23\n",
       "id              0\n",
       "ref_link        0\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "competitions.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   code_block_id                                         code_block  \\\n",
       "0         570367  `# My forecasting COVID-19 confirmed cases and...   \n",
       "1         570367  `# My forecasting COVID-19 confirmed cases and...   \n",
       "2         570368  `# load training and testing data \\nsubm = pd....   \n",
       "3         570369                                             `subm`   \n",
       "4         570367  `# My forecasting COVID-19 confirmed cases and...   \n",
       "\n",
       "  data_format  graph_vertex_id errors  marks  kaggle_id  competition_id  \n",
       "0       Table               45     No      2    8591010            3868  \n",
       "1       Table               45     No      2    8591010            3868  \n",
       "2       Table               45     No      5    8591010            3868  \n",
       "3       Table               41     No      5    8591010            3868  \n",
       "4       Table               45     No      2    8591010            3868  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>code_block_id</th>\n      <th>code_block</th>\n      <th>data_format</th>\n      <th>graph_vertex_id</th>\n      <th>errors</th>\n      <th>marks</th>\n      <th>kaggle_id</th>\n      <th>competition_id</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>570367</td>\n      <td>`# My forecasting COVID-19 confirmed cases and...</td>\n      <td>Table</td>\n      <td>45</td>\n      <td>No</td>\n      <td>2</td>\n      <td>8591010</td>\n      <td>3868</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>570367</td>\n      <td>`# My forecasting COVID-19 confirmed cases and...</td>\n      <td>Table</td>\n      <td>45</td>\n      <td>No</td>\n      <td>2</td>\n      <td>8591010</td>\n      <td>3868</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>570368</td>\n      <td>`# load training and testing data \\nsubm = pd....</td>\n      <td>Table</td>\n      <td>45</td>\n      <td>No</td>\n      <td>5</td>\n      <td>8591010</td>\n      <td>3868</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>570369</td>\n      <td>`subm`</td>\n      <td>Table</td>\n      <td>41</td>\n      <td>No</td>\n      <td>5</td>\n      <td>8591010</td>\n      <td>3868</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>570367</td>\n      <td>`# My forecasting COVID-19 confirmed cases and...</td>\n      <td>Table</td>\n      <td>45</td>\n      <td>No</td>\n      <td>2</td>\n      <td>8591010</td>\n      <td>3868</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "NOTEBOOKS_PATH = '../../data/markup_data_2021-05-22.csv'\n",
    "notebooks = pd.read_csv(NOTEBOOKS_PATH)\n",
    "notebooks.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(5932, 10)"
      ]
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "source": [
    "notebooks = notebooks.merge(graph, on='graph_vertex_id', how='left')\n",
    "notebooks.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "3207\n3110\n"
     ]
    }
   ],
   "source": [
    "nl2ml = notebooks.merge(competitions, left_on=['competition_id'], right_on=['id'], how='inner')\n",
    "print(nl2ml.shape[0])\n",
    "nl2ml.drop_duplicates(inplace=True, subset=['code_block_id', 'kaggle_id'])\n",
    "print(nl2ml.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "113 7\n"
     ]
    }
   ],
   "source": [
    "print(nl2ml['kaggle_id'].nunique(), nl2ml['competition_id'].nunique())"
   ]
  },
  {
   "source": [
    "### Vertices Preprocessing"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Data_Transform          936\n",
       "EDA                     747\n",
       "Model_Train             287\n",
       "Visualization           281\n",
       "Environment             202\n",
       "Data_Extraction         167\n",
       "Other                   147\n",
       "Hyperparam_Tuning       120\n",
       "Data_Export             104\n",
       "Model_Evaluation         95\n",
       "Model_Interpretation     21\n",
       "Hypothesis                3\n",
       "Name: graph_vertex, dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "source": [
    "nl2ml['graph_vertex'].apply(lambda x: x.split(';')[0].split('.')[0]).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Index(['code_block_id', 'code_block', 'data_format', 'graph_vertex_id',\n",
       "       'errors', 'marks', 'kaggle_id', 'competition_id', 'graph_vertex',\n",
       "       'graph_vertex_subclass', 'ref', 'comp_name', 'comp_type', 'description',\n",
       "       'metric', 'datatype', 'subject', 'problemtype', 'id', 'ref_link'],\n",
       "      dtype='object')"
      ]
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "source": [
    "nl2ml.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "nl2ml['vertex_l1'], nl2ml['vertex_l2'] = nl2ml['graph_vertex'].apply(lambda x: x.split(';')[0].split('.')[0]), nl2ml['graph_vertex_subclass']#.apply(lambda x: x.split(';')[0].split('.')[1])"
   ]
  },
  {
   "source": [
    "### Missing Values"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "code_block_id            0\ncode_block               0\ndata_format              0\ngraph_vertex_id          0\nerrors                   0\nmarks                    0\nkaggle_id                0\ncompetition_id           0\ngraph_vertex             0\ngraph_vertex_subclass    0\nref                      0\ncomp_name                0\ncomp_type                0\ndescription              0\nmetric                   0\ndatatype                 0\nsubject                  0\nproblemtype              0\nid                       0\nref_link                 0\nvertex_l1                0\nvertex_l2                0\ndtype: int64\ncode_block_id            0\ncode_block               0\ndata_format              0\ngraph_vertex_id          0\nerrors                   0\nmarks                    0\nkaggle_id                0\ncompetition_id           0\ngraph_vertex             0\ngraph_vertex_subclass    0\nref                      0\ncomp_name                0\ncomp_type                0\ndescription              0\nmetric                   0\ndatatype                 0\nsubject                  0\nproblemtype              0\nid                       0\nref_link                 0\nvertex_l1                0\nvertex_l2                0\ndtype: int64\n"
     ]
    }
   ],
   "source": [
    "nl2ml.replace('-', -1, inplace=True)\n",
    "print(nl2ml.isna().sum())\n",
    "nl2ml.fillna(-1, inplace=True)\n",
    "print(nl2ml.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "TASK_FEATURES = ['comp_name', 'comp_type', 'description',\n",
    "                'metric', 'datatype', 'subject', 'problemtype']\n",
    "# TASK_FEATURES = ['ProblemType',\n",
    "#                 'number of columns (for tabular)', 'number of entries',\n",
    "#                 'LabelType', 'Number of classes', 'Loss Function/Metrics',\n",
    "#                 'Target Column(s) Name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET_COLUMN = 'vertex_l2'"
   ]
  },
  {
   "source": [
    "### Grouping chunks by notebooks"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "notebook_id_col = 'kaggle_id'\n",
    "competition_id_col = 'competition_id'\n",
    "def group_by_notebooks(data:pd.DataFrame, vertex_col:str='vertex_l1') -> pd.DataFrame:\n",
    "    notebook_cols = [[notebook_id_col, vertex_col, competition_id_col] + TASK_FEATURES]\n",
    "    df = pd.DataFrame(columns=notebook_cols)\n",
    "    for i, notebook_id in enumerate(data[notebook_id_col].unique()):\n",
    "        notebook = data[data[notebook_id_col] == notebook_id].reset_index(drop=True)\n",
    "        vertices_seq = \" \".join(notebook[vertex_col])\n",
    "        task_features = notebook[TASK_FEATURES].loc[0]\n",
    "        competition_id = notebook[competition_id_col].unique()[0]\n",
    "        row = [notebook_id, vertices_seq, competition_id] + task_features.tolist()\n",
    "        df.loc[i] = row\n",
    "        print('notebook #{} done'.format(notebook_id))\n",
    "    return df"
   ]
  },
  {
   "source": [
    "### Taking Train Features"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "notebook #8591010 done\n",
      "notebook #8592598 done\n",
      "notebook #8596735 done\n",
      "notebook #8606894 done\n",
      "notebook #8609050 done\n",
      "notebook #8611767 done\n",
      "notebook #8630977 done\n",
      "notebook #8634286 done\n",
      "notebook #8640194 done\n",
      "notebook #8660923 done\n",
      "notebook #8667455 done\n",
      "notebook #8668446 done\n",
      "notebook #8678201 done\n",
      "notebook #8687334 done\n",
      "notebook #8689318 done\n",
      "notebook #8699382 done\n",
      "notebook #8705213 done\n",
      "notebook #8706858 done\n",
      "notebook #8708118 done\n",
      "notebook #8710137 done\n",
      "notebook #8710362 done\n",
      "notebook #8604602 done\n",
      "notebook #8617043 done\n",
      "notebook #8620454 done\n",
      "notebook #8625834 done\n",
      "notebook #8628909 done\n",
      "notebook #8658083 done\n",
      "notebook #8663175 done\n",
      "notebook #8671133 done\n",
      "notebook #8679319 done\n",
      "notebook #8682800 done\n",
      "notebook #8687249 done\n",
      "notebook #8693806 done\n",
      "notebook #8701862 done\n",
      "notebook #8702904 done\n",
      "notebook #8706295 done\n",
      "notebook #8711165 done\n",
      "notebook #9326374 done\n",
      "notebook #9349764 done\n",
      "notebook #9463384 done\n",
      "notebook #138832 done\n",
      "notebook #2637869 done\n",
      "notebook #5466844 done\n",
      "notebook #5729566 done\n",
      "notebook #6470191 done\n",
      "notebook #8382140 done\n",
      "notebook #9655329 done\n",
      "notebook #10424951 done\n",
      "notebook #10522332 done\n",
      "notebook #10702707 done\n",
      "notebook #10913030 done\n",
      "notebook #11097956 done\n",
      "notebook #11410370 done\n",
      "notebook #11611498 done\n",
      "notebook #11656525 done\n",
      "notebook #12034947 done\n",
      "notebook #12343159 done\n",
      "notebook #13503938 done\n",
      "notebook #14177670 done\n",
      "notebook #171635 done\n",
      "notebook #2843645 done\n",
      "notebook #2846432 done\n",
      "notebook #2874738 done\n",
      "notebook #2894439 done\n",
      "notebook #2895967 done\n",
      "notebook #2897818 done\n",
      "notebook #2942474 done\n",
      "notebook #3001116 done\n",
      "notebook #3065122 done\n",
      "notebook #3127294 done\n",
      "notebook #3155308 done\n",
      "notebook #3308267 done\n",
      "notebook #3338077 done\n",
      "notebook #3412975 done\n",
      "notebook #3424825 done\n",
      "notebook #3544896 done\n",
      "notebook #3577796 done\n",
      "notebook #3640289 done\n",
      "notebook #3663832 done\n",
      "notebook #11400829 done\n",
      "notebook #24315 done\n",
      "notebook #242408 done\n",
      "notebook #243149 done\n",
      "notebook #244547 done\n",
      "notebook #244742 done\n",
      "notebook #244890 done\n",
      "notebook #244905 done\n",
      "notebook #244962 done\n",
      "notebook #245675 done\n",
      "notebook #874590 done\n",
      "notebook #1140262 done\n",
      "notebook #2095107 done\n",
      "notebook #3237641 done\n",
      "notebook #3674829 done\n",
      "notebook #4029935 done\n",
      "notebook #6511394 done\n",
      "notebook #6511397 done\n",
      "notebook #6511403 done\n",
      "notebook #6511414 done\n",
      "notebook #6511456 done\n",
      "notebook #6511492 done\n",
      "notebook #6518412 done\n",
      "notebook #7004483 done\n",
      "notebook #7465372 done\n",
      "notebook #7859060 done\n",
      "notebook #8648443 done\n",
      "notebook #9904611 done\n",
      "notebook #11013798 done\n",
      "notebook #3389306 done\n",
      "notebook #3414311 done\n",
      "notebook #4374092 done\n",
      "notebook #10307360 done\n",
      "notebook #3344044 done\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(113, 10)"
      ]
     },
     "metadata": {},
     "execution_count": 25
    }
   ],
   "source": [
    "# nl2ml = group_by_notebooks(nl2ml, TARGET_COLUMN)\n",
    "# X, y = train[TASK_FEATURES], train[TARGET_COLUMN]\n",
    "prepared_data = group_by_notebooks(nl2ml, TARGET_COLUMN)\n",
    "prepared_data.shape"
   ]
  },
  {
   "source": [
    "### Converting Dtypes"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def strip_recurrent_vertices(row):\n",
    "    # sequence = row['vertex_l2'].split(' ')\n",
    "    # result = []\n",
    "    # if len(sequence) > 1:\n",
    "    #     last_index = len(sequence) - 1\n",
    "    #     i = 0\n",
    "    #     while i < last_index:\n",
    "    #         # print(sequence[i], sequence[i+1])\n",
    "    #         if sequence[i].strip(' ') != sequence[i+1].strip(' '):\n",
    "    #             # print('not equal')\n",
    "    #             result.append(sequence[i])\n",
    "    #         else:\n",
    "    #             print('equal', sequence[i], sequence[i+1])\n",
    "    #         i =+ 1\n",
    "    # return \" \".join(result)\n",
    "    result = row['vertex_l2'].split(' ')[0] + \" \" + \" \".join([row['vertex_l2'].split(' ')[i] for i in range(1, len(row['vertex_l2'].split(' '))) if (row['vertex_l2'].split(' ')[i-1] != row['vertex_l2'].split(' ')[i])&(row['vertex_l2'].split(' ')[i] != ' ')&(row['vertex_l2'].split(' ')[i] != '')])\n",
    "    if result.split(' ')[1] == ' ':\n",
    "        result.pop(1)\n",
    "        return result\n",
    "    else:\n",
    "        return \" \".join(row['vertex_l2'].split(' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prepared_data[TARGET_COLUMN] = prepared_data[TARGET_COLUMN].apply(strip_recurrent_vertices, axis=1)\n",
    "# prepared_data[TARGET_COLUMN] = prepared_data[TARGET_COLUMN].apply(lambda x: x.replace(' ', ''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'import_modules import_modules'"
      ]
     },
     "metadata": {},
     "execution_count": 292
    }
   ],
   "source": [
    "prepared_data[TARGET_COLUMN].loc[70]['vertex_l2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "('kaggle_id',)\n('competition_id',)\n('comp_name',)\n('comp_type',)\n('description',)\n('metric',)\n('datatype',)\n('subject',)\n('problemtype',)\n"
     ]
    }
   ],
   "source": [
    "cat_encodings = {}\n",
    "for i, col in enumerate(prepared_data):\n",
    "    if col[0] != TARGET_COLUMN:\n",
    "        print(col)\n",
    "        try:\n",
    "            prepared_data[col] =  prepared_data[col].astype('float32')\n",
    "        except:\n",
    "            prepared_data[col] = pd.Categorical(prepared_data[col])\n",
    "            cat_encodings.update({i:dict(enumerate(prepared_data[col].cat.categories))})\n",
    "            prepared_data[col] = prepared_data[col].cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "((54, 7), (59, 7))"
      ]
     },
     "metadata": {},
     "execution_count": 294
    }
   ],
   "source": [
    "competitions = prepared_data[competition_id_col].iloc[:, 0].unique()\n",
    "test_size = 0.25\n",
    "n_test_competitions = round(test_size * len(competitions))\n",
    "test_competitions, train_competitions = competitions[:n_test_competitions], competitions[n_test_competitions:]\n",
    "train = prepared_data[prepared_data['competition_id'].iloc[:, 0].isin(train_competitions)]\n",
    "test = prepared_data[prepared_data['competition_id'].iloc[:, 0].isin(test_competitions)]\n",
    "X_train, y_train = train[TASK_FEATURES], train[TARGET_COLUMN]\n",
    "X_test, y_test = test[TASK_FEATURES], test[TARGET_COLUMN]\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train, X_test, y_train, y_test = train_test_split(prepared_data[TASK_FEATURES], prepared_data[TARGET_COLUMN]\n",
    "#                                                     , test_size=0.25, shuffle=True, random_state=123)\n",
    "# X_train.shape, X_test.shape"
   ]
  },
  {
   "source": [
    "### Target Preprocessing: Encoding Vertices"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "lang = {vertice:i+2 for i, vertice in enumerate(nl2ml[TARGET_COLUMN].unique())} #TODO: save the dict as a local file\n",
    "lang.update({'<start>':1, '<end>':max(lang.values())+1})\n",
    "def encode_vertices(vertices_seq, lang:dict=lang):\n",
    "    # print(vertices_seq[0], type(vertices_seq[0]), vertices_seq[0].split(' '))\n",
    "    try:\n",
    "        encoded = np.append(np.flip(np.array([lang[vertex] for vertex in vertices_seq[0].split(' ')] + [lang['<end>']])), lang['<start>'])\n",
    "        # encoded = np.append(lang['<start>'], np.array([lang[vertex] for vertex in vertices_seq[0].split(' ')] + [lang['<end>']]))\n",
    "    except:\n",
    "        print(vertices_seq[0].split(' '))\n",
    "        raise Exception(\"Can't encode vertices\")\n",
    "    return encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_train.apply(encode_vertices, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X[TARGET_COLUMN] = y.apply(encode_vertices, axis=1)\n",
    "# X.to_csv('../data/nl2ml_train_example.csv', index=False)"
   ]
  },
  {
   "source": [
    "### Target Preprocessing: Padding Sequences"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length_targ, max_length_feat = prepared_data[TARGET_COLUMN].squeeze().str.split(' ').str.len().max() + 2, X_train.values.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train = tf.keras.preprocessing.sequence.pad_sequences(y_train.apply(encode_vertices, axis=1), maxlen=max_length_targ)\n",
    "Y_test = tf.keras.preprocessing.sequence.pad_sequences(y_test.apply(encode_vertices, axis=1), maxlen=max_length_targ)"
   ]
  },
  {
   "source": [
    "### Defining Constants"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_params = {\"Task\": \"train\"\n",
    "            , \"Model\": \"generative task2seq\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features = len(TASK_FEATURES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_params = {\"nrows\":X_train.shape[0]\n",
    "                , \"nfeatures\": n_features}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BUFFER_SIZE = len(input_tensor_train)\n",
    "LR = 0.001\n",
    "EPOCHS = 25\n",
    "gru_units = 128\n",
    "embedding_dim = 128\n",
    "dropout_rate = 0.0\n",
    "BATCH_SIZE = 1\n",
    "STEPS_PER_EPOCH = len(X_train)//BATCH_SIZE\n",
    "# vocab_inp_size = len(inp_lang.word_index) + 1\n",
    "# vocab_tar_size = len(targ_lang.word_index) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_params = {\"BATCH_SIZE\":BATCH_SIZE\n",
    "                , \"LR\":LR\n",
    "                , \"STEPS_PER_EPOCH\": STEPS_PER_EPOCH\n",
    "                , \"embedding_dim\": embedding_dim\n",
    "                , \"gru_units\": gru_units\n",
    "                , \"dropout_rate\": dropout_rate}"
   ]
  },
  {
   "source": [
    "### Creating tf.Dataset"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = tf.data.Dataset.from_tensor_slices((X_train.values, Y_train))\n",
    "train_dataset = train_dataset.batch(BATCH_SIZE, drop_remainder=True)"
   ]
  },
  {
   "source": [
    "### Building the Model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 501,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.Model):\n",
    "  def __init__(self, vocab_size, embedding_dim, dec_units, batch_sz):\n",
    "    super(Decoder, self).__init__()\n",
    "    self.batch_sz = batch_sz\n",
    "    self.dec_units = dec_units\n",
    "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "    # self.hidden_embedding = tf.keras.layers.Embedding(vocab_size, 1)\n",
    "    self.gru = tf.keras.layers.GRU(self.dec_units,\n",
    "                                   return_sequences=True,\n",
    "                                   return_state=True,\n",
    "                                   recurrent_initializer='glorot_uniform')\n",
    "    self.dropout = tf.keras.layers.Dropout(dropout_rate)\n",
    "    self.fc = tf.keras.layers.Dense(vocab_size, activation='sigmoid')\n",
    "    # self.vec_input_layer = tf.keras.layers.InputLayer(input_shape=tf.TensorShape([n_features, 1]), batch_size=(BATCH_SIZE))\n",
    "    self.fc_vec = tf.keras.layers.Dense(dec_units, activation='sigmoid')\n",
    "    # self.fc_seq = tf.keras.layers.Dense(vocab_size, activation='sigmoid')\n",
    "    # used for attention\n",
    "    # self.attention = BahdanauAttention(self.dec_units)\n",
    "\n",
    "  def call(self, x, hidden, vec_input):#, enc_output):\n",
    "    # enc_output shape == (batch_size, max_length, hidden_size)\n",
    "    # context_vector, attention_weights = self.attention(hidden, enc_output)\n",
    "    # attention_weights = tf.ones(x.shape)\n",
    "    # context_vector = tf.ones(x.shape)\n",
    "    # print(\"X Vector has {} type and {} shape\".format(type(x), x.shape))\n",
    "    # print(\"Context Vector has {} type and {} shape\".format(type(context_vector), context_vector.shape))\n",
    "    # print(\"Attention Vector has {} type and {} shape\".format(type(context_vector), context_vector.shape))\n",
    "    # x shape after passing through embedding == (batch_size, 1, embedding_dim)\n",
    "    x = self.embedding(x)\n",
    "    # x = tf.squeeze(self.hidden_embedding(x), axis=-1)\n",
    "    # x shape after concatenation == (batch_size, 1, embedding_dim + hidden_size)\n",
    "    # x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1)\n",
    "\n",
    "    # passing the concatenated vector to the GRU\n",
    "    output, state = self.gru(x, initial_state=hidden)\n",
    "\n",
    "    # output shape == (batch_size * 1, hidden_size)\n",
    "    output = tf.reshape(output, (-1, output.shape[2]))\n",
    "    output = self.dropout(output)\n",
    "    # output shape == (batch_size, vocab)\n",
    "    # vec = self.vec_input_layer(vec_input)\n",
    "    # print(vec)\n",
    "    vec = self.fc_vec(vec_input)\n",
    "    # vec = self.embedding(vec)\n",
    "    concatenated = tf.keras.layers.concatenate([vec, output], axis=1)\n",
    "    x = self.fc(concatenated)\n",
    "    # x = self.fc(output)\n",
    "    return x, state#, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Decoder output shape: (batch_size, vocab size`) (1, 72)\nModel: \"decoder_8\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nembedding_8 (Embedding)      multiple                  9216      \n_________________________________________________________________\ngru_8 (GRU)                  multiple                  99072     \n_________________________________________________________________\ndropout_8 (Dropout)          multiple                  0         \n_________________________________________________________________\ndense_16 (Dense)             multiple                  18504     \n_________________________________________________________________\ndense_17 (Dense)             multiple                  1024      \n=================================================================\nTotal params: 127,816\nTrainable params: 127,816\nNon-trainable params: 0\n_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "decoder = Decoder(len(lang)+2, embedding_dim, gru_units, BATCH_SIZE)\n",
    "sample_hidden = tf.zeros((BATCH_SIZE, gru_units))\n",
    "vec_input = np.ones((1, n_features))\n",
    "sample_decoder_output, state = decoder(tf.random.uniform((BATCH_SIZE, 1))\n",
    "                                          , sample_hidden\n",
    "                                          , vec_input\n",
    "                                          )\n",
    "print ('Decoder output shape: (batch_size, vocab size`) {}'.format(sample_decoder_output.shape))\n",
    "decoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 503,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(LR)\n",
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "                  from_logits=True, reduction='none')\n",
    "\n",
    "def loss_function(real, pred):\n",
    "  mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "  loss_ = loss_object(real, pred)\n",
    "\n",
    "  mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "  loss_ *= mask\n",
    "\n",
    "  return tf.reduce_mean(loss_)"
   ]
  },
  {
   "source": [
    "### Model Training or Loading Pre-Trained"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 504,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(inp, targ):#, enc_hidden):\n",
    "  loss = 0\n",
    "  # batch_perplexity = 1\n",
    "  with tf.GradientTape() as tape:\n",
    "    # enc_output, enc_hidden = encoder(inp, enc_hidden)\n",
    "\n",
    "    dec_hidden = tf.zeros((BATCH_SIZE, gru_units)) #enc_hidden\n",
    "\n",
    "    dec_input = tf.expand_dims([1] * BATCH_SIZE, 1)\n",
    "    # dec_input = tf.expand_dims(inp, 1)\n",
    "    # Teacher forcing - feeding the target as the next input\n",
    "    for t in range(1, targ.shape[1]): # for each vertex (token) from solution (sequence)\n",
    "      # passing enc_output to the decoder\n",
    "      predictions, dec_hidden = decoder(dec_input, dec_hidden, inp)#, enc_output)\n",
    "      loss += loss_function(targ[:, t], predictions)\n",
    "      # batch_perplexity *= tf.exp(loss)\n",
    "\n",
    "      # using teacher forcing\n",
    "      dec_input = tf.expand_dims(targ[:, t], 1)\n",
    "\n",
    "  batch_loss = (loss / int(targ.shape[1]))\n",
    "  variables = decoder.trainable_variables # + encoder.trainable_variables\n",
    "  gradients = tape.gradient(loss, variables)\n",
    "  optimizer.apply_gradients(zip(gradients, variables))\n",
    "  del inp, targ, gradients, variables\n",
    "  gc.collect()\n",
    "  return batch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_dir = './checkpoints/'\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
    "checkpoint = tf.train.Checkpoint(step=tf.Variable(1)\n",
    "                                , optimizer=optimizer\n",
    "                                # , metrics=perplexity_metric\n",
    "                                #  , encoder=encoder\n",
    "                                 , decoder=decoder)\n",
    "manager = tf.train.CheckpointManager(checkpoint, checkpoint_dir, max_to_keep=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if manager.latest_checkpoint:\n",
    "#     print(\"Restored from {}\".format(manager.latest_checkpoint))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 508,
   "metadata": {},
   "outputs": [],
   "source": [
    "# decoder.compile(\n",
    "#     optimizer=optimizer,\n",
    "#     loss=loss_object\n",
    "# )\n",
    "# tf.saved_model.save(decoder, './checkpoints/model1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 519,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses = []\n",
    "val_ce = []\n",
    "val_rr = []\n",
    "val_rp = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 520,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1 Batch 0 Loss 2.8313 Perplexity 16.9672\n",
      "predicting.. 0.00% 1.69% 3.39% 5.08% 6.78% 8.47% 10.17% 11.86% 13.56% 15.25% 16.95% 18.64% 20.34% 22.03% 23.73% 25.42% 27.12% 28.81% 30.51% 32.20% 33.90% 35.59% 37.29% 38.98% 40.68% 42.37% 44.07% 45.76% 47.46% 49.15% 50.85% 52.54% 54.24% 55.93% 57.63% 59.32% 61.02% 62.71% 64.41% 66.10% 67.80% 69.49% 71.19% 72.88% 74.58% 76.27% 77.97% 79.66% 81.36% 83.05% 84.75% 86.44% 88.14% 89.83% 91.53% 93.22% 94.92% 96.61% 98.31% \n",
      "Cross-Entropy: 114.86914825439453\n",
      "Perplexity: 7.709695538967837e+49\n",
      "ROUGE-Recall: 0.005406195207481006\n",
      "ROUGE-Precision: 0.023145818265239655\n",
      "Unique answers: 1\n",
      "Time taken for the epoch 173.35109663009644 sec\n",
      "\n",
      "Epoch 2 Batch 0 Loss 2.3387 Perplexity 10.3677\n",
      "predicting.. 0.00% 1.69% 3.39% 5.08% 6.78% 8.47% 10.17% 11.86% 13.56% 15.25% 16.95% 18.64% 20.34% 22.03% 23.73% 25.42% 27.12% 28.81% 30.51% 32.20% 33.90% 35.59% 37.29% 38.98% 40.68% 42.37% 44.07% 45.76% 47.46% 49.15% 50.85% 52.54% 54.24% 55.93% 57.63% 59.32% 61.02% 62.71% 64.41% 66.10% 67.80% 69.49% 71.19% 72.88% 74.58% 76.27% 77.97% 79.66% 81.36% 83.05% 84.75% 86.44% 88.14% 89.83% 91.53% 93.22% 94.92% 96.61% 98.31% \n",
      "Cross-Entropy: 131.202392578125\n",
      "Perplexity: 9.560378998369801e+56\n",
      "ROUGE-Recall: 0.005406195207481006\n",
      "ROUGE-Precision: 0.023145818265239655\n",
      "Unique answers: 1\n",
      "Time taken for the epoch 35.5967755317688 sec\n",
      "\n",
      "Epoch 3 Batch 0 Loss 2.1535 Perplexity 8.6148\n",
      "predicting.. 0.00% 1.69% 3.39% 5.08% 6.78% 8.47% 10.17% 11.86% 13.56% 15.25% 16.95% 18.64% 20.34% 22.03% 23.73% 25.42% 27.12% 28.81% 30.51% 32.20% 33.90% 35.59% 37.29% 38.98% 40.68% 42.37% 44.07% 45.76% 47.46% 49.15% 50.85% 52.54% 54.24% 55.93% 57.63% 59.32% 61.02% 62.71% 64.41% 66.10% 67.80% 69.49% 71.19% 72.88% 74.58% 76.27% 77.97% 79.66% 81.36% 83.05% 84.75% 86.44% 88.14% 89.83% 91.53% 93.22% 94.92% 96.61% 98.31% \n",
      "Cross-Entropy: 137.08322143554688\n",
      "Perplexity: 3.423628484035222e+59\n",
      "ROUGE-Recall: 0.004529514903565166\n",
      "ROUGE-Precision: 0.018292404625396035\n",
      "Unique answers: 2\n",
      "Time taken for the epoch 37.1164186000824 sec\n",
      "\n",
      "Epoch 4 Batch 0 Loss 1.9747 Perplexity 7.2048\n",
      "predicting.. 0.00% 1.69% 3.39% 5.08% 6.78% 8.47% 10.17% 11.86% 13.56% 15.25% 16.95% 18.64% 20.34% 22.03% 23.73% 25.42% 27.12% 28.81% 30.51% 32.20% 33.90% 35.59% 37.29% 38.98% 40.68% 42.37% 44.07% 45.76% 47.46% 49.15% 50.85% 52.54% 54.24% 55.93% 57.63% 59.32% 61.02% 62.71% 64.41% 66.10% 67.80% 69.49% 71.19% 72.88% 74.58% 76.27% 77.97% 79.66% 81.36% 83.05% 84.75% 86.44% 88.14% 89.83% 91.53% 93.22% 94.92% 96.61% 98.31% \n",
      "Cross-Entropy: 141.1514434814453\n",
      "Perplexity: 2.0012116233567928e+61\n",
      "ROUGE-Recall: 0.004529514903565166\n",
      "ROUGE-Precision: 0.018292404625396035\n",
      "Unique answers: 2\n",
      "Time taken for the epoch 36.15451121330261 sec\n",
      "\n",
      "Epoch 5 Batch 0 Loss 1.8649 Perplexity 6.4551\n",
      "predicting.. 0.00% 1.69% 3.39% 5.08% 6.78% 8.47% 10.17% 11.86% 13.56% 15.25% 16.95% 18.64% 20.34% 22.03% 23.73% 25.42% 27.12% 28.81% 30.51% 32.20% 33.90% 35.59% 37.29% 38.98% 40.68% 42.37% 44.07% 45.76% 47.46% 49.15% 50.85% 52.54% 54.24% 55.93% 57.63% 59.32% 61.02% 62.71% 64.41% 66.10% 67.80% 69.49% 71.19% 72.88% 74.58% 76.27% 77.97% 79.66% 81.36% 83.05% 84.75% 86.44% 88.14% 89.83% 91.53% 93.22% 94.92% 96.61% 98.31% \n",
      "Cross-Entropy: 139.4481964111328\n",
      "Perplexity: 3.64403225716733e+60\n",
      "ROUGE-Recall: 0.005406195207481006\n",
      "ROUGE-Precision: 0.023145818265239655\n",
      "Unique answers: 1\n",
      "saving\n",
      "saved\n",
      "Time taken for the epoch 35.68664503097534 sec\n",
      "\n",
      "Epoch 6 Batch 0 Loss 1.7594 Perplexity 5.8088\n",
      "predicting.. 0.00% 1.69% 3.39% 5.08% 6.78% 8.47% 10.17% 11.86% 13.56% 15.25% 16.95% 18.64% 20.34% 22.03% 23.73% 25.42% 27.12% 28.81% 30.51% 32.20% 33.90% 35.59% 37.29% 38.98% 40.68% 42.37% 44.07% 45.76% 47.46% 49.15% 50.85% 52.54% 54.24% 55.93% 57.63% 59.32% 61.02% 62.71% 64.41% 66.10% 67.80% 69.49% 71.19% 72.88% 74.58% 76.27% 77.97% 79.66% 81.36% 83.05% 84.75% 86.44% 88.14% 89.83% 91.53% 93.22% 94.92% 96.61% 98.31% \n",
      "Cross-Entropy: 143.90582275390625\n",
      "Perplexity: 3.144160705606485e+62\n",
      "ROUGE-Recall: 0.005406195207481006\n",
      "ROUGE-Precision: 0.023145818265239655\n",
      "Unique answers: 1\n",
      "Time taken for the epoch 36.14481282234192 sec\n",
      "\n",
      "Epoch 7 Batch 0 Loss 1.6806 Perplexity 5.3686\n",
      "predicting.. 0.00% 1.69% 3.39% 5.08% 6.78% 8.47% 10.17% 11.86% 13.56% 15.25% 16.95% 18.64% 20.34% 22.03% 23.73% 25.42% 27.12% 28.81% 30.51% 32.20% 33.90% 35.59% 37.29% 38.98% 40.68% 42.37% 44.07% 45.76% 47.46% 49.15% 50.85% 52.54% 54.24% 55.93% 57.63% 59.32% 61.02% 62.71% 64.41% 66.10% 67.80% 69.49% 71.19% 72.88% 74.58% 76.27% 77.97% 79.66% 81.36% 83.05% 84.75% 86.44% 88.14% 89.83% 91.53% 93.22% 94.92% 96.61% 98.31% \n",
      "Cross-Entropy: 148.07015991210938\n",
      "Perplexity: 2.023267867595449e+64\n",
      "ROUGE-Recall: 0.005406195207481006\n",
      "ROUGE-Precision: 0.023145818265239655\n",
      "Unique answers: 1\n",
      "Time taken for the epoch 37.997438192367554 sec\n",
      "\n",
      "Epoch 8 Batch 0 Loss 1.6186 Perplexity 5.0460\n",
      "predicting.. 0.00% 1.69% 3.39% 5.08% 6.78% 8.47% 10.17% 11.86% 13.56% 15.25% 16.95% 18.64% 20.34% 22.03% 23.73% 25.42% 27.12% 28.81% 30.51% 32.20% 33.90% 35.59% 37.29% 38.98% 40.68% 42.37% 44.07% 45.76% 47.46% 49.15% 50.85% 52.54% 54.24% 55.93% 57.63% 59.32% 61.02% 62.71% 64.41% 66.10% 67.80% 69.49% 71.19% 72.88% 74.58% 76.27% 77.97% 79.66% 81.36% 83.05% 84.75% 86.44% 88.14% 89.83% 91.53% 93.22% 94.92% 96.61% 98.31% \n",
      "Cross-Entropy: 150.53854370117188\n",
      "Perplexity: 2.388134832742539e+65\n",
      "ROUGE-Recall: 0.005406195207481006\n",
      "ROUGE-Precision: 0.023145818265239655\n",
      "Unique answers: 1\n",
      "Time taken for the epoch 35.92754769325256 sec\n",
      "\n",
      "Epoch 9 Batch 0 Loss 1.5526 Perplexity 4.7238\n",
      "predicting.. 0.00% 1.69% 3.39% 5.08% 6.78% 8.47% 10.17% 11.86% 13.56% 15.25% 16.95% 18.64% 20.34% 22.03% 23.73% 25.42% 27.12% 28.81% 30.51% 32.20% 33.90% 35.59% 37.29% 38.98% 40.68% 42.37% 44.07% 45.76% 47.46% 49.15% 50.85% 52.54% 54.24% 55.93% 57.63% 59.32% 61.02% 62.71% 64.41% 66.10% 67.80% 69.49% 71.19% 72.88% 74.58% 76.27% 77.97% 79.66% 81.36% 83.05% 84.75% 86.44% 88.14% 89.83% 91.53% 93.22% 94.92% 96.61% 98.31% \n",
      "Cross-Entropy: 152.4408721923828\n",
      "Perplexity: 1.600403931827307e+66\n",
      "ROUGE-Recall: 0.005406195207481006\n",
      "ROUGE-Precision: 0.023145818265239655\n",
      "Unique answers: 1\n",
      "Time taken for the epoch 35.576037645339966 sec\n",
      "\n",
      "Epoch 10 Batch 0 Loss 1.4772 Perplexity 4.3808\n",
      "predicting.. 0.00% 1.69% 3.39% 5.08% 6.78% 8.47% 10.17% 11.86% 13.56% 15.25% 16.95% 18.64% 20.34% 22.03% 23.73% 25.42% 27.12% 28.81% 30.51% 32.20% 33.90% 35.59% 37.29% 38.98% 40.68% 42.37% 44.07% 45.76% 47.46% 49.15% 50.85% 52.54% 54.24% 55.93% 57.63% 59.32% 61.02% 62.71% 64.41% 66.10% 67.80% 69.49% 71.19% 72.88% 74.58% 76.27% 77.97% 79.66% 81.36% 83.05% 84.75% 86.44% 88.14% 89.83% 91.53% 93.22% 94.92% 96.61% 98.31% \n",
      "Cross-Entropy: 154.6675567626953\n",
      "Perplexity: 1.4834278611450894e+67\n",
      "ROUGE-Recall: 0.005406195207481006\n",
      "ROUGE-Precision: 0.023145818265239655\n",
      "Unique answers: 1\n",
      "saving\n",
      "saved\n",
      "Time taken for the epoch 35.61084532737732 sec\n",
      "\n",
      "Epoch 11 Batch 0 Loss 1.4048 Perplexity 4.0749\n",
      "predicting.. 0.00% 1.69% 3.39% 5.08% 6.78% 8.47% 10.17% 11.86% 13.56% 15.25% 16.95% 18.64% 20.34% 22.03% 23.73% 25.42% 27.12% 28.81% 30.51% 32.20% 33.90% 35.59% 37.29% 38.98% 40.68% 42.37% 44.07% 45.76% 47.46% 49.15% 50.85% 52.54% 54.24% 55.93% 57.63% 59.32% 61.02% 62.71% 64.41% 66.10% 67.80% 69.49% 71.19% 72.88% 74.58% 76.27% 77.97% 79.66% 81.36% 83.05% 84.75% 86.44% 88.14% 89.83% 91.53% 93.22% 94.92% 96.61% 98.31% \n",
      "Cross-Entropy: 157.60964965820312\n",
      "Perplexity: 2.811908219672628e+68\n",
      "ROUGE-Recall: 0.005406195207481006\n",
      "ROUGE-Precision: 0.023145818265239655\n",
      "Unique answers: 1\n",
      "Time taken for the epoch 36.382935762405396 sec\n",
      "\n",
      "Epoch 12 Batch 0 Loss 1.3396 Perplexity 3.8175\n",
      "predicting.. 0.00% 1.69% 3.39% 5.08% 6.78% 8.47% 10.17% 11.86% 13.56% 15.25% 16.95% 18.64% 20.34% 22.03% 23.73% 25.42% 27.12% 28.81% 30.51% 32.20% 33.90% 35.59% 37.29% 38.98% 40.68% 42.37% 44.07% 45.76% 47.46% 49.15% 50.85% 52.54% 54.24% 55.93% 57.63% 59.32% 61.02% 62.71% 64.41% 66.10% 67.80% 69.49% 71.19% 72.88% 74.58% 76.27% 77.97% 79.66% 81.36% 83.05% 84.75% 86.44% 88.14% 89.83% 91.53% 93.22% 94.92% 96.61% 98.31% \n",
      "Cross-Entropy: 158.14051818847656\n",
      "Perplexity: 4.781392704697664e+68\n",
      "ROUGE-Recall: 0.005406195207481006\n",
      "ROUGE-Precision: 0.023145818265239655\n",
      "Unique answers: 1\n",
      "Time taken for the epoch 36.19788861274719 sec\n",
      "\n",
      "Epoch 13 Batch 0 Loss 1.3148 Perplexity 3.7240\n",
      "predicting.. 0.00% 1.69% 3.39% 5.08% 6.78% 8.47% 10.17% 11.86% 13.56% 15.25% 16.95% 18.64% 20.34% 22.03% 23.73% 25.42% 27.12% 28.81% 30.51% 32.20% 33.90% 35.59% 37.29% 38.98% 40.68% 42.37% 44.07% 45.76% 47.46% 49.15% 50.85% 52.54% 54.24% 55.93% 57.63% 59.32% 61.02% 62.71% 64.41% 66.10% 67.80% 69.49% 71.19% 72.88% 74.58% 76.27% 77.97% 79.66% 81.36% 83.05% 84.75% 86.44% 88.14% 89.83% 91.53% 93.22% 94.92% 96.61% 98.31% \n",
      "Cross-Entropy: 174.7957000732422\n",
      "Perplexity: 8.18103032012824e+75\n",
      "ROUGE-Recall: 0.010812390414962009\n",
      "ROUGE-Precision: 0.046376641766458525\n",
      "Unique answers: 2\n",
      "Time taken for the epoch 35.958003759384155 sec\n",
      "\n",
      "Epoch 14 Batch 0 Loss 1.2711 Perplexity 3.5646\n",
      "predicting.. 0.00% 1.69% 3.39% 5.08% 6.78% 8.47% 10.17% 11.86% 13.56% 15.25% 16.95% 18.64% 20.34% 22.03% 23.73% 25.42% 27.12% 28.81% 30.51% 32.20% 33.90% 35.59% 37.29% 38.98% 40.68% 42.37% 44.07% 45.76% 47.46% 49.15% 50.85% 52.54% 54.24% 55.93% 57.63% 59.32% 61.02% 62.71% 64.41% 66.10% 67.80% 69.49% 71.19% 72.88% 74.58% 76.27% 77.97% 79.66% 81.36% 83.05% 84.75% 86.44% 88.14% 89.83% 91.53% 93.22% 94.92% 96.61% 98.31% \n",
      "Cross-Entropy: 162.14137268066406\n",
      "Perplexity: 2.6127836121695153e+70\n",
      "ROUGE-Recall: 0.03024547048509644\n",
      "ROUGE-Precision: 0.2094833794039566\n",
      "Unique answers: 2\n",
      "Time taken for the epoch 38.0467369556427 sec\n",
      "\n",
      "Epoch 15 Batch 0 Loss 1.1889 Perplexity 3.2834\n",
      "predicting.. 0.00% 1.69% 3.39% 5.08% 6.78% 8.47% 10.17% 11.86% 13.56% 15.25% 16.95% 18.64% 20.34% 22.03% 23.73% 25.42% 27.12% 28.81% 30.51% 32.20% 33.90% 35.59% 37.29% 38.98% 40.68% 42.37% 44.07% 45.76% 47.46% 49.15% 50.85% 52.54% 54.24% 55.93% 57.63% 59.32% 61.02% 62.71% 64.41% 66.10% 67.80% 69.49% 71.19% 72.88% 74.58% 76.27% 77.97% 79.66% 81.36% 83.05% 84.75% 86.44% 88.14% 89.83% 91.53% 93.22% 94.92% 96.61% 98.31% \n",
      "Cross-Entropy: 173.40687561035156\n",
      "Perplexity: 2.0400894109610377e+75\n",
      "ROUGE-Recall: 0.029514903565166575\n",
      "ROUGE-Precision: 0.20793474710972867\n",
      "Unique answers: 2\n",
      "saving\n",
      "saved\n",
      "Time taken for the epoch 37.2369065284729 sec\n",
      "\n",
      "Epoch 16 Batch 0 Loss 1.2040 Perplexity 3.3333\n",
      "predicting.. 0.00% 1.69% 3.39% 5.08% 6.78% 8.47% 10.17% 11.86% 13.56% 15.25% 16.95% 18.64% 20.34% 22.03% 23.73% 25.42% 27.12% 28.81% 30.51% 32.20% 33.90% 35.59% 37.29% 38.98% 40.68% 42.37% 44.07% 45.76% 47.46% 49.15% 50.85% 52.54% 54.24% 55.93% 57.63% 59.32% 61.02% 62.71% 64.41% 66.10% 67.80% 69.49% 71.19% 72.88% 74.58% 76.27% 77.97% 79.66% 81.36% 83.05% 84.75% 86.44% 88.14% 89.83% 91.53% 93.22% 94.92% 96.61% 98.31% \n",
      "Cross-Entropy: 177.7776641845703\n",
      "Perplexity: 1.6138328857003378e+77\n",
      "ROUGE-Recall: 0.029514903565166575\n",
      "ROUGE-Precision: 0.20793474710972867\n",
      "Unique answers: 2\n",
      "Time taken for the epoch 41.36036944389343 sec\n",
      "\n",
      "Epoch 17 Batch 0 Loss 1.1217 Perplexity 3.0700\n",
      "predicting.. 0.00% 1.69% 3.39% 5.08% 6.78% 8.47% 10.17% 11.86% 13.56% 15.25% 16.95% 18.64% 20.34% 22.03% 23.73% 25.42% 27.12% 28.81% 30.51% 32.20% 33.90% 35.59% 37.29% 38.98% 40.68% 42.37% 44.07% 45.76% 47.46% 49.15% 50.85% 52.54% 54.24% 55.93% 57.63% 59.32% 61.02% 62.71% 64.41% 66.10% 67.80% 69.49% 71.19% 72.88% 74.58% 76.27% 77.97% 79.66% 81.36% 83.05% 84.75% 86.44% 88.14% 89.83% 91.53% 93.22% 94.92% 96.61% 98.31% \n",
      "Cross-Entropy: 173.41465759277344\n",
      "Perplexity: 2.0560272845903435e+75\n",
      "ROUGE-Recall: 0.031122150789012277\n",
      "ROUGE-Precision: 0.21342340095811763\n",
      "Unique answers: 2\n",
      "Time taken for the epoch 39.00362157821655 sec\n",
      "\n",
      "Epoch 18 Batch 0 Loss 1.0366 Perplexity 2.8195\n",
      "predicting.. 0.00% 1.69% 3.39% 5.08% 6.78% 8.47% 10.17% 11.86% 13.56% 15.25% 16.95% 18.64% 20.34% 22.03% 23.73% 25.42% 27.12% 28.81% 30.51% 32.20% 33.90% 35.59% 37.29% 38.98% 40.68% 42.37% 44.07% 45.76% 47.46% 49.15% 50.85% 52.54% 54.24% 55.93% 57.63% 59.32% 61.02% 62.71% 64.41% 66.10% 67.80% 69.49% 71.19% 72.88% 74.58% 76.27% 77.97% 79.66% 81.36% 83.05% 84.75% 86.44% 88.14% 89.83% 91.53% 93.22% 94.92% 96.61% 98.31% \n",
      "Cross-Entropy: 192.5018310546875\n",
      "Perplexity: 4.0038977981182224e+83\n",
      "ROUGE-Recall: 0.025862068965517244\n",
      "ROUGE-Precision: 0.18504667098706673\n",
      "Unique answers: 2\n",
      "Time taken for the epoch 36.258103370666504 sec\n",
      "\n",
      "Epoch 19 Batch 0 Loss 0.9906 Perplexity 2.6928\n",
      "predicting.. 0.00% 1.69% 3.39% 5.08% 6.78% 8.47% 10.17% 11.86% 13.56% 15.25% 16.95% 18.64% 20.34% 22.03% 23.73% 25.42% 27.12% 28.81% 30.51% 32.20% 33.90% 35.59% 37.29% 38.98% 40.68% 42.37% 44.07% 45.76% 47.46% 49.15% 50.85% 52.54% 54.24% 55.93% 57.63% 59.32% 61.02% 62.71% 64.41% 66.10% 67.80% 69.49% 71.19% 72.88% 74.58% 76.27% 77.97% 79.66% 81.36% 83.05% 84.75% 86.44% 88.14% 89.83% 91.53% 93.22% 94.92% 96.61% 98.31% \n",
      "Cross-Entropy: 194.7435760498047\n",
      "Perplexity: 3.767562491235786e+84\n",
      "ROUGE-Recall: 0.026738749269433083\n",
      "ROUGE-Precision: 0.1889866925412278\n",
      "Unique answers: 2\n",
      "Time taken for the epoch 35.98357534408569 sec\n",
      "\n",
      "Epoch 20 Batch 0 Loss 0.9462 Perplexity 2.5759\n",
      "predicting.. 0.00% 1.69% 3.39% 5.08% 6.78% 8.47% 10.17% 11.86% 13.56% 15.25% 16.95% 18.64% 20.34% 22.03% 23.73% 25.42% 27.12% 28.81% 30.51% 32.20% 33.90% 35.59% 37.29% 38.98% 40.68% 42.37% 44.07% 45.76% 47.46% 49.15% 50.85% 52.54% 54.24% 55.93% 57.63% 59.32% 61.02% 62.71% 64.41% 66.10% 67.80% 69.49% 71.19% 72.88% 74.58% 76.27% 77.97% 79.66% 81.36% 83.05% 84.75% 86.44% 88.14% 89.83% 91.53% 93.22% 94.92% 96.61% 98.31% \n",
      "Cross-Entropy: 187.96487426757812\n",
      "Perplexity: 4.286547948730334e+81\n",
      "ROUGE-Recall: 0.03024547048509644\n",
      "ROUGE-Precision: 0.2094833794039566\n",
      "Unique answers: 2\n",
      "saving\n",
      "saved\n",
      "Time taken for the epoch 36.034400939941406 sec\n",
      "\n",
      "Epoch 21 Batch 0 Loss 0.9333 Perplexity 2.5429\n",
      "predicting.. 0.00% 1.69% 3.39% 5.08% 6.78% 8.47% 10.17% 11.86% 13.56% 15.25% 16.95% 18.64% 20.34% 22.03% 23.73% 25.42% 27.12% 28.81% 30.51% 32.20% 33.90% 35.59% 37.29% 38.98% 40.68% 42.37% 44.07% 45.76% 47.46% 49.15% 50.85% 52.54% 54.24% 55.93% 57.63% 59.32% 61.02% 62.71% 64.41% 66.10% 67.80% 69.49% 71.19% 72.88% 74.58% 76.27% 77.97% 79.66% 81.36% 83.05% 84.75% 86.44% 88.14% 89.83% 91.53% 93.22% 94.92% 96.61% 98.31% \n",
      "Cross-Entropy: 184.1404571533203\n",
      "Perplexity: 9.358030079904565e+79\n",
      "ROUGE-Recall: 0.031122150789012277\n",
      "ROUGE-Precision: 0.21342340095811763\n",
      "Unique answers: 2\n",
      "Time taken for the epoch 37.14046382904053 sec\n",
      "\n",
      "Epoch 22 Batch 0 Loss 0.8647 Perplexity 2.3742\n",
      "predicting.. 0.00% 1.69% 3.39% 5.08% 6.78% 8.47% 10.17% 11.86% 13.56% 15.25% 16.95% 18.64% 20.34% 22.03% 23.73% 25.42% 27.12% 28.81% 30.51% 32.20% 33.90% 35.59% 37.29% 38.98% 40.68% 42.37% 44.07% 45.76% 47.46% 49.15% 50.85% 52.54% 54.24% 55.93% 57.63% 59.32% 61.02% 62.71% 64.41% 66.10% 67.80% 69.49% 71.19% 72.88% 74.58% 76.27% 77.97% 79.66% 81.36% 83.05% 84.75% 86.44% 88.14% 89.83% 91.53% 93.22% 94.92% 96.61% 98.31% \n",
      "Cross-Entropy: 192.6568603515625\n",
      "Perplexity: 4.675320109686451e+83\n",
      "ROUGE-Recall: 0.031122150789012277\n",
      "ROUGE-Precision: 0.21342340095811763\n",
      "Unique answers: 2\n",
      "Time taken for the epoch 36.23490881919861 sec\n",
      "\n",
      "Epoch 23 Batch 0 Loss 0.8197 Perplexity 2.2698\n",
      "predicting.. 0.00% 1.69% 3.39% 5.08% 6.78% 8.47% 10.17% 11.86% 13.56% 15.25% 16.95% 18.64% 20.34% 22.03% 23.73% 25.42% 27.12% 28.81% 30.51% 32.20% 33.90% 35.59% 37.29% 38.98% 40.68% 42.37% 44.07% 45.76% 47.46% 49.15% 50.85% 52.54% 54.24% 55.93% 57.63% 59.32% 61.02% 62.71% 64.41% 66.10% 67.80% 69.49% 71.19% 72.88% 74.58% 76.27% 77.97% 79.66% 81.36% 83.05% 84.75% 86.44% 88.14% 89.83% 91.53% 93.22% 94.92% 96.61% 98.31% \n",
      "Cross-Entropy: 192.25729370117188\n",
      "Perplexity: 3.135319186149728e+83\n",
      "ROUGE-Recall: 0.031122150789012277\n",
      "ROUGE-Precision: 0.21342340095811763\n",
      "Unique answers: 2\n",
      "Time taken for the epoch 35.34851670265198 sec\n",
      "\n",
      "Epoch 24 Batch 0 Loss 0.8011 Perplexity 2.2280\n",
      "predicting.. 0.00% 1.69% 3.39% 5.08% 6.78% 8.47% 10.17% 11.86% 13.56% 15.25% 16.95% 18.64% 20.34% 22.03% 23.73% 25.42% 27.12% 28.81% 30.51% 32.20% 33.90% 35.59% 37.29% 38.98% 40.68% 42.37% 44.07% 45.76% 47.46% 49.15% 50.85% 52.54% 54.24% 55.93% 57.63% 59.32% 61.02% 62.71% 64.41% 66.10% 67.80% 69.49% 71.19% 72.88% 74.58% 76.27% 77.97% 79.66% 81.36% 83.05% 84.75% 86.44% 88.14% 89.83% 91.53% 93.22% 94.92% 96.61% 98.31% \n",
      "Cross-Entropy: 199.41966247558594\n",
      "Perplexity: 4.04444558009036e+86\n",
      "ROUGE-Recall: 0.031122150789012277\n",
      "ROUGE-Precision: 0.21342340095811763\n",
      "Unique answers: 2\n",
      "Time taken for the epoch 36.095468044281006 sec\n",
      "\n",
      "Epoch 25 Batch 0 Loss 0.7487 Perplexity 2.1143\n",
      "predicting.. 0.00% 1.69% 3.39% 5.08% 6.78% 8.47% 10.17% 11.86% 13.56% 15.25% 16.95% 18.64% 20.34% 22.03% 23.73% 25.42% 27.12% 28.81% 30.51% 32.20% 33.90% 35.59% 37.29% 38.98% 40.68% 42.37% 44.07% 45.76% 47.46% 49.15% 50.85% 52.54% 54.24% 55.93% 57.63% 59.32% 61.02% 62.71% 64.41% 66.10% 67.80% 69.49% 71.19% 72.88% 74.58% 76.27% 77.97% 79.66% 81.36% 83.05% 84.75% 86.44% 88.14% 89.83% 91.53% 93.22% 94.92% 96.61% 98.31% \n",
      "Cross-Entropy: 190.6980438232422\n",
      "Perplexity: 6.593380543113957e+82\n",
      "ROUGE-Recall: 0.031122150789012277\n",
      "ROUGE-Precision: 0.21342340095811763\n",
      "Unique answers: 2\n",
      "saving\n",
      "saved\n",
      "Time taken for the epoch 35.85267376899719 sec\n",
      "\n",
      "The best epoch is 24\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x18d5356f6a0>]"
      ]
     },
     "metadata": {},
     "execution_count": 520
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\r\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\r\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\r\n<!-- Created with matplotlib (https://matplotlib.org/) -->\r\n<svg height=\"248.518125pt\" version=\"1.1\" viewBox=\"0 0 382.291761 248.518125\" width=\"382.291761pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\r\n <metadata>\r\n  <rdf:RDF xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\r\n   <cc:Work>\r\n    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\r\n    <dc:date>2021-05-31T15:22:16.057844</dc:date>\r\n    <dc:format>image/svg+xml</dc:format>\r\n    <dc:creator>\r\n     <cc:Agent>\r\n      <dc:title>Matplotlib v3.3.2, https://matplotlib.org/</dc:title>\r\n     </cc:Agent>\r\n    </dc:creator>\r\n   </cc:Work>\r\n  </rdf:RDF>\r\n </metadata>\r\n <defs>\r\n  <style type=\"text/css\">*{stroke-linecap:butt;stroke-linejoin:round;}</style>\r\n </defs>\r\n <g id=\"figure_1\">\r\n  <g id=\"patch_1\">\r\n   <path d=\"M 0 248.518125 \r\nL 382.291761 248.518125 \r\nL 382.291761 0 \r\nL 0 0 \r\nz\r\n\" style=\"fill:none;\"/>\r\n  </g>\r\n  <g id=\"axes_1\">\r\n   <g id=\"patch_2\">\r\n    <path d=\"M 36.465625 224.64 \r\nL 371.265625 224.64 \r\nL 371.265625 7.2 \r\nL 36.465625 7.2 \r\nz\r\n\" style=\"fill:#ffffff;\"/>\r\n   </g>\r\n   <g id=\"matplotlib.axis_1\">\r\n    <g id=\"xtick_1\">\r\n     <g id=\"line2d_1\">\r\n      <defs>\r\n       <path d=\"M 0 0 \r\nL 0 3.5 \r\n\" id=\"me7866d8a65\" style=\"stroke:#000000;stroke-width:0.8;\"/>\r\n      </defs>\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"51.683807\" xlink:href=\"#me7866d8a65\" y=\"224.64\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_1\">\r\n      <!-- 0 -->\r\n      <g transform=\"translate(48.502557 239.238438)scale(0.1 -0.1)\">\r\n       <defs>\r\n        <path d=\"M 31.78125 66.40625 \r\nQ 24.171875 66.40625 20.328125 58.90625 \r\nQ 16.5 51.421875 16.5 36.375 \r\nQ 16.5 21.390625 20.328125 13.890625 \r\nQ 24.171875 6.390625 31.78125 6.390625 \r\nQ 39.453125 6.390625 43.28125 13.890625 \r\nQ 47.125 21.390625 47.125 36.375 \r\nQ 47.125 51.421875 43.28125 58.90625 \r\nQ 39.453125 66.40625 31.78125 66.40625 \r\nz\r\nM 31.78125 74.21875 \r\nQ 44.046875 74.21875 50.515625 64.515625 \r\nQ 56.984375 54.828125 56.984375 36.375 \r\nQ 56.984375 17.96875 50.515625 8.265625 \r\nQ 44.046875 -1.421875 31.78125 -1.421875 \r\nQ 19.53125 -1.421875 13.0625 8.265625 \r\nQ 6.59375 17.96875 6.59375 36.375 \r\nQ 6.59375 54.828125 13.0625 64.515625 \r\nQ 19.53125 74.21875 31.78125 74.21875 \r\nz\r\n\" id=\"DejaVuSans-48\"/>\r\n       </defs>\r\n       <use xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_2\">\r\n     <g id=\"line2d_2\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"115.092898\" xlink:href=\"#me7866d8a65\" y=\"224.64\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_2\">\r\n      <!-- 5 -->\r\n      <g transform=\"translate(111.911648 239.238438)scale(0.1 -0.1)\">\r\n       <defs>\r\n        <path d=\"M 10.796875 72.90625 \r\nL 49.515625 72.90625 \r\nL 49.515625 64.59375 \r\nL 19.828125 64.59375 \r\nL 19.828125 46.734375 \r\nQ 21.96875 47.46875 24.109375 47.828125 \r\nQ 26.265625 48.1875 28.421875 48.1875 \r\nQ 40.625 48.1875 47.75 41.5 \r\nQ 54.890625 34.8125 54.890625 23.390625 \r\nQ 54.890625 11.625 47.5625 5.09375 \r\nQ 40.234375 -1.421875 26.90625 -1.421875 \r\nQ 22.3125 -1.421875 17.546875 -0.640625 \r\nQ 12.796875 0.140625 7.71875 1.703125 \r\nL 7.71875 11.625 \r\nQ 12.109375 9.234375 16.796875 8.0625 \r\nQ 21.484375 6.890625 26.703125 6.890625 \r\nQ 35.15625 6.890625 40.078125 11.328125 \r\nQ 45.015625 15.765625 45.015625 23.390625 \r\nQ 45.015625 31 40.078125 35.4375 \r\nQ 35.15625 39.890625 26.703125 39.890625 \r\nQ 22.75 39.890625 18.8125 39.015625 \r\nQ 14.890625 38.140625 10.796875 36.28125 \r\nz\r\n\" id=\"DejaVuSans-53\"/>\r\n       </defs>\r\n       <use xlink:href=\"#DejaVuSans-53\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_3\">\r\n     <g id=\"line2d_3\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"178.501989\" xlink:href=\"#me7866d8a65\" y=\"224.64\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_3\">\r\n      <!-- 10 -->\r\n      <g transform=\"translate(172.139489 239.238438)scale(0.1 -0.1)\">\r\n       <defs>\r\n        <path d=\"M 12.40625 8.296875 \r\nL 28.515625 8.296875 \r\nL 28.515625 63.921875 \r\nL 10.984375 60.40625 \r\nL 10.984375 69.390625 \r\nL 28.421875 72.90625 \r\nL 38.28125 72.90625 \r\nL 38.28125 8.296875 \r\nL 54.390625 8.296875 \r\nL 54.390625 0 \r\nL 12.40625 0 \r\nz\r\n\" id=\"DejaVuSans-49\"/>\r\n       </defs>\r\n       <use xlink:href=\"#DejaVuSans-49\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_4\">\r\n     <g id=\"line2d_4\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"241.91108\" xlink:href=\"#me7866d8a65\" y=\"224.64\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_4\">\r\n      <!-- 15 -->\r\n      <g transform=\"translate(235.54858 239.238438)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-49\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_5\">\r\n     <g id=\"line2d_5\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"305.32017\" xlink:href=\"#me7866d8a65\" y=\"224.64\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_5\">\r\n      <!-- 20 -->\r\n      <g transform=\"translate(298.95767 239.238438)scale(0.1 -0.1)\">\r\n       <defs>\r\n        <path d=\"M 19.1875 8.296875 \r\nL 53.609375 8.296875 \r\nL 53.609375 0 \r\nL 7.328125 0 \r\nL 7.328125 8.296875 \r\nQ 12.9375 14.109375 22.625 23.890625 \r\nQ 32.328125 33.6875 34.8125 36.53125 \r\nQ 39.546875 41.84375 41.421875 45.53125 \r\nQ 43.3125 49.21875 43.3125 52.78125 \r\nQ 43.3125 58.59375 39.234375 62.25 \r\nQ 35.15625 65.921875 28.609375 65.921875 \r\nQ 23.96875 65.921875 18.8125 64.3125 \r\nQ 13.671875 62.703125 7.8125 59.421875 \r\nL 7.8125 69.390625 \r\nQ 13.765625 71.78125 18.9375 73 \r\nQ 24.125 74.21875 28.421875 74.21875 \r\nQ 39.75 74.21875 46.484375 68.546875 \r\nQ 53.21875 62.890625 53.21875 53.421875 \r\nQ 53.21875 48.921875 51.53125 44.890625 \r\nQ 49.859375 40.875 45.40625 35.40625 \r\nQ 44.1875 33.984375 37.640625 27.21875 \r\nQ 31.109375 20.453125 19.1875 8.296875 \r\nz\r\n\" id=\"DejaVuSans-50\"/>\r\n       </defs>\r\n       <use xlink:href=\"#DejaVuSans-50\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_6\">\r\n     <g id=\"line2d_6\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"368.729261\" xlink:href=\"#me7866d8a65\" y=\"224.64\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_6\">\r\n      <!-- 25 -->\r\n      <g transform=\"translate(362.366761 239.238438)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-50\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n   </g>\r\n   <g id=\"matplotlib.axis_2\">\r\n    <g id=\"ytick_1\">\r\n     <g id=\"line2d_7\">\r\n      <defs>\r\n       <path d=\"M 0 0 \r\nL -3.5 0 \r\n\" id=\"m33ec0a0cfe\" style=\"stroke:#000000;stroke-width:0.8;\"/>\r\n      </defs>\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"36.465625\" xlink:href=\"#m33ec0a0cfe\" y=\"218.771499\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_7\">\r\n      <!-- 0.00 -->\r\n      <g transform=\"translate(7.2 222.570718)scale(0.1 -0.1)\">\r\n       <defs>\r\n        <path d=\"M 10.6875 12.40625 \r\nL 21 12.40625 \r\nL 21 0 \r\nL 10.6875 0 \r\nz\r\n\" id=\"DejaVuSans-46\"/>\r\n       </defs>\r\n       <use xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\r\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_2\">\r\n     <g id=\"line2d_8\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"36.465625\" xlink:href=\"#m33ec0a0cfe\" y=\"174.449581\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_8\">\r\n      <!-- 0.05 -->\r\n      <g transform=\"translate(7.2 178.2488)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\r\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-53\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_3\">\r\n     <g id=\"line2d_9\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"36.465625\" xlink:href=\"#m33ec0a0cfe\" y=\"130.127663\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_9\">\r\n      <!-- 0.10 -->\r\n      <g transform=\"translate(7.2 133.926882)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\r\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-49\"/>\r\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_4\">\r\n     <g id=\"line2d_10\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"36.465625\" xlink:href=\"#m33ec0a0cfe\" y=\"85.805744\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_10\">\r\n      <!-- 0.15 -->\r\n      <g transform=\"translate(7.2 89.604963)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\r\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-49\"/>\r\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-53\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_5\">\r\n     <g id=\"line2d_11\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"36.465625\" xlink:href=\"#m33ec0a0cfe\" y=\"41.483826\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_11\">\r\n      <!-- 0.20 -->\r\n      <g transform=\"translate(7.2 45.283045)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\r\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-50\"/>\r\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n   </g>\r\n   <g id=\"line2d_12\">\r\n    <path clip-path=\"url(#p01e0aac283)\" d=\"M 51.683807 17.083636 \r\nL 64.365625 46.953535 \r\nL 77.047443 67.328529 \r\nL 89.729261 72.624993 \r\nL 102.41108 75.439532 \r\nL 115.092898 76.898065 \r\nL 127.774716 76.664372 \r\nL 140.456534 76.846299 \r\nL 153.138352 77.379241 \r\nL 165.82017 77.698132 \r\nL 178.501989 77.888486 \r\nL 191.183807 77.249238 \r\nL 203.865625 86.323187 \r\nL 216.547443 90.878786 \r\nL 229.229261 96.783548 \r\nL 241.91108 88.439038 \r\nL 254.592898 101.46631 \r\nL 267.274716 98.665733 \r\nL 279.956534 104.838861 \r\nL 292.638352 106.532237 \r\nL 305.32017 117.907332 \r\nL 318.001989 113.915075 \r\nL 330.683807 113.758826 \r\nL 343.365625 118.270347 \r\nL 356.047443 131.18846 \r\n\" style=\"fill:none;stroke:#1f77b4;stroke-linecap:square;stroke-width:1.5;\"/>\r\n   </g>\r\n   <g id=\"line2d_13\">\r\n    <path clip-path=\"url(#p01e0aac283)\" d=\"M 51.683807 208.589057 \r\nL 64.365625 207.141216 \r\nL 77.047443 206.619917 \r\nL 89.729261 206.259294 \r\nL 102.41108 206.410276 \r\nL 115.092898 206.015135 \r\nL 127.774716 205.645993 \r\nL 140.456534 205.427185 \r\nL 153.138352 205.258556 \r\nL 165.82017 205.061174 \r\nL 178.501989 204.800375 \r\nL 191.183807 204.753318 \r\nL 203.865625 203.276937 \r\nL 216.547443 204.398666 \r\nL 229.229261 203.400048 \r\nL 241.91108 203.012605 \r\nL 254.592898 203.399358 \r\nL 267.274716 201.707399 \r\nL 279.956534 201.508682 \r\nL 292.638352 202.109572 \r\nL 305.32017 202.448582 \r\nL 318.001989 201.693657 \r\nL 330.683807 201.729075 \r\nL 343.365625 201.094175 \r\nL 356.047443 201.867294 \r\n\" style=\"fill:none;stroke:#ff7f0e;stroke-linecap:square;stroke-width:1.5;\"/>\r\n   </g>\r\n   <g id=\"line2d_14\">\r\n    <path clip-path=\"url(#p01e0aac283)\" d=\"M 51.683807 213.979241 \r\nL 64.365625 213.979241 \r\nL 77.047443 214.756364 \r\nL 89.729261 214.756364 \r\nL 102.41108 213.979241 \r\nL 115.092898 213.979241 \r\nL 127.774716 213.979241 \r\nL 140.456534 213.979241 \r\nL 153.138352 213.979241 \r\nL 165.82017 213.979241 \r\nL 178.501989 213.979241 \r\nL 191.183807 213.979241 \r\nL 203.865625 209.186982 \r\nL 216.547443 191.960754 \r\nL 229.229261 192.608357 \r\nL 241.91108 192.608357 \r\nL 254.592898 191.183631 \r\nL 267.274716 195.846369 \r\nL 279.956534 195.069246 \r\nL 292.638352 191.960754 \r\nL 305.32017 191.183631 \r\nL 318.001989 191.183631 \r\nL 330.683807 191.183631 \r\nL 343.365625 191.183631 \r\nL 356.047443 191.183631 \r\n\" style=\"fill:none;stroke:#2ca02c;stroke-linecap:square;stroke-width:1.5;\"/>\r\n   </g>\r\n   <g id=\"line2d_15\">\r\n    <path clip-path=\"url(#p01e0aac283)\" d=\"M 51.683807 198.254158 \r\nL 64.365625 198.254158 \r\nL 77.047443 202.55641 \r\nL 89.729261 202.55641 \r\nL 102.41108 198.254158 \r\nL 115.092898 198.254158 \r\nL 127.774716 198.254158 \r\nL 140.456534 198.254158 \r\nL 153.138352 198.254158 \r\nL 165.82017 198.254158 \r\nL 178.501989 198.254158 \r\nL 191.183807 198.254158 \r\nL 203.865625 177.661465 \r\nL 216.547443 33.077395 \r\nL 229.229261 34.450162 \r\nL 241.91108 34.450162 \r\nL 254.592898 29.584809 \r\nL 267.274716 54.739031 \r\nL 279.956534 51.246444 \r\nL 292.638352 33.077395 \r\nL 305.32017 29.584809 \r\nL 318.001989 29.584809 \r\nL 330.683807 29.584809 \r\nL 343.365625 29.584809 \r\nL 356.047443 29.584809 \r\n\" style=\"fill:none;stroke:#d62728;stroke-linecap:square;stroke-width:1.5;\"/>\r\n   </g>\r\n   <g id=\"patch_3\">\r\n    <path d=\"M 36.465625 224.64 \r\nL 36.465625 7.2 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_4\">\r\n    <path d=\"M 371.265625 224.64 \r\nL 371.265625 7.2 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_5\">\r\n    <path d=\"M 36.465625 224.64 \r\nL 371.265625 224.64 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_6\">\r\n    <path d=\"M 36.465625 7.2 \r\nL 371.265625 7.2 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n  </g>\r\n </g>\r\n <defs>\r\n  <clipPath id=\"p01e0aac283\">\r\n   <rect height=\"217.44\" width=\"334.8\" x=\"36.465625\" y=\"7.2\"/>\r\n  </clipPath>\r\n </defs>\r\n</svg>\r\n",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "source": [
    "for epoch in range(EPOCHS):\n",
    "    gc.collect()\n",
    "    start = time.time()\n",
    "    # enc_hidden = encoder.initialize_hidden_state()\n",
    "    total_loss = 0\n",
    "    total_batch_perplexity = 0\n",
    "    for (batch, (feat, targ)) in enumerate(train_dataset.take(STEPS_PER_EPOCH)):\n",
    "        # print ('Features: {}, Target: {}'.format(feat, targ))\n",
    "        batch_loss = train_step(feat, targ)#, enc_hidden)\n",
    "        batch_perplexity = tf.exp(batch_loss)\n",
    "\n",
    "        total_loss += batch_loss\n",
    "        total_batch_perplexity += batch_perplexity #perplexity_metric.result()\n",
    "        if batch % 100 == 0:\n",
    "            print('Epoch {} Batch {} Loss {:.4f}'.format(epoch + 1,\n",
    "                                                            batch,\n",
    "                                                            batch_loss.numpy()), end=' ')\n",
    "            print('Perplexity {:.4f}'.format(batch_perplexity))\n",
    "    train_losses.append(batch_loss)\n",
    "    _, losses_ce, rouge_recalls, rouge_precisions = predict_on_test(X_test[TASK_FEATURES], Y_test)\n",
    "    val_ce.append(losses_ce)\n",
    "    val_rr.append(rouge_recalls)\n",
    "    val_rp.append(rouge_precisions)\n",
    "    if (epoch + 1) % 5 == 0:\n",
    "        print('saving')\n",
    "        # checkpoint.write(file_prefix=checkpoint_prefix)\n",
    "        checkpoint.step.assign_add(5)\n",
    "        manager.save()\n",
    "        print('saved')\n",
    "    print('Time taken for the epoch {} sec\\n'.format(time.time() - start))\n",
    "best_epoch = np.argmin(train_losses)\n",
    "print('The best epoch is {}'.format(best_epoch))\n",
    "plt.plot(train_losses)\n",
    "plt.plot(np.mean(val_ce, axis=1)/10000)\n",
    "plt.plot(np.mean(val_rr, axis=1))\n",
    "plt.plot(np.mean(val_rp, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 535,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x18d53bc8d60>]"
      ]
     },
     "metadata": {},
     "execution_count": 535
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\r\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\r\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\r\n<!-- Created with matplotlib (https://matplotlib.org/) -->\r\n<svg height=\"248.518125pt\" version=\"1.1\" viewBox=\"0 0 382.291761 248.518125\" width=\"382.291761pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\r\n <metadata>\r\n  <rdf:RDF xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\r\n   <cc:Work>\r\n    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\r\n    <dc:date>2021-05-31T16:01:03.410929</dc:date>\r\n    <dc:format>image/svg+xml</dc:format>\r\n    <dc:creator>\r\n     <cc:Agent>\r\n      <dc:title>Matplotlib v3.3.2, https://matplotlib.org/</dc:title>\r\n     </cc:Agent>\r\n    </dc:creator>\r\n   </cc:Work>\r\n  </rdf:RDF>\r\n </metadata>\r\n <defs>\r\n  <style type=\"text/css\">*{stroke-linecap:butt;stroke-linejoin:round;}</style>\r\n </defs>\r\n <g id=\"figure_1\">\r\n  <g id=\"patch_1\">\r\n   <path d=\"M 0 248.518125 \r\nL 382.291761 248.518125 \r\nL 382.291761 0 \r\nL 0 0 \r\nz\r\n\" style=\"fill:none;\"/>\r\n  </g>\r\n  <g id=\"axes_1\">\r\n   <g id=\"patch_2\">\r\n    <path d=\"M 36.465625 224.64 \r\nL 371.265625 224.64 \r\nL 371.265625 7.2 \r\nL 36.465625 7.2 \r\nz\r\n\" style=\"fill:#ffffff;\"/>\r\n   </g>\r\n   <g id=\"matplotlib.axis_1\">\r\n    <g id=\"xtick_1\">\r\n     <g id=\"line2d_1\">\r\n      <defs>\r\n       <path d=\"M 0 0 \r\nL 0 3.5 \r\n\" id=\"mda5c3aaea7\" style=\"stroke:#000000;stroke-width:0.8;\"/>\r\n      </defs>\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"51.683807\" xlink:href=\"#mda5c3aaea7\" y=\"224.64\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_1\">\r\n      <!-- 0 -->\r\n      <g transform=\"translate(48.502557 239.238438)scale(0.1 -0.1)\">\r\n       <defs>\r\n        <path d=\"M 31.78125 66.40625 \r\nQ 24.171875 66.40625 20.328125 58.90625 \r\nQ 16.5 51.421875 16.5 36.375 \r\nQ 16.5 21.390625 20.328125 13.890625 \r\nQ 24.171875 6.390625 31.78125 6.390625 \r\nQ 39.453125 6.390625 43.28125 13.890625 \r\nQ 47.125 21.390625 47.125 36.375 \r\nQ 47.125 51.421875 43.28125 58.90625 \r\nQ 39.453125 66.40625 31.78125 66.40625 \r\nz\r\nM 31.78125 74.21875 \r\nQ 44.046875 74.21875 50.515625 64.515625 \r\nQ 56.984375 54.828125 56.984375 36.375 \r\nQ 56.984375 17.96875 50.515625 8.265625 \r\nQ 44.046875 -1.421875 31.78125 -1.421875 \r\nQ 19.53125 -1.421875 13.0625 8.265625 \r\nQ 6.59375 17.96875 6.59375 36.375 \r\nQ 6.59375 54.828125 13.0625 64.515625 \r\nQ 19.53125 74.21875 31.78125 74.21875 \r\nz\r\n\" id=\"DejaVuSans-48\"/>\r\n       </defs>\r\n       <use xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_2\">\r\n     <g id=\"line2d_2\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"115.092898\" xlink:href=\"#mda5c3aaea7\" y=\"224.64\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_2\">\r\n      <!-- 5 -->\r\n      <g transform=\"translate(111.911648 239.238438)scale(0.1 -0.1)\">\r\n       <defs>\r\n        <path d=\"M 10.796875 72.90625 \r\nL 49.515625 72.90625 \r\nL 49.515625 64.59375 \r\nL 19.828125 64.59375 \r\nL 19.828125 46.734375 \r\nQ 21.96875 47.46875 24.109375 47.828125 \r\nQ 26.265625 48.1875 28.421875 48.1875 \r\nQ 40.625 48.1875 47.75 41.5 \r\nQ 54.890625 34.8125 54.890625 23.390625 \r\nQ 54.890625 11.625 47.5625 5.09375 \r\nQ 40.234375 -1.421875 26.90625 -1.421875 \r\nQ 22.3125 -1.421875 17.546875 -0.640625 \r\nQ 12.796875 0.140625 7.71875 1.703125 \r\nL 7.71875 11.625 \r\nQ 12.109375 9.234375 16.796875 8.0625 \r\nQ 21.484375 6.890625 26.703125 6.890625 \r\nQ 35.15625 6.890625 40.078125 11.328125 \r\nQ 45.015625 15.765625 45.015625 23.390625 \r\nQ 45.015625 31 40.078125 35.4375 \r\nQ 35.15625 39.890625 26.703125 39.890625 \r\nQ 22.75 39.890625 18.8125 39.015625 \r\nQ 14.890625 38.140625 10.796875 36.28125 \r\nz\r\n\" id=\"DejaVuSans-53\"/>\r\n       </defs>\r\n       <use xlink:href=\"#DejaVuSans-53\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_3\">\r\n     <g id=\"line2d_3\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"178.501989\" xlink:href=\"#mda5c3aaea7\" y=\"224.64\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_3\">\r\n      <!-- 10 -->\r\n      <g transform=\"translate(172.139489 239.238438)scale(0.1 -0.1)\">\r\n       <defs>\r\n        <path d=\"M 12.40625 8.296875 \r\nL 28.515625 8.296875 \r\nL 28.515625 63.921875 \r\nL 10.984375 60.40625 \r\nL 10.984375 69.390625 \r\nL 28.421875 72.90625 \r\nL 38.28125 72.90625 \r\nL 38.28125 8.296875 \r\nL 54.390625 8.296875 \r\nL 54.390625 0 \r\nL 12.40625 0 \r\nz\r\n\" id=\"DejaVuSans-49\"/>\r\n       </defs>\r\n       <use xlink:href=\"#DejaVuSans-49\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_4\">\r\n     <g id=\"line2d_4\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"241.91108\" xlink:href=\"#mda5c3aaea7\" y=\"224.64\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_4\">\r\n      <!-- 15 -->\r\n      <g transform=\"translate(235.54858 239.238438)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-49\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_5\">\r\n     <g id=\"line2d_5\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"305.32017\" xlink:href=\"#mda5c3aaea7\" y=\"224.64\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_5\">\r\n      <!-- 20 -->\r\n      <g transform=\"translate(298.95767 239.238438)scale(0.1 -0.1)\">\r\n       <defs>\r\n        <path d=\"M 19.1875 8.296875 \r\nL 53.609375 8.296875 \r\nL 53.609375 0 \r\nL 7.328125 0 \r\nL 7.328125 8.296875 \r\nQ 12.9375 14.109375 22.625 23.890625 \r\nQ 32.328125 33.6875 34.8125 36.53125 \r\nQ 39.546875 41.84375 41.421875 45.53125 \r\nQ 43.3125 49.21875 43.3125 52.78125 \r\nQ 43.3125 58.59375 39.234375 62.25 \r\nQ 35.15625 65.921875 28.609375 65.921875 \r\nQ 23.96875 65.921875 18.8125 64.3125 \r\nQ 13.671875 62.703125 7.8125 59.421875 \r\nL 7.8125 69.390625 \r\nQ 13.765625 71.78125 18.9375 73 \r\nQ 24.125 74.21875 28.421875 74.21875 \r\nQ 39.75 74.21875 46.484375 68.546875 \r\nQ 53.21875 62.890625 53.21875 53.421875 \r\nQ 53.21875 48.921875 51.53125 44.890625 \r\nQ 49.859375 40.875 45.40625 35.40625 \r\nQ 44.1875 33.984375 37.640625 27.21875 \r\nQ 31.109375 20.453125 19.1875 8.296875 \r\nz\r\n\" id=\"DejaVuSans-50\"/>\r\n       </defs>\r\n       <use xlink:href=\"#DejaVuSans-50\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_6\">\r\n     <g id=\"line2d_6\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"368.729261\" xlink:href=\"#mda5c3aaea7\" y=\"224.64\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_6\">\r\n      <!-- 25 -->\r\n      <g transform=\"translate(362.366761 239.238438)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-50\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n   </g>\r\n   <g id=\"matplotlib.axis_2\">\r\n    <g id=\"ytick_1\">\r\n     <g id=\"line2d_7\">\r\n      <defs>\r\n       <path d=\"M 0 0 \r\nL -3.5 0 \r\n\" id=\"m6e3f62d82e\" style=\"stroke:#000000;stroke-width:0.8;\"/>\r\n      </defs>\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"36.465625\" xlink:href=\"#m6e3f62d82e\" y=\"218.771499\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_7\">\r\n      <!-- 0.00 -->\r\n      <g transform=\"translate(7.2 222.570718)scale(0.1 -0.1)\">\r\n       <defs>\r\n        <path d=\"M 10.6875 12.40625 \r\nL 21 12.40625 \r\nL 21 0 \r\nL 10.6875 0 \r\nz\r\n\" id=\"DejaVuSans-46\"/>\r\n       </defs>\r\n       <use xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\r\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_2\">\r\n     <g id=\"line2d_8\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"36.465625\" xlink:href=\"#m6e3f62d82e\" y=\"174.449581\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_8\">\r\n      <!-- 0.05 -->\r\n      <g transform=\"translate(7.2 178.2488)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\r\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-53\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_3\">\r\n     <g id=\"line2d_9\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"36.465625\" xlink:href=\"#m6e3f62d82e\" y=\"130.127663\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_9\">\r\n      <!-- 0.10 -->\r\n      <g transform=\"translate(7.2 133.926882)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\r\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-49\"/>\r\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_4\">\r\n     <g id=\"line2d_10\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"36.465625\" xlink:href=\"#m6e3f62d82e\" y=\"85.805744\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_10\">\r\n      <!-- 0.15 -->\r\n      <g transform=\"translate(7.2 89.604963)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\r\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-49\"/>\r\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-53\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_5\">\r\n     <g id=\"line2d_11\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"36.465625\" xlink:href=\"#m6e3f62d82e\" y=\"41.483826\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_11\">\r\n      <!-- 0.20 -->\r\n      <g transform=\"translate(7.2 45.283045)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\r\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-50\"/>\r\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n   </g>\r\n   <g id=\"line2d_12\">\r\n    <path clip-path=\"url(#p2c2704ab86)\" d=\"M 51.683807 17.083636 \r\nL 64.365625 46.953535 \r\nL 77.047443 67.328529 \r\nL 89.729261 72.624993 \r\nL 102.41108 75.439532 \r\nL 115.092898 76.898065 \r\nL 127.774716 76.664372 \r\nL 140.456534 76.846299 \r\nL 153.138352 77.379241 \r\nL 165.82017 77.698132 \r\nL 178.501989 77.888486 \r\nL 191.183807 77.249238 \r\nL 203.865625 86.323187 \r\nL 216.547443 90.878786 \r\nL 229.229261 96.783548 \r\nL 241.91108 88.439038 \r\nL 254.592898 101.46631 \r\nL 267.274716 98.665733 \r\nL 279.956534 104.838861 \r\nL 292.638352 106.532237 \r\nL 305.32017 117.907332 \r\nL 318.001989 113.915075 \r\nL 330.683807 113.758826 \r\nL 343.365625 118.270347 \r\nL 356.047443 131.18846 \r\n\" style=\"fill:none;stroke:#1f77b4;stroke-linecap:square;stroke-width:1.5;\"/>\r\n   </g>\r\n   <g id=\"line2d_13\">\r\n    <path clip-path=\"url(#p2c2704ab86)\" d=\"M 51.683807 116.94708 \r\nL 64.365625 102.468659 \r\nL 77.047443 97.255676 \r\nL 89.729261 93.649445 \r\nL 102.41108 95.159269 \r\nL 115.092898 91.207861 \r\nL 127.774716 87.516432 \r\nL 140.456534 85.328354 \r\nL 153.138352 83.642059 \r\nL 165.82017 81.668243 \r\nL 178.501989 79.060253 \r\nL 191.183807 78.589671 \r\nL 203.865625 63.825883 \r\nL 216.547443 75.04317 \r\nL 229.229261 65.056998 \r\nL 241.91108 61.182558 \r\nL 254.592898 65.050089 \r\nL 267.274716 48.130493 \r\nL 279.956534 46.143324 \r\nL 292.638352 52.152226 \r\nL 305.32017 55.542332 \r\nL 318.001989 47.993067 \r\nL 330.683807 48.347252 \r\nL 343.365625 41.99826 \r\nL 356.047443 49.729438 \r\n\" style=\"fill:none;stroke:#ff7f0e;stroke-linecap:square;stroke-width:1.5;\"/>\r\n   </g>\r\n   <g id=\"line2d_14\">\r\n    <path clip-path=\"url(#p2c2704ab86)\" d=\"M 51.683807 213.979241 \r\nL 64.365625 213.979241 \r\nL 77.047443 214.756364 \r\nL 89.729261 214.756364 \r\nL 102.41108 213.979241 \r\nL 115.092898 213.979241 \r\nL 127.774716 213.979241 \r\nL 140.456534 213.979241 \r\nL 153.138352 213.979241 \r\nL 165.82017 213.979241 \r\nL 178.501989 213.979241 \r\nL 191.183807 213.979241 \r\nL 203.865625 209.186982 \r\nL 216.547443 191.960754 \r\nL 229.229261 192.608357 \r\nL 241.91108 192.608357 \r\nL 254.592898 191.183631 \r\nL 267.274716 195.846369 \r\nL 279.956534 195.069246 \r\nL 292.638352 191.960754 \r\nL 305.32017 191.183631 \r\nL 318.001989 191.183631 \r\nL 330.683807 191.183631 \r\nL 343.365625 191.183631 \r\nL 356.047443 191.183631 \r\n\" style=\"fill:none;stroke:#2ca02c;stroke-linecap:square;stroke-width:1.5;\"/>\r\n   </g>\r\n   <g id=\"line2d_15\">\r\n    <path clip-path=\"url(#p2c2704ab86)\" d=\"M 51.683807 198.254158 \r\nL 64.365625 198.254158 \r\nL 77.047443 202.55641 \r\nL 89.729261 202.55641 \r\nL 102.41108 198.254158 \r\nL 115.092898 198.254158 \r\nL 127.774716 198.254158 \r\nL 140.456534 198.254158 \r\nL 153.138352 198.254158 \r\nL 165.82017 198.254158 \r\nL 178.501989 198.254158 \r\nL 191.183807 198.254158 \r\nL 203.865625 177.661465 \r\nL 216.547443 33.077395 \r\nL 229.229261 34.450162 \r\nL 241.91108 34.450162 \r\nL 254.592898 29.584809 \r\nL 267.274716 54.739031 \r\nL 279.956534 51.246444 \r\nL 292.638352 33.077395 \r\nL 305.32017 29.584809 \r\nL 318.001989 29.584809 \r\nL 330.683807 29.584809 \r\nL 343.365625 29.584809 \r\nL 356.047443 29.584809 \r\n\" style=\"fill:none;stroke:#d62728;stroke-linecap:square;stroke-width:1.5;\"/>\r\n   </g>\r\n   <g id=\"patch_3\">\r\n    <path d=\"M 36.465625 224.64 \r\nL 36.465625 7.2 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_4\">\r\n    <path d=\"M 371.265625 224.64 \r\nL 371.265625 7.2 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_5\">\r\n    <path d=\"M 36.465625 224.64 \r\nL 371.265625 224.64 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_6\">\r\n    <path d=\"M 36.465625 7.2 \r\nL 371.265625 7.2 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n  </g>\r\n </g>\r\n <defs>\r\n  <clipPath id=\"p2c2704ab86\">\r\n   <rect height=\"217.44\" width=\"334.8\" x=\"36.465625\" y=\"7.2\"/>\r\n  </clipPath>\r\n </defs>\r\n</svg>\r\n",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "source": [
    "plt.plot(train_losses)\n",
    "plt.plot(np.mean(val_ce, axis=1)/1000)\n",
    "plt.plot(np.mean(val_rr, axis=1))\n",
    "plt.plot(np.mean(val_rp, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 559,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(190.69804, 0.031122150789012277, 0.21342340095811763)"
      ]
     },
     "metadata": {},
     "execution_count": 559
    }
   ],
   "source": [
    "(np.mean(val_ce, axis=1))[best_epoch],\\\n",
    "(np.mean(val_rr, axis=1))[best_epoch],\\\n",
    "(np.mean(val_rp, axis=1))[best_epoch]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 522,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))"
   ]
  },
  {
   "source": [
    "### Sequence Generation"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 548,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_task(task_vector):\n",
    "    # either convert to float32 or encode to categoricals\n",
    "    for i, el in enumerate(task_vector):\n",
    "        try:\n",
    "            task_vector[i] = float(task_vector[i])\n",
    "        except:\n",
    "            task_vector[i] = get_key(cat_encodings[i], task_vector[i])\n",
    "    return task_vector.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 549,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_solution(task_vector, save_outputs:bool=False):\n",
    "  attention_plot = np.zeros((max_length_targ, max_length_feat))\n",
    "  task_vector = preprocess_task(task_vector)\n",
    "  inputs = tf.expand_dims(tf.convert_to_tensor(task_vector), axis=0)\n",
    "  result = ''\n",
    "\n",
    "  dec_hidden = tf.zeros((BATCH_SIZE, gru_units))\n",
    "  dec_input = tf.expand_dims([1], 0)\n",
    "  loss = 0\n",
    "  for t in range(max_length_targ):\n",
    "    predictions, dec_hidden = decoder(dec_input\n",
    "                                      , dec_hidden\n",
    "                                      , inputs)\n",
    "    # storing the attention weights to plot later on\n",
    "    # attention_weights = tf.reshape(attention_weights, (-1, ))\n",
    "    # attention_plot[t] = attention_weights.numpy()\n",
    "    predicted_id = tf.argmax(predictions[0]).numpy()\n",
    "    predicted_vertice = get_key(lang, predicted_id)\n",
    "    if (predicted_vertice != ' ')&(predicted_vertice != ''):\n",
    "      # loss += loss_function(true_vector, predictions)\n",
    "      # print(loss)\n",
    "      result = predicted_vertice + ' ' + result #targ_lang.index_word[predicted_id] + ' '\n",
    "    elif (predicted_vertice == '<start>')&(predicted_vertice == '<end>'):\n",
    "      print('Evaluation: found start/end, ending')\n",
    "      return result, task_vector#, attention_plot\n",
    "    \n",
    "    # the predicted ID is fed back into the model\n",
    "    dec_input = tf.expand_dims([predicted_id], 0)\n",
    "  if save_outputs:\n",
    "    OUTPUT_FILE = './task2seq/outputs/output.py'\n",
    "    with open(OUTPUT_FILE, 'w') as f:\n",
    "        last_vertice = ''\n",
    "        for vertice in result.split(' '):\n",
    "            if vertice:\n",
    "                if (vertice!='<start>')&(vertice!='<end>')&(vertice!=last_vertice):\n",
    "                    line = '#@ {} \\n\\n'.format(vertice)\n",
    "                    f.write(line)\n",
    "                    last_vertice = vertice\n",
    "  return result, task_vector#, attention_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 550,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# i = 0\n",
    "# example_task_vector = X_test.reset_index(drop=True).loc[i]\n",
    "# example_true_vector = Y_test[i]\n",
    "# example_true_sequence = y_test.loc[i][0]\n",
    "# print('task vector: {} \\n'.format(example_task_vector.values))\n",
    "# print('true sequence is: {}\\n'.format(example_true_sequence))\n",
    "# result, task_vector = generate_solution(example_task_vector)\n",
    "# print(result, '\\n')\n",
    "# print('length of the result sequence is: {} \\n'.format(len(result.split(' '))))"
   ]
  },
  {
   "source": [
    "### Model Evaluation"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rouge_recall(true_string_vector:list, predicted_string_vector:list) -> float:\n",
    "    true_string_vector = [el for el in true_string_vector if el != 0]\n",
    "    # predicted_string_vector = [el for el in predicted_string_vector if el != 0]\n",
    "    n_overlapping_words = len(set(true_string_vector).intersection(set(predicted_string_vector)))\n",
    "    total_words_in_output = len(predicted_string_vector)\n",
    "    return n_overlapping_words / total_words_in_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rouge_precision(true_string_vector:list, predicted_string_vector:list) -> float:\n",
    "    true_string_vector = [el for el in true_string_vector if el != 0]\n",
    "    n_overlapping_words = len(set(true_string_vector).intersection(set(predicted_string_vector)))\n",
    "    total_words_in_reference = len(true_string_vector)\n",
    "    return n_overlapping_words / total_words_in_reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_generated_sequence(generated_sequence_string:str, output_path:str):\n",
    "    # OUTPUT_FILE = './task2seq/outputs/output.py'\n",
    "    with open(output_path, 'w') as f:\n",
    "        last_vertice = ''\n",
    "        for vertice in generated_sequence_string.split(' '):\n",
    "            if vertice:\n",
    "                if (vertice!='<start>')&(vertice!='<end>')&(vertice!=last_vertice):\n",
    "                    line = '#@ {} \\n\\n'.format(vertice)\n",
    "                    f.write(line)\n",
    "                    last_vertice = vertice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_solution_with_evaluation(task_vector, true_sequence:np.array, save_outputs:bool=False):\n",
    "    task_vector = preprocess_task(task_vector)\n",
    "    inputs = tf.expand_dims(tf.convert_to_tensor(task_vector), axis=0)\n",
    "    generated_sequence_string = ''\n",
    "    generated_sequence_array = []\n",
    "    metrics = {}\n",
    "\n",
    "    dec_hidden = tf.zeros((BATCH_SIZE, gru_units))\n",
    "    dec_input = tf.expand_dims([1], 0)\n",
    "    loss = 0\n",
    "    for t in range(max_length_targ):\n",
    "        predictions, dec_hidden = decoder(dec_input\n",
    "                                          , dec_hidden\n",
    "                                          , inputs)\n",
    "        predicted_id = tf.argmax(predictions[0]).numpy()\n",
    "        generated_sequence_array.append(predicted_id)\n",
    "\n",
    "        predicted_vertice = get_key(lang, predicted_id)\n",
    "        if (predicted_vertice != ' ')&(predicted_vertice != ''):\n",
    "            loss += loss_function(true_sequence[t], predictions)\n",
    "            generated_sequence_string = predicted_vertice + ' ' + generated_sequence_string\n",
    "        elif (predicted_vertice == '<start>')&(predicted_vertice == '<end>'):\n",
    "            print('Evaluation: found start/end, ending')\n",
    "            return generated_sequence_string, metrics\n",
    "\n",
    "        dec_input = tf.expand_dims([predicted_id], 0)\n",
    "    metrics.update({\"Cross-Entropy\":loss.numpy(),\n",
    "                  \"Perplexity\":tf.exp(loss).numpy(),\n",
    "                  \"ROUGE-Recall\":rouge_recall(true_sequence, generated_sequence_array),\n",
    "                  \"ROUGE-Precision\": rouge_precision(true_sequence, generated_sequence_array)})\n",
    "    if save_outputs:\n",
    "        TODAY_NOW = datetime.now().strftime(\"%d-%m-%y_%H-%M-%S\")\n",
    "        save_generated_sequence(generated_sequence_string, output_path='./outputs/output_{}.py'.format(TODAY_NOW))\n",
    "    return generated_sequence_string, metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {},
   "outputs": [],
   "source": [
    "# i = 0\n",
    "# example_task_vector = X_test.reset_index(drop=True).loc[i]\n",
    "# example_true_vector = Y_test[i]\n",
    "# example_true_sequence = y_test.loc[i][0]\n",
    "# print('task vector: {} \\n'.format(example_task_vector.values))\n",
    "# print('true sequence is: {}\\n'.format(example_true_sequence))\n",
    "# result, metrics = generate_solution_with_evaluation(example_task_vector, example_true_vector, save_outputs=True)\n",
    "# print('predicted sequence is: {}\\n'.format(result))\n",
    "# print('predicted unique sequence is: {}\\n'.format(\" \".join(list(set(result.split(' ')))))) #[el for i, el in enumerate(result.split(' ')) if result.split(' ')[i-1] != el])\n",
    "# print('length of the result sequence is: {} \\n'.format(len(result.split(' '))))\n",
    "# print('Metrics:', metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_on_test(X_test, Y_test):\n",
    "    y_pred = []\n",
    "    losses_ce = []\n",
    "    rouge_recalls = []\n",
    "    rouge_precisions = []\n",
    "    print('predicting..', end=' ')\n",
    "    for i, task_vector in X_test.reset_index(drop=True).iterrows():\n",
    "        print('{:.1%}'.format(i/X_test.shape[0]), end=' ')\n",
    "        true_vector = Y_test[i]\n",
    "        result, metrics = generate_solution_with_evaluation(task_vector, true_vector)\n",
    "        # print(loss.numpy())\n",
    "        y_pred.append(result[:-1])\n",
    "        losses_ce.append(metrics['Cross-Entropy'])\n",
    "        rouge_recalls.append(metrics['ROUGE-Recall'])\n",
    "        rouge_precisions.append(metrics['ROUGE-Precision'])\n",
    "    print()\n",
    "    y_pred = pd.DataFrame(y_pred, columns=[TARGET_COLUMN])\n",
    "    print('Cross-Entropy: {}'.format(np.mean(losses_ce)))\n",
    "    print('Perplexity: {}'.format(np.exp(float(np.mean(losses_ce)))))\n",
    "    print('ROUGE-Recall: {}'.format(np.mean(rouge_recalls)))\n",
    "    print('ROUGE-Precision: {}'.format(np.mean(rouge_precisions)))\n",
    "    print('Unique answers: {}'.format(y_pred[TARGET_COLUMN].nunique()))\n",
    "    return y_pred, losses_ce, rouge_recalls, rouge_precisions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "predicting.. 0.00% 1.85% 3.70% 5.56% 7.41% 9.26% 11.11% 12.96% 14.81% 16.67% 18.52% 20.37% 22.22% 24.07% 25.93% 27.78% 29.63% 31.48% 33.33% 35.19% 37.04% 38.89% 40.74% 42.59% 44.44% 46.30% 48.15% 50.00% 51.85% 53.70% 55.56% 57.41% 59.26% 61.11% 62.96% 64.81% 66.67% 68.52% 70.37% 72.22% 74.07% 75.93% 77.78% 79.63% 81.48% 83.33% 85.19% 87.04% 88.89% 90.74% 92.59% 94.44% 96.30% 98.15% \n",
      "Cross-Entropy: 412.9048156738281\n",
      "Perplexity: 2.1003080572384504e+179\n",
      "ROUGE-Recall: 0.07838441890166029\n",
      "ROUGE-Precision: 0.31504992246593394\n",
      "Unique answers: 4\n"
     ]
    }
   ],
   "source": [
    "## Predict on Train\n",
    "_, _, _, _ = predict_on_test(X_train[TASK_FEATURES], Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "predicting.. 0.00% 1.69% 3.39% 5.08% 6.78% 8.47% 10.17% 11.86% 13.56% 15.25% 16.95% 18.64% 20.34% 22.03% 23.73% 25.42% 27.12% 28.81% 30.51% 32.20% 33.90% 35.59% 37.29% 38.98% 40.68% 42.37% 44.07% 45.76% 47.46% 49.15% 50.85% 52.54% 54.24% 55.93% 57.63% 59.32% 61.02% 62.71% 64.41% 66.10% 67.80% 69.49% 71.19% 72.88% 74.58% 76.27% 77.97% 79.66% 81.36% 83.05% 84.75% 86.44% 88.14% 89.83% 91.53% 93.22% 94.92% 96.61% 98.31% \n",
      "Cross-Entropy: 549.2652587890625\n",
      "Perplexity: 3.490366190935956e+238\n",
      "ROUGE-Recall: 0.03755113968439509\n",
      "ROUGE-Precision: 0.164129474579846\n",
      "Unique answers: 2\n"
     ]
    }
   ],
   "source": [
    "## Predict on Test\n",
    "_, _, _, _ = predict_on_test(X_test[TASK_FEATURES], Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {},
   "outputs": [],
   "source": [
    "# val_ce = []\n",
    "# val_rr = []\n",
    "# val_rp = []\n",
    "# for i in range(1, EPOCHS//5 + 1):\n",
    "#     checkpoint.restore('./checkpoints/ckpt-{}.index'.format(i))\n",
    "#     _, losses_ce, rouge_recalls, rouge_precisions = predict_on_test(X_test[TASK_FEATURES], Y_test)\n",
    "#     val_ce.append(losses_ce)\n",
    "#     val_rr.append(rouge_recalls)\n",
    "#     val_rp.append(rouge_precisions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred[TARGET_COLUMN].unique()"
   ]
  },
  {
   "source": [
    "---\n",
    "## To Do"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {},
   "outputs": [],
   "source": [
    "##TODO: To py and argparse"
   ]
  },
  {
   "source": [
    "### To DAGsHub"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ##TODO: Export to DAGsHub\n",
    "# experiment_params = run_params.update(model_params)\n",
    "# experiment_params = experiment_params.update(data_params)\n",
    "# print(experiment_params)\n",
    "# # experiment_results = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}