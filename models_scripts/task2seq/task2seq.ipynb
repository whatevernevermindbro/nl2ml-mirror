{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python385jvsc74a57bd0d0ddd292140de7144a2e52e7cfaaa287bc93c7991ea231311f4a8d4f39ae4756",
   "display_name": "Python 3.8.5 64-bit ('base': conda)"
  },
  "metadata": {
   "interpreter": {
    "hash": "0de36b31320ba4c88b4f85a74724f3d16c36a44df48581253710b1065e752d9e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import gc\n",
    "from datetime import datetime\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import backend as K\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import log_loss\n",
    "from sqlalchemy import create_engine\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('mode.chained_assignment', None)"
   ]
  },
  {
   "source": [
    "### Defining Methods"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_key(my_dict, val):\n",
    "    for key, value in my_dict.items():\n",
    "         if val == value:\n",
    "             return key\n",
    " \n",
    "    return \"key doesn't exist\""
   ]
  },
  {
   "source": [
    "### Reading Data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "---"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Index(['graph_vertex_id', 'graph_vertex', 'graph_vertex_subclass'], dtype='object')"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "graph_path = '../../data/actual_graph_2021-05-22.csv'\n",
    "graph = pd.read_csv(graph_path)\n",
    "graph.rename({'id':'graph_vertex_id'}, axis=1, inplace=True)\n",
    "graph.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(266, 8)"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "COMPETITIONS_PATH = \"../../data/competitions_info_cleaned_filled.csv\" #./data/competitions_info_cleaned.csv\n",
    "competitions_filled = pd.read_csv(COMPETITIONS_PATH)\n",
    "competitions_filled.drop_duplicates(inplace=True)\n",
    "competitions_filled.rename({'Description': 'description', 'Metric':'metric', 'DataType':'datatype', 'Subject':'subject', 'ProblemType':'problemtype'}\n",
    "                        , axis=1, inplace=True)\n",
    "competitions_filled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "ref             0\n",
       "comp_name       0\n",
       "comp_type       0\n",
       "description    21\n",
       "metric         19\n",
       "datatype       19\n",
       "subject        19\n",
       "problemtype    19\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "competitions_filled.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "competitions_filled['ref'] = competitions_filled['ref'].str.replace(\"'\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(5060, 10)"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "COMPETITIONS_PATH = \"../../data/competitions_2021-05-22.csv\" #./data/competitions_info_cleaned.csv\n",
    "competitions = pd.read_csv(COMPETITIONS_PATH)\n",
    "competitions.drop_duplicates(inplace=True)\n",
    "competitions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# competitions['ref'] = competitions['ref'].apply(lambda x: x.split(',')[0])\n",
    "# competitions['ref'] = competitions['ref'].str.replace(\"'\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# competitions['exists_in_comp_filled'] = competitions.apply(lambda x: x['ref'] in competitions_filled['ref'].unique(), axis=1)\n",
    "# competitions['exists_in_comp_filled'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# competitions_filled.merge(competitions[['id', 'ref']], on=['ref']).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(312, 10)"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "competitions = competitions_filled.merge(competitions[['id', 'ref_link']], how='inner', left_on=['ref'], right_on=['ref_link'])\n",
    "competitions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "ref             0\n",
       "comp_name       0\n",
       "comp_type       0\n",
       "description    26\n",
       "metric         23\n",
       "datatype       23\n",
       "subject        23\n",
       "problemtype    23\n",
       "id              0\n",
       "ref_link        0\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "competitions.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   code_block_id                                         code_block  \\\n",
       "0         570367  `# My forecasting COVID-19 confirmed cases and...   \n",
       "1         570367  `# My forecasting COVID-19 confirmed cases and...   \n",
       "2         570368  `# load training and testing data \\nsubm = pd....   \n",
       "3         570369                                             `subm`   \n",
       "4         570367  `# My forecasting COVID-19 confirmed cases and...   \n",
       "\n",
       "  data_format  graph_vertex_id errors  marks  kaggle_id  competition_id  \n",
       "0       Table               45     No      2    8591010            3868  \n",
       "1       Table               45     No      2    8591010            3868  \n",
       "2       Table               45     No      5    8591010            3868  \n",
       "3       Table               41     No      5    8591010            3868  \n",
       "4       Table               45     No      2    8591010            3868  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>code_block_id</th>\n      <th>code_block</th>\n      <th>data_format</th>\n      <th>graph_vertex_id</th>\n      <th>errors</th>\n      <th>marks</th>\n      <th>kaggle_id</th>\n      <th>competition_id</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>570367</td>\n      <td>`# My forecasting COVID-19 confirmed cases and...</td>\n      <td>Table</td>\n      <td>45</td>\n      <td>No</td>\n      <td>2</td>\n      <td>8591010</td>\n      <td>3868</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>570367</td>\n      <td>`# My forecasting COVID-19 confirmed cases and...</td>\n      <td>Table</td>\n      <td>45</td>\n      <td>No</td>\n      <td>2</td>\n      <td>8591010</td>\n      <td>3868</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>570368</td>\n      <td>`# load training and testing data \\nsubm = pd....</td>\n      <td>Table</td>\n      <td>45</td>\n      <td>No</td>\n      <td>5</td>\n      <td>8591010</td>\n      <td>3868</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>570369</td>\n      <td>`subm`</td>\n      <td>Table</td>\n      <td>41</td>\n      <td>No</td>\n      <td>5</td>\n      <td>8591010</td>\n      <td>3868</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>570367</td>\n      <td>`# My forecasting COVID-19 confirmed cases and...</td>\n      <td>Table</td>\n      <td>45</td>\n      <td>No</td>\n      <td>2</td>\n      <td>8591010</td>\n      <td>3868</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "NOTEBOOKS_PATH = '../../data/markup_data_2021-05-22.csv'\n",
    "notebooks = pd.read_csv(NOTEBOOKS_PATH)\n",
    "notebooks.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(5932, 10)"
      ]
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "source": [
    "notebooks = notebooks.merge(graph, on='graph_vertex_id', how='left')\n",
    "notebooks.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "3207\n3110\n"
     ]
    }
   ],
   "source": [
    "nl2ml = notebooks.merge(competitions, left_on=['competition_id'], right_on=['id'], how='inner')\n",
    "print(nl2ml.shape[0])\n",
    "nl2ml.drop_duplicates(inplace=True, subset=['code_block_id', 'kaggle_id'])\n",
    "print(nl2ml.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "113 7\n"
     ]
    }
   ],
   "source": [
    "print(nl2ml['kaggle_id'].nunique(), nl2ml['competition_id'].nunique())"
   ]
  },
  {
   "source": [
    "### Vertices Preprocessing"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Data_Transform          936\n",
       "EDA                     747\n",
       "Model_Train             287\n",
       "Visualization           281\n",
       "Environment             202\n",
       "Data_Extraction         167\n",
       "Other                   147\n",
       "Hyperparam_Tuning       120\n",
       "Data_Export             104\n",
       "Model_Evaluation         95\n",
       "Model_Interpretation     21\n",
       "Hypothesis                3\n",
       "Name: graph_vertex, dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "source": [
    "nl2ml['graph_vertex'].apply(lambda x: x.split(';')[0].split('.')[0]).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Index(['code_block_id', 'code_block', 'data_format', 'graph_vertex_id',\n",
       "       'errors', 'marks', 'kaggle_id', 'competition_id', 'graph_vertex',\n",
       "       'graph_vertex_subclass', 'ref', 'comp_name', 'comp_type', 'description',\n",
       "       'metric', 'datatype', 'subject', 'problemtype', 'id', 'ref_link'],\n",
       "      dtype='object')"
      ]
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "source": [
    "nl2ml.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "nl2ml['vertex_l1'], nl2ml['vertex_l2'] = nl2ml['graph_vertex'].apply(lambda x: x.split(';')[0].split('.')[0]), nl2ml['graph_vertex_subclass']#.apply(lambda x: x.split(';')[0].split('.')[1])"
   ]
  },
  {
   "source": [
    "### Missing Values"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "code_block_id            0\ncode_block               0\ndata_format              0\ngraph_vertex_id          0\nerrors                   0\nmarks                    0\nkaggle_id                0\ncompetition_id           0\ngraph_vertex             0\ngraph_vertex_subclass    0\nref                      0\ncomp_name                0\ncomp_type                0\ndescription              0\nmetric                   0\ndatatype                 0\nsubject                  0\nproblemtype              0\nid                       0\nref_link                 0\nvertex_l1                0\nvertex_l2                0\ndtype: int64\ncode_block_id            0\ncode_block               0\ndata_format              0\ngraph_vertex_id          0\nerrors                   0\nmarks                    0\nkaggle_id                0\ncompetition_id           0\ngraph_vertex             0\ngraph_vertex_subclass    0\nref                      0\ncomp_name                0\ncomp_type                0\ndescription              0\nmetric                   0\ndatatype                 0\nsubject                  0\nproblemtype              0\nid                       0\nref_link                 0\nvertex_l1                0\nvertex_l2                0\ndtype: int64\n"
     ]
    }
   ],
   "source": [
    "nl2ml.replace('-', -1, inplace=True)\n",
    "print(nl2ml.isna().sum())\n",
    "nl2ml.fillna(-1, inplace=True)\n",
    "print(nl2ml.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "TASK_FEATURES = ['comp_name', 'comp_type', 'description',\n",
    "                'metric', 'datatype', 'subject', 'problemtype']\n",
    "# TASK_FEATURES = ['ProblemType',\n",
    "#                 'number of columns (for tabular)', 'number of entries',\n",
    "#                 'LabelType', 'Number of classes', 'Loss Function/Metrics',\n",
    "#                 'Target Column(s) Name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET_COLUMN = 'vertex_l2'"
   ]
  },
  {
   "source": [
    "### Grouping chunks by notebooks"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "notebook_id_col = 'kaggle_id'\n",
    "competition_id_col = 'competition_id'\n",
    "def group_by_notebooks(data:pd.DataFrame, vertex_col:str='vertex_l1') -> pd.DataFrame:\n",
    "    notebook_cols = [[notebook_id_col, vertex_col, competition_id_col] + TASK_FEATURES]\n",
    "    df = pd.DataFrame(columns=notebook_cols)\n",
    "    for i, notebook_id in enumerate(data[notebook_id_col].unique()):\n",
    "        notebook = data[data[notebook_id_col] == notebook_id].reset_index(drop=True)\n",
    "        vertices_seq = \" \".join(notebook[vertex_col])\n",
    "        task_features = notebook[TASK_FEATURES].loc[0]\n",
    "        competition_id = notebook[competition_id_col].unique()[0]\n",
    "        row = [notebook_id, vertices_seq, competition_id] + task_features.tolist()\n",
    "        df.loc[i] = row\n",
    "        print('notebook #{} done'.format(notebook_id))\n",
    "    return df"
   ]
  },
  {
   "source": [
    "### Taking Train Features"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "notebook #8591010 done\n",
      "notebook #8592598 done\n",
      "notebook #8596735 done\n",
      "notebook #8606894 done\n",
      "notebook #8609050 done\n",
      "notebook #8611767 done\n",
      "notebook #8630977 done\n",
      "notebook #8634286 done\n",
      "notebook #8640194 done\n",
      "notebook #8660923 done\n",
      "notebook #8667455 done\n",
      "notebook #8668446 done\n",
      "notebook #8678201 done\n",
      "notebook #8687334 done\n",
      "notebook #8689318 done\n",
      "notebook #8699382 done\n",
      "notebook #8705213 done\n",
      "notebook #8706858 done\n",
      "notebook #8708118 done\n",
      "notebook #8710137 done\n",
      "notebook #8710362 done\n",
      "notebook #8604602 done\n",
      "notebook #8617043 done\n",
      "notebook #8620454 done\n",
      "notebook #8625834 done\n",
      "notebook #8628909 done\n",
      "notebook #8658083 done\n",
      "notebook #8663175 done\n",
      "notebook #8671133 done\n",
      "notebook #8679319 done\n",
      "notebook #8682800 done\n",
      "notebook #8687249 done\n",
      "notebook #8693806 done\n",
      "notebook #8701862 done\n",
      "notebook #8702904 done\n",
      "notebook #8706295 done\n",
      "notebook #8711165 done\n",
      "notebook #9326374 done\n",
      "notebook #9349764 done\n",
      "notebook #9463384 done\n",
      "notebook #138832 done\n",
      "notebook #2637869 done\n",
      "notebook #5466844 done\n",
      "notebook #5729566 done\n",
      "notebook #6470191 done\n",
      "notebook #8382140 done\n",
      "notebook #9655329 done\n",
      "notebook #10424951 done\n",
      "notebook #10522332 done\n",
      "notebook #10702707 done\n",
      "notebook #10913030 done\n",
      "notebook #11097956 done\n",
      "notebook #11410370 done\n",
      "notebook #11611498 done\n",
      "notebook #11656525 done\n",
      "notebook #12034947 done\n",
      "notebook #12343159 done\n",
      "notebook #13503938 done\n",
      "notebook #14177670 done\n",
      "notebook #171635 done\n",
      "notebook #2843645 done\n",
      "notebook #2846432 done\n",
      "notebook #2874738 done\n",
      "notebook #2894439 done\n",
      "notebook #2895967 done\n",
      "notebook #2897818 done\n",
      "notebook #2942474 done\n",
      "notebook #3001116 done\n",
      "notebook #3065122 done\n",
      "notebook #3127294 done\n",
      "notebook #3155308 done\n",
      "notebook #3308267 done\n",
      "notebook #3338077 done\n",
      "notebook #3412975 done\n",
      "notebook #3424825 done\n",
      "notebook #3544896 done\n",
      "notebook #3577796 done\n",
      "notebook #3640289 done\n",
      "notebook #3663832 done\n",
      "notebook #11400829 done\n",
      "notebook #24315 done\n",
      "notebook #242408 done\n",
      "notebook #243149 done\n",
      "notebook #244547 done\n",
      "notebook #244742 done\n",
      "notebook #244890 done\n",
      "notebook #244905 done\n",
      "notebook #244962 done\n",
      "notebook #245675 done\n",
      "notebook #874590 done\n",
      "notebook #1140262 done\n",
      "notebook #2095107 done\n",
      "notebook #3237641 done\n",
      "notebook #3674829 done\n",
      "notebook #4029935 done\n",
      "notebook #6511394 done\n",
      "notebook #6511397 done\n",
      "notebook #6511403 done\n",
      "notebook #6511414 done\n",
      "notebook #6511456 done\n",
      "notebook #6511492 done\n",
      "notebook #6518412 done\n",
      "notebook #7004483 done\n",
      "notebook #7465372 done\n",
      "notebook #7859060 done\n",
      "notebook #8648443 done\n",
      "notebook #9904611 done\n",
      "notebook #11013798 done\n",
      "notebook #3389306 done\n",
      "notebook #3414311 done\n",
      "notebook #4374092 done\n",
      "notebook #10307360 done\n",
      "notebook #3344044 done\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(113, 10)"
      ]
     },
     "metadata": {},
     "execution_count": 25
    }
   ],
   "source": [
    "# nl2ml = group_by_notebooks(nl2ml, TARGET_COLUMN)\n",
    "# X, y = train[TASK_FEATURES], train[TARGET_COLUMN]\n",
    "prepared_data = group_by_notebooks(nl2ml, TARGET_COLUMN)\n",
    "prepared_data.shape"
   ]
  },
  {
   "source": [
    "### Converting Dtypes"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def strip_recurrent_vertices(row):\n",
    "    # sequence = row['vertex_l2'].split(' ')\n",
    "    # result = []\n",
    "    # if len(sequence) > 1:\n",
    "    #     last_index = len(sequence) - 1\n",
    "    #     i = 0\n",
    "    #     while i < last_index:\n",
    "    #         # print(sequence[i], sequence[i+1])\n",
    "    #         if sequence[i].strip(' ') != sequence[i+1].strip(' '):\n",
    "    #             # print('not equal')\n",
    "    #             result.append(sequence[i])\n",
    "    #         else:\n",
    "    #             print('equal', sequence[i], sequence[i+1])\n",
    "    #         i =+ 1\n",
    "    # return \" \".join(result)\n",
    "    result = row['vertex_l2'].split(' ')[0] + \" \" + \" \".join([row['vertex_l2'].split(' ')[i] for i in range(1, len(row['vertex_l2'].split(' '))) if (row['vertex_l2'].split(' ')[i-1] != row['vertex_l2'].split(' ')[i])&(row['vertex_l2'].split(' ')[i] != ' ')&(row['vertex_l2'].split(' ')[i] != '')])\n",
    "    if result.split(' ')[1] == ' ':\n",
    "        result.pop(1)\n",
    "        return result\n",
    "    else:\n",
    "        return \" \".join(row['vertex_l2'].split(' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prepared_data[TARGET_COLUMN] = prepared_data[TARGET_COLUMN].apply(strip_recurrent_vertices, axis=1)\n",
    "# prepared_data[TARGET_COLUMN] = prepared_data[TARGET_COLUMN].apply(lambda x: x.replace(' ', ''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'import_modules import_modules'"
      ]
     },
     "metadata": {},
     "execution_count": 292
    }
   ],
   "source": [
    "prepared_data[TARGET_COLUMN].loc[70]['vertex_l2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "('kaggle_id',)\n('competition_id',)\n('comp_name',)\n('comp_type',)\n('description',)\n('metric',)\n('datatype',)\n('subject',)\n('problemtype',)\n"
     ]
    }
   ],
   "source": [
    "cat_encodings = {}\n",
    "for i, col in enumerate(prepared_data):\n",
    "    if col[0] != TARGET_COLUMN:\n",
    "        print(col)\n",
    "        try:\n",
    "            prepared_data[col] =  prepared_data[col].astype('float32')\n",
    "        except:\n",
    "            prepared_data[col] = pd.Categorical(prepared_data[col])\n",
    "            cat_encodings.update({i:dict(enumerate(prepared_data[col].cat.categories))})\n",
    "            prepared_data[col] = prepared_data[col].cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "((54, 7), (59, 7))"
      ]
     },
     "metadata": {},
     "execution_count": 294
    }
   ],
   "source": [
    "competitions = prepared_data[competition_id_col].iloc[:, 0].unique()\n",
    "test_size = 0.25\n",
    "n_test_competitions = round(test_size * len(competitions))\n",
    "test_competitions, train_competitions = competitions[:n_test_competitions], competitions[n_test_competitions:]\n",
    "train = prepared_data[prepared_data['competition_id'].iloc[:, 0].isin(train_competitions)]\n",
    "test = prepared_data[prepared_data['competition_id'].iloc[:, 0].isin(test_competitions)]\n",
    "X_train, y_train = train[TASK_FEATURES], train[TARGET_COLUMN]\n",
    "X_test, y_test = test[TASK_FEATURES], test[TARGET_COLUMN]\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train, X_test, y_train, y_test = train_test_split(prepared_data[TASK_FEATURES], prepared_data[TARGET_COLUMN]\n",
    "#                                                     , test_size=0.25, shuffle=True, random_state=123)\n",
    "# X_train.shape, X_test.shape"
   ]
  },
  {
   "source": [
    "### Target Preprocessing: Encoding Vertices"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "lang = {vertice:i+2 for i, vertice in enumerate(nl2ml[TARGET_COLUMN].unique())} #TODO: save the dict as a local file\n",
    "lang.update({'<start>':1, '<end>':max(lang.values())+1})\n",
    "def encode_vertices(vertices_seq, lang:dict=lang):\n",
    "    # print(vertices_seq[0], type(vertices_seq[0]), vertices_seq[0].split(' '))\n",
    "    try:\n",
    "        encoded = np.append(np.flip(np.array([lang[vertex] for vertex in vertices_seq[0].split(' ')] + [lang['<end>']])), lang['<start>'])\n",
    "        # encoded = np.append(lang['<start>'], np.array([lang[vertex] for vertex in vertices_seq[0].split(' ')] + [lang['<end>']]))\n",
    "    except:\n",
    "        print(vertices_seq[0].split(' '))\n",
    "        raise Exception(\"Can't encode vertices\")\n",
    "    return encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_train.apply(encode_vertices, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X[TARGET_COLUMN] = y.apply(encode_vertices, axis=1)\n",
    "# X.to_csv('../data/nl2ml_train_example.csv', index=False)"
   ]
  },
  {
   "source": [
    "### Target Preprocessing: Padding Sequences"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length_targ, max_length_feat = prepared_data[TARGET_COLUMN].squeeze().str.split(' ').str.len().max() + 2, X_train.values.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train = tf.keras.preprocessing.sequence.pad_sequences(y_train.apply(encode_vertices, axis=1), maxlen=max_length_targ)\n",
    "Y_test = tf.keras.preprocessing.sequence.pad_sequences(y_test.apply(encode_vertices, axis=1), maxlen=max_length_targ)"
   ]
  },
  {
   "source": [
    "### Defining Constants"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_params = {\"Task\": \"train\"\n",
    "            , \"Model\": \"generative task2seq\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features = len(TASK_FEATURES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_params = {\"nrows\":X_train.shape[0]\n",
    "                , \"nfeatures\": n_features}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 560,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BUFFER_SIZE = len(input_tensor_train)\n",
    "LR = 0.001\n",
    "EPOCHS = 25\n",
    "gru_units = 256\n",
    "embedding_dim = 128\n",
    "dropout_rate = 0.0\n",
    "BATCH_SIZE = 1\n",
    "STEPS_PER_EPOCH = len(X_train)//BATCH_SIZE\n",
    "# vocab_inp_size = len(inp_lang.word_index) + 1\n",
    "# vocab_tar_size = len(targ_lang.word_index) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 561,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_params = {\"BATCH_SIZE\":BATCH_SIZE\n",
    "                , \"LR\":LR\n",
    "                , \"STEPS_PER_EPOCH\": STEPS_PER_EPOCH\n",
    "                , \"embedding_dim\": embedding_dim\n",
    "                , \"gru_units\": gru_units\n",
    "                , \"dropout_rate\": dropout_rate}"
   ]
  },
  {
   "source": [
    "### Creating tf.Dataset"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 562,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = tf.data.Dataset.from_tensor_slices((X_train.values, Y_train))\n",
    "train_dataset = train_dataset.batch(BATCH_SIZE, drop_remainder=True)"
   ]
  },
  {
   "source": [
    "### Building the Model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 563,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.Model):\n",
    "  def __init__(self, vocab_size, embedding_dim, dec_units, batch_sz):\n",
    "    super(Decoder, self).__init__()\n",
    "    self.batch_sz = batch_sz\n",
    "    self.dec_units = dec_units\n",
    "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "    self.gru = tf.keras.layers.GRU(self.dec_units,\n",
    "                                   return_sequences=True,\n",
    "                                   return_state=True,\n",
    "                                   recurrent_initializer='glorot_uniform')\n",
    "    self.dropout = tf.keras.layers.Dropout(dropout_rate)\n",
    "    self.fc = tf.keras.layers.Dense(vocab_size, activation='sigmoid')\n",
    "    self.fc_vec = tf.keras.layers.Dense(dec_units, activation='sigmoid')\n",
    "\n",
    "  def call(self, x, hidden, vec_input):\n",
    "    x = self.embedding(x)\n",
    "    output, state = self.gru(x, initial_state=hidden)\n",
    "    output = tf.reshape(output, (-1, output.shape[2]))\n",
    "    output = self.dropout(output)\n",
    "    vec = self.fc_vec(vec_input)\n",
    "    concatenated = tf.keras.layers.concatenate([vec, output], axis=1)\n",
    "    x = self.fc(concatenated)\n",
    "    return x, state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 564,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Decoder output shape: (batch_size, vocab size`) (1, 72)\nModel: \"decoder_9\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nembedding_9 (Embedding)      multiple                  9216      \n_________________________________________________________________\ngru_9 (GRU)                  multiple                  296448    \n_________________________________________________________________\ndropout_9 (Dropout)          multiple                  0         \n_________________________________________________________________\ndense_18 (Dense)             multiple                  36936     \n_________________________________________________________________\ndense_19 (Dense)             multiple                  2048      \n=================================================================\nTotal params: 344,648\nTrainable params: 344,648\nNon-trainable params: 0\n_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "decoder = Decoder(len(lang)+2, embedding_dim, gru_units, BATCH_SIZE)\n",
    "sample_hidden = tf.zeros((BATCH_SIZE, gru_units))\n",
    "vec_input = np.ones((1, n_features))\n",
    "sample_decoder_output, state = decoder(tf.random.uniform((BATCH_SIZE, 1))\n",
    "                                          , sample_hidden\n",
    "                                          , vec_input\n",
    "                                          )\n",
    "print ('Decoder output shape: (batch_size, vocab size`) {}'.format(sample_decoder_output.shape))\n",
    "decoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 565,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(LR)\n",
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "                  from_logits=True, reduction='none')\n",
    "\n",
    "def loss_function(real, pred):\n",
    "  mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "  loss_ = loss_object(real, pred)\n",
    "\n",
    "  mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "  loss_ *= mask\n",
    "\n",
    "  return tf.reduce_mean(loss_)"
   ]
  },
  {
   "source": [
    "### Model Training or Loading Pre-Trained"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 566,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(inp, targ):\n",
    "  loss = 0\n",
    "  with tf.GradientTape() as tape:\n",
    "    dec_hidden = tf.zeros((BATCH_SIZE, gru_units))\n",
    "    dec_input = tf.expand_dims([1] * BATCH_SIZE, 1)\n",
    "    for t in range(1, targ.shape[1]): # for each vertex (token) from solution (sequence)\n",
    "      predictions, dec_hidden = decoder(dec_input, dec_hidden, inp)\n",
    "      loss += loss_function(targ[:, t], predictions)\n",
    "      dec_input = tf.expand_dims(targ[:, t], 1)\n",
    "\n",
    "  batch_loss = (loss / int(targ.shape[1]))\n",
    "  variables = decoder.trainable_variables\n",
    "  gradients = tape.gradient(loss, variables)\n",
    "  optimizer.apply_gradients(zip(gradients, variables))\n",
    "  del inp, targ, gradients, variables\n",
    "  gc.collect()\n",
    "  return batch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_dir = './checkpoints/'\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
    "checkpoint = tf.train.Checkpoint(step=tf.Variable(1)\n",
    "                                , optimizer=optimizer\n",
    "                                 , decoder=decoder)\n",
    "manager = tf.train.CheckpointManager(checkpoint, checkpoint_dir, max_to_keep=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 568,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if manager.latest_checkpoint:\n",
    "#     print(\"Restored from {}\".format(manager.latest_checkpoint))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 569,
   "metadata": {},
   "outputs": [],
   "source": [
    "# decoder.compile(\n",
    "#     optimizer=optimizer,\n",
    "#     loss=loss_object\n",
    "# )\n",
    "# tf.saved_model.save(decoder, './checkpoints/model1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 570,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses = []\n",
    "val_ce = []\n",
    "val_rr = []\n",
    "val_rp = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 571,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1 Batch 0 Loss 2.9096 Perplexity 18.3496\n",
      "predicting.. 0.00% 1.69% 3.39% 5.08% 6.78% 8.47% 10.17% 11.86% 13.56% 15.25% 16.95% 18.64% 20.34% 22.03% 23.73% 25.42% 27.12% 28.81% 30.51% 32.20% 33.90% 35.59% 37.29% 38.98% 40.68% 42.37% 44.07% 45.76% 47.46% 49.15% 50.85% 52.54% 54.24% 55.93% 57.63% 59.32% 61.02% 62.71% 64.41% 66.10% 67.80% 69.49% 71.19% 72.88% 74.58% 76.27% 77.97% 79.66% 81.36% 83.05% 84.75% 86.44% 88.14% 89.83% 91.53% 93.22% 94.92% 96.61% 98.31% \n",
      "Cross-Entropy: 125.42818450927734\n",
      "Perplexity: 2.970081779435162e+54\n",
      "ROUGE-Recall: 0.01022793687901812\n",
      "ROUGE-Precision: 0.039256270410442724\n",
      "Unique answers: 2\n",
      "Time taken for the epoch 454.7074146270752 sec\n",
      "\n",
      "Epoch 2 Batch 0 Loss 2.2544 Perplexity 9.5296\n",
      "predicting.. 0.00% 1.69% 3.39% 5.08% 6.78% 8.47% 10.17% 11.86% 13.56% 15.25% 16.95% 18.64% 20.34% 22.03% 23.73% 25.42% 27.12% 28.81% 30.51% 32.20% 33.90% 35.59% 37.29% 38.98% 40.68% 42.37% 44.07% 45.76% 47.46% 49.15% 50.85% 52.54% 54.24% 55.93% 57.63% 59.32% 61.02% 62.71% 64.41% 66.10% 67.80% 69.49% 71.19% 72.88% 74.58% 76.27% 77.97% 79.66% 81.36% 83.05% 84.75% 86.44% 88.14% 89.83% 91.53% 93.22% 94.92% 96.61% 98.31% \n",
      "Cross-Entropy: 124.86677551269531\n",
      "Perplexity: 1.6941489003128338e+54\n",
      "ROUGE-Recall: 0.005552308591466979\n",
      "ROUGE-Precision: 0.02367116109906207\n",
      "Unique answers: 2\n",
      "Time taken for the epoch 102.19952630996704 sec\n",
      "\n",
      "Epoch 3 Batch 0 Loss 2.1608 Perplexity 8.6780\n",
      "predicting.. 0.00% 1.69% 3.39% 5.08% 6.78% 8.47% 10.17% 11.86% 13.56% 15.25% 16.95% 18.64% 20.34% 22.03% 23.73% 25.42% 27.12% 28.81% 30.51% 32.20% 33.90% 35.59% 37.29% 38.98% 40.68% 42.37% 44.07% 45.76% 47.46% 49.15% 50.85% 52.54% 54.24% 55.93% 57.63% 59.32% 61.02% 62.71% 64.41% 66.10% 67.80% 69.49% 71.19% 72.88% 74.58% 76.27% 77.97% 79.66% 81.36% 83.05% 84.75% 86.44% 88.14% 89.83% 91.53% 93.22% 94.92% 96.61% 98.31% \n",
      "Cross-Entropy: 153.63035583496094\n",
      "Perplexity: 5.257942010080877e+66\n",
      "ROUGE-Recall: 0.005406195207481006\n",
      "ROUGE-Precision: 0.023145818265239655\n",
      "Unique answers: 1\n",
      "Time taken for the epoch 99.46054339408875 sec\n",
      "\n",
      "Epoch 4 Batch 0 Loss 1.9975 Perplexity 7.3708\n",
      "predicting.. 0.00% 1.69% 3.39% 5.08% 6.78% 8.47% 10.17% 11.86% 13.56% 15.25% 16.95% 18.64% 20.34% 22.03% 23.73% 25.42% 27.12% 28.81% 30.51% 32.20% 33.90% 35.59% 37.29% 38.98% 40.68% 42.37% 44.07% 45.76% 47.46% 49.15% 50.85% 52.54% 54.24% 55.93% 57.63% 59.32% 61.02% 62.71% 64.41% 66.10% 67.80% 69.49% 71.19% 72.88% 74.58% 76.27% 77.97% 79.66% 81.36% 83.05% 84.75% 86.44% 88.14% 89.83% 91.53% 93.22% 94.92% 96.61% 98.31% \n",
      "Cross-Entropy: 145.1381072998047\n",
      "Perplexity: 1.078149818660869e+63\n",
      "ROUGE-Recall: 0.005406195207481006\n",
      "ROUGE-Precision: 0.023145818265239655\n",
      "Unique answers: 1\n",
      "Time taken for the epoch 102.95149159431458 sec\n",
      "\n",
      "Epoch 5 Batch 0 Loss 1.8838 Perplexity 6.5781\n",
      "predicting.. 0.00% 1.69% 3.39% 5.08% 6.78% 8.47% 10.17% 11.86% 13.56% 15.25% 16.95% 18.64% 20.34% 22.03% 23.73% 25.42% 27.12% 28.81% 30.51% 32.20% 33.90% 35.59% 37.29% 38.98% 40.68% 42.37% 44.07% 45.76% 47.46% 49.15% 50.85% 52.54% 54.24% 55.93% 57.63% 59.32% 61.02% 62.71% 64.41% 66.10% 67.80% 69.49% 71.19% 72.88% 74.58% 76.27% 77.97% 79.66% 81.36% 83.05% 84.75% 86.44% 88.14% 89.83% 91.53% 93.22% 94.92% 96.61% 98.31% \n",
      "Cross-Entropy: 142.70840454101562\n",
      "Perplexity: 9.494511249047575e+61\n",
      "ROUGE-Recall: 0.005406195207481006\n",
      "ROUGE-Precision: 0.023145818265239655\n",
      "Unique answers: 1\n",
      "saving\n",
      "saved\n",
      "Time taken for the epoch 98.69779539108276 sec\n",
      "\n",
      "Epoch 6 Batch 0 Loss 1.7455 Perplexity 5.7289\n",
      "predicting.. 0.00% 1.69% 3.39% 5.08% 6.78% 8.47% 10.17% 11.86% 13.56% 15.25% 16.95% 18.64% 20.34% 22.03% 23.73% 25.42% 27.12% 28.81% 30.51% 32.20% 33.90% 35.59% 37.29% 38.98% 40.68% 42.37% 44.07% 45.76% 47.46% 49.15% 50.85% 52.54% 54.24% 55.93% 57.63% 59.32% 61.02% 62.71% 64.41% 66.10% 67.80% 69.49% 71.19% 72.88% 74.58% 76.27% 77.97% 79.66% 81.36% 83.05% 84.75% 86.44% 88.14% 89.83% 91.53% 93.22% 94.92% 96.61% 98.31% \n",
      "Cross-Entropy: 152.7882843017578\n",
      "Perplexity: 2.26521157269463e+66\n",
      "ROUGE-Recall: 0.005406195207481006\n",
      "ROUGE-Precision: 0.023145818265239655\n",
      "Unique answers: 1\n",
      "Time taken for the epoch 95.7166690826416 sec\n",
      "\n",
      "Epoch 7 Batch 0 Loss 1.6651 Perplexity 5.2864\n",
      "predicting.. 0.00% 1.69% 3.39% 5.08% 6.78% 8.47% 10.17% 11.86% 13.56% 15.25% 16.95% 18.64% 20.34% 22.03% 23.73% 25.42% 27.12% 28.81% 30.51% 32.20% 33.90% 35.59% 37.29% 38.98% 40.68% 42.37% 44.07% 45.76% 47.46% 49.15% 50.85% 52.54% 54.24% 55.93% 57.63% 59.32% 61.02% 62.71% 64.41% 66.10% 67.80% 69.49% 71.19% 72.88% 74.58% 76.27% 77.97% 79.66% 81.36% 83.05% 84.75% 86.44% 88.14% 89.83% 91.53% 93.22% 94.92% 96.61% 98.31% \n",
      "Cross-Entropy: 156.96978759765625\n",
      "Perplexity: 1.4829024379819254e+68\n",
      "ROUGE-Recall: 0.005406195207481006\n",
      "ROUGE-Precision: 0.023145818265239655\n",
      "Unique answers: 1\n",
      "Time taken for the epoch 101.97038292884827 sec\n",
      "\n",
      "Epoch 8 Batch 0 Loss 1.5701 Perplexity 4.8073\n",
      "predicting.. 0.00% 1.69% 3.39% 5.08% 6.78% 8.47% 10.17% 11.86% 13.56% 15.25% 16.95% 18.64% 20.34% 22.03% 23.73% 25.42% 27.12% 28.81% 30.51% 32.20% 33.90% 35.59% 37.29% 38.98% 40.68% 42.37% 44.07% 45.76% 47.46% 49.15% 50.85% 52.54% 54.24% 55.93% 57.63% 59.32% 61.02% 62.71% 64.41% 66.10% 67.80% 69.49% 71.19% 72.88% 74.58% 76.27% 77.97% 79.66% 81.36% 83.05% 84.75% 86.44% 88.14% 89.83% 91.53% 93.22% 94.92% 96.61% 98.31% \n",
      "Cross-Entropy: 161.6254425048828\n",
      "Perplexity: 1.5596883026431927e+70\n",
      "ROUGE-Recall: 0.005406195207481006\n",
      "ROUGE-Precision: 0.023145818265239655\n",
      "Unique answers: 1\n",
      "Time taken for the epoch 100.90166783332825 sec\n",
      "\n",
      "Epoch 9 Batch 0 Loss 1.5481 Perplexity 4.7027\n",
      "predicting.. 0.00% 1.69% 3.39% 5.08% 6.78% 8.47% 10.17% 11.86% 13.56% 15.25% 16.95% 18.64% 20.34% 22.03% 23.73% 25.42% 27.12% 28.81% 30.51% 32.20% 33.90% 35.59% 37.29% 38.98% 40.68% 42.37% 44.07% 45.76% 47.46% 49.15% 50.85% 52.54% 54.24% 55.93% 57.63% 59.32% 61.02% 62.71% 64.41% 66.10% 67.80% 69.49% 71.19% 72.88% 74.58% 76.27% 77.97% 79.66% 81.36% 83.05% 84.75% 86.44% 88.14% 89.83% 91.53% 93.22% 94.92% 96.61% 98.31% \n",
      "Cross-Entropy: 158.72618103027344\n",
      "Perplexity: 8.5882475669397545e+68\n",
      "ROUGE-Recall: 0.005406195207481006\n",
      "ROUGE-Precision: 0.023145818265239655\n",
      "Unique answers: 1\n",
      "Time taken for the epoch 100.55925130844116 sec\n",
      "\n",
      "Epoch 10 Batch 0 Loss 1.4076 Perplexity 4.0861\n",
      "predicting.. 0.00% 1.69% 3.39% 5.08% 6.78% 8.47% 10.17% 11.86% 13.56% 15.25% 16.95% 18.64% 20.34% 22.03% 23.73% 25.42% 27.12% 28.81% 30.51% 32.20% 33.90% 35.59% 37.29% 38.98% 40.68% 42.37% 44.07% 45.76% 47.46% 49.15% 50.85% 52.54% 54.24% 55.93% 57.63% 59.32% 61.02% 62.71% 64.41% 66.10% 67.80% 69.49% 71.19% 72.88% 74.58% 76.27% 77.97% 79.66% 81.36% 83.05% 84.75% 86.44% 88.14% 89.83% 91.53% 93.22% 94.92% 96.61% 98.31% \n",
      "Cross-Entropy: 171.9102020263672\n",
      "Perplexity: 4.567222010028761e+74\n",
      "ROUGE-Recall: 0.008328462887200466\n",
      "ROUGE-Precision: 0.037008304813068924\n",
      "Unique answers: 2\n",
      "saving\n",
      "saved\n",
      "Time taken for the epoch 98.16008114814758 sec\n",
      "\n",
      "Epoch 11 Batch 0 Loss 1.3502 Perplexity 3.8581\n",
      "predicting.. 0.00% 1.69% 3.39% 5.08% 6.78% 8.47% 10.17% 11.86% 13.56% 15.25% 16.95% 18.64% 20.34% 22.03% 23.73% 25.42% 27.12% 28.81% 30.51% 32.20% 33.90% 35.59% 37.29% 38.98% 40.68% 42.37% 44.07% 45.76% 47.46% 49.15% 50.85% 52.54% 54.24% 55.93% 57.63% 59.32% 61.02% 62.71% 64.41% 66.10% 67.80% 69.49% 71.19% 72.88% 74.58% 76.27% 77.97% 79.66% 81.36% 83.05% 84.75% 86.44% 88.14% 89.83% 91.53% 93.22% 94.92% 96.61% 98.31% \n",
      "Cross-Entropy: 193.26153564453125\n",
      "Perplexity: 8.558910688379289e+83\n",
      "ROUGE-Recall: 0.015195791934541202\n",
      "ROUGE-Precision: 0.06188940304928737\n",
      "Unique answers: 2\n",
      "Time taken for the epoch 97.94762682914734 sec\n",
      "\n",
      "Epoch 12 Batch 0 Loss 1.2926 Perplexity 3.6423\n",
      "predicting.. 0.00% 1.69% 3.39% 5.08% 6.78% 8.47% 10.17% 11.86% 13.56% 15.25% 16.95% 18.64% 20.34% 22.03% 23.73% 25.42% 27.12% 28.81% 30.51% 32.20% 33.90% 35.59% 37.29% 38.98% 40.68% 42.37% 44.07% 45.76% 47.46% 49.15% 50.85% 52.54% 54.24% 55.93% 57.63% 59.32% 61.02% 62.71% 64.41% 66.10% 67.80% 69.49% 71.19% 72.88% 74.58% 76.27% 77.97% 79.66% 81.36% 83.05% 84.75% 86.44% 88.14% 89.83% 91.53% 93.22% 94.92% 96.61% 98.31% \n",
      "Cross-Entropy: 162.41012573242188\n",
      "Perplexity: 3.4183884372507866e+70\n",
      "ROUGE-Recall: 0.008328462887200468\n",
      "ROUGE-Precision: 0.033023869621703415\n",
      "Unique answers: 2\n",
      "Time taken for the epoch 99.9737868309021 sec\n",
      "\n",
      "Epoch 13 Batch 0 Loss 1.1294 Perplexity 3.0939\n",
      "predicting.. 0.00% 1.69% 3.39% 5.08% 6.78% 8.47% 10.17% 11.86% 13.56% 15.25% 16.95% 18.64% 20.34% 22.03% 23.73% 25.42% 27.12% 28.81% 30.51% 32.20% 33.90% 35.59% 37.29% 38.98% 40.68% 42.37% 44.07% 45.76% 47.46% 49.15% 50.85% 52.54% 54.24% 55.93% 57.63% 59.32% 61.02% 62.71% 64.41% 66.10% 67.80% 69.49% 71.19% 72.88% 74.58% 76.27% 77.97% 79.66% 81.36% 83.05% 84.75% 86.44% 88.14% 89.83% 91.53% 93.22% 94.92% 96.61% 98.31% \n",
      "Cross-Entropy: 161.96034240722656\n",
      "Perplexity: 2.1801330294951047e+70\n",
      "ROUGE-Recall: 0.0071595558153126826\n",
      "ROUGE-Precision: 0.028375725334536816\n",
      "Unique answers: 1\n",
      "Time taken for the epoch 102.52917838096619 sec\n",
      "\n",
      "Epoch 14 Batch 0 Loss 1.1113 Perplexity 3.0384\n",
      "predicting.. 0.00% 1.69% 3.39% 5.08% 6.78% 8.47% 10.17% 11.86% 13.56% 15.25% 16.95% 18.64% 20.34% 22.03% 23.73% 25.42% 27.12% 28.81% 30.51% 32.20% 33.90% 35.59% 37.29% 38.98% 40.68% 42.37% 44.07% 45.76% 47.46% 49.15% 50.85% 52.54% 54.24% 55.93% 57.63% 59.32% 61.02% 62.71% 64.41% 66.10% 67.80% 69.49% 71.19% 72.88% 74.58% 76.27% 77.97% 79.66% 81.36% 83.05% 84.75% 86.44% 88.14% 89.83% 91.53% 93.22% 94.92% 96.61% 98.31% \n",
      "Cross-Entropy: 170.5730438232422\n",
      "Perplexity: 1.1993106599381982e+74\n",
      "ROUGE-Recall: 0.0071595558153126826\n",
      "ROUGE-Precision: 0.028375725334536816\n",
      "Unique answers: 2\n",
      "Time taken for the epoch 99.59313154220581 sec\n",
      "\n",
      "Epoch 15 Batch 0 Loss 0.9927 Perplexity 2.6984\n",
      "predicting.. 0.00% 1.69% 3.39% 5.08% 6.78% 8.47% 10.17% 11.86% 13.56% 15.25% 16.95% 18.64% 20.34% 22.03% 23.73% 25.42% 27.12% 28.81% 30.51% 32.20% 33.90% 35.59% 37.29% 38.98% 40.68% 42.37% 44.07% 45.76% 47.46% 49.15% 50.85% 52.54% 54.24% 55.93% 57.63% 59.32% 61.02% 62.71% 64.41% 66.10% 67.80% 69.49% 71.19% 72.88% 74.58% 76.27% 77.97% 79.66% 81.36% 83.05% 84.75% 86.44% 88.14% 89.83% 91.53% 93.22% 94.92% 96.61% 98.31% \n",
      "Cross-Entropy: 176.9017791748047\n",
      "Perplexity: 6.72150513082568e+76\n",
      "ROUGE-Recall: 0.010666277030976038\n",
      "ROUGE-Precision: 0.044685329802677934\n",
      "Unique answers: 2\n",
      "saving\n",
      "saved\n",
      "Time taken for the epoch 98.46572494506836 sec\n",
      "\n",
      "Epoch 16 Batch 0 Loss 0.8645 Perplexity 2.3739\n",
      "predicting.. 0.00% 1.69% 3.39% 5.08% 6.78% 8.47% 10.17% 11.86% 13.56% 15.25% 16.95% 18.64% 20.34% 22.03% 23.73% 25.42% 27.12% 28.81% 30.51% 32.20% 33.90% 35.59% 37.29% 38.98% 40.68% 42.37% 44.07% 45.76% 47.46% 49.15% 50.85% 52.54% 54.24% 55.93% 57.63% 59.32% 61.02% 62.71% 64.41% 66.10% 67.80% 69.49% 71.19% 72.88% 74.58% 76.27% 77.97% 79.66% 81.36% 83.05% 84.75% 86.44% 88.14% 89.83% 91.53% 93.22% 94.92% 96.61% 98.31% \n",
      "Cross-Entropy: 208.64402770996094\n",
      "Perplexity: 4.101568003582053e+90\n",
      "ROUGE-Recall: 0.015488018702513151\n",
      "ROUGE-Precision: 0.06282085453473912\n",
      "Unique answers: 2\n",
      "Time taken for the epoch 99.89650678634644 sec\n",
      "\n",
      "Epoch 17 Batch 0 Loss 0.8237 Perplexity 2.2790\n",
      "predicting.. 0.00% 1.69% 3.39% 5.08% 6.78% 8.47% 10.17% 11.86% 13.56% 15.25% 16.95% 18.64% 20.34% 22.03% 23.73% 25.42% 27.12% 28.81% 30.51% 32.20% 33.90% 35.59% 37.29% 38.98% 40.68% 42.37% 44.07% 45.76% 47.46% 49.15% 50.85% 52.54% 54.24% 55.93% 57.63% 59.32% 61.02% 62.71% 64.41% 66.10% 67.80% 69.49% 71.19% 72.88% 74.58% 76.27% 77.97% 79.66% 81.36% 83.05% 84.75% 86.44% 88.14% 89.83% 91.53% 93.22% 94.92% 96.61% 98.31% \n",
      "Cross-Entropy: 185.81594848632812\n",
      "Perplexity: 4.998515892153055e+80\n",
      "ROUGE-Recall: 0.012857977790765633\n",
      "ROUGE-Precision: 0.055465504478644186\n",
      "Unique answers: 2\n",
      "Time taken for the epoch 98.63181471824646 sec\n",
      "\n",
      "Epoch 18 Batch 0 Loss 0.7749 Perplexity 2.1703\n",
      "predicting.. 0.00% 1.69% 3.39% 5.08% 6.78% 8.47% 10.17% 11.86% 13.56% 15.25% 16.95% 18.64% 20.34% 22.03% 23.73% 25.42% 27.12% 28.81% 30.51% 32.20% 33.90% 35.59% 37.29% 38.98% 40.68% 42.37% 44.07% 45.76% 47.46% 49.15% 50.85% 52.54% 54.24% 55.93% 57.63% 59.32% 61.02% 62.71% 64.41% 66.10% 67.80% 69.49% 71.19% 72.88% 74.58% 76.27% 77.97% 79.66% 81.36% 83.05% 84.75% 86.44% 88.14% 89.83% 91.53% 93.22% 94.92% 96.61% 98.31% \n",
      "Cross-Entropy: 226.22007751464844\n",
      "Perplexity: 1.7625090690158576e+98\n",
      "ROUGE-Recall: 0.022501461133839867\n",
      "ROUGE-Precision: 0.16982057945826756\n",
      "Unique answers: 2\n",
      "Time taken for the epoch 99.08927631378174 sec\n",
      "\n",
      "Epoch 19 Batch 0 Loss 0.8775 Perplexity 2.4049\n",
      "predicting.. 0.00% 1.69% 3.39% 5.08% 6.78% 8.47% 10.17% 11.86% 13.56% 15.25% 16.95% 18.64% 20.34% 22.03% 23.73% 25.42% 27.12% 28.81% 30.51% 32.20% 33.90% 35.59% 37.29% 38.98% 40.68% 42.37% 44.07% 45.76% 47.46% 49.15% 50.85% 52.54% 54.24% 55.93% 57.63% 59.32% 61.02% 62.71% 64.41% 66.10% 67.80% 69.49% 71.19% 72.88% 74.58% 76.27% 77.97% 79.66% 81.36% 83.05% 84.75% 86.44% 88.14% 89.83% 91.53% 93.22% 94.92% 96.61% 98.31% \n",
      "Cross-Entropy: 234.2451629638672\n",
      "Perplexity: 5.387430588105686e+101\n",
      "ROUGE-Recall: 0.009935710111046173\n",
      "ROUGE-Precision: 0.039448382673571696\n",
      "Unique answers: 2\n",
      "Time taken for the epoch 98.9277834892273 sec\n",
      "\n",
      "Epoch 20 Batch 0 Loss 0.6979 Perplexity 2.0095\n",
      "predicting.. 0.00% 1.69% 3.39% 5.08% 6.78% 8.47% 10.17% 11.86% 13.56% 15.25% 16.95% 18.64% 20.34% 22.03% 23.73% 25.42% 27.12% 28.81% 30.51% 32.20% 33.90% 35.59% 37.29% 38.98% 40.68% 42.37% 44.07% 45.76% 47.46% 49.15% 50.85% 52.54% 54.24% 55.93% 57.63% 59.32% 61.02% 62.71% 64.41% 66.10% 67.80% 69.49% 71.19% 72.88% 74.58% 76.27% 77.97% 79.66% 81.36% 83.05% 84.75% 86.44% 88.14% 89.83% 91.53% 93.22% 94.92% 96.61% 98.31% \n",
      "Cross-Entropy: 183.75216674804688\n",
      "Perplexity: 6.346759714700031e+79\n",
      "ROUGE-Recall: 0.02381648158971362\n",
      "ROUGE-Precision: 0.10024438364358677\n",
      "Unique answers: 2\n",
      "saving\n",
      "saved\n",
      "Time taken for the epoch 97.77637577056885 sec\n",
      "\n",
      "Epoch 21 Batch 0 Loss 0.6783 Perplexity 1.9705\n",
      "predicting.. 0.00% 1.69% 3.39% 5.08% 6.78% 8.47% 10.17% 11.86% 13.56% 15.25% 16.95% 18.64% 20.34% 22.03% 23.73% 25.42% 27.12% 28.81% 30.51% 32.20% 33.90% 35.59% 37.29% 38.98% 40.68% 42.37% 44.07% 45.76% 47.46% 49.15% 50.85% 52.54% 54.24% 55.93% 57.63% 59.32% 61.02% 62.71% 64.41% 66.10% 67.80% 69.49% 71.19% 72.88% 74.58% 76.27% 77.97% 79.66% 81.36% 83.05% 84.75% 86.44% 88.14% 89.83% 91.53% 93.22% 94.92% 96.61% 98.31% \n",
      "Cross-Entropy: 224.63914489746094\n",
      "Perplexity: 3.626945656114911e+97\n",
      "ROUGE-Recall: 0.06078316773816482\n",
      "ROUGE-Precision: 0.3399736870281395\n",
      "Unique answers: 2\n",
      "Time taken for the epoch 98.51380610466003 sec\n",
      "\n",
      "Epoch 22 Batch 0 Loss 0.5030 Perplexity 1.6537\n",
      "predicting.. 0.00% 1.69% 3.39% 5.08% 6.78% 8.47% 10.17% 11.86% 13.56% 15.25% 16.95% 18.64% 20.34% 22.03% 23.73% 25.42% 27.12% 28.81% 30.51% 32.20% 33.90% 35.59% 37.29% 38.98% 40.68% 42.37% 44.07% 45.76% 47.46% 49.15% 50.85% 52.54% 54.24% 55.93% 57.63% 59.32% 61.02% 62.71% 64.41% 66.10% 67.80% 69.49% 71.19% 72.88% 74.58% 76.27% 77.97% 79.66% 81.36% 83.05% 84.75% 86.44% 88.14% 89.83% 91.53% 93.22% 94.92% 96.61% 98.31% \n",
      "Cross-Entropy: 236.2872772216797\n",
      "Perplexity: 4.152031515557732e+102\n",
      "ROUGE-Recall: 0.0669199298655757\n",
      "ROUGE-Precision: 0.3730597822007693\n",
      "Unique answers: 2\n",
      "Time taken for the epoch 98.93155980110168 sec\n",
      "\n",
      "Epoch 23 Batch 0 Loss 0.5068 Perplexity 1.6599\n",
      "predicting.. 0.00% 1.69% 3.39% 5.08% 6.78% 8.47% 10.17% 11.86% 13.56% 15.25% 16.95% 18.64% 20.34% 22.03% 23.73% 25.42% 27.12% 28.81% 30.51% 32.20% 33.90% 35.59% 37.29% 38.98% 40.68% 42.37% 44.07% 45.76% 47.46% 49.15% 50.85% 52.54% 54.24% 55.93% 57.63% 59.32% 61.02% 62.71% 64.41% 66.10% 67.80% 69.49% 71.19% 72.88% 74.58% 76.27% 77.97% 79.66% 81.36% 83.05% 84.75% 86.44% 88.14% 89.83% 91.53% 93.22% 94.92% 96.61% 98.31% \n",
      "Cross-Entropy: 244.7866668701172\n",
      "Perplexity: 2.0393823914892653e+106\n",
      "ROUGE-Recall: 0.04047340736411456\n",
      "ROUGE-Precision: 0.25454389329698535\n",
      "Unique answers: 2\n",
      "Time taken for the epoch 98.84154009819031 sec\n",
      "\n",
      "Epoch 24 Batch 0 Loss 0.5424 Perplexity 1.7202\n",
      "predicting.. 0.00% 1.69% 3.39% 5.08% 6.78% 8.47% 10.17% 11.86% 13.56% 15.25% 16.95% 18.64% 20.34% 22.03% 23.73% 25.42% 27.12% 28.81% 30.51% 32.20% 33.90% 35.59% 37.29% 38.98% 40.68% 42.37% 44.07% 45.76% 47.46% 49.15% 50.85% 52.54% 54.24% 55.93% 57.63% 59.32% 61.02% 62.71% 64.41% 66.10% 67.80% 69.49% 71.19% 72.88% 74.58% 76.27% 77.97% 79.66% 81.36% 83.05% 84.75% 86.44% 88.14% 89.83% 91.53% 93.22% 94.92% 96.61% 98.31% \n",
      "Cross-Entropy: 244.3234100341797\n",
      "Perplexity: 1.2832426269191164e+106\n",
      "ROUGE-Recall: 0.059614260666277036\n",
      "ROUGE-Precision: 0.329959774971376\n",
      "Unique answers: 2\n",
      "Time taken for the epoch 98.94567775726318 sec\n",
      "\n",
      "Epoch 25 Batch 0 Loss 0.4944 Perplexity 1.6394\n",
      "predicting.. 0.00% 1.69% 3.39% 5.08% 6.78% 8.47% 10.17% 11.86% 13.56% 15.25% 16.95% 18.64% 20.34% 22.03% 23.73% 25.42% 27.12% 28.81% 30.51% 32.20% 33.90% 35.59% 37.29% 38.98% 40.68% 42.37% 44.07% 45.76% 47.46% 49.15% 50.85% 52.54% 54.24% 55.93% 57.63% 59.32% 61.02% 62.71% 64.41% 66.10% 67.80% 69.49% 71.19% 72.88% 74.58% 76.27% 77.97% 79.66% 81.36% 83.05% 84.75% 86.44% 88.14% 89.83% 91.53% 93.22% 94.92% 96.61% 98.31% \n",
      "Cross-Entropy: 237.00262451171875\n",
      "Perplexity: 8.490475674088998e+102\n",
      "ROUGE-Recall: 0.07057276446522501\n",
      "ROUGE-Precision: 0.383702272441643\n",
      "Unique answers: 2\n",
      "saving\n",
      "saved\n",
      "Time taken for the epoch 97.69384551048279 sec\n",
      "\n",
      "The best epoch is 22\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x18d56394370>]"
      ]
     },
     "metadata": {},
     "execution_count": 571
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\r\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\r\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\r\n<!-- Created with matplotlib (https://matplotlib.org/) -->\r\n<svg height=\"250.949831pt\" version=\"1.1\" viewBox=\"0 0 382.291761 250.949831\" width=\"382.291761pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\r\n <metadata>\r\n  <rdf:RDF xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\r\n   <cc:Work>\r\n    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\r\n    <dc:date>2021-05-31T17:26:29.988737</dc:date>\r\n    <dc:format>image/svg+xml</dc:format>\r\n    <dc:creator>\r\n     <cc:Agent>\r\n      <dc:title>Matplotlib v3.3.2, https://matplotlib.org/</dc:title>\r\n     </cc:Agent>\r\n    </dc:creator>\r\n   </cc:Work>\r\n  </rdf:RDF>\r\n </metadata>\r\n <defs>\r\n  <style type=\"text/css\">*{stroke-linecap:butt;stroke-linejoin:round;}</style>\r\n </defs>\r\n <g id=\"figure_1\">\r\n  <g id=\"patch_1\">\r\n   <path d=\"M 0 250.949831 \r\nL 382.291761 250.949831 \r\nL 382.291761 0 \r\nL 0 0 \r\nz\r\n\" style=\"fill:none;\"/>\r\n  </g>\r\n  <g id=\"axes_1\">\r\n   <g id=\"patch_2\">\r\n    <path d=\"M 36.465625 227.071706 \r\nL 371.265625 227.071706 \r\nL 371.265625 9.631706 \r\nL 36.465625 9.631706 \r\nz\r\n\" style=\"fill:#ffffff;\"/>\r\n   </g>\r\n   <g id=\"matplotlib.axis_1\">\r\n    <g id=\"xtick_1\">\r\n     <g id=\"line2d_1\">\r\n      <defs>\r\n       <path d=\"M 0 0 \r\nL 0 3.5 \r\n\" id=\"m0cd4e5cda4\" style=\"stroke:#000000;stroke-width:0.8;\"/>\r\n      </defs>\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"51.683807\" xlink:href=\"#m0cd4e5cda4\" y=\"227.071706\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_1\">\r\n      <!-- 0 -->\r\n      <g transform=\"translate(48.502557 241.670144)scale(0.1 -0.1)\">\r\n       <defs>\r\n        <path d=\"M 31.78125 66.40625 \r\nQ 24.171875 66.40625 20.328125 58.90625 \r\nQ 16.5 51.421875 16.5 36.375 \r\nQ 16.5 21.390625 20.328125 13.890625 \r\nQ 24.171875 6.390625 31.78125 6.390625 \r\nQ 39.453125 6.390625 43.28125 13.890625 \r\nQ 47.125 21.390625 47.125 36.375 \r\nQ 47.125 51.421875 43.28125 58.90625 \r\nQ 39.453125 66.40625 31.78125 66.40625 \r\nz\r\nM 31.78125 74.21875 \r\nQ 44.046875 74.21875 50.515625 64.515625 \r\nQ 56.984375 54.828125 56.984375 36.375 \r\nQ 56.984375 17.96875 50.515625 8.265625 \r\nQ 44.046875 -1.421875 31.78125 -1.421875 \r\nQ 19.53125 -1.421875 13.0625 8.265625 \r\nQ 6.59375 17.96875 6.59375 36.375 \r\nQ 6.59375 54.828125 13.0625 64.515625 \r\nQ 19.53125 74.21875 31.78125 74.21875 \r\nz\r\n\" id=\"DejaVuSans-48\"/>\r\n       </defs>\r\n       <use xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_2\">\r\n     <g id=\"line2d_2\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"115.092898\" xlink:href=\"#m0cd4e5cda4\" y=\"227.071706\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_2\">\r\n      <!-- 5 -->\r\n      <g transform=\"translate(111.911648 241.670144)scale(0.1 -0.1)\">\r\n       <defs>\r\n        <path d=\"M 10.796875 72.90625 \r\nL 49.515625 72.90625 \r\nL 49.515625 64.59375 \r\nL 19.828125 64.59375 \r\nL 19.828125 46.734375 \r\nQ 21.96875 47.46875 24.109375 47.828125 \r\nQ 26.265625 48.1875 28.421875 48.1875 \r\nQ 40.625 48.1875 47.75 41.5 \r\nQ 54.890625 34.8125 54.890625 23.390625 \r\nQ 54.890625 11.625 47.5625 5.09375 \r\nQ 40.234375 -1.421875 26.90625 -1.421875 \r\nQ 22.3125 -1.421875 17.546875 -0.640625 \r\nQ 12.796875 0.140625 7.71875 1.703125 \r\nL 7.71875 11.625 \r\nQ 12.109375 9.234375 16.796875 8.0625 \r\nQ 21.484375 6.890625 26.703125 6.890625 \r\nQ 35.15625 6.890625 40.078125 11.328125 \r\nQ 45.015625 15.765625 45.015625 23.390625 \r\nQ 45.015625 31 40.078125 35.4375 \r\nQ 35.15625 39.890625 26.703125 39.890625 \r\nQ 22.75 39.890625 18.8125 39.015625 \r\nQ 14.890625 38.140625 10.796875 36.28125 \r\nz\r\n\" id=\"DejaVuSans-53\"/>\r\n       </defs>\r\n       <use xlink:href=\"#DejaVuSans-53\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_3\">\r\n     <g id=\"line2d_3\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"178.501989\" xlink:href=\"#m0cd4e5cda4\" y=\"227.071706\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_3\">\r\n      <!-- 10 -->\r\n      <g transform=\"translate(172.139489 241.670144)scale(0.1 -0.1)\">\r\n       <defs>\r\n        <path d=\"M 12.40625 8.296875 \r\nL 28.515625 8.296875 \r\nL 28.515625 63.921875 \r\nL 10.984375 60.40625 \r\nL 10.984375 69.390625 \r\nL 28.421875 72.90625 \r\nL 38.28125 72.90625 \r\nL 38.28125 8.296875 \r\nL 54.390625 8.296875 \r\nL 54.390625 0 \r\nL 12.40625 0 \r\nz\r\n\" id=\"DejaVuSans-49\"/>\r\n       </defs>\r\n       <use xlink:href=\"#DejaVuSans-49\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_4\">\r\n     <g id=\"line2d_4\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"241.91108\" xlink:href=\"#m0cd4e5cda4\" y=\"227.071706\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_4\">\r\n      <!-- 15 -->\r\n      <g transform=\"translate(235.54858 241.670144)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-49\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_5\">\r\n     <g id=\"line2d_5\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"305.32017\" xlink:href=\"#m0cd4e5cda4\" y=\"227.071706\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_5\">\r\n      <!-- 20 -->\r\n      <g transform=\"translate(298.95767 241.670144)scale(0.1 -0.1)\">\r\n       <defs>\r\n        <path d=\"M 19.1875 8.296875 \r\nL 53.609375 8.296875 \r\nL 53.609375 0 \r\nL 7.328125 0 \r\nL 7.328125 8.296875 \r\nQ 12.9375 14.109375 22.625 23.890625 \r\nQ 32.328125 33.6875 34.8125 36.53125 \r\nQ 39.546875 41.84375 41.421875 45.53125 \r\nQ 43.3125 49.21875 43.3125 52.78125 \r\nQ 43.3125 58.59375 39.234375 62.25 \r\nQ 35.15625 65.921875 28.609375 65.921875 \r\nQ 23.96875 65.921875 18.8125 64.3125 \r\nQ 13.671875 62.703125 7.8125 59.421875 \r\nL 7.8125 69.390625 \r\nQ 13.765625 71.78125 18.9375 73 \r\nQ 24.125 74.21875 28.421875 74.21875 \r\nQ 39.75 74.21875 46.484375 68.546875 \r\nQ 53.21875 62.890625 53.21875 53.421875 \r\nQ 53.21875 48.921875 51.53125 44.890625 \r\nQ 49.859375 40.875 45.40625 35.40625 \r\nQ 44.1875 33.984375 37.640625 27.21875 \r\nQ 31.109375 20.453125 19.1875 8.296875 \r\nz\r\n\" id=\"DejaVuSans-50\"/>\r\n       </defs>\r\n       <use xlink:href=\"#DejaVuSans-50\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_6\">\r\n     <g id=\"line2d_6\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"368.729261\" xlink:href=\"#m0cd4e5cda4\" y=\"227.071706\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_6\">\r\n      <!-- 25 -->\r\n      <g transform=\"translate(362.366761 241.670144)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-50\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n   </g>\r\n   <g id=\"matplotlib.axis_2\">\r\n    <g id=\"ytick_1\">\r\n     <g id=\"line2d_7\">\r\n      <defs>\r\n       <path d=\"M 0 0 \r\nL -3.5 0 \r\n\" id=\"me53837cece\" style=\"stroke:#000000;stroke-width:0.8;\"/>\r\n      </defs>\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"36.465625\" xlink:href=\"#me53837cece\" y=\"220.012993\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_7\">\r\n      <!-- 0.00 -->\r\n      <g transform=\"translate(7.2 223.812212)scale(0.1 -0.1)\">\r\n       <defs>\r\n        <path d=\"M 10.6875 12.40625 \r\nL 21 12.40625 \r\nL 21 0 \r\nL 10.6875 0 \r\nz\r\n\" id=\"DejaVuSans-46\"/>\r\n       </defs>\r\n       <use xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\r\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_2\">\r\n     <g id=\"line2d_8\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"36.465625\" xlink:href=\"#me53837cece\" y=\"193.886271\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_8\">\r\n      <!-- 0.05 -->\r\n      <g transform=\"translate(7.2 197.68549)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\r\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-53\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_3\">\r\n     <g id=\"line2d_9\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"36.465625\" xlink:href=\"#me53837cece\" y=\"167.759549\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_9\">\r\n      <!-- 0.10 -->\r\n      <g transform=\"translate(7.2 171.558768)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\r\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-49\"/>\r\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_4\">\r\n     <g id=\"line2d_10\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"36.465625\" xlink:href=\"#me53837cece\" y=\"141.632828\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_10\">\r\n      <!-- 0.15 -->\r\n      <g transform=\"translate(7.2 145.432046)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\r\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-49\"/>\r\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-53\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_5\">\r\n     <g id=\"line2d_11\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"36.465625\" xlink:href=\"#me53837cece\" y=\"115.506106\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_11\">\r\n      <!-- 0.20 -->\r\n      <g transform=\"translate(7.2 119.305325)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\r\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-50\"/>\r\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_6\">\r\n     <g id=\"line2d_12\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"36.465625\" xlink:href=\"#me53837cece\" y=\"89.379384\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_12\">\r\n      <!-- 0.25 -->\r\n      <g transform=\"translate(7.2 93.178603)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\r\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-50\"/>\r\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-53\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_7\">\r\n     <g id=\"line2d_13\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"36.465625\" xlink:href=\"#me53837cece\" y=\"63.252662\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_13\">\r\n      <!-- 0.30 -->\r\n      <g transform=\"translate(7.2 67.051881)scale(0.1 -0.1)\">\r\n       <defs>\r\n        <path d=\"M 40.578125 39.3125 \r\nQ 47.65625 37.796875 51.625 33 \r\nQ 55.609375 28.21875 55.609375 21.1875 \r\nQ 55.609375 10.40625 48.1875 4.484375 \r\nQ 40.765625 -1.421875 27.09375 -1.421875 \r\nQ 22.515625 -1.421875 17.65625 -0.515625 \r\nQ 12.796875 0.390625 7.625 2.203125 \r\nL 7.625 11.71875 \r\nQ 11.71875 9.328125 16.59375 8.109375 \r\nQ 21.484375 6.890625 26.8125 6.890625 \r\nQ 36.078125 6.890625 40.9375 10.546875 \r\nQ 45.796875 14.203125 45.796875 21.1875 \r\nQ 45.796875 27.640625 41.28125 31.265625 \r\nQ 36.765625 34.90625 28.71875 34.90625 \r\nL 20.21875 34.90625 \r\nL 20.21875 43.015625 \r\nL 29.109375 43.015625 \r\nQ 36.375 43.015625 40.234375 45.921875 \r\nQ 44.09375 48.828125 44.09375 54.296875 \r\nQ 44.09375 59.90625 40.109375 62.90625 \r\nQ 36.140625 65.921875 28.71875 65.921875 \r\nQ 24.65625 65.921875 20.015625 65.03125 \r\nQ 15.375 64.15625 9.8125 62.3125 \r\nL 9.8125 71.09375 \r\nQ 15.4375 72.65625 20.34375 73.4375 \r\nQ 25.25 74.21875 29.59375 74.21875 \r\nQ 40.828125 74.21875 47.359375 69.109375 \r\nQ 53.90625 64.015625 53.90625 55.328125 \r\nQ 53.90625 49.265625 50.4375 45.09375 \r\nQ 46.96875 40.921875 40.578125 39.3125 \r\nz\r\n\" id=\"DejaVuSans-51\"/>\r\n       </defs>\r\n       <use xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\r\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-51\"/>\r\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_8\">\r\n     <g id=\"line2d_14\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"36.465625\" xlink:href=\"#me53837cece\" y=\"37.125941\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_14\">\r\n      <!-- 0.35 -->\r\n      <g transform=\"translate(7.2 40.925159)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\r\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-51\"/>\r\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-53\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_9\">\r\n     <g id=\"line2d_15\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"36.465625\" xlink:href=\"#me53837cece\" y=\"10.999219\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_15\">\r\n      <!-- 0.40 -->\r\n      <g transform=\"translate(7.2 14.798437)scale(0.1 -0.1)\">\r\n       <defs>\r\n        <path d=\"M 37.796875 64.3125 \r\nL 12.890625 25.390625 \r\nL 37.796875 25.390625 \r\nz\r\nM 35.203125 72.90625 \r\nL 47.609375 72.90625 \r\nL 47.609375 25.390625 \r\nL 58.015625 25.390625 \r\nL 58.015625 17.1875 \r\nL 47.609375 17.1875 \r\nL 47.609375 0 \r\nL 37.796875 0 \r\nL 37.796875 17.1875 \r\nL 4.890625 17.1875 \r\nL 4.890625 26.703125 \r\nz\r\n\" id=\"DejaVuSans-52\"/>\r\n       </defs>\r\n       <use xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\r\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-52\"/>\r\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n   </g>\r\n   <g id=\"line2d_16\">\r\n    <path clip-path=\"url(#p1fc96c67a4)\" d=\"M 51.683807 94.721394 \r\nL 64.365625 110.846507 \r\nL 77.047443 121.695007 \r\nL 89.729261 131.254372 \r\nL 102.41108 134.673134 \r\nL 115.092898 132.927858 \r\nL 127.774716 132.41866 \r\nL 140.456534 125.208591 \r\nL 153.138352 124.620463 \r\nL 165.82017 135.089401 \r\nL 178.501989 138.544159 \r\nL 191.183807 135.261487 \r\nL 203.865625 147.353315 \r\nL 216.547443 154.534746 \r\nL 229.229261 152.724649 \r\nL 241.91108 152.026453 \r\nL 254.592898 164.287268 \r\nL 267.274716 165.129737 \r\nL 279.956534 166.6673 \r\nL 292.638352 174.19881 \r\nL 305.32017 167.941026 \r\nL 318.001989 176.344567 \r\nL 330.683807 186.170595 \r\nL 343.365625 184.134787 \r\nL 356.047443 183.74089 \r\n\" style=\"fill:none;stroke:#1f77b4;stroke-linecap:square;stroke-width:1.5;\"/>\r\n   </g>\r\n   <g id=\"line2d_17\">\r\n    <path clip-path=\"url(#p1fc96c67a4)\" d=\"M 51.683807 213.458938 \r\nL 64.365625 213.488274 \r\nL 77.047443 211.985278 \r\nL 89.729261 212.429027 \r\nL 102.41108 212.555988 \r\nL 115.092898 212.029279 \r\nL 127.774716 211.810781 \r\nL 140.456534 211.567507 \r\nL 153.138352 211.719003 \r\nL 165.82017 211.030093 \r\nL 178.501989 209.914412 \r\nL 191.183807 211.526505 \r\nL 203.865625 211.550007 \r\nL 216.547443 211.099964 \r\nL 229.229261 210.769266 \r\nL 241.91108 209.110624 \r\nL 254.592898 210.30347 \r\nL 267.274716 208.192215 \r\nL 279.956534 207.772877 \r\nL 292.638352 210.41131 \r\nL 305.32017 208.274824 \r\nL 318.001989 207.666169 \r\nL 330.683807 207.222047 \r\nL 343.365625 207.246254 \r\nL 356.047443 207.628789 \r\n\" style=\"fill:none;stroke:#ff7f0e;stroke-linecap:square;stroke-width:1.5;\"/>\r\n   </g>\r\n   <g id=\"line2d_18\">\r\n    <path clip-path=\"url(#p1fc96c67a4)\" d=\"M 51.683807 214.668544 \r\nL 64.365625 217.111721 \r\nL 77.047443 217.18807 \r\nL 89.729261 217.18807 \r\nL 102.41108 217.18807 \r\nL 115.092898 217.18807 \r\nL 127.774716 217.18807 \r\nL 140.456534 217.18807 \r\nL 153.138352 217.18807 \r\nL 165.82017 215.661084 \r\nL 178.501989 212.072668 \r\nL 191.183807 215.661084 \r\nL 203.865625 216.271879 \r\nL 216.547443 216.271879 \r\nL 229.229261 214.439496 \r\nL 241.91108 211.91997 \r\nL 254.592898 213.294257 \r\nL 267.274716 208.255205 \r\nL 279.956534 214.821242 \r\nL 292.638352 207.568061 \r\nL 305.32017 188.251695 \r\nL 318.001989 185.045025 \r\nL 330.683807 198.864244 \r\nL 343.365625 188.862489 \r\nL 356.047443 183.136293 \r\n\" style=\"fill:none;stroke:#2ca02c;stroke-linecap:square;stroke-width:1.5;\"/>\r\n   </g>\r\n   <g id=\"line2d_19\">\r\n    <path clip-path=\"url(#p1fc96c67a4)\" d=\"M 51.683807 199.50024 \r\nL 64.365625 207.643996 \r\nL 77.047443 207.918506 \r\nL 89.729261 207.918506 \r\nL 102.41108 207.918506 \r\nL 115.092898 207.918506 \r\nL 127.774716 207.918506 \r\nL 140.456534 207.918506 \r\nL 153.138352 207.918506 \r\nL 165.82017 200.674879 \r\nL 178.501989 187.673649 \r\nL 191.183807 202.756884 \r\nL 203.865625 205.185699 \r\nL 216.547443 205.185699 \r\nL 229.229261 196.663369 \r\nL 241.91108 187.186933 \r\nL 254.592898 191.030357 \r\nL 267.274716 131.275892 \r\nL 279.956534 199.399855 \r\nL 292.638352 167.631851 \r\nL 305.32017 42.365034 \r\nL 318.001989 25.07641 \r\nL 330.683807 87.005043 \r\nL 343.365625 47.597648 \r\nL 356.047443 19.515343 \r\n\" style=\"fill:none;stroke:#d62728;stroke-linecap:square;stroke-width:1.5;\"/>\r\n   </g>\r\n   <g id=\"patch_3\">\r\n    <path d=\"M 36.465625 227.071706 \r\nL 36.465625 9.631706 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_4\">\r\n    <path d=\"M 371.265625 227.071706 \r\nL 371.265625 9.631706 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_5\">\r\n    <path d=\"M 36.465625 227.071706 \r\nL 371.265625 227.071706 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_6\">\r\n    <path d=\"M 36.465625 9.631706 \r\nL 371.265625 9.631706 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n  </g>\r\n </g>\r\n <defs>\r\n  <clipPath id=\"p1fc96c67a4\">\r\n   <rect height=\"217.44\" width=\"334.8\" x=\"36.465625\" y=\"9.631706\"/>\r\n  </clipPath>\r\n </defs>\r\n</svg>\r\n",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "source": [
    "for epoch in range(EPOCHS):\n",
    "    gc.collect()\n",
    "    start = time.time()\n",
    "    # enc_hidden = encoder.initialize_hidden_state()\n",
    "    total_loss = 0\n",
    "    total_batch_perplexity = 0\n",
    "    for (batch, (feat, targ)) in enumerate(train_dataset.take(STEPS_PER_EPOCH)):\n",
    "        batch_loss = train_step(feat, targ)#, enc_hidden)\n",
    "        batch_perplexity = tf.exp(batch_loss)\n",
    "\n",
    "        total_loss += batch_loss\n",
    "        total_batch_perplexity += batch_perplexity\n",
    "        if batch % 100 == 0:\n",
    "            print('Epoch {} Batch {} Loss {:.4f}'.format(epoch + 1,\n",
    "                                                            batch,\n",
    "                                                            batch_loss.numpy()), end=' ')\n",
    "            print('Perplexity {:.4f}'.format(batch_perplexity))\n",
    "    train_losses.append(batch_loss)\n",
    "    _, losses_ce, rouge_recalls, rouge_precisions = predict_on_test(X_test[TASK_FEATURES], Y_test)\n",
    "    val_ce.append(losses_ce)\n",
    "    val_rr.append(rouge_recalls)\n",
    "    val_rp.append(rouge_precisions)\n",
    "    if (epoch + 1) % 5 == 0:\n",
    "        print('saving')\n",
    "        checkpoint.step.assign_add(5)\n",
    "        manager.save()\n",
    "        print('saved')\n",
    "    print('Time taken for the epoch {} sec\\n'.format(time.time() - start))\n",
    "best_epoch = np.argmin(train_losses)\n",
    "print('The best epoch is {}'.format(best_epoch))\n",
    "plt.plot(train_losses)\n",
    "plt.plot(np.mean(val_ce, axis=1)/10000)\n",
    "plt.plot(np.mean(val_rr, axis=1))\n",
    "plt.plot(np.mean(val_rp, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 575,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x18d564b3bb0>]"
      ]
     },
     "metadata": {},
     "execution_count": 575
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\r\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\r\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\r\n<!-- Created with matplotlib (https://matplotlib.org/) -->\r\n<svg height=\"250.949831pt\" version=\"1.1\" viewBox=\"0 0 382.291761 250.949831\" width=\"382.291761pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\r\n <metadata>\r\n  <rdf:RDF xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\r\n   <cc:Work>\r\n    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\r\n    <dc:date>2021-05-31T17:50:06.132981</dc:date>\r\n    <dc:format>image/svg+xml</dc:format>\r\n    <dc:creator>\r\n     <cc:Agent>\r\n      <dc:title>Matplotlib v3.3.2, https://matplotlib.org/</dc:title>\r\n     </cc:Agent>\r\n    </dc:creator>\r\n   </cc:Work>\r\n  </rdf:RDF>\r\n </metadata>\r\n <defs>\r\n  <style type=\"text/css\">*{stroke-linecap:butt;stroke-linejoin:round;}</style>\r\n </defs>\r\n <g id=\"figure_1\">\r\n  <g id=\"patch_1\">\r\n   <path d=\"M 0 250.949831 \r\nL 382.291761 250.949831 \r\nL 382.291761 0 \r\nL 0 0 \r\nz\r\n\" style=\"fill:none;\"/>\r\n  </g>\r\n  <g id=\"axes_1\">\r\n   <g id=\"patch_2\">\r\n    <path d=\"M 36.465625 227.071706 \r\nL 371.265625 227.071706 \r\nL 371.265625 9.631706 \r\nL 36.465625 9.631706 \r\nz\r\n\" style=\"fill:#ffffff;\"/>\r\n   </g>\r\n   <g id=\"matplotlib.axis_1\">\r\n    <g id=\"xtick_1\">\r\n     <g id=\"line2d_1\">\r\n      <defs>\r\n       <path d=\"M 0 0 \r\nL 0 3.5 \r\n\" id=\"m3e14822f7a\" style=\"stroke:#000000;stroke-width:0.8;\"/>\r\n      </defs>\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"51.683807\" xlink:href=\"#m3e14822f7a\" y=\"227.071706\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_1\">\r\n      <!-- 0 -->\r\n      <g transform=\"translate(48.502557 241.670144)scale(0.1 -0.1)\">\r\n       <defs>\r\n        <path d=\"M 31.78125 66.40625 \r\nQ 24.171875 66.40625 20.328125 58.90625 \r\nQ 16.5 51.421875 16.5 36.375 \r\nQ 16.5 21.390625 20.328125 13.890625 \r\nQ 24.171875 6.390625 31.78125 6.390625 \r\nQ 39.453125 6.390625 43.28125 13.890625 \r\nQ 47.125 21.390625 47.125 36.375 \r\nQ 47.125 51.421875 43.28125 58.90625 \r\nQ 39.453125 66.40625 31.78125 66.40625 \r\nz\r\nM 31.78125 74.21875 \r\nQ 44.046875 74.21875 50.515625 64.515625 \r\nQ 56.984375 54.828125 56.984375 36.375 \r\nQ 56.984375 17.96875 50.515625 8.265625 \r\nQ 44.046875 -1.421875 31.78125 -1.421875 \r\nQ 19.53125 -1.421875 13.0625 8.265625 \r\nQ 6.59375 17.96875 6.59375 36.375 \r\nQ 6.59375 54.828125 13.0625 64.515625 \r\nQ 19.53125 74.21875 31.78125 74.21875 \r\nz\r\n\" id=\"DejaVuSans-48\"/>\r\n       </defs>\r\n       <use xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_2\">\r\n     <g id=\"line2d_2\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"115.092898\" xlink:href=\"#m3e14822f7a\" y=\"227.071706\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_2\">\r\n      <!-- 5 -->\r\n      <g transform=\"translate(111.911648 241.670144)scale(0.1 -0.1)\">\r\n       <defs>\r\n        <path d=\"M 10.796875 72.90625 \r\nL 49.515625 72.90625 \r\nL 49.515625 64.59375 \r\nL 19.828125 64.59375 \r\nL 19.828125 46.734375 \r\nQ 21.96875 47.46875 24.109375 47.828125 \r\nQ 26.265625 48.1875 28.421875 48.1875 \r\nQ 40.625 48.1875 47.75 41.5 \r\nQ 54.890625 34.8125 54.890625 23.390625 \r\nQ 54.890625 11.625 47.5625 5.09375 \r\nQ 40.234375 -1.421875 26.90625 -1.421875 \r\nQ 22.3125 -1.421875 17.546875 -0.640625 \r\nQ 12.796875 0.140625 7.71875 1.703125 \r\nL 7.71875 11.625 \r\nQ 12.109375 9.234375 16.796875 8.0625 \r\nQ 21.484375 6.890625 26.703125 6.890625 \r\nQ 35.15625 6.890625 40.078125 11.328125 \r\nQ 45.015625 15.765625 45.015625 23.390625 \r\nQ 45.015625 31 40.078125 35.4375 \r\nQ 35.15625 39.890625 26.703125 39.890625 \r\nQ 22.75 39.890625 18.8125 39.015625 \r\nQ 14.890625 38.140625 10.796875 36.28125 \r\nz\r\n\" id=\"DejaVuSans-53\"/>\r\n       </defs>\r\n       <use xlink:href=\"#DejaVuSans-53\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_3\">\r\n     <g id=\"line2d_3\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"178.501989\" xlink:href=\"#m3e14822f7a\" y=\"227.071706\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_3\">\r\n      <!-- 10 -->\r\n      <g transform=\"translate(172.139489 241.670144)scale(0.1 -0.1)\">\r\n       <defs>\r\n        <path d=\"M 12.40625 8.296875 \r\nL 28.515625 8.296875 \r\nL 28.515625 63.921875 \r\nL 10.984375 60.40625 \r\nL 10.984375 69.390625 \r\nL 28.421875 72.90625 \r\nL 38.28125 72.90625 \r\nL 38.28125 8.296875 \r\nL 54.390625 8.296875 \r\nL 54.390625 0 \r\nL 12.40625 0 \r\nz\r\n\" id=\"DejaVuSans-49\"/>\r\n       </defs>\r\n       <use xlink:href=\"#DejaVuSans-49\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_4\">\r\n     <g id=\"line2d_4\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"241.91108\" xlink:href=\"#m3e14822f7a\" y=\"227.071706\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_4\">\r\n      <!-- 15 -->\r\n      <g transform=\"translate(235.54858 241.670144)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-49\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_5\">\r\n     <g id=\"line2d_5\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"305.32017\" xlink:href=\"#m3e14822f7a\" y=\"227.071706\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_5\">\r\n      <!-- 20 -->\r\n      <g transform=\"translate(298.95767 241.670144)scale(0.1 -0.1)\">\r\n       <defs>\r\n        <path d=\"M 19.1875 8.296875 \r\nL 53.609375 8.296875 \r\nL 53.609375 0 \r\nL 7.328125 0 \r\nL 7.328125 8.296875 \r\nQ 12.9375 14.109375 22.625 23.890625 \r\nQ 32.328125 33.6875 34.8125 36.53125 \r\nQ 39.546875 41.84375 41.421875 45.53125 \r\nQ 43.3125 49.21875 43.3125 52.78125 \r\nQ 43.3125 58.59375 39.234375 62.25 \r\nQ 35.15625 65.921875 28.609375 65.921875 \r\nQ 23.96875 65.921875 18.8125 64.3125 \r\nQ 13.671875 62.703125 7.8125 59.421875 \r\nL 7.8125 69.390625 \r\nQ 13.765625 71.78125 18.9375 73 \r\nQ 24.125 74.21875 28.421875 74.21875 \r\nQ 39.75 74.21875 46.484375 68.546875 \r\nQ 53.21875 62.890625 53.21875 53.421875 \r\nQ 53.21875 48.921875 51.53125 44.890625 \r\nQ 49.859375 40.875 45.40625 35.40625 \r\nQ 44.1875 33.984375 37.640625 27.21875 \r\nQ 31.109375 20.453125 19.1875 8.296875 \r\nz\r\n\" id=\"DejaVuSans-50\"/>\r\n       </defs>\r\n       <use xlink:href=\"#DejaVuSans-50\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_6\">\r\n     <g id=\"line2d_6\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"368.729261\" xlink:href=\"#m3e14822f7a\" y=\"227.071706\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_6\">\r\n      <!-- 25 -->\r\n      <g transform=\"translate(362.366761 241.670144)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-50\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n   </g>\r\n   <g id=\"matplotlib.axis_2\">\r\n    <g id=\"ytick_1\">\r\n     <g id=\"line2d_7\">\r\n      <defs>\r\n       <path d=\"M 0 0 \r\nL -3.5 0 \r\n\" id=\"mbb9fc86722\" style=\"stroke:#000000;stroke-width:0.8;\"/>\r\n      </defs>\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"36.465625\" xlink:href=\"#mbb9fc86722\" y=\"220.012993\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_7\">\r\n      <!-- 0.00 -->\r\n      <g transform=\"translate(7.2 223.812212)scale(0.1 -0.1)\">\r\n       <defs>\r\n        <path d=\"M 10.6875 12.40625 \r\nL 21 12.40625 \r\nL 21 0 \r\nL 10.6875 0 \r\nz\r\n\" id=\"DejaVuSans-46\"/>\r\n       </defs>\r\n       <use xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\r\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_2\">\r\n     <g id=\"line2d_8\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"36.465625\" xlink:href=\"#mbb9fc86722\" y=\"193.886271\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_8\">\r\n      <!-- 0.05 -->\r\n      <g transform=\"translate(7.2 197.68549)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\r\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-53\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_3\">\r\n     <g id=\"line2d_9\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"36.465625\" xlink:href=\"#mbb9fc86722\" y=\"167.759549\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_9\">\r\n      <!-- 0.10 -->\r\n      <g transform=\"translate(7.2 171.558768)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\r\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-49\"/>\r\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_4\">\r\n     <g id=\"line2d_10\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"36.465625\" xlink:href=\"#mbb9fc86722\" y=\"141.632828\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_10\">\r\n      <!-- 0.15 -->\r\n      <g transform=\"translate(7.2 145.432046)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\r\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-49\"/>\r\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-53\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_5\">\r\n     <g id=\"line2d_11\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"36.465625\" xlink:href=\"#mbb9fc86722\" y=\"115.506106\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_11\">\r\n      <!-- 0.20 -->\r\n      <g transform=\"translate(7.2 119.305325)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\r\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-50\"/>\r\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_6\">\r\n     <g id=\"line2d_12\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"36.465625\" xlink:href=\"#mbb9fc86722\" y=\"89.379384\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_12\">\r\n      <!-- 0.25 -->\r\n      <g transform=\"translate(7.2 93.178603)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\r\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-50\"/>\r\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-53\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_7\">\r\n     <g id=\"line2d_13\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"36.465625\" xlink:href=\"#mbb9fc86722\" y=\"63.252662\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_13\">\r\n      <!-- 0.30 -->\r\n      <g transform=\"translate(7.2 67.051881)scale(0.1 -0.1)\">\r\n       <defs>\r\n        <path d=\"M 40.578125 39.3125 \r\nQ 47.65625 37.796875 51.625 33 \r\nQ 55.609375 28.21875 55.609375 21.1875 \r\nQ 55.609375 10.40625 48.1875 4.484375 \r\nQ 40.765625 -1.421875 27.09375 -1.421875 \r\nQ 22.515625 -1.421875 17.65625 -0.515625 \r\nQ 12.796875 0.390625 7.625 2.203125 \r\nL 7.625 11.71875 \r\nQ 11.71875 9.328125 16.59375 8.109375 \r\nQ 21.484375 6.890625 26.8125 6.890625 \r\nQ 36.078125 6.890625 40.9375 10.546875 \r\nQ 45.796875 14.203125 45.796875 21.1875 \r\nQ 45.796875 27.640625 41.28125 31.265625 \r\nQ 36.765625 34.90625 28.71875 34.90625 \r\nL 20.21875 34.90625 \r\nL 20.21875 43.015625 \r\nL 29.109375 43.015625 \r\nQ 36.375 43.015625 40.234375 45.921875 \r\nQ 44.09375 48.828125 44.09375 54.296875 \r\nQ 44.09375 59.90625 40.109375 62.90625 \r\nQ 36.140625 65.921875 28.71875 65.921875 \r\nQ 24.65625 65.921875 20.015625 65.03125 \r\nQ 15.375 64.15625 9.8125 62.3125 \r\nL 9.8125 71.09375 \r\nQ 15.4375 72.65625 20.34375 73.4375 \r\nQ 25.25 74.21875 29.59375 74.21875 \r\nQ 40.828125 74.21875 47.359375 69.109375 \r\nQ 53.90625 64.015625 53.90625 55.328125 \r\nQ 53.90625 49.265625 50.4375 45.09375 \r\nQ 46.96875 40.921875 40.578125 39.3125 \r\nz\r\n\" id=\"DejaVuSans-51\"/>\r\n       </defs>\r\n       <use xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\r\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-51\"/>\r\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_8\">\r\n     <g id=\"line2d_14\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"36.465625\" xlink:href=\"#mbb9fc86722\" y=\"37.125941\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_14\">\r\n      <!-- 0.35 -->\r\n      <g transform=\"translate(7.2 40.925159)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\r\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-51\"/>\r\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-53\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_9\">\r\n     <g id=\"line2d_15\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"36.465625\" xlink:href=\"#mbb9fc86722\" y=\"10.999219\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_15\">\r\n      <!-- 0.40 -->\r\n      <g transform=\"translate(7.2 14.798437)scale(0.1 -0.1)\">\r\n       <defs>\r\n        <path d=\"M 37.796875 64.3125 \r\nL 12.890625 25.390625 \r\nL 37.796875 25.390625 \r\nz\r\nM 35.203125 72.90625 \r\nL 47.609375 72.90625 \r\nL 47.609375 25.390625 \r\nL 58.015625 25.390625 \r\nL 58.015625 17.1875 \r\nL 47.609375 17.1875 \r\nL 47.609375 0 \r\nL 37.796875 0 \r\nL 37.796875 17.1875 \r\nL 4.890625 17.1875 \r\nL 4.890625 26.703125 \r\nz\r\n\" id=\"DejaVuSans-52\"/>\r\n       </defs>\r\n       <use xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\r\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-52\"/>\r\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n   </g>\r\n   <g id=\"line2d_16\">\r\n    <path clip-path=\"url(#p2a7f5f2071)\" d=\"M 51.683807 94.721394 \r\nL 64.365625 110.846507 \r\nL 77.047443 121.695007 \r\nL 89.729261 131.254372 \r\nL 102.41108 134.673134 \r\nL 115.092898 132.927858 \r\nL 127.774716 132.41866 \r\nL 140.456534 125.208591 \r\nL 153.138352 124.620463 \r\nL 165.82017 135.089401 \r\nL 178.501989 138.544159 \r\nL 191.183807 135.261487 \r\nL 203.865625 147.353315 \r\nL 216.547443 154.534746 \r\nL 229.229261 152.724649 \r\nL 241.91108 152.026453 \r\nL 254.592898 164.287268 \r\nL 267.274716 165.129737 \r\nL 279.956534 166.6673 \r\nL 292.638352 174.19881 \r\nL 305.32017 167.941026 \r\nL 318.001989 176.344567 \r\nL 330.683807 186.170595 \r\nL 343.365625 184.134787 \r\nL 356.047443 183.74089 \r\n\" style=\"fill:none;stroke:#1f77b4;stroke-linecap:square;stroke-width:1.5;\"/>\r\n   </g>\r\n   <g id=\"line2d_17\">\r\n    <path clip-path=\"url(#p2a7f5f2071)\" d=\"M 51.683807 154.472447 \r\nL 64.365625 154.765803 \r\nL 77.047443 139.735839 \r\nL 89.729261 144.17333 \r\nL 102.41108 145.442937 \r\nL 115.092898 140.175855 \r\nL 127.774716 137.990875 \r\nL 140.456534 135.558132 \r\nL 153.138352 137.073095 \r\nL 165.82017 130.183996 \r\nL 178.501989 119.027186 \r\nL 191.183807 135.14811 \r\nL 203.865625 135.383134 \r\nL 216.547443 130.882705 \r\nL 229.229261 127.575725 \r\nL 241.91108 110.989301 \r\nL 254.592898 122.917763 \r\nL 267.274716 101.805216 \r\nL 279.956534 97.611827 \r\nL 292.638352 123.99616 \r\nL 305.32017 102.631303 \r\nL 318.001989 96.544752 \r\nL 330.683807 92.103531 \r\nL 343.365625 92.345602 \r\nL 356.047443 96.17096 \r\n\" style=\"fill:none;stroke:#ff7f0e;stroke-linecap:square;stroke-width:1.5;\"/>\r\n   </g>\r\n   <g id=\"line2d_18\">\r\n    <path clip-path=\"url(#p2a7f5f2071)\" d=\"M 51.683807 214.668544 \r\nL 64.365625 217.111721 \r\nL 77.047443 217.18807 \r\nL 89.729261 217.18807 \r\nL 102.41108 217.18807 \r\nL 115.092898 217.18807 \r\nL 127.774716 217.18807 \r\nL 140.456534 217.18807 \r\nL 153.138352 217.18807 \r\nL 165.82017 215.661084 \r\nL 178.501989 212.072668 \r\nL 191.183807 215.661084 \r\nL 203.865625 216.271879 \r\nL 216.547443 216.271879 \r\nL 229.229261 214.439496 \r\nL 241.91108 211.91997 \r\nL 254.592898 213.294257 \r\nL 267.274716 208.255205 \r\nL 279.956534 214.821242 \r\nL 292.638352 207.568061 \r\nL 305.32017 188.251695 \r\nL 318.001989 185.045025 \r\nL 330.683807 198.864244 \r\nL 343.365625 188.862489 \r\nL 356.047443 183.136293 \r\n\" style=\"fill:none;stroke:#2ca02c;stroke-linecap:square;stroke-width:1.5;\"/>\r\n   </g>\r\n   <g id=\"line2d_19\">\r\n    <path clip-path=\"url(#p2a7f5f2071)\" d=\"M 51.683807 199.50024 \r\nL 64.365625 207.643996 \r\nL 77.047443 207.918506 \r\nL 89.729261 207.918506 \r\nL 102.41108 207.918506 \r\nL 115.092898 207.918506 \r\nL 127.774716 207.918506 \r\nL 140.456534 207.918506 \r\nL 153.138352 207.918506 \r\nL 165.82017 200.674879 \r\nL 178.501989 187.673649 \r\nL 191.183807 202.756884 \r\nL 203.865625 205.185699 \r\nL 216.547443 205.185699 \r\nL 229.229261 196.663369 \r\nL 241.91108 187.186933 \r\nL 254.592898 191.030357 \r\nL 267.274716 131.275892 \r\nL 279.956534 199.399855 \r\nL 292.638352 167.631851 \r\nL 305.32017 42.365034 \r\nL 318.001989 25.07641 \r\nL 330.683807 87.005043 \r\nL 343.365625 47.597648 \r\nL 356.047443 19.515343 \r\n\" style=\"fill:none;stroke:#d62728;stroke-linecap:square;stroke-width:1.5;\"/>\r\n   </g>\r\n   <g id=\"patch_3\">\r\n    <path d=\"M 36.465625 227.071706 \r\nL 36.465625 9.631706 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_4\">\r\n    <path d=\"M 371.265625 227.071706 \r\nL 371.265625 9.631706 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_5\">\r\n    <path d=\"M 36.465625 227.071706 \r\nL 371.265625 227.071706 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_6\">\r\n    <path d=\"M 36.465625 9.631706 \r\nL 371.265625 9.631706 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n  </g>\r\n </g>\r\n <defs>\r\n  <clipPath id=\"p2a7f5f2071\">\r\n   <rect height=\"217.44\" width=\"334.8\" x=\"36.465625\" y=\"9.631706\"/>\r\n  </clipPath>\r\n </defs>\r\n</svg>\r\n",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "source": [
    "plt.plot(train_losses)\n",
    "plt.plot(np.mean(val_ce, axis=1)/1000)\n",
    "plt.plot(np.mean(val_rr, axis=1))\n",
    "plt.plot(np.mean(val_rp, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 573,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(244.78667, 0.04047340736411456, 0.25454389329698535)"
      ]
     },
     "metadata": {},
     "execution_count": 573
    }
   ],
   "source": [
    "(np.mean(val_ce, axis=1))[best_epoch],\\\n",
    "(np.mean(val_rr, axis=1))[best_epoch],\\\n",
    "(np.mean(val_rp, axis=1))[best_epoch]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 522,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))"
   ]
  },
  {
   "source": [
    "### Sequence Generation"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 548,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_task(task_vector):\n",
    "    # either convert to float32 or encode to categoricals\n",
    "    for i, el in enumerate(task_vector):\n",
    "        try:\n",
    "            task_vector[i] = float(task_vector[i])\n",
    "        except:\n",
    "            task_vector[i] = get_key(cat_encodings[i], task_vector[i])\n",
    "    return task_vector.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 549,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_solution(task_vector, save_outputs:bool=False):\n",
    "  attention_plot = np.zeros((max_length_targ, max_length_feat))\n",
    "  task_vector = preprocess_task(task_vector)\n",
    "  inputs = tf.expand_dims(tf.convert_to_tensor(task_vector), axis=0)\n",
    "  result = ''\n",
    "\n",
    "  dec_hidden = tf.zeros((BATCH_SIZE, gru_units))\n",
    "  dec_input = tf.expand_dims([1], 0)\n",
    "  loss = 0\n",
    "  for t in range(max_length_targ):\n",
    "    predictions, dec_hidden = decoder(dec_input\n",
    "                                      , dec_hidden\n",
    "                                      , inputs)\n",
    "    # storing the attention weights to plot later on\n",
    "    # attention_weights = tf.reshape(attention_weights, (-1, ))\n",
    "    # attention_plot[t] = attention_weights.numpy()\n",
    "    predicted_id = tf.argmax(predictions[0]).numpy()\n",
    "    predicted_vertice = get_key(lang, predicted_id)\n",
    "    if (predicted_vertice != ' ')&(predicted_vertice != ''):\n",
    "      # loss += loss_function(true_vector, predictions)\n",
    "      # print(loss)\n",
    "      result = predicted_vertice + ' ' + result #targ_lang.index_word[predicted_id] + ' '\n",
    "    elif (predicted_vertice == '<start>')&(predicted_vertice == '<end>'):\n",
    "      print('Evaluation: found start/end, ending')\n",
    "      return result, task_vector#, attention_plot\n",
    "    \n",
    "    # the predicted ID is fed back into the model\n",
    "    dec_input = tf.expand_dims([predicted_id], 0)\n",
    "  if save_outputs:\n",
    "    OUTPUT_FILE = './task2seq/outputs/output.py'\n",
    "    with open(OUTPUT_FILE, 'w') as f:\n",
    "        last_vertice = ''\n",
    "        for vertice in result.split(' '):\n",
    "            if vertice:\n",
    "                if (vertice!='<start>')&(vertice!='<end>')&(vertice!=last_vertice):\n",
    "                    line = '#@ {} \\n\\n'.format(vertice)\n",
    "                    f.write(line)\n",
    "                    last_vertice = vertice\n",
    "  return result, task_vector#, attention_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 550,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# i = 0\n",
    "# example_task_vector = X_test.reset_index(drop=True).loc[i]\n",
    "# example_true_vector = Y_test[i]\n",
    "# example_true_sequence = y_test.loc[i][0]\n",
    "# print('task vector: {} \\n'.format(example_task_vector.values))\n",
    "# print('true sequence is: {}\\n'.format(example_true_sequence))\n",
    "# result, task_vector = generate_solution(example_task_vector)\n",
    "# print(result, '\\n')\n",
    "# print('length of the result sequence is: {} \\n'.format(len(result.split(' '))))"
   ]
  },
  {
   "source": [
    "### Model Evaluation"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rouge_recall(true_string_vector:list, predicted_string_vector:list) -> float:\n",
    "    true_string_vector = [el for el in true_string_vector if el != 0]\n",
    "    # predicted_string_vector = [el for el in predicted_string_vector if el != 0]\n",
    "    n_overlapping_words = len(set(true_string_vector).intersection(set(predicted_string_vector)))\n",
    "    total_words_in_output = len(predicted_string_vector)\n",
    "    return n_overlapping_words / total_words_in_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rouge_precision(true_string_vector:list, predicted_string_vector:list) -> float:\n",
    "    true_string_vector = [el for el in true_string_vector if el != 0]\n",
    "    n_overlapping_words = len(set(true_string_vector).intersection(set(predicted_string_vector)))\n",
    "    total_words_in_reference = len(true_string_vector)\n",
    "    return n_overlapping_words / total_words_in_reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_generated_sequence(generated_sequence_string:str, output_path:str):\n",
    "    # OUTPUT_FILE = './task2seq/outputs/output.py'\n",
    "    with open(output_path, 'w') as f:\n",
    "        last_vertice = ''\n",
    "        for vertice in generated_sequence_string.split(' '):\n",
    "            if vertice:\n",
    "                if (vertice!='<start>')&(vertice!='<end>')&(vertice!=last_vertice):\n",
    "                    line = '#@ {} \\n\\n'.format(vertice)\n",
    "                    f.write(line)\n",
    "                    last_vertice = vertice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_solution_with_evaluation(task_vector, true_sequence:np.array, save_outputs:bool=False):\n",
    "    task_vector = preprocess_task(task_vector)\n",
    "    inputs = tf.expand_dims(tf.convert_to_tensor(task_vector), axis=0)\n",
    "    generated_sequence_string = ''\n",
    "    generated_sequence_array = []\n",
    "    metrics = {}\n",
    "\n",
    "    dec_hidden = tf.zeros((BATCH_SIZE, gru_units))\n",
    "    dec_input = tf.expand_dims([1], 0)\n",
    "    loss = 0\n",
    "    for t in range(max_length_targ):\n",
    "        predictions, dec_hidden = decoder(dec_input\n",
    "                                          , dec_hidden\n",
    "                                          , inputs)\n",
    "        predicted_id = tf.argmax(predictions[0]).numpy()\n",
    "        generated_sequence_array.append(predicted_id)\n",
    "\n",
    "        predicted_vertice = get_key(lang, predicted_id)\n",
    "        if (predicted_vertice != ' ')&(predicted_vertice != ''):\n",
    "            loss += loss_function(true_sequence[t], predictions)\n",
    "            generated_sequence_string = predicted_vertice + ' ' + generated_sequence_string\n",
    "        elif (predicted_vertice == '<start>')&(predicted_vertice == '<end>'):\n",
    "            print('Evaluation: found start/end, ending')\n",
    "            return generated_sequence_string, metrics\n",
    "\n",
    "        dec_input = tf.expand_dims([predicted_id], 0)\n",
    "    metrics.update({\"Cross-Entropy\":loss.numpy(),\n",
    "                  \"Perplexity\":tf.exp(loss).numpy(),\n",
    "                  \"ROUGE-Recall\":rouge_recall(true_sequence, generated_sequence_array),\n",
    "                  \"ROUGE-Precision\": rouge_precision(true_sequence, generated_sequence_array)})\n",
    "    if save_outputs:\n",
    "        TODAY_NOW = datetime.now().strftime(\"%d-%m-%y_%H-%M-%S\")\n",
    "        save_generated_sequence(generated_sequence_string, output_path='./outputs/output_{}.py'.format(TODAY_NOW))\n",
    "    return generated_sequence_string, metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {},
   "outputs": [],
   "source": [
    "# i = 0\n",
    "# example_task_vector = X_test.reset_index(drop=True).loc[i]\n",
    "# example_true_vector = Y_test[i]\n",
    "# example_true_sequence = y_test.loc[i][0]\n",
    "# print('task vector: {} \\n'.format(example_task_vector.values))\n",
    "# print('true sequence is: {}\\n'.format(example_true_sequence))\n",
    "# result, metrics = generate_solution_with_evaluation(example_task_vector, example_true_vector, save_outputs=True)\n",
    "# print('predicted sequence is: {}\\n'.format(result))\n",
    "# print('predicted unique sequence is: {}\\n'.format(\" \".join(list(set(result.split(' ')))))) #[el for i, el in enumerate(result.split(' ')) if result.split(' ')[i-1] != el])\n",
    "# print('length of the result sequence is: {} \\n'.format(len(result.split(' '))))\n",
    "# print('Metrics:', metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_on_test(X_test, Y_test):\n",
    "    y_pred = []\n",
    "    losses_ce = []\n",
    "    rouge_recalls = []\n",
    "    rouge_precisions = []\n",
    "    print('predicting..', end=' ')\n",
    "    for i, task_vector in X_test.reset_index(drop=True).iterrows():\n",
    "        print('{:.1%}'.format(i/X_test.shape[0]), end=' ')\n",
    "        true_vector = Y_test[i]\n",
    "        result, metrics = generate_solution_with_evaluation(task_vector, true_vector)\n",
    "        # print(loss.numpy())\n",
    "        y_pred.append(result[:-1])\n",
    "        losses_ce.append(metrics['Cross-Entropy'])\n",
    "        rouge_recalls.append(metrics['ROUGE-Recall'])\n",
    "        rouge_precisions.append(metrics['ROUGE-Precision'])\n",
    "    print()\n",
    "    y_pred = pd.DataFrame(y_pred, columns=[TARGET_COLUMN])\n",
    "    print('Cross-Entropy: {}'.format(np.mean(losses_ce)))\n",
    "    print('Perplexity: {}'.format(np.exp(float(np.mean(losses_ce)))))\n",
    "    print('ROUGE-Recall: {}'.format(np.mean(rouge_recalls)))\n",
    "    print('ROUGE-Precision: {}'.format(np.mean(rouge_precisions)))\n",
    "    print('Unique answers: {}'.format(y_pred[TARGET_COLUMN].nunique()))\n",
    "    return y_pred, losses_ce, rouge_recalls, rouge_precisions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "predicting.. 0.00% 1.85% 3.70% 5.56% 7.41% 9.26% 11.11% 12.96% 14.81% 16.67% 18.52% 20.37% 22.22% 24.07% 25.93% 27.78% 29.63% 31.48% 33.33% 35.19% 37.04% 38.89% 40.74% 42.59% 44.44% 46.30% 48.15% 50.00% 51.85% 53.70% 55.56% 57.41% 59.26% 61.11% 62.96% 64.81% 66.67% 68.52% 70.37% 72.22% 74.07% 75.93% 77.78% 79.63% 81.48% 83.33% 85.19% 87.04% 88.89% 90.74% 92.59% 94.44% 96.30% 98.15% \n",
      "Cross-Entropy: 412.9048156738281\n",
      "Perplexity: 2.1003080572384504e+179\n",
      "ROUGE-Recall: 0.07838441890166029\n",
      "ROUGE-Precision: 0.31504992246593394\n",
      "Unique answers: 4\n"
     ]
    }
   ],
   "source": [
    "## Predict on Train\n",
    "_, _, _, _ = predict_on_test(X_train[TASK_FEATURES], Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "predicting.. 0.00% 1.69% 3.39% 5.08% 6.78% 8.47% 10.17% 11.86% 13.56% 15.25% 16.95% 18.64% 20.34% 22.03% 23.73% 25.42% 27.12% 28.81% 30.51% 32.20% 33.90% 35.59% 37.29% 38.98% 40.68% 42.37% 44.07% 45.76% 47.46% 49.15% 50.85% 52.54% 54.24% 55.93% 57.63% 59.32% 61.02% 62.71% 64.41% 66.10% 67.80% 69.49% 71.19% 72.88% 74.58% 76.27% 77.97% 79.66% 81.36% 83.05% 84.75% 86.44% 88.14% 89.83% 91.53% 93.22% 94.92% 96.61% 98.31% \n",
      "Cross-Entropy: 549.2652587890625\n",
      "Perplexity: 3.490366190935956e+238\n",
      "ROUGE-Recall: 0.03755113968439509\n",
      "ROUGE-Precision: 0.164129474579846\n",
      "Unique answers: 2\n"
     ]
    }
   ],
   "source": [
    "## Predict on Test\n",
    "_, _, _, _ = predict_on_test(X_test[TASK_FEATURES], Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {},
   "outputs": [],
   "source": [
    "# val_ce = []\n",
    "# val_rr = []\n",
    "# val_rp = []\n",
    "# for i in range(1, EPOCHS//5 + 1):\n",
    "#     checkpoint.restore('./checkpoints/ckpt-{}.index'.format(i))\n",
    "#     _, losses_ce, rouge_recalls, rouge_precisions = predict_on_test(X_test[TASK_FEATURES], Y_test)\n",
    "#     val_ce.append(losses_ce)\n",
    "#     val_rr.append(rouge_recalls)\n",
    "#     val_rp.append(rouge_precisions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred[TARGET_COLUMN].unique()"
   ]
  },
  {
   "source": [
    "---\n",
    "## To Do"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {},
   "outputs": [],
   "source": [
    "##TODO: To py and argparse"
   ]
  },
  {
   "source": [
    "### To DAGsHub"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ##TODO: Export to DAGsHub\n",
    "# experiment_params = run_params.update(model_params)\n",
    "# experiment_params = experiment_params.update(data_params)\n",
    "# print(experiment_params)\n",
    "# # experiment_results = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}