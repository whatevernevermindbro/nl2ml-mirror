{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python385jvsc74a57bd0d0ddd292140de7144a2e52e7cfaaa287bc93c7991ea231311f4a8d4f39ae4756",
   "display_name": "Python 3.8.5 64-bit ('base': conda)"
  },
  "metadata": {
   "interpreter": {
    "hash": "0de36b31320ba4c88b4f85a74724f3d16c36a44df48581253710b1065e752d9e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "###TODO: Recalculate the results\n",
    "###TODO: Check CE calculation\n",
    "###TODO: Stack more layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import gc\n",
    "from datetime import datetime\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import backend as K\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import log_loss\n",
    "from sqlalchemy import create_engine\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('mode.chained_assignment', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_params = {\"Task\": \"train\"\n",
    "            , \"Model\": \"generative task2seq\"}"
   ]
  },
  {
   "source": [
    "### Defining Methods"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_key(my_dict, val):\n",
    "    for key, value in my_dict.items():\n",
    "         if val == value:\n",
    "             return key\n",
    " \n",
    "    return \"key doesn't exist\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_task(task_vector):\n",
    "    # either convert to float32 or encode to categoricals\n",
    "    for i, el in enumerate(task_vector):\n",
    "        try:\n",
    "            task_vector[i] = float(task_vector[i])\n",
    "        except:\n",
    "            task_vector[i] = get_key(cat_encodings[i], task_vector[i])\n",
    "    return task_vector.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_by_notebooks(data:pd.DataFrame, vertex_col:str='vertex_l1') -> pd.DataFrame:\n",
    "    notebook_cols = [[notebook_id_col, vertex_col, competition_id_col] + TASK_FEATURES]\n",
    "    df = pd.DataFrame(columns=notebook_cols)\n",
    "    for i, notebook_id in enumerate(data[notebook_id_col].unique()):\n",
    "        notebook = data[data[notebook_id_col] == notebook_id].reset_index(drop=True)\n",
    "        vertices_seq = \" \".join(notebook[vertex_col])\n",
    "        task_features = notebook[TASK_FEATURES].loc[0]\n",
    "        competition_id = notebook[competition_id_col].unique()[0]\n",
    "        row = [notebook_id, vertices_seq, competition_id] + task_features.tolist()\n",
    "        df.loc[i] = row\n",
    "        print('notebook #{} done'.format(notebook_id))\n",
    "    return df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_vertices(vertices_seq): #, lang\n",
    "    # print(vertices_seq[0], type(vertices_seq[0]), vertices_seq[0].split(' '))\n",
    "    try:\n",
    "        encoded = np.append(np.flip(np.array([lang[vertex] for vertex in vertices_seq[0].split(' ')] + [lang['<end>']])), lang['<start>'])\n",
    "        # encoded = np.append(lang['<start>'], np.array([lang[vertex] for vertex in vertices_seq[0].split(' ')] + [lang['<end>']]))\n",
    "    except:\n",
    "        print(vertices_seq[0].split(' '))\n",
    "        raise Exception(\"Can't encode vertices\")\n",
    "    return encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.Model):\n",
    "  def __init__(self, vocab_size, embedding_dim, dec_units, batch_sz):\n",
    "    super(Decoder, self).__init__()\n",
    "    self.batch_sz = batch_sz\n",
    "    self.dec_units = dec_units\n",
    "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "    self.gru = tf.keras.layers.GRU(self.dec_units,\n",
    "                                   return_sequences=True,\n",
    "                                   return_state=True,\n",
    "                                   recurrent_initializer='glorot_uniform')\n",
    "    self.dropout = tf.keras.layers.Dropout(dropout_rate)\n",
    "    self.fc = tf.keras.layers.Dense(vocab_size, activation='sigmoid')\n",
    "    self.fc_vec = tf.keras.layers.Dense(dec_units, activation='sigmoid')\n",
    "\n",
    "  def call(self, x, hidden, vec_input):\n",
    "    x = self.embedding(x)\n",
    "    output, state = self.gru(x, initial_state=hidden)\n",
    "    output = tf.reshape(output, (-1, output.shape[2]))\n",
    "    output = self.dropout(output)\n",
    "    vec = self.fc_vec(vec_input)\n",
    "    concatenated = tf.keras.layers.concatenate([vec, output], axis=1)\n",
    "    x = self.fc(concatenated)\n",
    "    return x, state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_function(real, pred):\n",
    "  mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "  loss_ = loss_object(real, pred)\n",
    "\n",
    "  mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "  loss_ *= mask\n",
    "\n",
    "  return tf.reduce_mean(loss_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(inp, targ): #decoder, optimizer, loss_function, \n",
    "  loss = 0\n",
    "  with tf.GradientTape() as tape:\n",
    "    dec_hidden = tf.zeros((BATCH_SIZE, gru_units))\n",
    "    dec_input = tf.expand_dims([1] * BATCH_SIZE, 1)\n",
    "    for t in range(1, targ.shape[1]): # for each vertex (token) from solution (sequence)\n",
    "      predictions, dec_hidden = decoder(dec_input, dec_hidden, inp) #decoder\n",
    "      print('target token: {}, \\n predictions distribution: {}, \\n, old sum loss: {}'.format(targ[:, t], predictions, loss))\n",
    "      loss += loss_function(targ[:, t], predictions)\n",
    "      print('new sum loss: {}, calculated loss: {}'.format(loss, loss_function(targ[:, t], predictions)))\n",
    "      dec_input = tf.expand_dims(targ[:, t], 1)\n",
    "  batch_loss = (loss / int(targ.shape[1]))\n",
    "  variables = decoder.trainable_variables\n",
    "  gradients = tape.gradient(loss, variables)\n",
    "  optimizer.apply_gradients(zip(gradients, variables))\n",
    "  del inp, targ, gradients, variables\n",
    "  gc.collect()\n",
    "  return batch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @tf.function\n",
    "# def train_generator(STEPS_PER_EPOCH, EPOCHS, ):\n",
    "#     @tf.function\n",
    "#     def train_step(inp, targ): #decoder, optimizer, loss_function, \n",
    "#         loss = 0\n",
    "#         with tf.GradientTape() as tape:\n",
    "#             dec_hidden = tf.zeros((BATCH_SIZE, gru_units))\n",
    "#             dec_input = tf.expand_dims([1] * BATCH_SIZE, 1)\n",
    "#             for t in range(1, targ.shape[1]): # for each vertex (token) from solution (sequence)\n",
    "#             predictions, dec_hidden = decoder(dec_input, dec_hidden, inp) #decoder\n",
    "#             loss += loss_function(targ[:, t], predictions)\n",
    "#             dec_input = tf.expand_dims(targ[:, t], 1)\n",
    "\n",
    "#         batch_loss = (loss / int(targ.shape[1]))\n",
    "#         variables = decoder.trainable_variables\n",
    "#         gradients = tape.gradient(loss, variables)\n",
    "#         optimizer.apply_gradients(zip(gradients, variables))\n",
    "#         del inp, targ, gradients, variables\n",
    "#         gc.collect()\n",
    "#         return batch_loss\n",
    "#     for epoch in range(EPOCHS):\n",
    "#         gc.collect()\n",
    "#         start = time.time()\n",
    "#         total_loss = 0\n",
    "#         for (batch, (feat, targ)) in enumerate(train_dataset.take(STEPS_PER_EPOCH)):\n",
    "#             batch_loss = train_step(feat, targ)#, enc_hidden)\n",
    "#             batch_perplexity = tf.exp(batch_loss)\n",
    "#             total_loss += batch_loss\n",
    "#             if batch % 100 == 0:\n",
    "#                 print('Epoch {} Batch {} Loss {:.4f} Perplexity {:.4f}'.format(epoch + 1,\n",
    "#                                                                 batch,\n",
    "#                                                                 batch_loss.numpy(),\n",
    "#                                                                 batch_perplexity))\n",
    "#         train_losses.append(batch_loss)\n",
    "\n",
    "#         print('Validating')\n",
    "#         _, losses_ce, rouge_recalls, rouge_precisions = predict_on_test(X_test[TASK_FEATURES], Y_test)\n",
    "#         val_ce.append(losses_ce)\n",
    "#         val_rr.append(rouge_recalls)\n",
    "#         val_rp.append(rouge_precisions)\n",
    "#         if (epoch + 1) % 5 == 0:\n",
    "#             print('Saving..', end='')\n",
    "#             checkpoint.step.assign_add(5)\n",
    "#             manager.save()\n",
    "#             print('saved')\n",
    "#         print('Time taken for the epoch {} sec\\n'.format(time.time() - start))\n",
    "#     best_epoch = np.argmin(val_ce, axis=1)\n",
    "#     print('The best epoch is {} with CE = {}, RR = {}, RP = {}'.format(best_epoch, val_ce[best_epoch], val_rr[best_epoch], val_rp[best_epoch]))\n",
    "#     plt.plot(train_losses)\n",
    "#     plt.plot(np.mean(val_ce, axis=1)/10000)\n",
    "#     plt.plot(np.mean(val_rr, axis=1))\n",
    "#     plt.plot(np.mean(val_rp, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_solution(task_vector, save_outputs:bool=False):\n",
    "  attention_plot = np.zeros((max_length_targ, max_length_feat))\n",
    "  task_vector = preprocess_task(task_vector)\n",
    "  inputs = tf.expand_dims(tf.convert_to_tensor(task_vector), axis=0)\n",
    "  result = ''\n",
    "\n",
    "  dec_hidden = tf.zeros((BATCH_SIZE, gru_units))\n",
    "  dec_input = tf.expand_dims([1], 0)\n",
    "  loss = 0\n",
    "  for t in range(max_length_targ):\n",
    "    predictions, dec_hidden = decoder(dec_input\n",
    "                                      , dec_hidden\n",
    "                                      , inputs)\n",
    "    # storing the attention weights to plot later on\n",
    "    # attention_weights = tf.reshape(attention_weights, (-1, ))\n",
    "    # attention_plot[t] = attention_weights.numpy()\n",
    "    predicted_id = tf.argmax(predictions[0]).numpy()\n",
    "    predicted_vertice = get_key(lang, predicted_id)\n",
    "    if (predicted_vertice != ' ')&(predicted_vertice != ''):\n",
    "      # loss += loss_function(true_vector, predictions)\n",
    "      # print(loss)\n",
    "      result = predicted_vertice + ' ' + result #targ_lang.index_word[predicted_id] + ' '\n",
    "    elif (predicted_vertice == '<start>')&(predicted_vertice == '<end>'):\n",
    "      print('Evaluation: found start/end, ending')\n",
    "      return result, task_vector#, attention_plot\n",
    "    \n",
    "    # the predicted ID is fed back into the model\n",
    "    dec_input = tf.expand_dims([predicted_id], 0)\n",
    "  if save_outputs:\n",
    "    OUTPUT_FILE = './task2seq/outputs/output.py'\n",
    "    with open(OUTPUT_FILE, 'w') as f:\n",
    "        last_vertice = ''\n",
    "        for vertice in result.split(' '):\n",
    "            if vertice:\n",
    "                if (vertice!='<start>')&(vertice!='<end>')&(vertice!=last_vertice):\n",
    "                    line = '#@ {} \\n\\n'.format(vertice)\n",
    "                    f.write(line)\n",
    "                    last_vertice = vertice\n",
    "  return result, task_vector#, attention_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_solution_with_evaluation(task_vector, true_sequence:np.array, save_outputs:bool=False):\n",
    "    task_vector = preprocess_task(task_vector)\n",
    "    inputs = tf.expand_dims(tf.convert_to_tensor(task_vector), axis=0)\n",
    "    generated_sequence_string = ''\n",
    "    generated_sequence_array = []\n",
    "    metrics = {}\n",
    "\n",
    "    dec_hidden = tf.zeros((BATCH_SIZE, gru_units))\n",
    "    dec_input = tf.expand_dims([1], 0)\n",
    "    loss = 0\n",
    "    for t in range(max_length_targ):\n",
    "        predictions, dec_hidden = decoder(dec_input\n",
    "                                          , dec_hidden\n",
    "                                          , inputs)\n",
    "        predicted_id = tf.argmax(predictions[0]).numpy()\n",
    "        generated_sequence_array.append(predicted_id)\n",
    "\n",
    "        predicted_vertice = get_key(lang, predicted_id)\n",
    "        if (predicted_vertice != ' ')&(predicted_vertice != ''):\n",
    "            print('true sequence: {}, type[t]: {}, type: {}'.format(true_sequence[t], type(true_sequence[t]), type(true_sequence)))\n",
    "            print('predictions: {}, type: {}'.format(predictions, type(predictions)))\n",
    "            loss += loss_function(true_sequence[t], predictions)\n",
    "            generated_sequence_string = predicted_vertice + ' ' + generated_sequence_string\n",
    "        elif (predicted_vertice == '<start>')&(predicted_vertice == '<end>'):\n",
    "            print('Evaluation: found start/end, ending')\n",
    "            return generated_sequence_string, metrics\n",
    "\n",
    "        dec_input = tf.expand_dims([predicted_id], 0)\n",
    "    print('loss: {}, type: {}. len(true_sequence) == {}, shape == {}'.format(loss, type(loss), len(true_sequence), true_sequence.shape))\n",
    "    ce = loss.numpy()/len(true_sequence)\n",
    "    metrics.update({\"Cross-Entropy\":ce,\n",
    "                  \"Perplexity\":tf.exp(ce),\n",
    "                  \"ROUGE-Recall\":rouge_recall(true_sequence, generated_sequence_array),\n",
    "                  \"ROUGE-Precision\": rouge_precision(true_sequence, generated_sequence_array),\n",
    "                  \"Nunique_Tokens\": np.unique(generated_sequence_string)})\n",
    "    if save_outputs:\n",
    "        TODAY_NOW = datetime.now().strftime(\"%d-%m-%y_%H-%M-%S\")\n",
    "        save_generated_sequence(generated_sequence_string, output_path='./outputs/output_{}.py'.format(TODAY_NOW))\n",
    "    return generated_sequence_string, metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_on_test(X_test, Y_test):\n",
    "    y_pred = []\n",
    "    losses_ce = []\n",
    "    rouge_recalls = []\n",
    "    rouge_precisions = []\n",
    "    nunique_tokens = []\n",
    "    print('predicting..', end=' ')\n",
    "    for i, task_vector in X_test.reset_index(drop=True).iterrows():\n",
    "        if i % 100 == 0:\n",
    "            print('{:.1%}'.format(i/X_test.shape[0]), end=' ')\n",
    "        true_vector = Y_test[i]\n",
    "        result, metrics = generate_solution_with_evaluation(task_vector, true_vector)\n",
    "        # print(loss.numpy())\n",
    "        y_pred.append(result[:-1])\n",
    "        losses_ce.append(metrics['Cross-Entropy'])\n",
    "        rouge_recalls.append(metrics['ROUGE-Recall'])\n",
    "        rouge_precisions.append(metrics['ROUGE-Precision'])\n",
    "        nunique_tokens.append(metrics['Nunique_Tokens'])\n",
    "    print()\n",
    "    y_pred = pd.DataFrame(y_pred, columns=[TARGET_COLUMN])\n",
    "    print('Cross-Entropy: {:.4f}'.format(np.mean(losses_ce)))\n",
    "    print('Perplexity: {:.4f}'.format(np.exp(float(np.mean(losses_ce)))))\n",
    "    print('ROUGE-Recall: {:.4f}'.format(np.mean(rouge_recalls)))\n",
    "    print('ROUGE-Precision: {:.4f}'.format(np.mean(rouge_precisions)))\n",
    "    print('Avg nunique tokens: {}'.format(np.mean(nunique_tokens)))\n",
    "    print('Unique answers: {}'.format(y_pred[TARGET_COLUMN].nunique()))\n",
    "    \n",
    "    return y_pred, losses_ce, rouge_recalls, rouge_precisions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rouge_recall(true_string_vector:list, predicted_string_vector:list) -> float:\n",
    "    true_string_vector = [el for el in true_string_vector if el != 0]\n",
    "    # predicted_string_vector = [el for el in predicted_string_vector if el != 0]\n",
    "    n_overlapping_words = len(set(true_string_vector).intersection(set(predicted_string_vector)))\n",
    "    total_words_in_output = len(predicted_string_vector)\n",
    "    return n_overlapping_words / total_words_in_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rouge_precision(true_string_vector:list, predicted_string_vector:list) -> float:\n",
    "    true_string_vector = [el for el in true_string_vector if el != 0]\n",
    "    n_overlapping_words = len(set(true_string_vector).intersection(set(predicted_string_vector)))\n",
    "    total_words_in_reference = len(true_string_vector)\n",
    "    return n_overlapping_words / total_words_in_reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_generated_sequence(generated_sequence_string:str, output_path:str):\n",
    "    # OUTPUT_FILE = './task2seq/outputs/output.py'\n",
    "    with open(output_path, 'w') as f:\n",
    "        last_vertice = ''\n",
    "        for vertice in generated_sequence_string.split(' '):\n",
    "            if vertice:\n",
    "                if (vertice!='<start>')&(vertice!='<end>')&(vertice!=last_vertice):\n",
    "                    line = '#@ {} \\n\\n'.format(vertice)\n",
    "                    f.write(line)\n",
    "                    last_vertice = vertice"
   ]
  },
  {
   "source": [
    "---"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Data Preprocessing Parameters"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXPORT_DATE = '2021-05-26'\n",
    "REMOVE_RECURRINGS = True\n",
    "TEST_SIZE = test_size = 0.2"
   ]
  },
  {
   "source": [
    "### Reading Data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Index(['graph_vertex_id', 'graph_vertex', 'graph_vertex_subclass'], dtype='object')"
      ]
     },
     "metadata": {},
     "execution_count": 20
    }
   ],
   "source": [
    "graph_path = '../../data/actual_graph_{}.csv'.format(EXPORT_DATE)\n",
    "graph = pd.read_csv(graph_path)\n",
    "graph.rename({'id':'graph_vertex_id'}, axis=1, inplace=True)\n",
    "graph.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(266, 8)"
      ]
     },
     "metadata": {},
     "execution_count": 21
    }
   ],
   "source": [
    "COMPETITIONS_PATH = \"../../data/competitions_info_cleaned_filled.csv\" #./data/competitions_info_cleaned.csv\n",
    "competitions_filled = pd.read_csv(COMPETITIONS_PATH)\n",
    "competitions_filled.drop_duplicates(inplace=True)\n",
    "competitions_filled.rename({'Description': 'description', 'Metric':'metric', 'DataType':'datatype', 'Subject':'subject', 'ProblemType':'problemtype'}\n",
    "                        , axis=1, inplace=True)\n",
    "competitions_filled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "ref             0\n",
       "comp_name       0\n",
       "comp_type       0\n",
       "description    21\n",
       "metric         19\n",
       "datatype       19\n",
       "subject        19\n",
       "problemtype    19\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 22
    }
   ],
   "source": [
    "competitions_filled.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "competitions_filled['ref'] = competitions_filled['ref'].str.replace(\"'\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(5060, 10)"
      ]
     },
     "metadata": {},
     "execution_count": 24
    }
   ],
   "source": [
    "COMPETITIONS_PATH = \"../../data/competitions_{}.csv\".format(EXPORT_DATE) #./data/competitions_info_cleaned.csv\n",
    "competitions = pd.read_csv(COMPETITIONS_PATH)\n",
    "competitions.drop_duplicates(inplace=True)\n",
    "competitions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# competitions['ref'] = competitions['ref'].apply(lambda x: x.split(',')[0])\n",
    "# competitions['ref'] = competitions['ref'].str.replace(\"'\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# competitions['exists_in_comp_filled'] = competitions.apply(lambda x: x['ref'] in competitions_filled['ref'].unique(), axis=1)\n",
    "# competitions['exists_in_comp_filled'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# competitions_filled.merge(competitions[['id', 'ref']], on=['ref']).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(312, 10)"
      ]
     },
     "metadata": {},
     "execution_count": 28
    }
   ],
   "source": [
    "competitions = competitions_filled.merge(competitions[['id', 'ref_link']], how='inner', left_on=['ref'], right_on=['ref_link'])\n",
    "competitions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "ref             0\n",
       "comp_name       0\n",
       "comp_type       0\n",
       "description    26\n",
       "metric         23\n",
       "datatype       23\n",
       "subject        23\n",
       "problemtype    23\n",
       "id              0\n",
       "ref_link        0\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 29
    }
   ],
   "source": [
    "competitions.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   code_block_id                                         code_block  \\\n",
       "0         570367  `# My forecasting COVID-19 confirmed cases and...   \n",
       "1         570367  `# My forecasting COVID-19 confirmed cases and...   \n",
       "2         570368  `# load training and testing data \\nsubm = pd....   \n",
       "3         570369                                             `subm`   \n",
       "4         570367  `# My forecasting COVID-19 confirmed cases and...   \n",
       "\n",
       "  data_format  graph_vertex_id errors  marks  kaggle_id  competition_id  \n",
       "0       Table               45     No      2    8591010            3868  \n",
       "1       Table               45     No      2    8591010            3868  \n",
       "2       Table               45     No      5    8591010            3868  \n",
       "3       Table               41     No      5    8591010            3868  \n",
       "4       Table               45     No      2    8591010            3868  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>code_block_id</th>\n      <th>code_block</th>\n      <th>data_format</th>\n      <th>graph_vertex_id</th>\n      <th>errors</th>\n      <th>marks</th>\n      <th>kaggle_id</th>\n      <th>competition_id</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>570367</td>\n      <td>`# My forecasting COVID-19 confirmed cases and...</td>\n      <td>Table</td>\n      <td>45</td>\n      <td>No</td>\n      <td>2</td>\n      <td>8591010</td>\n      <td>3868</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>570367</td>\n      <td>`# My forecasting COVID-19 confirmed cases and...</td>\n      <td>Table</td>\n      <td>45</td>\n      <td>No</td>\n      <td>2</td>\n      <td>8591010</td>\n      <td>3868</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>570368</td>\n      <td>`# load training and testing data \\nsubm = pd....</td>\n      <td>Table</td>\n      <td>45</td>\n      <td>No</td>\n      <td>5</td>\n      <td>8591010</td>\n      <td>3868</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>570369</td>\n      <td>`subm`</td>\n      <td>Table</td>\n      <td>41</td>\n      <td>No</td>\n      <td>5</td>\n      <td>8591010</td>\n      <td>3868</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>570367</td>\n      <td>`# My forecasting COVID-19 confirmed cases and...</td>\n      <td>Table</td>\n      <td>45</td>\n      <td>No</td>\n      <td>2</td>\n      <td>8591010</td>\n      <td>3868</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 30
    }
   ],
   "source": [
    "# NOTEBOOKS_PATH = \"../../data/codeblocks_2021-04-01_concatenated_cleaned_linkedwithcompetitions_pred.csv\"\n",
    "NOTEBOOKS_PATH = '../../data/markup_data_{}.csv'.format(EXPORT_DATE)\n",
    "notebooks = pd.read_csv(NOTEBOOKS_PATH)\n",
    "notebooks.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(5933, 10)"
      ]
     },
     "metadata": {},
     "execution_count": 31
    }
   ],
   "source": [
    "notebooks = notebooks.merge(graph, on='graph_vertex_id', how='left')\n",
    "notebooks.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "3208\n3111\n"
     ]
    }
   ],
   "source": [
    "# nl2ml = notebooks.merge(competitions[['ref', 'id']], left_on=['ref'], right_on=['ref'], how='inner').rename({'id':'competition_id'}, axis=1)\n",
    "nl2ml = notebooks.merge(competitions, left_on=['competition_id'], right_on=['id'], how='inner')\n",
    "print(nl2ml.shape[0])\n",
    "nl2ml.drop_duplicates(inplace=True, subset=['code_block_id', 'kaggle_id'])\n",
    "print(nl2ml.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "113 7\n"
     ]
    }
   ],
   "source": [
    "print(nl2ml['kaggle_id'].nunique(), nl2ml['ref'].nunique())"
   ]
  },
  {
   "source": [
    "### Vertices Preprocessing"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Data_Transform          936\n",
       "EDA                     747\n",
       "Model_Train             287\n",
       "Visualization           281\n",
       "Environment             202\n",
       "Data_Extraction         168\n",
       "Other                   147\n",
       "Hyperparam_Tuning       120\n",
       "Data_Export             104\n",
       "Model_Evaluation         95\n",
       "Model_Interpretation     21\n",
       "Hypothesis                3\n",
       "Name: graph_vertex, dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 34
    }
   ],
   "source": [
    "nl2ml['graph_vertex'].apply(lambda x: x.split(';')[0].split('.')[0]).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "nl2ml['vertex_l1'], nl2ml['vertex_l2'] = nl2ml['graph_vertex'].apply(lambda x: x.split(';')[0].split('.')[0]), nl2ml['graph_vertex_subclass']#.apply(lambda x: x.split(';')[0].split('.')[1])"
   ]
  },
  {
   "source": [
    "### Missing Values"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "code_block_id            0\ncode_block               0\ndata_format              0\ngraph_vertex_id          0\nerrors                   0\nmarks                    0\nkaggle_id                0\ncompetition_id           0\ngraph_vertex             0\ngraph_vertex_subclass    0\nref                      0\ncomp_name                0\ncomp_type                0\ndescription              0\nmetric                   0\ndatatype                 0\nsubject                  0\nproblemtype              0\nid                       0\nref_link                 0\nvertex_l1                0\nvertex_l2                0\ndtype: int64\ncode_block_id            0\ncode_block               0\ndata_format              0\ngraph_vertex_id          0\nerrors                   0\nmarks                    0\nkaggle_id                0\ncompetition_id           0\ngraph_vertex             0\ngraph_vertex_subclass    0\nref                      0\ncomp_name                0\ncomp_type                0\ndescription              0\nmetric                   0\ndatatype                 0\nsubject                  0\nproblemtype              0\nid                       0\nref_link                 0\nvertex_l1                0\nvertex_l2                0\ndtype: int64\n"
     ]
    }
   ],
   "source": [
    "nl2ml.replace('-', -1, inplace=True)\n",
    "print(nl2ml.isna().sum())\n",
    "nl2ml.fillna(-1, inplace=True)\n",
    "print(nl2ml.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TASK_FEATURES = ['comp_name', 'comp_type', 'Description', 'Metric', 'DataType', 'Subject', 'ProblemType']\n",
    "TASK_FEATURES = ['comp_name', 'comp_type', 'description', 'metric', 'datatype', 'subject', 'problemtype']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET_COLUMN = 'vertex_l2'"
   ]
  },
  {
   "source": [
    "### Grouping chunks by notebooks"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "notebook_id_col = 'kaggle_id'\n",
    "competition_id_col = 'competition_id'"
   ]
  },
  {
   "source": [
    "### Taking Train Features"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "notebook #8591010 done\n",
      "notebook #8592598 done\n",
      "notebook #8596735 done\n",
      "notebook #8606894 done\n",
      "notebook #8609050 done\n",
      "notebook #8611767 done\n",
      "notebook #8630977 done\n",
      "notebook #8634286 done\n",
      "notebook #8640194 done\n",
      "notebook #8660923 done\n",
      "notebook #8667455 done\n",
      "notebook #8668446 done\n",
      "notebook #8678201 done\n",
      "notebook #8687334 done\n",
      "notebook #8689318 done\n",
      "notebook #8699382 done\n",
      "notebook #8705213 done\n",
      "notebook #8706858 done\n",
      "notebook #8708118 done\n",
      "notebook #8710137 done\n",
      "notebook #8710362 done\n",
      "notebook #8604602 done\n",
      "notebook #8617043 done\n",
      "notebook #8620454 done\n",
      "notebook #8625834 done\n",
      "notebook #8628909 done\n",
      "notebook #8658083 done\n",
      "notebook #8663175 done\n",
      "notebook #8671133 done\n",
      "notebook #8679319 done\n",
      "notebook #8682800 done\n",
      "notebook #8687249 done\n",
      "notebook #8693806 done\n",
      "notebook #8701862 done\n",
      "notebook #8702904 done\n",
      "notebook #8706295 done\n",
      "notebook #8711165 done\n",
      "notebook #9326374 done\n",
      "notebook #9349764 done\n",
      "notebook #9463384 done\n",
      "notebook #138832 done\n",
      "notebook #2637869 done\n",
      "notebook #5466844 done\n",
      "notebook #5729566 done\n",
      "notebook #6470191 done\n",
      "notebook #8382140 done\n",
      "notebook #9655329 done\n",
      "notebook #10424951 done\n",
      "notebook #10522332 done\n",
      "notebook #10702707 done\n",
      "notebook #10913030 done\n",
      "notebook #11097956 done\n",
      "notebook #11410370 done\n",
      "notebook #11611498 done\n",
      "notebook #11656525 done\n",
      "notebook #12034947 done\n",
      "notebook #12343159 done\n",
      "notebook #13503938 done\n",
      "notebook #14177670 done\n",
      "notebook #171635 done\n",
      "notebook #2843645 done\n",
      "notebook #2846432 done\n",
      "notebook #2874738 done\n",
      "notebook #2894439 done\n",
      "notebook #2895967 done\n",
      "notebook #2897818 done\n",
      "notebook #2942474 done\n",
      "notebook #3001116 done\n",
      "notebook #3065122 done\n",
      "notebook #3127294 done\n",
      "notebook #3155308 done\n",
      "notebook #3308267 done\n",
      "notebook #3338077 done\n",
      "notebook #3412975 done\n",
      "notebook #3424825 done\n",
      "notebook #3544896 done\n",
      "notebook #3577796 done\n",
      "notebook #3640289 done\n",
      "notebook #3663832 done\n",
      "notebook #11400829 done\n",
      "notebook #24315 done\n",
      "notebook #242408 done\n",
      "notebook #243149 done\n",
      "notebook #244547 done\n",
      "notebook #244742 done\n",
      "notebook #244890 done\n",
      "notebook #244905 done\n",
      "notebook #244962 done\n",
      "notebook #245675 done\n",
      "notebook #874590 done\n",
      "notebook #1140262 done\n",
      "notebook #2095107 done\n",
      "notebook #3237641 done\n",
      "notebook #3674829 done\n",
      "notebook #4029935 done\n",
      "notebook #6511394 done\n",
      "notebook #6511397 done\n",
      "notebook #6511403 done\n",
      "notebook #6511414 done\n",
      "notebook #6511456 done\n",
      "notebook #6511492 done\n",
      "notebook #6518412 done\n",
      "notebook #7004483 done\n",
      "notebook #7465372 done\n",
      "notebook #7859060 done\n",
      "notebook #8648443 done\n",
      "notebook #9904611 done\n",
      "notebook #11013798 done\n",
      "notebook #3389306 done\n",
      "notebook #3414311 done\n",
      "notebook #4374092 done\n",
      "notebook #10307360 done\n",
      "notebook #3344044 done\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(113, 10)"
      ]
     },
     "metadata": {},
     "execution_count": 40
    }
   ],
   "source": [
    "# nl2ml = group_by_notebooks(nl2ml, TARGET_COLUMN)\n",
    "# X, y = train[TASK_FEATURES], train[TARGET_COLUMN]\n",
    "prepared_data = group_by_notebooks(nl2ml, TARGET_COLUMN)\n",
    "prepared_data.shape"
   ]
  },
  {
   "source": [
    "### Converting Dtypes"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def strip_recurrent_vertices(row):\n",
    "    # sequence = row['vertex_l2'].split(' ')\n",
    "    # result = []\n",
    "    # if len(sequence) > 1:\n",
    "    #     last_index = len(sequence) - 1\n",
    "    #     i = 0\n",
    "    #     while i < last_index:\n",
    "    #         # print(sequence[i], sequence[i+1])\n",
    "    #         if sequence[i].strip(' ') != sequence[i+1].strip(' '):\n",
    "    #             # print('not equal')\n",
    "    #             result.append(sequence[i])\n",
    "    #         else:\n",
    "    #             print('equal', sequence[i], sequence[i+1])\n",
    "    #         i =+ 1\n",
    "    # return \" \".join(result)\n",
    "    result = row['vertex_l2'].split(' ')[0] + \" \" + \" \".join([row['vertex_l2'].split(' ')[i] for i in range(1, len(row['vertex_l2'].split(' '))) if (row['vertex_l2'].split(' ')[i-1] != row['vertex_l2'].split(' ')[i])&(row['vertex_l2'].split(' ')[i] != ' ')&(row['vertex_l2'].split(' ')[i] != '')])\n",
    "    if result.split(' ')[1] == ' ':\n",
    "        result.pop(1)\n",
    "        return result\n",
    "    else:\n",
    "        return \" \".join(row['vertex_l2'].split(' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "removing\n"
     ]
    }
   ],
   "source": [
    "if REMOVE_RECURRINGS:\n",
    "    print('removing')\n",
    "    prepared_data[TARGET_COLUMN] = prepared_data[TARGET_COLUMN].apply(strip_recurrent_vertices, axis=1)\n",
    "# prepared_data[TARGET_COLUMN] = prepared_data[TARGET_COLUMN].apply(lambda x: x.replace(' ', ''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Encoding columns: \nkaggle_id\ncompetition_id\ncomp_name\ncomp_type\ndescription\nmetric\ndatatype\nsubject\nproblemtype\n"
     ]
    }
   ],
   "source": [
    "cat_encodings = {}\n",
    "print('Encoding columns: ')\n",
    "for i, col in enumerate(prepared_data):\n",
    "    if col[0] != TARGET_COLUMN:\n",
    "        print(col[0])\n",
    "        try:\n",
    "            prepared_data[col] =  prepared_data[col].astype('float32')\n",
    "        except:\n",
    "            prepared_data[col] = pd.Categorical(prepared_data[col])\n",
    "            cat_encodings.update({i:dict(enumerate(prepared_data[col].cat.categories))})\n",
    "            prepared_data[col] = prepared_data[col].cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "((73, 7), (40, 7))"
      ]
     },
     "metadata": {},
     "execution_count": 44
    }
   ],
   "source": [
    "competitions = prepared_data[competition_id_col].iloc[:, 0].unique()\n",
    "n_test_competitions = round(test_size * len(competitions))\n",
    "# n_val_competitions = test_size // 2\n",
    "test_competitions, train_competitions = competitions[:n_test_competitions], competitions[n_test_competitions:]\n",
    "# test_competitions, val_competitions = test_competitions[:n_val_competitions], test_competitions[n_val_competitions:]\n",
    "train = prepared_data[prepared_data['competition_id'].iloc[:, 0].isin(train_competitions)]\n",
    "test = prepared_data[prepared_data['competition_id'].iloc[:, 0].isin(test_competitions)]\n",
    "# val = prepared_data[prepared_data['competition_id'].iloc[:, 0].isin(val_competitions)]\n",
    "X_train, y_train = train[TASK_FEATURES], train[TARGET_COLUMN]\n",
    "X_test, y_test = test[TASK_FEATURES], test[TARGET_COLUMN]\n",
    "# X_val, y_val = val[TASK_FEATURES], val[TARGET_COLUMN]\n",
    "X_train.shape, X_test.shape\n",
    "# X_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train, X_test, y_train, y_test = train_test_split(prepared_data[TASK_FEATURES], prepared_data[TARGET_COLUMN]\n",
    "#                                                     , test_size=0.25, shuffle=True, random_state=123)\n",
    "# X_train.shape, X_test.shape"
   ]
  },
  {
   "source": [
    "### Target Preprocessing: Encoding Vertices"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "lang = {vertice:i+2 for i, vertice in enumerate(nl2ml[TARGET_COLUMN].unique())} #TODO: save the dict as a local file\n",
    "lang.update({'<start>':1, '<end>':max(lang.values())+1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_train.apply(encode_vertices, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X[TARGET_COLUMN] = y.apply(encode_vertices, axis=1)\n",
    "# X.to_csv('../data/nl2ml_train_example.csv', index=False)"
   ]
  },
  {
   "source": [
    "### Target Preprocessing: Padding Sequences"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(116, 7)"
      ]
     },
     "metadata": {},
     "execution_count": 49
    }
   ],
   "source": [
    "max_length_targ, max_length_feat = prepared_data[TARGET_COLUMN].squeeze().str.split(' ').str.len().max() + 2, X_train.values.shape[1]\n",
    "max_length_targ, max_length_feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train = tf.keras.preprocessing.sequence.pad_sequences(y_train.apply(encode_vertices, axis=1), maxlen=max_length_targ)\n",
    "Y_test = tf.keras.preprocessing.sequence.pad_sequences(y_test.apply(encode_vertices, axis=1), maxlen=max_length_targ)"
   ]
  },
  {
   "source": [
    "### Model Parameters"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features = len(TASK_FEATURES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_params = {\"nrows\": X_train.shape[0]\n",
    "                , \"nfeatures\": n_features\n",
    "                , \"EXPORT_DATE\": EXPORT_DATE\n",
    "                , \"REMOVE_RECURRINGS\": REMOVE_RECURRINGS\n",
    "                , \"TEST_SIZE\": TEST_SIZE}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Configuration 1\n",
    "# LR = 0.001  \n",
    "# EPOCHS = 200\n",
    "# gru_units = 512\n",
    "# embedding_dim = 256\n",
    "# dropout_rate = 0.2\n",
    "# BATCH_SIZE = 1\n",
    "# STEPS_PER_EPOCH = len(X_train)//BATCH_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Configuration 2\n",
    "# LR = 0.002\n",
    "# EPOCHS = 100\n",
    "# gru_units = 256\n",
    "# embedding_dim = 128\n",
    "# dropout_rate = 0.0\n",
    "# BATCH_SIZE = 1\n",
    "# STEPS_PER_EPOCH = len(X_train)//BATCH_SIZE\n",
    "# # BUFFER_SIZE = len(input_tensor_train)\n",
    "# # vocab_inp_size = len(inp_lang.word_index) + 1\n",
    "# # vocab_tar_size = len(targ_lang.word_index) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Configuration 3\n",
    "LR = 0.002\n",
    "EPOCHS = 100\n",
    "gru_units = 128\n",
    "embedding_dim = 64\n",
    "dropout_rate = 0.0\n",
    "BATCH_SIZE = 1\n",
    "STEPS_PER_EPOCH = len(X_train)//BATCH_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_params = {\"BATCH_SIZE\":BATCH_SIZE\n",
    "                , \"LR\":LR\n",
    "                , \"STEPS_PER_EPOCH\": STEPS_PER_EPOCH\n",
    "                , \"embedding_dim\": embedding_dim\n",
    "                , \"gru_units\": gru_units\n",
    "                , \"dropout_rate\": dropout_rate}"
   ]
  },
  {
   "source": [
    "### Creating tf.Dataset"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = tf.data.Dataset.from_tensor_slices((X_train.values, Y_train))\n",
    "train_dataset = train_dataset.batch(BATCH_SIZE, drop_remainder=True) "
   ]
  },
  {
   "source": [
    "### Building the Model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Decoder output shape: (batch_size, vocab size`) (1, 72)\nModel: \"decoder\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nembedding (Embedding)        multiple                  4608      \n_________________________________________________________________\ngru (GRU)                    multiple                  74496     \n_________________________________________________________________\ndropout (Dropout)            multiple                  0         \n_________________________________________________________________\ndense (Dense)                multiple                  18504     \n_________________________________________________________________\ndense_1 (Dense)              multiple                  1024      \n=================================================================\nTotal params: 98,632\nTrainable params: 98,632\nNon-trainable params: 0\n_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "decoder = Decoder(len(lang)+2, embedding_dim, gru_units, BATCH_SIZE)\n",
    "sample_hidden = tf.zeros((BATCH_SIZE, gru_units))\n",
    "vec_input = np.ones((1, n_features))\n",
    "sample_decoder_output, state = decoder(tf.random.uniform((BATCH_SIZE, 1))\n",
    "                                          , sample_hidden\n",
    "                                          , vec_input\n",
    "                                          )\n",
    "print ('Decoder output shape: (batch_size, vocab size`) {}'.format(sample_decoder_output.shape))\n",
    "decoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(LR)\n",
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False, reduction='none') ##True"
   ]
  },
  {
   "source": [
    "### Model Training or Loading Pre-Trained"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_dir = './checkpoints/'\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
    "checkpoint = tf.train.Checkpoint(step=tf.Variable(1)\n",
    "                                , optimizer=optimizer\n",
    "                                 , decoder=decoder)\n",
    "manager = tf.train.CheckpointManager(checkpoint, checkpoint_dir, max_to_keep=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if manager.latest_checkpoint:\n",
    "#     print(\"Restored from {}\".format(manager.latest_checkpoint))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# decoder.compile(\n",
    "#     optimizer=optimizer,\n",
    "#     loss=loss_object\n",
    "# )\n",
    "# tf.saved_model.save(decoder, './checkpoints/model1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses = []\n",
    "val_ce = []\n",
    "val_rr = []\n",
    "val_rp = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'train_dataset' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-63-40db0a74c6e6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mtotal_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mtotal_batch_perplexity\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mfeat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mSTEPS_PER_EPOCH\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m         \u001b[0mbatch_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;31m#, enc_hidden)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[0mbatch_perplexity\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_loss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train_dataset' is not defined"
     ]
    }
   ],
   "source": [
    "for epoch in range(EPOCHS):\n",
    "    gc.collect()\n",
    "    start = time.time()\n",
    "    # enc_hidden = encoder.initialize_hidden_state()\n",
    "    total_loss = 0\n",
    "    total_batch_perplexity = 0\n",
    "    for (batch, (feat, targ)) in enumerate(train_dataset.take(STEPS_PER_EPOCH)):\n",
    "        batch_loss = train_step(feat, targ)#, enc_hidden)\n",
    "        batch_perplexity = tf.exp(batch_loss)\n",
    "\n",
    "        total_loss += batch_loss\n",
    "        total_batch_perplexity += batch_perplexity\n",
    "        if batch % 100 == 0:\n",
    "            print('Epoch {} Batch {} Loss {:.4f}'.format(epoch + 1,\n",
    "                                                            batch,\n",
    "                                                            batch_loss.numpy()), end=' ')\n",
    "            print('Perplexity {:.4f}'.format(batch_perplexity))\n",
    "    train_losses.append(batch_loss)\n",
    "    print('Validating')\n",
    "    _, losses_ce, rouge_recalls, rouge_precisions = predict_on_test(X_test[TASK_FEATURES], Y_test)\n",
    "    val_ce.append(losses_ce)\n",
    "    val_rr.append(rouge_recalls)\n",
    "    val_rp.append(rouge_precisions)\n",
    "    if (epoch + 1) % 5 == 0:\n",
    "        print('Saving..', end='')\n",
    "        checkpoint.step.assign_add(5)\n",
    "        manager.save()\n",
    "        print('saved')\n",
    "    print('Time taken for the epoch {} sec\\n'.format(time.time() - start))\n",
    "best_epoch = np.argmin(np.mean(val_ce, axis=1)) + 1\n",
    "print('The best epoch is {} with CE = {:.4f}, RR = {:.4f}, RP = {:.4f}'.format(best_epoch, np.mean(val_ce[best_epoch]), np.mean(val_rr[best_epoch]), np.mean(val_rp[best_epoch])))\n",
    "plt.plot(train_losses)\n",
    "plt.plot(np.mean(val_ce, axis=1))\n",
    "plt.plot(np.mean(val_rr, axis=1))\n",
    "plt.plot(np.mean(val_rp, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2a6582c3730>]"
      ]
     },
     "metadata": {},
     "execution_count": 64
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\r\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\r\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\r\n<!-- Created with matplotlib (https://matplotlib.org/) -->\r\n<svg height=\"248.518125pt\" version=\"1.1\" viewBox=\"0 0 372.103125 248.518125\" width=\"372.103125pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\r\n <metadata>\r\n  <rdf:RDF xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\r\n   <cc:Work>\r\n    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\r\n    <dc:date>2021-06-10T15:37:54.665595</dc:date>\r\n    <dc:format>image/svg+xml</dc:format>\r\n    <dc:creator>\r\n     <cc:Agent>\r\n      <dc:title>Matplotlib v3.3.2, https://matplotlib.org/</dc:title>\r\n     </cc:Agent>\r\n    </dc:creator>\r\n   </cc:Work>\r\n  </rdf:RDF>\r\n </metadata>\r\n <defs>\r\n  <style type=\"text/css\">*{stroke-linecap:butt;stroke-linejoin:round;}</style>\r\n </defs>\r\n <g id=\"figure_1\">\r\n  <g id=\"patch_1\">\r\n   <path d=\"M 0 248.518125 \r\nL 372.103125 248.518125 \r\nL 372.103125 0 \r\nL 0 0 \r\nz\r\n\" style=\"fill:none;\"/>\r\n  </g>\r\n  <g id=\"axes_1\">\r\n   <g id=\"patch_2\">\r\n    <path d=\"M 30.103125 224.64 \r\nL 364.903125 224.64 \r\nL 364.903125 7.2 \r\nL 30.103125 7.2 \r\nz\r\n\" style=\"fill:#ffffff;\"/>\r\n   </g>\r\n   <g id=\"matplotlib.axis_1\">\r\n    <g id=\"xtick_1\">\r\n     <g id=\"line2d_1\">\r\n      <defs>\r\n       <path d=\"M 0 0 \r\nL 0 3.5 \r\n\" id=\"me07f3d39ad\" style=\"stroke:#000000;stroke-width:0.8;\"/>\r\n      </defs>\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"45.321307\" xlink:href=\"#me07f3d39ad\" y=\"224.64\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_1\">\r\n      <!-- 0 -->\r\n      <g transform=\"translate(42.140057 239.238437)scale(0.1 -0.1)\">\r\n       <defs>\r\n        <path d=\"M 31.78125 66.40625 \r\nQ 24.171875 66.40625 20.328125 58.90625 \r\nQ 16.5 51.421875 16.5 36.375 \r\nQ 16.5 21.390625 20.328125 13.890625 \r\nQ 24.171875 6.390625 31.78125 6.390625 \r\nQ 39.453125 6.390625 43.28125 13.890625 \r\nQ 47.125 21.390625 47.125 36.375 \r\nQ 47.125 51.421875 43.28125 58.90625 \r\nQ 39.453125 66.40625 31.78125 66.40625 \r\nz\r\nM 31.78125 74.21875 \r\nQ 44.046875 74.21875 50.515625 64.515625 \r\nQ 56.984375 54.828125 56.984375 36.375 \r\nQ 56.984375 17.96875 50.515625 8.265625 \r\nQ 44.046875 -1.421875 31.78125 -1.421875 \r\nQ 19.53125 -1.421875 13.0625 8.265625 \r\nQ 6.59375 17.96875 6.59375 36.375 \r\nQ 6.59375 54.828125 13.0625 64.515625 \r\nQ 19.53125 74.21875 31.78125 74.21875 \r\nz\r\n\" id=\"DejaVuSans-48\"/>\r\n       </defs>\r\n       <use xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_2\">\r\n     <g id=\"line2d_2\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"106.80891\" xlink:href=\"#me07f3d39ad\" y=\"224.64\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_2\">\r\n      <!-- 20 -->\r\n      <g transform=\"translate(100.44641 239.238437)scale(0.1 -0.1)\">\r\n       <defs>\r\n        <path d=\"M 19.1875 8.296875 \r\nL 53.609375 8.296875 \r\nL 53.609375 0 \r\nL 7.328125 0 \r\nL 7.328125 8.296875 \r\nQ 12.9375 14.109375 22.625 23.890625 \r\nQ 32.328125 33.6875 34.8125 36.53125 \r\nQ 39.546875 41.84375 41.421875 45.53125 \r\nQ 43.3125 49.21875 43.3125 52.78125 \r\nQ 43.3125 58.59375 39.234375 62.25 \r\nQ 35.15625 65.921875 28.609375 65.921875 \r\nQ 23.96875 65.921875 18.8125 64.3125 \r\nQ 13.671875 62.703125 7.8125 59.421875 \r\nL 7.8125 69.390625 \r\nQ 13.765625 71.78125 18.9375 73 \r\nQ 24.125 74.21875 28.421875 74.21875 \r\nQ 39.75 74.21875 46.484375 68.546875 \r\nQ 53.21875 62.890625 53.21875 53.421875 \r\nQ 53.21875 48.921875 51.53125 44.890625 \r\nQ 49.859375 40.875 45.40625 35.40625 \r\nQ 44.1875 33.984375 37.640625 27.21875 \r\nQ 31.109375 20.453125 19.1875 8.296875 \r\nz\r\n\" id=\"DejaVuSans-50\"/>\r\n       </defs>\r\n       <use xlink:href=\"#DejaVuSans-50\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_3\">\r\n     <g id=\"line2d_3\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"168.296513\" xlink:href=\"#me07f3d39ad\" y=\"224.64\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_3\">\r\n      <!-- 40 -->\r\n      <g transform=\"translate(161.934013 239.238437)scale(0.1 -0.1)\">\r\n       <defs>\r\n        <path d=\"M 37.796875 64.3125 \r\nL 12.890625 25.390625 \r\nL 37.796875 25.390625 \r\nz\r\nM 35.203125 72.90625 \r\nL 47.609375 72.90625 \r\nL 47.609375 25.390625 \r\nL 58.015625 25.390625 \r\nL 58.015625 17.1875 \r\nL 47.609375 17.1875 \r\nL 47.609375 0 \r\nL 37.796875 0 \r\nL 37.796875 17.1875 \r\nL 4.890625 17.1875 \r\nL 4.890625 26.703125 \r\nz\r\n\" id=\"DejaVuSans-52\"/>\r\n       </defs>\r\n       <use xlink:href=\"#DejaVuSans-52\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_4\">\r\n     <g id=\"line2d_4\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"229.784117\" xlink:href=\"#me07f3d39ad\" y=\"224.64\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_4\">\r\n      <!-- 60 -->\r\n      <g transform=\"translate(223.421617 239.238437)scale(0.1 -0.1)\">\r\n       <defs>\r\n        <path d=\"M 33.015625 40.375 \r\nQ 26.375 40.375 22.484375 35.828125 \r\nQ 18.609375 31.296875 18.609375 23.390625 \r\nQ 18.609375 15.53125 22.484375 10.953125 \r\nQ 26.375 6.390625 33.015625 6.390625 \r\nQ 39.65625 6.390625 43.53125 10.953125 \r\nQ 47.40625 15.53125 47.40625 23.390625 \r\nQ 47.40625 31.296875 43.53125 35.828125 \r\nQ 39.65625 40.375 33.015625 40.375 \r\nz\r\nM 52.59375 71.296875 \r\nL 52.59375 62.3125 \r\nQ 48.875 64.0625 45.09375 64.984375 \r\nQ 41.3125 65.921875 37.59375 65.921875 \r\nQ 27.828125 65.921875 22.671875 59.328125 \r\nQ 17.53125 52.734375 16.796875 39.40625 \r\nQ 19.671875 43.65625 24.015625 45.921875 \r\nQ 28.375 48.1875 33.59375 48.1875 \r\nQ 44.578125 48.1875 50.953125 41.515625 \r\nQ 57.328125 34.859375 57.328125 23.390625 \r\nQ 57.328125 12.15625 50.6875 5.359375 \r\nQ 44.046875 -1.421875 33.015625 -1.421875 \r\nQ 20.359375 -1.421875 13.671875 8.265625 \r\nQ 6.984375 17.96875 6.984375 36.375 \r\nQ 6.984375 53.65625 15.1875 63.9375 \r\nQ 23.390625 74.21875 37.203125 74.21875 \r\nQ 40.921875 74.21875 44.703125 73.484375 \r\nQ 48.484375 72.75 52.59375 71.296875 \r\nz\r\n\" id=\"DejaVuSans-54\"/>\r\n       </defs>\r\n       <use xlink:href=\"#DejaVuSans-54\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_5\">\r\n     <g id=\"line2d_5\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"291.27172\" xlink:href=\"#me07f3d39ad\" y=\"224.64\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_5\">\r\n      <!-- 80 -->\r\n      <g transform=\"translate(284.90922 239.238437)scale(0.1 -0.1)\">\r\n       <defs>\r\n        <path d=\"M 31.78125 34.625 \r\nQ 24.75 34.625 20.71875 30.859375 \r\nQ 16.703125 27.09375 16.703125 20.515625 \r\nQ 16.703125 13.921875 20.71875 10.15625 \r\nQ 24.75 6.390625 31.78125 6.390625 \r\nQ 38.8125 6.390625 42.859375 10.171875 \r\nQ 46.921875 13.96875 46.921875 20.515625 \r\nQ 46.921875 27.09375 42.890625 30.859375 \r\nQ 38.875 34.625 31.78125 34.625 \r\nz\r\nM 21.921875 38.8125 \r\nQ 15.578125 40.375 12.03125 44.71875 \r\nQ 8.5 49.078125 8.5 55.328125 \r\nQ 8.5 64.0625 14.71875 69.140625 \r\nQ 20.953125 74.21875 31.78125 74.21875 \r\nQ 42.671875 74.21875 48.875 69.140625 \r\nQ 55.078125 64.0625 55.078125 55.328125 \r\nQ 55.078125 49.078125 51.53125 44.71875 \r\nQ 48 40.375 41.703125 38.8125 \r\nQ 48.828125 37.15625 52.796875 32.3125 \r\nQ 56.78125 27.484375 56.78125 20.515625 \r\nQ 56.78125 9.90625 50.3125 4.234375 \r\nQ 43.84375 -1.421875 31.78125 -1.421875 \r\nQ 19.734375 -1.421875 13.25 4.234375 \r\nQ 6.78125 9.90625 6.78125 20.515625 \r\nQ 6.78125 27.484375 10.78125 32.3125 \r\nQ 14.796875 37.15625 21.921875 38.8125 \r\nz\r\nM 18.3125 54.390625 \r\nQ 18.3125 48.734375 21.84375 45.5625 \r\nQ 25.390625 42.390625 31.78125 42.390625 \r\nQ 38.140625 42.390625 41.71875 45.5625 \r\nQ 45.3125 48.734375 45.3125 54.390625 \r\nQ 45.3125 60.0625 41.71875 63.234375 \r\nQ 38.140625 66.40625 31.78125 66.40625 \r\nQ 25.390625 66.40625 21.84375 63.234375 \r\nQ 18.3125 60.0625 18.3125 54.390625 \r\nz\r\n\" id=\"DejaVuSans-56\"/>\r\n       </defs>\r\n       <use xlink:href=\"#DejaVuSans-56\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_6\">\r\n     <g id=\"line2d_6\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"352.759323\" xlink:href=\"#me07f3d39ad\" y=\"224.64\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_6\">\r\n      <!-- 100 -->\r\n      <g transform=\"translate(343.215573 239.238437)scale(0.1 -0.1)\">\r\n       <defs>\r\n        <path d=\"M 12.40625 8.296875 \r\nL 28.515625 8.296875 \r\nL 28.515625 63.921875 \r\nL 10.984375 60.40625 \r\nL 10.984375 69.390625 \r\nL 28.421875 72.90625 \r\nL 38.28125 72.90625 \r\nL 38.28125 8.296875 \r\nL 54.390625 8.296875 \r\nL 54.390625 0 \r\nL 12.40625 0 \r\nz\r\n\" id=\"DejaVuSans-49\"/>\r\n       </defs>\r\n       <use xlink:href=\"#DejaVuSans-49\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n   </g>\r\n   <g id=\"matplotlib.axis_2\">\r\n    <g id=\"ytick_1\">\r\n     <g id=\"line2d_7\">\r\n      <defs>\r\n       <path d=\"M 0 0 \r\nL -3.5 0 \r\n\" id=\"m1a881c0538\" style=\"stroke:#000000;stroke-width:0.8;\"/>\r\n      </defs>\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"30.103125\" xlink:href=\"#m1a881c0538\" y=\"214.840141\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_7\">\r\n      <!-- 0.0 -->\r\n      <g transform=\"translate(7.2 218.639359)scale(0.1 -0.1)\">\r\n       <defs>\r\n        <path d=\"M 10.6875 12.40625 \r\nL 21 12.40625 \r\nL 21 0 \r\nL 10.6875 0 \r\nz\r\n\" id=\"DejaVuSans-46\"/>\r\n       </defs>\r\n       <use xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\r\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_2\">\r\n     <g id=\"line2d_8\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"30.103125\" xlink:href=\"#m1a881c0538\" y=\"183.3698\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_8\">\r\n      <!-- 0.5 -->\r\n      <g transform=\"translate(7.2 187.169018)scale(0.1 -0.1)\">\r\n       <defs>\r\n        <path d=\"M 10.796875 72.90625 \r\nL 49.515625 72.90625 \r\nL 49.515625 64.59375 \r\nL 19.828125 64.59375 \r\nL 19.828125 46.734375 \r\nQ 21.96875 47.46875 24.109375 47.828125 \r\nQ 26.265625 48.1875 28.421875 48.1875 \r\nQ 40.625 48.1875 47.75 41.5 \r\nQ 54.890625 34.8125 54.890625 23.390625 \r\nQ 54.890625 11.625 47.5625 5.09375 \r\nQ 40.234375 -1.421875 26.90625 -1.421875 \r\nQ 22.3125 -1.421875 17.546875 -0.640625 \r\nQ 12.796875 0.140625 7.71875 1.703125 \r\nL 7.71875 11.625 \r\nQ 12.109375 9.234375 16.796875 8.0625 \r\nQ 21.484375 6.890625 26.703125 6.890625 \r\nQ 35.15625 6.890625 40.078125 11.328125 \r\nQ 45.015625 15.765625 45.015625 23.390625 \r\nQ 45.015625 31 40.078125 35.4375 \r\nQ 35.15625 39.890625 26.703125 39.890625 \r\nQ 22.75 39.890625 18.8125 39.015625 \r\nQ 14.890625 38.140625 10.796875 36.28125 \r\nz\r\n\" id=\"DejaVuSans-53\"/>\r\n       </defs>\r\n       <use xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\r\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-53\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_3\">\r\n     <g id=\"line2d_9\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"30.103125\" xlink:href=\"#m1a881c0538\" y=\"151.899459\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_9\">\r\n      <!-- 1.0 -->\r\n      <g transform=\"translate(7.2 155.698677)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-49\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\r\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_4\">\r\n     <g id=\"line2d_10\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"30.103125\" xlink:href=\"#m1a881c0538\" y=\"120.429118\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_10\">\r\n      <!-- 1.5 -->\r\n      <g transform=\"translate(7.2 124.228336)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-49\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\r\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-53\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_5\">\r\n     <g id=\"line2d_11\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"30.103125\" xlink:href=\"#m1a881c0538\" y=\"88.958776\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_11\">\r\n      <!-- 2.0 -->\r\n      <g transform=\"translate(7.2 92.757995)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-50\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\r\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_6\">\r\n     <g id=\"line2d_12\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"30.103125\" xlink:href=\"#m1a881c0538\" y=\"57.488435\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_12\">\r\n      <!-- 2.5 -->\r\n      <g transform=\"translate(7.2 61.287654)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-50\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\r\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-53\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_7\">\r\n     <g id=\"line2d_13\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"30.103125\" xlink:href=\"#m1a881c0538\" y=\"26.018094\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_13\">\r\n      <!-- 3.0 -->\r\n      <g transform=\"translate(7.2 29.817313)scale(0.1 -0.1)\">\r\n       <defs>\r\n        <path d=\"M 40.578125 39.3125 \r\nQ 47.65625 37.796875 51.625 33 \r\nQ 55.609375 28.21875 55.609375 21.1875 \r\nQ 55.609375 10.40625 48.1875 4.484375 \r\nQ 40.765625 -1.421875 27.09375 -1.421875 \r\nQ 22.515625 -1.421875 17.65625 -0.515625 \r\nQ 12.796875 0.390625 7.625 2.203125 \r\nL 7.625 11.71875 \r\nQ 11.71875 9.328125 16.59375 8.109375 \r\nQ 21.484375 6.890625 26.8125 6.890625 \r\nQ 36.078125 6.890625 40.9375 10.546875 \r\nQ 45.796875 14.203125 45.796875 21.1875 \r\nQ 45.796875 27.640625 41.28125 31.265625 \r\nQ 36.765625 34.90625 28.71875 34.90625 \r\nL 20.21875 34.90625 \r\nL 20.21875 43.015625 \r\nL 29.109375 43.015625 \r\nQ 36.375 43.015625 40.234375 45.921875 \r\nQ 44.09375 48.828125 44.09375 54.296875 \r\nQ 44.09375 59.90625 40.109375 62.90625 \r\nQ 36.140625 65.921875 28.71875 65.921875 \r\nQ 24.65625 65.921875 20.015625 65.03125 \r\nQ 15.375 64.15625 9.8125 62.3125 \r\nL 9.8125 71.09375 \r\nQ 15.4375 72.65625 20.34375 73.4375 \r\nQ 25.25 74.21875 29.59375 74.21875 \r\nQ 40.828125 74.21875 47.359375 69.109375 \r\nQ 53.90625 64.015625 53.90625 55.328125 \r\nQ 53.90625 49.265625 50.4375 45.09375 \r\nQ 46.96875 40.921875 40.578125 39.3125 \r\nz\r\n\" id=\"DejaVuSans-51\"/>\r\n       </defs>\r\n       <use xlink:href=\"#DejaVuSans-51\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\r\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n   </g>\r\n   <g id=\"line2d_14\">\r\n    <path clip-path=\"url(#pebc996a9a9)\" d=\"M 45.321307 203.520913 \r\nL 48.395687 203.834525 \r\nL 51.470067 205.432943 \r\nL 54.544447 205.495239 \r\nL 57.618827 205.150493 \r\nL 60.693208 205.172618 \r\nL 63.767588 205.462629 \r\nL 66.841968 205.646831 \r\nL 69.916348 205.912437 \r\nL 72.990728 206.254288 \r\nL 76.065108 207.879236 \r\nL 79.139489 207.06651 \r\nL 82.213869 208.701496 \r\nL 85.288249 209.944298 \r\nL 88.362629 210.519807 \r\nL 91.437009 210.971276 \r\nL 94.511389 211.305216 \r\nL 97.58577 211.721972 \r\nL 100.66015 212.260355 \r\nL 103.73453 212.560368 \r\nL 106.80891 212.380564 \r\nL 109.88329 212.767046 \r\nL 112.95767 212.779721 \r\nL 116.032051 212.815723 \r\nL 119.106431 212.916431 \r\nL 122.180811 212.93004 \r\nL 125.255191 213.162321 \r\nL 128.329571 213.153071 \r\nL 131.403951 213.239994 \r\nL 134.478332 213.215163 \r\nL 137.552712 213.207549 \r\nL 140.627092 213.372203 \r\nL 143.701472 213.289062 \r\nL 146.775852 213.283891 \r\nL 149.850232 213.357815 \r\nL 152.924613 213.405753 \r\nL 155.998993 213.402324 \r\nL 159.073373 213.497693 \r\nL 162.147753 213.270499 \r\nL 165.222133 213.460971 \r\nL 168.296513 213.392926 \r\nL 171.370894 213.456125 \r\nL 174.445274 213.498394 \r\nL 177.519654 213.450484 \r\nL 180.594034 213.52094 \r\nL 183.668414 213.415593 \r\nL 186.742794 213.719615 \r\nL 189.817175 213.796758 \r\nL 192.891555 213.871803 \r\nL 195.965935 213.811175 \r\nL 199.040315 213.719933 \r\nL 202.114695 214.112403 \r\nL 205.189075 213.646952 \r\nL 208.263456 214.059116 \r\nL 211.337836 213.969836 \r\nL 214.412216 214.095584 \r\nL 217.486596 213.373086 \r\nL 220.560976 212.933889 \r\nL 223.635356 211.209699 \r\nL 226.709737 211.626873 \r\nL 229.784117 213.179876 \r\nL 232.858497 213.640687 \r\nL 235.932877 214.0125 \r\nL 239.007257 213.972312 \r\nL 242.081637 214.085982 \r\nL 245.156018 214.02984 \r\nL 248.230398 214.218826 \r\nL 251.304778 214.269702 \r\nL 254.379158 214.284668 \r\nL 257.453538 214.393759 \r\nL 260.527918 214.396192 \r\nL 263.602299 214.508314 \r\nL 266.676679 214.382046 \r\nL 269.751059 214.50766 \r\nL 272.825439 214.5877 \r\nL 275.899819 214.434317 \r\nL 278.974199 214.494768 \r\nL 282.04858 214.552495 \r\nL 285.12296 214.555591 \r\nL 288.19734 214.567144 \r\nL 291.27172 214.593287 \r\nL 294.3461 214.593129 \r\nL 297.42048 214.585502 \r\nL 300.494861 214.669181 \r\nL 303.569241 214.653092 \r\nL 306.643621 214.577671 \r\nL 309.718001 214.675606 \r\nL 312.792381 214.643888 \r\nL 315.866761 214.701217 \r\nL 318.941142 214.700516 \r\nL 322.015522 214.685209 \r\nL 325.089902 214.702226 \r\nL 328.164282 214.656511 \r\nL 331.238662 214.611207 \r\nL 334.313042 214.464658 \r\nL 337.387423 214.64711 \r\nL 340.461803 214.693161 \r\nL 343.536183 214.756364 \r\nL 346.610563 214.374963 \r\nL 349.684943 214.692999 \r\n\" style=\"fill:none;stroke:#1f77b4;stroke-linecap:square;stroke-width:1.5;\"/>\r\n   </g>\r\n   <g id=\"line2d_15\">\r\n    <path clip-path=\"url(#pebc996a9a9)\" d=\"M 45.321307 141.035386 \r\nL 48.395687 137.55339 \r\nL 51.470067 134.966292 \r\nL 54.544447 127.145941 \r\nL 57.618827 124.680341 \r\nL 60.693208 127.989858 \r\nL 63.767588 104.529389 \r\nL 66.841968 119.344938 \r\nL 69.916348 99.603927 \r\nL 72.990728 113.308147 \r\nL 76.065108 101.488465 \r\nL 79.139489 102.294258 \r\nL 82.213869 94.140216 \r\nL 85.288249 100.776518 \r\nL 88.362629 79.571217 \r\nL 91.437009 74.999636 \r\nL 94.511389 74.493752 \r\nL 97.58577 89.665352 \r\nL 100.66015 86.908537 \r\nL 103.73453 87.698917 \r\nL 106.80891 73.47763 \r\nL 109.88329 89.645825 \r\nL 112.95767 88.610278 \r\nL 116.032051 83.759221 \r\nL 119.106431 86.493662 \r\nL 122.180811 68.833861 \r\nL 125.255191 82.762451 \r\nL 128.329571 87.55136 \r\nL 131.403951 92.703508 \r\nL 134.478332 70.496352 \r\nL 137.552712 71.805573 \r\nL 140.627092 61.978198 \r\nL 143.701472 65.152788 \r\nL 146.775852 51.482902 \r\nL 149.850232 72.589653 \r\nL 152.924613 74.314772 \r\nL 155.998993 69.392904 \r\nL 159.073373 67.82156 \r\nL 162.147753 81.974117 \r\nL 165.222133 87.107625 \r\nL 168.296513 61.803867 \r\nL 171.370894 52.842231 \r\nL 174.445274 61.413593 \r\nL 177.519654 73.978826 \r\nL 180.594034 51.132627 \r\nL 183.668414 70.08017 \r\nL 186.742794 54.088206 \r\nL 189.817175 45.288447 \r\nL 192.891555 67.9558 \r\nL 195.965935 51.883044 \r\nL 199.040315 46.592735 \r\nL 202.114695 67.197828 \r\nL 205.189075 59.972114 \r\nL 208.263456 45.131065 \r\nL 211.337836 29.502798 \r\nL 214.412216 37.221119 \r\nL 217.486596 67.965862 \r\nL 220.560976 53.478502 \r\nL 223.635356 73.449986 \r\nL 226.709737 87.43199 \r\nL 229.784117 61.994251 \r\nL 232.858497 45.564575 \r\nL 235.932877 56.036175 \r\nL 239.007257 60.925893 \r\nL 242.081637 65.993105 \r\nL 245.156018 54.674693 \r\nL 248.230398 68.65933 \r\nL 251.304778 74.651433 \r\nL 254.379158 56.316776 \r\nL 257.453538 49.765447 \r\nL 260.527918 46.929316 \r\nL 263.602299 40.439568 \r\nL 266.676679 30.978361 \r\nL 269.751059 45.092319 \r\nL 272.825439 46.870581 \r\nL 275.899819 57.861406 \r\nL 278.974199 51.797421 \r\nL 282.04858 33.336094 \r\nL 285.12296 43.788816 \r\nL 288.19734 73.293329 \r\nL 291.27172 43.960887 \r\nL 294.3461 57.150549 \r\nL 297.42048 38.419929 \r\nL 300.494861 36.707972 \r\nL 303.569241 31.634235 \r\nL 306.643621 32.960697 \r\nL 309.718001 33.009795 \r\nL 312.792381 32.40766 \r\nL 315.866761 49.011032 \r\nL 318.941142 50.267589 \r\nL 322.015522 22.252264 \r\nL 325.089902 42.339983 \r\nL 328.164282 44.409173 \r\nL 331.238662 44.229571 \r\nL 334.313042 46.714946 \r\nL 337.387423 25.541565 \r\nL 340.461803 29.789628 \r\nL 343.536183 26.573965 \r\nL 346.610563 17.083636 \r\nL 349.684943 35.576758 \r\n\" style=\"fill:none;stroke:#ff7f0e;stroke-linecap:square;stroke-width:1.5;\"/>\r\n   </g>\r\n   <g id=\"patch_3\">\r\n    <path d=\"M 30.103125 224.64 \r\nL 30.103125 7.2 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_4\">\r\n    <path d=\"M 364.903125 224.64 \r\nL 364.903125 7.2 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_5\">\r\n    <path d=\"M 30.103125 224.64 \r\nL 364.903125 224.64 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_6\">\r\n    <path d=\"M 30.103125 7.2 \r\nL 364.903125 7.2 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n  </g>\r\n </g>\r\n <defs>\r\n  <clipPath id=\"pebc996a9a9\">\r\n   <rect height=\"217.44\" width=\"334.8\" x=\"30.103125\" y=\"7.2\"/>\r\n  </clipPath>\r\n </defs>\r\n</svg>\r\n",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "source": [
    "plt.plot(train_losses)\n",
    "plt.plot(np.mean(val_ce, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.4225994617290196"
      ]
     },
     "metadata": {},
     "execution_count": 65
    }
   ],
   "source": [
    "np.max(np.mean(val_rp, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "32\n32\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\r\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\r\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\r\n<!-- Created with matplotlib (https://matplotlib.org/) -->\r\n<svg height=\"248.518125pt\" version=\"1.1\" viewBox=\"0 0 372.103125 248.518125\" width=\"372.103125pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\r\n <metadata>\r\n  <rdf:RDF xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\r\n   <cc:Work>\r\n    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\r\n    <dc:date>2021-06-10T15:37:55.436849</dc:date>\r\n    <dc:format>image/svg+xml</dc:format>\r\n    <dc:creator>\r\n     <cc:Agent>\r\n      <dc:title>Matplotlib v3.3.2, https://matplotlib.org/</dc:title>\r\n     </cc:Agent>\r\n    </dc:creator>\r\n   </cc:Work>\r\n  </rdf:RDF>\r\n </metadata>\r\n <defs>\r\n  <style type=\"text/css\">*{stroke-linecap:butt;stroke-linejoin:round;}</style>\r\n </defs>\r\n <g id=\"figure_1\">\r\n  <g id=\"patch_1\">\r\n   <path d=\"M 0 248.518125 \r\nL 372.103125 248.518125 \r\nL 372.103125 0 \r\nL 0 0 \r\nz\r\n\" style=\"fill:none;\"/>\r\n  </g>\r\n  <g id=\"axes_1\">\r\n   <g id=\"patch_2\">\r\n    <path d=\"M 30.103125 224.64 \r\nL 364.903125 224.64 \r\nL 364.903125 7.2 \r\nL 30.103125 7.2 \r\nz\r\n\" style=\"fill:#ffffff;\"/>\r\n   </g>\r\n   <g id=\"matplotlib.axis_1\">\r\n    <g id=\"xtick_1\">\r\n     <g id=\"line2d_1\">\r\n      <defs>\r\n       <path d=\"M 0 0 \r\nL 0 3.5 \r\n\" id=\"m8b6c6fb77d\" style=\"stroke:#000000;stroke-width:0.8;\"/>\r\n      </defs>\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"45.321307\" xlink:href=\"#m8b6c6fb77d\" y=\"224.64\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_1\">\r\n      <!-- 0 -->\r\n      <g transform=\"translate(42.140057 239.238437)scale(0.1 -0.1)\">\r\n       <defs>\r\n        <path d=\"M 31.78125 66.40625 \r\nQ 24.171875 66.40625 20.328125 58.90625 \r\nQ 16.5 51.421875 16.5 36.375 \r\nQ 16.5 21.390625 20.328125 13.890625 \r\nQ 24.171875 6.390625 31.78125 6.390625 \r\nQ 39.453125 6.390625 43.28125 13.890625 \r\nQ 47.125 21.390625 47.125 36.375 \r\nQ 47.125 51.421875 43.28125 58.90625 \r\nQ 39.453125 66.40625 31.78125 66.40625 \r\nz\r\nM 31.78125 74.21875 \r\nQ 44.046875 74.21875 50.515625 64.515625 \r\nQ 56.984375 54.828125 56.984375 36.375 \r\nQ 56.984375 17.96875 50.515625 8.265625 \r\nQ 44.046875 -1.421875 31.78125 -1.421875 \r\nQ 19.53125 -1.421875 13.0625 8.265625 \r\nQ 6.59375 17.96875 6.59375 36.375 \r\nQ 6.59375 54.828125 13.0625 64.515625 \r\nQ 19.53125 74.21875 31.78125 74.21875 \r\nz\r\n\" id=\"DejaVuSans-48\"/>\r\n       </defs>\r\n       <use xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_2\">\r\n     <g id=\"line2d_2\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"106.80891\" xlink:href=\"#m8b6c6fb77d\" y=\"224.64\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_2\">\r\n      <!-- 20 -->\r\n      <g transform=\"translate(100.44641 239.238437)scale(0.1 -0.1)\">\r\n       <defs>\r\n        <path d=\"M 19.1875 8.296875 \r\nL 53.609375 8.296875 \r\nL 53.609375 0 \r\nL 7.328125 0 \r\nL 7.328125 8.296875 \r\nQ 12.9375 14.109375 22.625 23.890625 \r\nQ 32.328125 33.6875 34.8125 36.53125 \r\nQ 39.546875 41.84375 41.421875 45.53125 \r\nQ 43.3125 49.21875 43.3125 52.78125 \r\nQ 43.3125 58.59375 39.234375 62.25 \r\nQ 35.15625 65.921875 28.609375 65.921875 \r\nQ 23.96875 65.921875 18.8125 64.3125 \r\nQ 13.671875 62.703125 7.8125 59.421875 \r\nL 7.8125 69.390625 \r\nQ 13.765625 71.78125 18.9375 73 \r\nQ 24.125 74.21875 28.421875 74.21875 \r\nQ 39.75 74.21875 46.484375 68.546875 \r\nQ 53.21875 62.890625 53.21875 53.421875 \r\nQ 53.21875 48.921875 51.53125 44.890625 \r\nQ 49.859375 40.875 45.40625 35.40625 \r\nQ 44.1875 33.984375 37.640625 27.21875 \r\nQ 31.109375 20.453125 19.1875 8.296875 \r\nz\r\n\" id=\"DejaVuSans-50\"/>\r\n       </defs>\r\n       <use xlink:href=\"#DejaVuSans-50\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_3\">\r\n     <g id=\"line2d_3\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"168.296513\" xlink:href=\"#m8b6c6fb77d\" y=\"224.64\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_3\">\r\n      <!-- 40 -->\r\n      <g transform=\"translate(161.934013 239.238437)scale(0.1 -0.1)\">\r\n       <defs>\r\n        <path d=\"M 37.796875 64.3125 \r\nL 12.890625 25.390625 \r\nL 37.796875 25.390625 \r\nz\r\nM 35.203125 72.90625 \r\nL 47.609375 72.90625 \r\nL 47.609375 25.390625 \r\nL 58.015625 25.390625 \r\nL 58.015625 17.1875 \r\nL 47.609375 17.1875 \r\nL 47.609375 0 \r\nL 37.796875 0 \r\nL 37.796875 17.1875 \r\nL 4.890625 17.1875 \r\nL 4.890625 26.703125 \r\nz\r\n\" id=\"DejaVuSans-52\"/>\r\n       </defs>\r\n       <use xlink:href=\"#DejaVuSans-52\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_4\">\r\n     <g id=\"line2d_4\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"229.784117\" xlink:href=\"#m8b6c6fb77d\" y=\"224.64\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_4\">\r\n      <!-- 60 -->\r\n      <g transform=\"translate(223.421617 239.238437)scale(0.1 -0.1)\">\r\n       <defs>\r\n        <path d=\"M 33.015625 40.375 \r\nQ 26.375 40.375 22.484375 35.828125 \r\nQ 18.609375 31.296875 18.609375 23.390625 \r\nQ 18.609375 15.53125 22.484375 10.953125 \r\nQ 26.375 6.390625 33.015625 6.390625 \r\nQ 39.65625 6.390625 43.53125 10.953125 \r\nQ 47.40625 15.53125 47.40625 23.390625 \r\nQ 47.40625 31.296875 43.53125 35.828125 \r\nQ 39.65625 40.375 33.015625 40.375 \r\nz\r\nM 52.59375 71.296875 \r\nL 52.59375 62.3125 \r\nQ 48.875 64.0625 45.09375 64.984375 \r\nQ 41.3125 65.921875 37.59375 65.921875 \r\nQ 27.828125 65.921875 22.671875 59.328125 \r\nQ 17.53125 52.734375 16.796875 39.40625 \r\nQ 19.671875 43.65625 24.015625 45.921875 \r\nQ 28.375 48.1875 33.59375 48.1875 \r\nQ 44.578125 48.1875 50.953125 41.515625 \r\nQ 57.328125 34.859375 57.328125 23.390625 \r\nQ 57.328125 12.15625 50.6875 5.359375 \r\nQ 44.046875 -1.421875 33.015625 -1.421875 \r\nQ 20.359375 -1.421875 13.671875 8.265625 \r\nQ 6.984375 17.96875 6.984375 36.375 \r\nQ 6.984375 53.65625 15.1875 63.9375 \r\nQ 23.390625 74.21875 37.203125 74.21875 \r\nQ 40.921875 74.21875 44.703125 73.484375 \r\nQ 48.484375 72.75 52.59375 71.296875 \r\nz\r\n\" id=\"DejaVuSans-54\"/>\r\n       </defs>\r\n       <use xlink:href=\"#DejaVuSans-54\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_5\">\r\n     <g id=\"line2d_5\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"291.27172\" xlink:href=\"#m8b6c6fb77d\" y=\"224.64\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_5\">\r\n      <!-- 80 -->\r\n      <g transform=\"translate(284.90922 239.238437)scale(0.1 -0.1)\">\r\n       <defs>\r\n        <path d=\"M 31.78125 34.625 \r\nQ 24.75 34.625 20.71875 30.859375 \r\nQ 16.703125 27.09375 16.703125 20.515625 \r\nQ 16.703125 13.921875 20.71875 10.15625 \r\nQ 24.75 6.390625 31.78125 6.390625 \r\nQ 38.8125 6.390625 42.859375 10.171875 \r\nQ 46.921875 13.96875 46.921875 20.515625 \r\nQ 46.921875 27.09375 42.890625 30.859375 \r\nQ 38.875 34.625 31.78125 34.625 \r\nz\r\nM 21.921875 38.8125 \r\nQ 15.578125 40.375 12.03125 44.71875 \r\nQ 8.5 49.078125 8.5 55.328125 \r\nQ 8.5 64.0625 14.71875 69.140625 \r\nQ 20.953125 74.21875 31.78125 74.21875 \r\nQ 42.671875 74.21875 48.875 69.140625 \r\nQ 55.078125 64.0625 55.078125 55.328125 \r\nQ 55.078125 49.078125 51.53125 44.71875 \r\nQ 48 40.375 41.703125 38.8125 \r\nQ 48.828125 37.15625 52.796875 32.3125 \r\nQ 56.78125 27.484375 56.78125 20.515625 \r\nQ 56.78125 9.90625 50.3125 4.234375 \r\nQ 43.84375 -1.421875 31.78125 -1.421875 \r\nQ 19.734375 -1.421875 13.25 4.234375 \r\nQ 6.78125 9.90625 6.78125 20.515625 \r\nQ 6.78125 27.484375 10.78125 32.3125 \r\nQ 14.796875 37.15625 21.921875 38.8125 \r\nz\r\nM 18.3125 54.390625 \r\nQ 18.3125 48.734375 21.84375 45.5625 \r\nQ 25.390625 42.390625 31.78125 42.390625 \r\nQ 38.140625 42.390625 41.71875 45.5625 \r\nQ 45.3125 48.734375 45.3125 54.390625 \r\nQ 45.3125 60.0625 41.71875 63.234375 \r\nQ 38.140625 66.40625 31.78125 66.40625 \r\nQ 25.390625 66.40625 21.84375 63.234375 \r\nQ 18.3125 60.0625 18.3125 54.390625 \r\nz\r\n\" id=\"DejaVuSans-56\"/>\r\n       </defs>\r\n       <use xlink:href=\"#DejaVuSans-56\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_6\">\r\n     <g id=\"line2d_6\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"352.759323\" xlink:href=\"#m8b6c6fb77d\" y=\"224.64\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_6\">\r\n      <!-- 100 -->\r\n      <g transform=\"translate(343.215573 239.238437)scale(0.1 -0.1)\">\r\n       <defs>\r\n        <path d=\"M 12.40625 8.296875 \r\nL 28.515625 8.296875 \r\nL 28.515625 63.921875 \r\nL 10.984375 60.40625 \r\nL 10.984375 69.390625 \r\nL 28.421875 72.90625 \r\nL 38.28125 72.90625 \r\nL 38.28125 8.296875 \r\nL 54.390625 8.296875 \r\nL 54.390625 0 \r\nL 12.40625 0 \r\nz\r\n\" id=\"DejaVuSans-49\"/>\r\n       </defs>\r\n       <use xlink:href=\"#DejaVuSans-49\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n   </g>\r\n   <g id=\"matplotlib.axis_2\">\r\n    <g id=\"ytick_1\">\r\n     <g id=\"line2d_7\">\r\n      <defs>\r\n       <path d=\"M 0 0 \r\nL -3.5 0 \r\n\" id=\"mb2dc0b2020\" style=\"stroke:#000000;stroke-width:0.8;\"/>\r\n      </defs>\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"30.103125\" xlink:href=\"#mb2dc0b2020\" y=\"215.56614\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_7\">\r\n      <!-- 0.0 -->\r\n      <g transform=\"translate(7.2 219.365359)scale(0.1 -0.1)\">\r\n       <defs>\r\n        <path d=\"M 10.6875 12.40625 \r\nL 21 12.40625 \r\nL 21 0 \r\nL 10.6875 0 \r\nz\r\n\" id=\"DejaVuSans-46\"/>\r\n       </defs>\r\n       <use xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\r\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_2\">\r\n     <g id=\"line2d_8\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"30.103125\" xlink:href=\"#mb2dc0b2020\" y=\"168.59909\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_8\">\r\n      <!-- 0.1 -->\r\n      <g transform=\"translate(7.2 172.398308)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\r\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-49\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_3\">\r\n     <g id=\"line2d_9\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"30.103125\" xlink:href=\"#mb2dc0b2020\" y=\"121.632039\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_9\">\r\n      <!-- 0.2 -->\r\n      <g transform=\"translate(7.2 125.431257)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\r\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-50\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_4\">\r\n     <g id=\"line2d_10\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"30.103125\" xlink:href=\"#mb2dc0b2020\" y=\"74.664988\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_10\">\r\n      <!-- 0.3 -->\r\n      <g transform=\"translate(7.2 78.464207)scale(0.1 -0.1)\">\r\n       <defs>\r\n        <path d=\"M 40.578125 39.3125 \r\nQ 47.65625 37.796875 51.625 33 \r\nQ 55.609375 28.21875 55.609375 21.1875 \r\nQ 55.609375 10.40625 48.1875 4.484375 \r\nQ 40.765625 -1.421875 27.09375 -1.421875 \r\nQ 22.515625 -1.421875 17.65625 -0.515625 \r\nQ 12.796875 0.390625 7.625 2.203125 \r\nL 7.625 11.71875 \r\nQ 11.71875 9.328125 16.59375 8.109375 \r\nQ 21.484375 6.890625 26.8125 6.890625 \r\nQ 36.078125 6.890625 40.9375 10.546875 \r\nQ 45.796875 14.203125 45.796875 21.1875 \r\nQ 45.796875 27.640625 41.28125 31.265625 \r\nQ 36.765625 34.90625 28.71875 34.90625 \r\nL 20.21875 34.90625 \r\nL 20.21875 43.015625 \r\nL 29.109375 43.015625 \r\nQ 36.375 43.015625 40.234375 45.921875 \r\nQ 44.09375 48.828125 44.09375 54.296875 \r\nQ 44.09375 59.90625 40.109375 62.90625 \r\nQ 36.140625 65.921875 28.71875 65.921875 \r\nQ 24.65625 65.921875 20.015625 65.03125 \r\nQ 15.375 64.15625 9.8125 62.3125 \r\nL 9.8125 71.09375 \r\nQ 15.4375 72.65625 20.34375 73.4375 \r\nQ 25.25 74.21875 29.59375 74.21875 \r\nQ 40.828125 74.21875 47.359375 69.109375 \r\nQ 53.90625 64.015625 53.90625 55.328125 \r\nQ 53.90625 49.265625 50.4375 45.09375 \r\nQ 46.96875 40.921875 40.578125 39.3125 \r\nz\r\n\" id=\"DejaVuSans-51\"/>\r\n       </defs>\r\n       <use xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\r\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-51\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_5\">\r\n     <g id=\"line2d_11\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"30.103125\" xlink:href=\"#mb2dc0b2020\" y=\"27.697937\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_11\">\r\n      <!-- 0.4 -->\r\n      <g transform=\"translate(7.2 31.497156)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-48\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\r\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-52\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n   </g>\r\n   <g id=\"line2d_12\">\r\n    <path clip-path=\"url(#pfe78b864b7)\" d=\"M 45.321307 214.756364 \r\nL 48.395687 213.238032 \r\nL 51.470067 213.238032 \r\nL 54.544447 213.238032 \r\nL 57.618827 213.238032 \r\nL 60.693208 213.238032 \r\nL 63.767588 202.407268 \r\nL 66.841968 213.238032 \r\nL 69.916348 202.407268 \r\nL 72.990728 202.407268 \r\nL 76.065108 202.407268 \r\nL 79.139489 202.407268 \r\nL 82.213869 202.407268 \r\nL 85.288249 191.070394 \r\nL 88.362629 204.229266 \r\nL 91.437009 206.253708 \r\nL 94.511389 202.407268 \r\nL 97.58577 188.236175 \r\nL 100.66015 191.880171 \r\nL 103.73453 190.058173 \r\nL 106.80891 188.033731 \r\nL 109.88329 189.349618 \r\nL 112.95767 195.321722 \r\nL 116.032051 190.665506 \r\nL 119.106431 190.463061 \r\nL 122.180811 189.754507 \r\nL 125.255191 192.892392 \r\nL 128.329571 196.435165 \r\nL 131.403951 192.285059 \r\nL 134.478332 189.450841 \r\nL 137.552712 193.600946 \r\nL 140.627092 188.539842 \r\nL 143.701472 180.846963 \r\nL 146.775852 194.107057 \r\nL 149.850232 181.150629 \r\nL 152.924613 186.312956 \r\nL 155.998993 193.904613 \r\nL 159.073373 186.717844 \r\nL 162.147753 199.066939 \r\nL 165.222133 196.941275 \r\nL 168.296513 188.134953 \r\nL 171.370894 191.880171 \r\nL 174.445274 188.134953 \r\nL 177.519654 188.134953 \r\nL 180.594034 185.908067 \r\nL 183.668414 185.806845 \r\nL 186.742794 187.932509 \r\nL 189.817175 181.960406 \r\nL 192.891555 190.463061 \r\nL 195.965935 181.960406 \r\nL 199.040315 194.916834 \r\nL 202.114695 191.880171 \r\nL 205.189075 189.552063 \r\nL 208.263456 194.916834 \r\nL 211.337836 199.066939 \r\nL 214.412216 199.066939 \r\nL 217.486596 197.042497 \r\nL 220.560976 197.447386 \r\nL 223.635356 187.831287 \r\nL 226.709737 198.560829 \r\nL 229.784117 188.539842 \r\nL 232.858497 191.272838 \r\nL 235.932877 188.94473 \r\nL 239.007257 183.579959 \r\nL 242.081637 184.59218 \r\nL 245.156018 183.984848 \r\nL 248.230398 189.653285 \r\nL 251.304778 184.794624 \r\nL 254.379158 187.831287 \r\nL 257.453538 188.843508 \r\nL 260.527918 187.325177 \r\nL 263.602299 187.325177 \r\nL 266.676679 182.264072 \r\nL 269.751059 189.450841 \r\nL 272.825439 184.794624 \r\nL 275.899819 185.098291 \r\nL 278.974199 186.5154 \r\nL 282.04858 188.337398 \r\nL 285.12296 186.920288 \r\nL 288.19734 188.033731 \r\nL 291.27172 186.110512 \r\nL 294.3461 184.997068 \r\nL 297.42048 182.16285 \r\nL 300.494861 186.717844 \r\nL 303.569241 186.009289 \r\nL 306.643621 187.628843 \r\nL 309.718001 189.248396 \r\nL 312.792381 187.628843 \r\nL 315.866761 182.264072 \r\nL 318.941142 182.365294 \r\nL 322.015522 182.871405 \r\nL 325.089902 186.717844 \r\nL 328.164282 186.110512 \r\nL 331.238662 187.527621 \r\nL 334.313042 194.815611 \r\nL 337.387423 192.386281 \r\nL 340.461803 192.082615 \r\nL 343.536183 192.588725 \r\nL 346.610563 187.527621 \r\nL 349.684943 190.564284 \r\n\" style=\"fill:none;stroke:#1f77b4;stroke-linecap:square;stroke-width:1.5;\"/>\r\n   </g>\r\n   <g id=\"line2d_13\">\r\n    <path clip-path=\"url(#pfe78b864b7)\" d=\"M 45.321307 212.520049 \r\nL 48.395687 205.433812 \r\nL 51.470067 205.433812 \r\nL 54.544447 205.433812 \r\nL 57.618827 205.433812 \r\nL 60.693208 205.433812 \r\nL 63.767588 103.8806 \r\nL 66.841968 205.433812 \r\nL 69.916348 103.8806 \r\nL 72.990728 103.8806 \r\nL 76.065108 103.8806 \r\nL 79.139489 103.8806 \r\nL 82.213869 103.8806 \r\nL 85.288249 55.704585 \r\nL 88.362629 118.648965 \r\nL 91.437009 177.654865 \r\nL 94.511389 103.8806 \r\nL 97.58577 44.142267 \r\nL 100.66015 56.041889 \r\nL 103.73453 49.765086 \r\nL 106.80891 42.441784 \r\nL 109.88329 47.344143 \r\nL 112.95767 69.058188 \r\nL 116.032051 52.968275 \r\nL 119.106431 51.610931 \r\nL 122.180811 49.238789 \r\nL 125.255191 61.453204 \r\nL 128.329571 73.450378 \r\nL 131.403951 56.965201 \r\nL 134.478332 46.331857 \r\nL 137.552712 63.713617 \r\nL 140.627092 46.861962 \r\nL 143.701472 17.083636 \r\nL 146.775852 67.180375 \r\nL 149.850232 17.948022 \r\nL 152.924613 35.886659 \r\nL 155.998993 64.981366 \r\nL 159.073373 38.672779 \r\nL 162.147753 91.316962 \r\nL 165.222133 83.39661 \r\nL 168.296513 41.715022 \r\nL 171.370894 56.854441 \r\nL 174.445274 41.715022 \r\nL 177.519654 41.715022 \r\nL 180.594034 37.143227 \r\nL 183.668414 35.152656 \r\nL 186.742794 41.782254 \r\nL 189.817175 21.630141 \r\nL 192.891555 49.440461 \r\nL 195.965935 21.630141 \r\nL 199.040315 68.750396 \r\nL 202.114695 56.854441 \r\nL 205.189075 49.674569 \r\nL 208.263456 67.752245 \r\nL 211.337836 91.316962 \r\nL 214.412216 91.316962 \r\nL 217.486596 74.447326 \r\nL 220.560976 84.821631 \r\nL 223.635356 41.188725 \r\nL 226.709737 87.961535 \r\nL 229.784117 46.602112 \r\nL 232.858497 62.287715 \r\nL 235.932877 43.905087 \r\nL 239.007257 25.637445 \r\nL 242.081637 29.644553 \r\nL 245.156018 26.2413 \r\nL 248.230398 44.581959 \r\nL 251.304778 32.763468 \r\nL 254.379158 41.364592 \r\nL 257.453538 46.91221 \r\nL 260.527918 36.090684 \r\nL 263.602299 38.881343 \r\nL 266.676679 20.882671 \r\nL 269.751059 43.658851 \r\nL 272.825439 28.870793 \r\nL 275.899819 29.586957 \r\nL 278.974199 35.248847 \r\nL 282.04858 42.461978 \r\nL 285.12296 34.75112 \r\nL 288.19734 40.004936 \r\nL 291.27172 32.850712 \r\nL 294.3461 29.911101 \r\nL 297.42048 22.09294 \r\nL 300.494861 38.522623 \r\nL 303.569241 36.016093 \r\nL 306.643621 40.715804 \r\nL 309.718001 46.28885 \r\nL 312.792381 40.715804 \r\nL 315.866761 20.408541 \r\nL 318.941142 21.947959 \r\nL 322.015522 23.148004 \r\nL 325.089902 35.139761 \r\nL 328.164282 31.379839 \r\nL 331.238662 40.852459 \r\nL 334.313042 67.163739 \r\nL 337.387423 56.51504 \r\nL 340.461803 60.29731 \r\nL 343.536183 56.837805 \r\nL 346.610563 41.276124 \r\nL 349.684943 50.245259 \r\n\" style=\"fill:none;stroke:#ff7f0e;stroke-linecap:square;stroke-width:1.5;\"/>\r\n   </g>\r\n   <g id=\"patch_3\">\r\n    <path d=\"M 30.103125 224.64 \r\nL 30.103125 7.2 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_4\">\r\n    <path d=\"M 364.903125 224.64 \r\nL 364.903125 7.2 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_5\">\r\n    <path d=\"M 30.103125 224.64 \r\nL 364.903125 224.64 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_6\">\r\n    <path d=\"M 30.103125 7.2 \r\nL 364.903125 7.2 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n  </g>\r\n </g>\r\n <defs>\r\n  <clipPath id=\"pfe78b864b7\">\r\n   <rect height=\"217.44\" width=\"334.8\" x=\"30.103125\" y=\"7.2\"/>\r\n  </clipPath>\r\n </defs>\r\n</svg>\r\n",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "source": [
    "plt.plot(np.mean(val_rr, axis=1))\n",
    "print(np.argmax(np.mean(val_rr, axis=1)))\n",
    "plt.plot(np.mean(val_rp, axis=1))\n",
    "print(np.argmax(np.mean(val_rp, axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))"
   ]
  },
  {
   "source": [
    "### Sequence Generation"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# i = 0\n",
    "# example_task_vector = X_test.reset_index(drop=True).loc[i]\n",
    "# example_true_vector = Y_test[i]\n",
    "# example_true_sequence = y_test.loc[i][0]\n",
    "# print('task vector: {} \\n'.format(example_task_vector.values))\n",
    "# print('true sequence is: {}\\n'.format(example_true_sequence))\n",
    "# result, task_vector = generate_solution(example_task_vector)\n",
    "# print(result, '\\n')\n",
    "# print('length of the result sequence is: {} \\n'.format(len(result.split(' '))))"
   ]
  },
  {
   "source": [
    "### Model Evaluation"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# i = 0\n",
    "# example_task_vector = X_test.reset_index(drop=True).loc[i]\n",
    "# example_true_vector = Y_test[i]\n",
    "# example_true_sequence = y_test.loc[i][0]\n",
    "# print('task vector: {} \\n'.format(example_task_vector.values))\n",
    "# print('true sequence is: {}\\n'.format(example_true_sequence))\n",
    "# result, metrics = generate_solution_with_evaluation(example_task_vector, example_true_vector, save_outputs=True)\n",
    "# print('predicted sequence is: {}\\n'.format(result))\n",
    "# print('predicted unique sequence is: {}\\n'.format(\" \".join(list(set(result.split(' ')))))) #[el for i, el in enumerate(result.split(' ')) if result.split(' ')[i-1] != el])\n",
    "# print('length of the result sequence is: {} \\n'.format(len(result.split(' '))))\n",
    "# print('Metrics:', metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "predicting.. 0.0% \n",
      "Cross-Entropy: 2.7858\n",
      "Perplexity: 16.2125\n",
      "ROUGE-Recall: 0.0785\n",
      "ROUGE-Precision: 0.3962\n",
      "Unique answers: 5\n"
     ]
    }
   ],
   "source": [
    "## Predict on Train\n",
    "_, _, _, _ = predict_on_test(X_train[TASK_FEATURES], Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "predicting.. 0.0% \n",
      "Cross-Entropy: 2.8481\n",
      "Perplexity: 17.2555\n",
      "ROUGE-Recall: 0.0532\n",
      "ROUGE-Precision: 0.3520\n",
      "Unique answers: 1\n"
     ]
    }
   ],
   "source": [
    "## Predict on Test\n",
    "_, _, _, _ = predict_on_test(X_test[TASK_FEATURES], Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# val_ce = []\n",
    "# val_rr = []\n",
    "# val_rp = []\n",
    "# for i in range(1, EPOCHS//5 + 1):\n",
    "#     checkpoint.restore('./checkpoints/ckpt-{}.index'.format(i))\n",
    "#     _, losses_ce, rouge_recalls, rouge_precisions = predict_on_test(X_test[TASK_FEATURES], Y_test)\n",
    "#     val_ce.append(losses_ce)\n",
    "#     val_rr.append(rouge_recalls)\n",
    "#     val_rp.append(rouge_precisions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred[TARGET_COLUMN].unique()"
   ]
  },
  {
   "source": [
    "---\n",
    "## To Do"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "##TODO: To py and argparse"
   ]
  },
  {
   "source": [
    "### To DAGsHub"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ##TODO: Export to DAGsHub\n",
    "# experiment_params = run_params.update(model_params)\n",
    "# experiment_params = experiment_params.update(data_params)\n",
    "# print(experiment_params)\n",
    "# # experiment_results = {}"
   ]
  }
 ]
}