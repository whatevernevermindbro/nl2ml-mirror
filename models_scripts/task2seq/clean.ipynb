{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.4 64-bit"
  },
  "metadata": {
   "interpreter": {
    "hash": "0de36b31320ba4c88b4f85a74724f3d16c36a44df48581253710b1065e752d9e"
   }
  },
  "interpreter": {
   "hash": "fa674fb5f6cdc24eb5c9cc6738104f28cbed8563d07fbe9a025c38c5c7354d6b"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sqlalchemy import create_engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "connection_string_path = '../../.vscode/mariadb_connection.txt'\n",
    "connection_string = open(connection_string_path, 'r').read()\n",
    "engine = create_engine(connection_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from sqlalchemy import inspect\n",
    "# inspector = inspect(engine)\n",
    "# schemas = inspector.get_schema_names()\n",
    "# for schema in schemas:\n",
    "#     print(\"schema: %s\" % schema)\n",
    "#     for table_name in inspector.get_table_names(schema=schema):\n",
    "#         print(table_name)\n",
    "#         # for column in inspector.get_columns(table_name, schema=schema):\n",
    "#         #     print(\"Column: %s\" % column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "select * from chunks_data\n",
    "\"\"\"\n",
    "data = pd.read_sql_query(query, engine)\n",
    "data.shape[0], data.kaggle_id.nunique(), data.ref_link.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check how many competitions are missing\n",
    "# competitions[~competitions['ref'].isin(data['ref_link'].unique())].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('mode.chained_assignment', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHUNKS_PATH = \"../../data/codeblocks_2021-04-01_concatenated_cleaned_linkedwithcompetitions.csv\"\n",
    "# chunks = pd.read_csv(CHUNKS_PATH)\n",
    "# chunks.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "MARKUP_DATA_PATH = \"../../data/markup_data_2021-05-26.csv\"\n",
    "markup_data = pd.read_csv(MARKUP_DATA_PATH)#, nrows=25)\n",
    "print('Loaded: {} chunks of {} notebooks from {} competitions'.format(markup_data.shape[0], markup_data['kaggle_id'].nunique(), markup_data['competition_id'].nunique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NOT_YET_MARKUP_DATA_PATH = \"../../data/not_yet_markup_data_2021-05-26.csv\"\n",
    "not_yet_markup_data = pd.read_csv(NOT_YET_MARKUP_DATA_PATH)#, nrows=25)\n",
    "# not_yet_markup_data.head()\n",
    "print('Loaded: {} chunks of {} notebooks from {} competitions'.format(not_yet_markup_data.shape[0], not_yet_markup_data['kaggle_id'].nunique(), not_yet_markup_data['competition_id'].nunique()))\n",
    "# new_notebooks.rename({'data_sources':'ref'}, axis=1, inplace=True)\n",
    "# def clean_comp(string:str) -> str:\n",
    "#     string = string.strip('[').strip(']').replace(\"'\", \"\")\n",
    "#     return string\n",
    "# new_notebooks['ref'] = new_notebooks['ref'].apply(clean_comp)\n",
    "# new_notebooks['ref'] = new_notebooks['ref'].apply(lambda x: x.split(',')[0].strip(' ').strip(\"'\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Parsed: 2587074 chunks of 101071 notebooks from 22935 competitions\n"
     ]
    }
   ],
   "source": [
    "NEW_NOTEBOOKS_PATH = \"../../data/codeblocks_2021-04-01_concatenated.csv\"\n",
    "new_notebooks = pd.read_csv(NEW_NOTEBOOKS_PATH)#, nrows=25)\n",
    "new_notebooks.rename({'data_sources':'ref'}, axis=1, inplace=True)\n",
    "print('Parsed: {} chunks of {} notebooks from {} competitions'.format(new_notebooks.shape[0], new_notebooks['kaggle_link'].nunique(), new_notebooks['ref'].nunique()))\n",
    "def clean_comp(string:str) -> str:\n",
    "    string = string.strip('[').strip(']').replace(\"'\", \"\")\n",
    "    return string\n",
    "new_notebooks['ref'] = new_notebooks['ref'].apply(clean_comp)\n",
    "new_notebooks['ref'] = new_notebooks['ref'].apply(lambda x: x.split(',')[0].strip(' ').strip(\"'\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(2441865, 9) 101065\n",
      "Parsed and cleaned: 2441864 chunks of 101065 notebooks from 12984 competitions\n"
     ]
    }
   ],
   "source": [
    "new_notebooks.drop_duplicates(inplace=True, subset=['code_block_id', 'kaggle_id'])\n",
    "print(new_notebooks.shape, new_notebooks.kaggle_link.nunique())\n",
    "new_notebooks.dropna(axis=0, subset=['code_block'], inplace=True)\n",
    "# print(new_notebooks.shape, new_notebooks.kaggle_link.nunique())\n",
    "gc.collect()\n",
    "print('Parsed and cleaned: {} chunks of {} notebooks from {} competitions'.format(new_notebooks.shape[0], new_notebooks['kaggle_link'].nunique(), new_notebooks['ref'].nunique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "With kaggle_score: 617441 chunks of 23425 notebooks from 553 competitions\n"
     ]
    }
   ],
   "source": [
    "new_notebooks.dropna(axis=0, subset=['kaggle_score'], inplace=True) \n",
    "print('With kaggle_score: {} chunks of {} notebooks from {} competitions'.format(new_notebooks.shape[0], new_notebooks['kaggle_link'].nunique(), new_notebooks['ref'].nunique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_notebooks['code_block'] = new_notebooks['code_block'].str.replace('`', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_notebooks.to_csv(\"../../data/codeblocks_2021-04-01_concatenated_cleaned.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(5060, 8)\n(4352, 8)\n"
     ]
    }
   ],
   "source": [
    "COMPETITIONS_PATH = \"../../data/competitions_info.csv\"\n",
    "competitions = pd.read_csv(COMPETITIONS_PATH)\n",
    "print(competitions.shape)\n",
    "competitions.drop_duplicates(inplace=True)\n",
    "competitions['ref'] = competitions['ref'].apply(clean_comp)\n",
    "print(competitions.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "# Chunks: 77649\n# Notebooks: 2827\n# Competitions: 266\n"
     ]
    }
   ],
   "source": [
    "new_notebooks = new_notebooks.merge(competitions, on=['ref'], how='inner')\n",
    "# new_notebooks.merge(competitions, on=['ref'], how='right').shape\n",
    "print('# Chunks: {}\\n# Notebooks: {}\\n# Competitions: {}'.format(new_notebooks.shape[0], new_notebooks.kaggle_link.nunique(), new_notebooks.ref.nunique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "metadata": {},
     "execution_count": 24
    }
   ],
   "source": [
    "# Check number of \"non competition\" refs\n",
    "new_notebooks[~new_notebooks['ref'].str.contains('c/')].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_notebooks.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "# new_notebooks.to_csv('../../data/codeblocks_2021-04-01_concatenated_cleaned.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "# Chunks: 77649\n# Notebooks: 2827\n# Competitions: 266\n"
     ]
    }
   ],
   "source": [
    "# new_notebooks['exists_in_competitions'] = new_notebooks.apply(lambda x: x['ref'] in competitions['ref'].unique(), axis=1)\n",
    "# print('# Chunks: {}\\n# Notebooks: {}\\n# Competitions: {}'.format(new_notebooks[new_notebooks['exists_in_competitions'] == True].shape[0], new_notebooks[new_notebooks['exists_in_competitions'] == True]['kaggle_link'].nunique(), new_notebooks[new_notebooks['exists_in_competitions'] == True]['ref'].nunique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "competitions['has_notebooks'] = competitions.apply(lambda x: x['ref'] in new_notebooks['ref'].tolist(), axis=1)\n",
    "competitions_cleaned = competitions[competitions['has_notebooks']]\n",
    "competitions_cleaned.shape\n",
    "# competitions_cleaned.to_csv('../data/competitions_info_cleaned.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "COMPETITIONS_FILLED_PATH = \"../../data/competitions_info_cleaned.csv\"\n",
    "competitions_filled = pd.read_csv(COMPETITIONS_FILLED_PATH)\n",
    "competitions_filled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "competitions_cleaned_with_filled = competitions_cleaned[['ref', 'comp_name', 'comp_type']].merge(competitions_filled[['ref', 'Description',\n",
    "                                        'Metric', 'DataType', 'Subject', 'ProblemType']]\n",
    "                                    , on=['ref'], how='left')\n",
    "competitions_cleaned_with_filled.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# competitions_filled.to_csv('../../data/competitions_info_filled.csv', index=False)\n",
    "# competitions_filled.to_csv('../../data_mini/competitions_info_filled.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# competitions_cleaned.to_csv('../../data/competitions_info_cleaned.csv', index=False)\n",
    "# competitions_cleaned.to_csv('../../data_mini/competitions_info_cleaned.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# competitions_cleaned_with_filled.to_csv('../../data/competitions_info_cleaned_filled.csv', index=False)\n",
    "# competitions_cleaned_with_filled.to_csv('../../data_mini/competitions_info_cleaned_filled.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}