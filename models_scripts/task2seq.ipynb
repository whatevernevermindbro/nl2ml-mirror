{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python386jvsc74a57bd00de36b31320ba4c88b4f85a74724f3d16c36a44df48581253710b1065e752d9e",
   "display_name": "Python 3.8.6 64-bit"
  },
  "metadata": {
   "interpreter": {
    "hash": "0de36b31320ba4c88b4f85a74724f3d16c36a44df48581253710b1065e752d9e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import backend as K\n",
    "# from sklearn.preprocessing import LabelEncoder \n",
    "from sqlalchemy import create_engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('mode.chained_assignment', None)"
   ]
  },
  {
   "source": [
    "### Defining Methods"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_key(my_dict, val):\n",
    "    for key, value in my_dict.items():\n",
    "         if val == value:\n",
    "             return key\n",
    " \n",
    "    return \"key doesn't exist\""
   ]
  },
  {
   "source": [
    "### Reading Data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # NEW_NOTEBOOKS_PATH = \"../data/codeblocks_2021-03-31.csv\"\n",
    "# # new_notebooks_1 = pd.read_csv(NEW_NOTEBOOKS_PATH)\n",
    "# # NEW_NOTEBOOKS_PATH = \"../data/codeblocks_2021-04-01.csv\"\n",
    "# # new_notebooks = pd.read_csv(NEW_NOTEBOOKS_PATH)\n",
    "# # new_notebooks = new_notebooks.append(new_notebooks_1)\n",
    "# # new_notebooks.to_csv(\"../data/codeblocks_2021-04-01_concatenated.csv\", index=False)\n",
    "\n",
    "# NEW_NOTEBOOKS_PATH = \"../data/codeblocks_2021-04-01_concatenated.csv\"\n",
    "# new_notebooks = pd.read_csv(NEW_NOTEBOOKS_PATH)\n",
    "# print(new_notebooks.shape, new_notebooks.kaggle_link.nunique())\n",
    "# def clean_comp(string:str) -> str:\n",
    "#     string = string.strip('[').strip(']').strip(\"'\")\n",
    "#     return string\n",
    "# new_notebooks['data_sources'] = new_notebooks['data_sources'].apply(clean_comp)\n",
    "# new_notebooks.rename({'data_sources':'ref'}, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_notebooks.dropna(axis=0, subset=['code_block', 'kaggle_score'], inplace=True)\n",
    "# new_notebooks = new_notebooks[new_notebooks.duplicated() == False]\n",
    "# new_notebooks['ref'] = new_notebooks['ref'].apply(lambda x: x.split(',')[0])\n",
    "# print(new_notebooks['kaggle_link'].nunique(), new_notebooks['ref'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# COMPETITIONS_PATH = \"../data/competitions_info_cleaned.csv\"\n",
    "# competitions = pd.read_csv(COMPETITIONS_PATH)\n",
    "# competitions.drop_duplicates(inplace=True)\n",
    "# competitions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # competitions = competitions[competitions['comp_type'] != 'inClass']\n",
    "# competitions.dropna(axis=0, subset=['Metric'], inplace=True)\n",
    "# competitions.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# notebooks_with_labelling = new_notebooks.merge(competitions, on='ref', how='inner')\n",
    "# print(notebooks_with_labelling.shape, notebooks_with_labelling['kaggle_link'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# competitions['has_notebooks'] = competitions.apply(lambda x: x['ref'] in new_notebooks['ref'].tolist(), axis=1)\n",
    "# competitions_cleaned = competitions[competitions['has_notebooks']]\n",
    "# competitions_cleaned.shape\n",
    "# competitions_cleaned.to_csv('../data/competitions_info_cleaned.csv', index=False)"
   ]
  },
  {
   "source": [
    "---"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mariadb_engine = create_engine(\"mysql+pymysql://root:$a8`k?B2y4nUxX2G@40.119.1.127:32006/nl2ml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# query = \"select * from chunks limit 10000\"\n",
    "# data = pd.read_sql(query, mariadb_engine.raw_connection())\n",
    "# data.shape"
   ]
  },
  {
   "source": [
    "---"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATASETS_PATH = '../data/NL2ML_ structure - data_structure.csv'\n",
    "# datasets = pd.read_csv(DATASETS_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTEBOOKS_PATH = '../data/NL2ML_ structure - levin.csv'\n",
    "# notebooks = pd.read_csv(NOTEBOOKS_PATH, skiprows=1, nrows=96)\n",
    "# notebooks.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Index(['graph_vertex_id', 'graph_vertex', 'graph_vertex_subclass'], dtype='object')"
      ]
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "source": [
    "graph_path = '../data/actual_graph_2021-04-18.csv'\n",
    "graph = pd.read_csv(graph_path)\n",
    "graph.rename({'id':'graph_vertex_id'}, axis=1, inplace=True)\n",
    "graph.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(247, 9)"
      ]
     },
     "metadata": {},
     "execution_count": 26
    }
   ],
   "source": [
    "COMPETITIONS_PATH = \"../data/competitions_info_cleaned.csv\"\n",
    "competitions = pd.read_csv(COMPETITIONS_PATH)\n",
    "competitions.drop_duplicates(inplace=True)\n",
    "competitions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "NOTEBOOKS_PATH = '../data/markup_data.csv'\n",
    "notebooks = pd.read_csv(NOTEBOOKS_PATH)\n",
    "notebooks.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Index(['code_block_id', 'code_block', 'data_format', 'graph_vertex_id',\n",
       "       'errors', 'marks', 'kaggle_id', 'competition_id', 'graph_vertex',\n",
       "       'graph_vertex_subclass'],\n",
       "      dtype='object')"
      ]
     },
     "metadata": {},
     "execution_count": 25
    }
   ],
   "source": [
    "notebooks = notebooks.merge(graph, on='graph_vertex_id', how='left')\n",
    "notebooks.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nl2ml = notebooks.merge(competitions, on=['competition_id'], how='left')\n",
    "nl2ml.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nl2ml = notebooks.merge(datasets, on=['dataset_id'], how='left')\n",
    "# nl2ml.head(2)"
   ]
  },
  {
   "source": [
    "### Vertices Preprocessing"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Data_Transform       32\n",
       "EDA                  20\n",
       "Model_Train          14\n",
       "Visualization        11\n",
       "Environment           7\n",
       "Data_Extraction       4\n",
       "Hyperparam_Tuning     4\n",
       "Exporatory_DA         3\n",
       "Data_Export           1\n",
       "Name: graph_vertex, dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "source": [
    "nl2ml['graph_vertex'].apply(lambda x: x.split(';')[0].split('.')[0]).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Index(['chunk_id', 'dataset_id', 'notebook_id', 'splitting_id', 'code_block',\n",
       "       'data_format', 'graph_vertex', 'errors', 'graph_vertex_m1',\n",
       "       'graph_vertex_m2', 'graph_vertex_m3', 'graph_vertex_p1',\n",
       "       'graph_vertex_p2', 'graph_vertex_p3', 'comments', 'libraries', 'ast',\n",
       "       'graph_vertex_regex', 'python_methods', 'docstrings',\n",
       "       'python_methods_m1', 'python_methods_m2', 'python_methods_m3',\n",
       "       'python_methods_p1', 'python_methods_p2', 'python_methods_p3',\n",
       "       'kaggle_link', 'kaggle_comments', 'kaggle_upvotes', 'kaggle_section',\n",
       "       'kaggle_section_overview', 'kaggle_score', 'url', 'Name',\n",
       "       'TL;DR (In plain English)', 'ProblemType',\n",
       "       'number of columns (for tabular)', 'number of entries',\n",
       "       'image resolution', 'number of images', 'Data Format', 'LabelType',\n",
       "       'Number of classes', 'Loss Function/Metrics', 'Target Column(s) Name',\n",
       "       'Columns DTypes'],\n",
       "      dtype='object')"
      ]
     },
     "metadata": {},
     "execution_count": 20
    }
   ],
   "source": [
    "nl2ml.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "nl2ml['vertex_l1'], nl2ml['vertex_l2'] = nl2ml['graph_vertex'].apply(lambda x: x.split(';')[0].split('.')[0]), nl2ml['graph_vertex'].apply(lambda x: x.split(';')[0].split('.')[1])"
   ]
  },
  {
   "source": [
    "### Missing Values"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "nl2ml.replace('-', -1, inplace=True)\n",
    "nl2ml.fillna(-1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "TASK_FEATURES = ['comp_name', 'comp_type', 'Description',\n",
    "                'Metric', 'DataType', 'Subject', 'ProblemType']\n",
    "# TASK_FEATURES = ['ProblemType',\n",
    "#                 'number of columns (for tabular)', 'number of entries',\n",
    "#                 'LabelType', 'Number of classes', 'Loss Function/Metrics',\n",
    "#                 'Target Column(s) Name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET_COLUMN = 'vertex_l2'"
   ]
  },
  {
   "source": [
    "### Grouping chunks by notebooks"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_by_notebooks(data:pd.DataFrame, vertex_col:str='vertex_l1') -> pd.DataFrame:\n",
    "    notebook_cols = [['notebook_id', vertex_col] + TASK_FEATURES]\n",
    "    df = pd.DataFrame(columns=notebook_cols)\n",
    "    for i, notebook_id in enumerate(data['notebook_id'].unique()):\n",
    "        notebook = data[data['notebook_id'] == notebook_id].reset_index(drop=True)\n",
    "        vertices_seq = \" \".join(notebook[vertex_col])\n",
    "        task_features = notebook[TASK_FEATURES].loc[0]\n",
    "        row = [notebook_id, vertices_seq] + task_features.tolist()\n",
    "        df.loc[i] = row\n",
    "        print('notebook #{} done'.format(notebook_id))\n",
    "    return df"
   ]
  },
  {
   "source": [
    "### Taking Train Features"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "notebook #1 done\nnotebook #7 done\nnotebook #9 done\n"
     ]
    }
   ],
   "source": [
    "train = group_by_notebooks(nl2ml, TARGET_COLUMN)\n",
    "X, y = train[TASK_FEATURES], train[TARGET_COLUMN]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "  notebook_id                                          vertex_l2  \\\n",
       "0           1  import_modules load_from_csv filter choose_mod...   \n",
       "1           7  import_modules load_from_csv show_table show_t...   \n",
       "2           9  import_modules import_modules load_from_csv sh...   \n",
       "\n",
       "      ProblemType number of columns (for tabular) number of entries LabelType  \\\n",
       "0  classification                             303                -1      -1.0   \n",
       "1      regression                             163                -1      -1.0   \n",
       "2      regression                             163                -1      -1.0   \n",
       "\n",
       "  Number of classes Loss Function/Metrics Target Column(s) Name  \n",
       "0                 2        custom metrics                action  \n",
       "1                -1                 rmsle             SalePrice  \n",
       "2                -1                 rmsle             SalePrice  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead tr th {\n        text-align: left;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr>\n      <th></th>\n      <th>notebook_id</th>\n      <th>vertex_l2</th>\n      <th>ProblemType</th>\n      <th>number of columns (for tabular)</th>\n      <th>number of entries</th>\n      <th>LabelType</th>\n      <th>Number of classes</th>\n      <th>Loss Function/Metrics</th>\n      <th>Target Column(s) Name</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>import_modules load_from_csv filter choose_mod...</td>\n      <td>classification</td>\n      <td>303</td>\n      <td>-1</td>\n      <td>-1.0</td>\n      <td>2</td>\n      <td>custom metrics</td>\n      <td>action</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>7</td>\n      <td>import_modules load_from_csv show_table show_t...</td>\n      <td>regression</td>\n      <td>163</td>\n      <td>-1</td>\n      <td>-1.0</td>\n      <td>-1</td>\n      <td>rmsle</td>\n      <td>SalePrice</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>9</td>\n      <td>import_modules import_modules load_from_csv sh...</td>\n      <td>regression</td>\n      <td>163</td>\n      <td>-1</td>\n      <td>-1.0</td>\n      <td>-1</td>\n      <td>rmsle</td>\n      <td>SalePrice</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 34
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "source": [
    "### Converting Dtypes"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "<ipython-input-35-da4655537486>:6: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  X[col] = pd.Categorical(X[col])\n<ipython-input-35-da4655537486>:8: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  X[col] = X[col].cat.codes\n<ipython-input-35-da4655537486>:4: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  X[col] =  X[col].astype('float32')\n"
     ]
    }
   ],
   "source": [
    "cat_encodings = {}\n",
    "for i, col in enumerate(X.columns):\n",
    "    try:\n",
    "        X[col] =  X[col].astype('float32')\n",
    "    except:\n",
    "        X[col] = pd.Categorical(X[col])\n",
    "        cat_encodings.update({i:dict(enumerate(X[col].cat.categories))})\n",
    "        X[col] = X[col].cat.codes"
   ]
  },
  {
   "source": [
    "### Target Preprocessing: Encoding Vertices"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "lang = {vertice:i+2 for i, vertice in enumerate(nl2ml[TARGET_COLUMN].unique())} #TODO: save the dict as a local file\n",
    "lang.update({'<start>':1, '<end>':max(lang.values())+1})\n",
    "def encode_vertices(vertices_seq, lang:dict=lang):\n",
    "    encoded = np.append(np.flip(np.array([lang[vertex] for vertex in vertices_seq[0].split(' ')] + [lang['<end>']])), lang['<start>'])\n",
    "    return encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0                            [29, 7, 6, 5, 4, 3, 2, 1]\n",
       "1    [29, 18, 22, 7, 5, 21, 5, 5, 5, 5, 19, 20, 19,...\n",
       "2    [29, 7, 28, 27, 2, 7, 7, 5, 26, 25, 25, 5, 2, ...\n",
       "dtype: object"
      ]
     },
     "metadata": {},
     "execution_count": 37
    }
   ],
   "source": [
    "y.apply(encode_vertices, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X['vertex_l2'] = y.apply(encode_vertices, axis=1)\n",
    "# X.to_csv('../data/nl2ml_train_example.csv', index=False)"
   ]
  },
  {
   "source": [
    "### Target Preprocessing: Padding Sequences"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = tf.keras.preprocessing.sequence.pad_sequences(y.apply(encode_vertices, axis=1))"
   ]
  },
  {
   "source": [
    "### Defining Constants"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BUFFER_SIZE = len(input_tensor_train)\n",
    "BATCH_SIZE = 1\n",
    "steps_per_epoch = len(X)//BATCH_SIZE\n",
    "embedding_dim = 128\n",
    "units = 512\n",
    "# vocab_inp_size = len(inp_lang.word_index) + 1\n",
    "# vocab_tar_size = len(targ_lang.word_index) + 1"
   ]
  },
  {
   "source": [
    "### Creating tf.Dataset"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices((X.values, Y))\n",
    "dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length_targ, max_length_feat = Y.shape[1], X.values.shape[1]"
   ]
  },
  {
   "source": [
    "### Building the Model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://machinelearningmastery.com/text-generation-lstm-recurrent-neural-networks-python-keras/\n",
    "# https://www.tensorflow.org/tutorials/text/text_generation\n",
    "# https://www.tensorflow.org/guide/keras/rnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.Model):\n",
    "  def __init__(self, vocab_size, embedding_dim, dec_units, batch_sz):\n",
    "    super(Decoder, self).__init__()\n",
    "    self.batch_sz = batch_sz\n",
    "    self.dec_units = dec_units\n",
    "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "    # self.hidden_embedding = tf.keras.layers.Embedding(vocab_size, 1)\n",
    "    self.gru = tf.keras.layers.GRU(self.dec_units,\n",
    "                                   return_sequences=True,\n",
    "                                   return_state=True,\n",
    "                                   recurrent_initializer='glorot_uniform')\n",
    "    self.fc = tf.keras.layers.Dense(vocab_size)\n",
    "\n",
    "    # used for attention\n",
    "    # self.attention = BahdanauAttention(self.dec_units)\n",
    "\n",
    "  def call(self, x, hidden):#, enc_output):\n",
    "    # enc_output shape == (batch_size, max_length, hidden_size)\n",
    "    # context_vector, attention_weights = self.attention(hidden, enc_output)\n",
    "    attention_weights = tf.ones(x.shape)\n",
    "    # context_vector = tf.ones(x.shape)\n",
    "    # print(\"X Vector has {} type and {} shape\".format(type(x), x.shape))\n",
    "    # print(\"Context Vector has {} type and {} shape\".format(type(context_vector), context_vector.shape))\n",
    "    # print(\"Attention Vector has {} type and {} shape\".format(type(context_vector), context_vector.shape))\n",
    "    # x shape after passing through embedding == (batch_size, 1, embedding_dim)\n",
    "    x = self.embedding(x)\n",
    "    # x = tf.squeeze(self.hidden_embedding(x), axis=-1)\n",
    "    # x shape after concatenation == (batch_size, 1, embedding_dim + hidden_size)\n",
    "    # x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1)\n",
    "\n",
    "    # passing the concatenated vector to the GRU\n",
    "    output, state = self.gru(x, initial_state=hidden)\n",
    "\n",
    "    # output shape == (batch_size * 1, hidden_size)\n",
    "    output = tf.reshape(output, (-1, output.shape[2]))\n",
    "\n",
    "    # output shape == (batch_size, vocab)\n",
    "    x = self.fc(output)\n",
    "\n",
    "    return x, state, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Decoder output shape: (batch_size, vocab size) (1, 31)\nModel: \"decoder\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nembedding (Embedding)        multiple                  3968      \n_________________________________________________________________\ngru (GRU)                    multiple                  986112    \n_________________________________________________________________\ndense (Dense)                multiple                  15903     \n=================================================================\nTotal params: 1,005,983\nTrainable params: 1,005,983\nNon-trainable params: 0\n_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "decoder = Decoder(len(lang)+2, embedding_dim, units, BATCH_SIZE)\n",
    "sample_hidden = tf.zeros((BATCH_SIZE, units))\n",
    "sample_decoder_output, _, _ = decoder(tf.random.uniform((BATCH_SIZE, 1))\n",
    "                                      , sample_hidden\n",
    "                                    #   , sample_output\n",
    "                                    )\n",
    "print ('Decoder output shape: (batch_size, vocab size) {}'.format(sample_decoder_output.shape))\n",
    "decoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam()\n",
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "                  from_logits=True, reduction='none')\n",
    "\n",
    "def loss_function(real, pred):\n",
    "  mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "  loss_ = loss_object(real, pred)\n",
    "\n",
    "  mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "  loss_ *= mask\n",
    "\n",
    "  return tf.reduce_mean(loss_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def compute_bleu(reference_corpus, translation_corpus, max_order=4,\n",
    "#                  smooth=False):\n",
    "#   \"\"\"Computes BLEU score of translated segments against one or more references.\n",
    "#   Args:\n",
    "#     reference_corpus: list of lists of references for each translation. Each\n",
    "#         reference should be tokenized into a list of tokens.\n",
    "#     translation_corpus: list of translations to score. Each translation\n",
    "#         should be tokenized into a list of tokens.\n",
    "#     max_order: Maximum n-gram order to use when computing BLEU score.\n",
    "#     smooth: Whether or not to apply Lin et al. 2004 smoothing.\n",
    "#   Returns:\n",
    "#     3-Tuple with the BLEU score, n-gram precisions, geometric mean of n-gram\n",
    "#     precisions and brevity penalty.\n",
    "#   \"\"\"\n",
    "#   matches_by_order = [0] * max_order\n",
    "#   possible_matches_by_order = [0] * max_order\n",
    "#   reference_length = 0\n",
    "#   translation_length = 0\n",
    "#   for (references, translation) in zip(reference_corpus,\n",
    "#                                        translation_corpus):\n",
    "#     reference_length += min(len(r) for r in references)\n",
    "#     translation_length += len(translation)\n",
    "\n",
    "#     merged_ref_ngram_counts = collections.Counter()\n",
    "#     for reference in references:\n",
    "#       merged_ref_ngram_counts |= _get_ngrams(reference, max_order)\n",
    "#     translation_ngram_counts = _get_ngrams(translation, max_order)\n",
    "#     overlap = translation_ngram_counts & merged_ref_ngram_counts\n",
    "#     for ngram in overlap:\n",
    "#       matches_by_order[len(ngram)-1] += overlap[ngram]\n",
    "#     for order in range(1, max_order+1):\n",
    "#       possible_matches = len(translation) - order + 1\n",
    "#       if possible_matches > 0:\n",
    "#         possible_matches_by_order[order-1] += possible_matches\n",
    "\n",
    "#   precisions = [0] * max_order\n",
    "#   for i in range(0, max_order):\n",
    "#     if smooth:\n",
    "#       precisions[i] = ((matches_by_order[i] + 1.) /\n",
    "#                        (possible_matches_by_order[i] + 1.))\n",
    "#     else:\n",
    "#       if possible_matches_by_order[i] > 0:\n",
    "#         precisions[i] = (float(matches_by_order[i]) /\n",
    "#                          possible_matches_by_order[i])\n",
    "#       else:\n",
    "#         precisions[i] = 0.0\n",
    "\n",
    "#   if min(precisions) > 0:\n",
    "#     p_log_sum = sum((1. / max_order) * math.log(p) for p in precisions)\n",
    "#     geo_mean = math.exp(p_log_sum)\n",
    "#   else:\n",
    "#     geo_mean = 0\n",
    "\n",
    "#   ratio = float(translation_length) / reference_length\n",
    "\n",
    "#   if ratio > 1.0:\n",
    "#     bp = 1.\n",
    "#   else:\n",
    "#     bp = math.exp(1 - 1. / ratio)\n",
    "\n",
    "#   bleu = geo_mean * bp\n",
    "\n",
    "#   return (bleu, precisions, bp, ratio, translation_length, reference_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class PerplexityMetric(tf.keras.metrics.Metric):\n",
    "#     ##TODO: calculate perplexity for one example\n",
    "#     # average for batch\n",
    "#     # average for epoch\n",
    "#     \"\"\"\n",
    "#     USAGE NOTICE: this metric accepts only logits for now (i.e. expect the same behaviour as from tf.keras.losses.SparseCategoricalCrossentropy with the a provided argument \"from_logits=True\", \n",
    "# \t\there the same loss is used with \"from_logits=True\" enforced so you need to provide it in such a format)\n",
    "#     METRIC DESCRIPTION:\n",
    "#     Popular metric for evaluating language modelling architectures.\n",
    "#     More info: http://cs224d.stanford.edu/lecture_notes/LectureNotes4.pdf.\n",
    "#     DISCLAIMER: Original function created by Kirill Mavreshko in https://github.com/kpot/keras-transformer/blob/b9d4e76c535c0c62cadc73e37416e4dc18b635ca/example/run_gpt.py#L106. \n",
    "#     My \"contribution\": I converted Kirill method's logic (and added a padding masking to to it) into this new Tensorflow 2.0 way of doing things via a stateful \"Metric\" object. This required making the metric a fully-fledged object by subclassing      the Metric class. \n",
    "#     \"\"\"\n",
    "#     def __init__(self, name='perplexity', **kwargs):\n",
    "#       super(PerplexityMetric, self).__init__(name=name, **kwargs)\n",
    "#       self.cross_entropy = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False, reduction='none')\n",
    "#       # self.cross_entropy = tf.keras.losses.CategoricalCrossentropy(from_logits=False, reduction='none')\n",
    "#       self.perplexity = self.add_weight(name='tp', initializer='ones') #tf.math.multiply(1, 1)\n",
    "# \t\t# Consider uncommenting the decorator for a performance boost (?)  \t\t\n",
    "#     # @tf.function\n",
    "#     def _calculate_perplexity(self, real, pred):\n",
    "# \t\t\t# The next 4 lines zero-out the padding from loss calculations, \n",
    "# \t\t\t# this follows the logic from: https://www.tensorflow.org/beta/tutorials/text/transformer#loss_and_metrics \t\t\t\n",
    "#       mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "#       loss_ = self.cross_entropy(real, pred)\n",
    "#       mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "#       loss_ *= mask\n",
    "# \t\t\t# Calculating the perplexity steps:\n",
    "#       step1 = K.mean(loss_, axis=0)#axis=-1)\n",
    "#       step2 = K.exp(step1)\n",
    "#       perplexity = K.mean(step2)\n",
    "#       return perplexity\n",
    "\n",
    "#     def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "#       # TODO:FIXME: handle sample_weight !\n",
    "#       if sample_weight is not None:\n",
    "#           print(\"WARNING! Provided 'sample_weight' argument to the perplexity metric. Currently this is not handled and won't do anything differently..\")\n",
    "#       cur_perplexity = self._calculate_perplexity(y_true, y_pred)\n",
    "# \t\t\t# Remember self.perplexity is a tensor (tf.Variable), so using simply \"self.perplexity = perplexity\" will result in error because of mixing EagerTensor and Graph operations \n",
    "#       # self.perplexity.assign_add(cur_perplexity)\n",
    "#       # print('cur_perplexity: {}'.format(cur_perplexity))\n",
    "#       # print('self.perplexity: {}'.format(self.perplexity))\n",
    "#       # print('mul : {}'.format(tf.math.multiply(self.perplexity, cur_perplexity)))\n",
    "#       self.perplexity.assign(tf.math.multiply(self.perplexity, cur_perplexity))\n",
    "#       # self.perplexity = tf.math.multiply(self.perplexity, cur_perplexity) ##TODO\n",
    "#       # print('current perplexity is: {}'.format(self.perplexity))\n",
    "\n",
    "#     def result(self):\n",
    "#       return self.perplexity\n",
    "\n",
    "#     def reset_states(self):\n",
    "#       # The state of the metric will be reset at the start of each epoch.\n",
    "#       self.perplexity.assign(1.0) # = tf.math.multiply(1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(inp, targ):#, enc_hidden):\n",
    "  loss = 0\n",
    "  batch_perplexity = 1\n",
    "  with tf.GradientTape() as tape:\n",
    "    # enc_output, enc_hidden = encoder(inp, enc_hidden)\n",
    "\n",
    "    dec_hidden = tf.zeros((BATCH_SIZE, units)) #enc_hidden\n",
    "\n",
    "    dec_input = tf.expand_dims([1] * BATCH_SIZE, 1)\n",
    "    \n",
    "    # Teacher forcing - feeding the target as the next input\n",
    "    for t in range(1, targ.shape[1]): # for each vertex (token) from solution (sequence)\n",
    "      # passing enc_output to the decoder\n",
    "      predictions, dec_hidden, _ = decoder(dec_input, dec_hidden)#, enc_output)\n",
    "      loss += loss_function(targ[:, t], predictions)\n",
    "      batch_perplexity *= tf.exp(loss)      \n",
    "\n",
    "      # using teacher forcing\n",
    "      dec_input = tf.expand_dims(targ[:, t], 1)\n",
    "\n",
    "  batch_loss = (loss / int(targ.shape[1]))\n",
    "  variables = decoder.trainable_variables # + encoder.trainable_variables\n",
    "\n",
    "  gradients = tape.gradient(loss, variables)\n",
    "\n",
    "  optimizer.apply_gradients(zip(gradients, variables))\n",
    "  return batch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_dir = './saved_checkpoints/'\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
    "checkpoint = tf.train.Checkpoint(optimizer=optimizer\n",
    "                                # , metrics=perplexity_metric\n",
    "                                #  , encoder=encoder\n",
    "                                 , decoder=decoder)"
   ]
  },
  {
   "source": [
    "### Model Training"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1 Batch 0 Loss 0.0239 Perplexity 1.0242\n",
      "Epoch 2 Batch 0 Loss 0.0222 Perplexity 1.0224\n",
      "Epoch 3 Batch 0 Loss 0.0207 Perplexity 1.0209\n",
      "Epoch 4 Batch 0 Loss 0.0195 Perplexity 1.0197\n",
      "Epoch 5 Batch 0 Loss 0.0189 Perplexity 1.0191\n",
      "Epoch 6 Batch 0 Loss 0.0182 Perplexity 1.0184\n",
      "Epoch 7 Batch 0 Loss 0.0173 Perplexity 1.0175\n",
      "Epoch 8 Batch 0 Loss 0.0168 Perplexity 1.0169\n",
      "Epoch 9 Batch 0 Loss 0.0162 Perplexity 1.0163\n",
      "Epoch 10 Batch 0 Loss 0.0154 Perplexity 1.0156\n",
      "Epoch 11 Batch 0 Loss 0.0149 Perplexity 1.0150\n",
      "Epoch 12 Batch 0 Loss 0.0136 Perplexity 1.0137\n",
      "Epoch 13 Batch 0 Loss 0.0131 Perplexity 1.0132\n",
      "Epoch 14 Batch 0 Loss 0.0132 Perplexity 1.0133\n",
      "Epoch 15 Batch 0 Loss 0.0132 Perplexity 1.0133\n",
      "Epoch 16 Batch 0 Loss 0.0122 Perplexity 1.0123\n",
      "Epoch 17 Batch 0 Loss 0.0107 Perplexity 1.0108\n",
      "Epoch 18 Batch 0 Loss 0.0106 Perplexity 1.0107\n",
      "Epoch 19 Batch 0 Loss 0.0111 Perplexity 1.0111\n",
      "Epoch 20 Batch 0 Loss 0.0101 Perplexity 1.0101\n",
      "Epoch 21 Batch 0 Loss 0.0089 Perplexity 1.0090\n",
      "Epoch 22 Batch 0 Loss 0.0086 Perplexity 1.0086\n",
      "Epoch 23 Batch 0 Loss 0.0082 Perplexity 1.0082\n",
      "Epoch 24 Batch 0 Loss 0.0073 Perplexity 1.0073\n",
      "Epoch 25 Batch 0 Loss 0.0067 Perplexity 1.0067\n",
      "Epoch 26 Batch 0 Loss 0.0062 Perplexity 1.0062\n",
      "Epoch 27 Batch 0 Loss 0.0057 Perplexity 1.0058\n",
      "Epoch 28 Batch 0 Loss 0.0052 Perplexity 1.0053\n",
      "Epoch 29 Batch 0 Loss 0.0049 Perplexity 1.0049\n",
      "Epoch 30 Batch 0 Loss 0.0045 Perplexity 1.0046\n",
      "Epoch 31 Batch 0 Loss 0.0044 Perplexity 1.0044\n",
      "Epoch 32 Batch 0 Loss 0.0040 Perplexity 1.0040\n",
      "Epoch 33 Batch 0 Loss 0.0039 Perplexity 1.0039\n",
      "Epoch 34 Batch 0 Loss 0.0037 Perplexity 1.0037\n",
      "Epoch 35 Batch 0 Loss 0.0034 Perplexity 1.0034\n",
      "Epoch 36 Batch 0 Loss 0.0033 Perplexity 1.0033\n",
      "Epoch 37 Batch 0 Loss 0.0032 Perplexity 1.0032\n",
      "Epoch 38 Batch 0 Loss 0.0030 Perplexity 1.0030\n",
      "Epoch 39 Batch 0 Loss 0.0029 Perplexity 1.0029\n",
      "Epoch 40 Batch 0 Loss 0.0028 Perplexity 1.0028\n",
      "Epoch 41 Batch 0 Loss 0.0027 Perplexity 1.0027\n",
      "Epoch 42 Batch 0 Loss 0.0026 Perplexity 1.0026\n",
      "Epoch 43 Batch 0 Loss 0.0025 Perplexity 1.0025\n",
      "Epoch 44 Batch 0 Loss 0.0024 Perplexity 1.0024\n",
      "Epoch 45 Batch 0 Loss 0.0023 Perplexity 1.0023\n",
      "Epoch 46 Batch 0 Loss 0.0022 Perplexity 1.0022\n",
      "Epoch 47 Batch 0 Loss 0.0022 Perplexity 1.0022\n",
      "Epoch 48 Batch 0 Loss 0.0021 Perplexity 1.0021\n",
      "Epoch 49 Batch 0 Loss 0.0020 Perplexity 1.0020\n",
      "Epoch 50 Batch 0 Loss 0.0020 Perplexity 1.0020\n",
      "saving\n",
      "saved\n",
      "Time taken for 1 epoch 5.757328987121582 sec\n",
      "\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 50\n",
    "for epoch in range(EPOCHS):\n",
    "  start = time.time()\n",
    "  # enc_hidden = encoder.initialize_hidden_state()\n",
    "  total_loss = 0\n",
    "  total_batch_perplexity = 0\n",
    "  for (batch, (feat, targ)) in enumerate(dataset.take(steps_per_epoch)):\n",
    "    # print ('Features: {}, Target: {}'.format(feat, targ))\n",
    "    batch_loss = train_step(feat, targ)#, enc_hidden)\n",
    "    batch_perplexity = tf.exp(batch_loss)\n",
    "\n",
    "    total_loss += batch_loss\n",
    "    total_batch_perplexity += batch_perplexity #perplexity_metric.result()\n",
    "\n",
    "    if batch % 100 == 0:\n",
    "      print('Epoch {} Batch {} Loss {:.4f}'.format(epoch + 1,\n",
    "                                                    batch,\n",
    "                                                    batch_loss.numpy()), end=' ')\n",
    "      print('Perplexity {:.4f}'.format(batch_perplexity))\n",
    "if (epoch + 1) % 2 == 0:\n",
    "  print('saving')\n",
    "  checkpoint.save(file_prefix = checkpoint_prefix)\n",
    "  print('saved')\n",
    "\n",
    "print('Time taken for 1 epoch {} sec\\n'.format(time.time() - start))"
   ]
  },
  {
   "source": [
    "### Model Evaluation"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_task(task_vector):\n",
    "    # either convert to float32 or encode to categoricals\n",
    "    for i, el in enumerate(task_vector):\n",
    "        try:\n",
    "            task_vector[i] = float(task_vector[i])\n",
    "        except:\n",
    "            task_vector[i] = get_key(cat_encodings[i], task_vector[i])\n",
    "    return task_vector.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_task_vector = X.loc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(task_vector):\n",
    "  attention_plot = np.zeros((max_length_targ, max_length_feat))\n",
    "\n",
    "  task_vector = preprocess_task(task_vector)\n",
    "\n",
    "  # inputs = [inp_lang.word_index[i] for i in task_vector.split(' ')]\n",
    "  # inputs = tf.keras.preprocessing.sequence.pad_sequences([inputs],\n",
    "  #                                                        maxlen=max_length_feat,\n",
    "  #                                                        padding='post')\n",
    "  inputs = tf.convert_to_tensor(task_vector) #inputs)\n",
    "\n",
    "  result = ''\n",
    "\n",
    "  # hidden = [tf.zeros((1, units))]\n",
    "  # enc_out, enc_hidden = encoder(inputs, hidden)\n",
    "\n",
    "  dec_hidden = tf.zeros((BATCH_SIZE, units)) #enc_hidden\n",
    "  dec_input = tf.expand_dims([1], 0)\n",
    "\n",
    "  for t in range(max_length_targ):\n",
    "    # print(t, max_length_targ)\n",
    "    predictions, dec_hidden, attention_weights = decoder(dec_input\n",
    "                                                         , dec_hidden,\n",
    "                                                        #  , enc_out\n",
    "                                                         )\n",
    "    \n",
    "    # storing the attention weights to plot later on\n",
    "    attention_weights = tf.reshape(attention_weights, (-1, ))\n",
    "    attention_plot[t] = attention_weights.numpy()\n",
    "    predicted_id = tf.argmax(predictions[0]).numpy()\n",
    "\n",
    "    result = get_key(lang, predicted_id) + ' ' + result #targ_lang.index_word[predicted_id] + ' '\n",
    "\n",
    "    if get_key(lang, predicted_id) == '<start>':\n",
    "      print('Evaluation: found start, ending')\n",
    "      return result, task_vector, attention_plot\n",
    "\n",
    "    # the predicted ID is fed back into the model\n",
    "    dec_input = tf.expand_dims([predicted_id], 0)\n",
    "\n",
    "  return result, task_vector, attention_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Evaluation: found start, ending\nThe number of vertices is: 61 \n\n<start> import_modules load_from_csv show_table show_table_attributes load_from_csv show_table show_table_attributes show_table_attributes show_table_attributes show_table_attributes count_duplicates create_dataframe count_missing_values correct_missing_values count_data_types correct_missing_values count_missing_values correct_missing_values correct_missing_values correct_missing_values correct_missing_values correct_missing_values correct_missing_values correct_missing_values correct_missing_values correct_missing_values correct_missing_values correct_missing_values missing_values count_missing_values correct_missing_values count_data_types correct_missing_values correct_missing_values count_missing_values correct_missing_values missing_values show_table_attributes show_table_attributes concatenate data_types_conversions show_table count_missing_values filter show_table filter distribution normalization split normalization choose_model_class choose_model_class choose_model_class choose_model_class find_best_model_class choose_model_class predict save_to_csv distribution \n"
     ]
    }
   ],
   "source": [
    "result, task_vector, attention_plot = evaluate(example_task_vector)\n",
    "print('The number of vertices is: {} \\n'.format(len(result.split(' '))))\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_FILE = './task2seq/outputs/output.py'\n",
    "with open(OUTPUT_FILE, 'w') as f:\n",
    "    last_vertice = ''\n",
    "    for vertice in result.split(' '):\n",
    "        if vertice:\n",
    "            if (vertice!='<start>')&(vertice!='<end>')&(vertice!=last_vertice):\n",
    "                line = '#@ {} \\n\\n'.format(vertice)\n",
    "                f.write(line)\n",
    "                last_vertice = vertice"
   ]
  },
  {
   "source": [
    "### Metrics"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_scores()"
   ]
  }
 ]
}