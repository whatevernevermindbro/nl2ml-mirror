{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python386jvsc74a57bd00de36b31320ba4c88b4f85a74724f3d16c36a44df48581253710b1065e752d9e",
   "display_name": "Python 3.8.6 64-bit"
  },
  "metadata": {
   "interpreter": {
    "hash": "0de36b31320ba4c88b4f85a74724f3d16c36a44df48581253710b1065e752d9e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import backend as K\n",
    "# from sklearn.preprocessing import LabelEncoder \n",
    "from sqlalchemy import create_engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('mode.chained_assignment', None)"
   ]
  },
  {
   "source": [
    "### Defining Methods"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_key(my_dict, val):\n",
    "    for key, value in my_dict.items():\n",
    "         if val == value:\n",
    "             return key\n",
    " \n",
    "    return \"key doesn't exist\""
   ]
  },
  {
   "source": [
    "### Reading Data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # NEW_NOTEBOOKS_PATH = \"../data/codeblocks_2021-03-31.csv\"\n",
    "# # new_notebooks_1 = pd.read_csv(NEW_NOTEBOOKS_PATH)\n",
    "# # NEW_NOTEBOOKS_PATH = \"../data/codeblocks_2021-04-01.csv\"\n",
    "# # new_notebooks = pd.read_csv(NEW_NOTEBOOKS_PATH)\n",
    "# # new_notebooks = new_notebooks.append(new_notebooks_1)\n",
    "# # new_notebooks.to_csv(\"../data/codeblocks_2021-04-01_concatenated.csv\", index=False)\n",
    "\n",
    "# NEW_NOTEBOOKS_PATH = \"../data/codeblocks_2021-04-01_concatenated.csv\"\n",
    "# new_notebooks = pd.read_csv(NEW_NOTEBOOKS_PATH)\n",
    "# print(new_notebooks.shape, new_notebooks.kaggle_link.nunique())\n",
    "# def clean_comp(string:str) -> str:\n",
    "#     string = string.strip('[').strip(']').strip(\"'\")\n",
    "#     return string\n",
    "# new_notebooks['data_sources'] = new_notebooks['data_sources'].apply(clean_comp)\n",
    "# new_notebooks.rename({'data_sources':'ref'}, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_notebooks.dropna(axis=0, subset=['code_block', 'kaggle_score'], inplace=True)\n",
    "# new_notebooks = new_notebooks[new_notebooks.duplicated() == False]\n",
    "# new_notebooks['ref'] = new_notebooks['ref'].apply(lambda x: x.split(',')[0])\n",
    "# print(new_notebooks['kaggle_link'].nunique(), new_notebooks['ref'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# COMPETITIONS_PATH = \"../data/competitions_info_cleaned.csv\"\n",
    "# competitions = pd.read_csv(COMPETITIONS_PATH)\n",
    "# competitions.drop_duplicates(inplace=True)\n",
    "# competitions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # competitions = competitions[competitions['comp_type'] != 'inClass']\n",
    "# competitions.dropna(axis=0, subset=['Metric'], inplace=True)\n",
    "# competitions.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# notebooks_with_labelling = new_notebooks.merge(competitions, on='ref', how='inner')\n",
    "# print(notebooks_with_labelling.shape, notebooks_with_labelling['kaggle_link'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# competitions['has_notebooks'] = competitions.apply(lambda x: x['ref'] in new_notebooks['ref'].tolist(), axis=1)\n",
    "# competitions_cleaned = competitions[competitions['has_notebooks']]\n",
    "# competitions_cleaned.shape\n",
    "# competitions_cleaned.to_csv('../data/competitions_info_cleaned.csv', index=False)"
   ]
  },
  {
   "source": [
    "---"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mariadb_engine = create_engine(\"mysql+pymysql://root:$a8`k?B2y4nUxX2G@40.119.1.127:32006/nl2ml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# query = \"select * from chunks limit 10000\"\n",
    "# data = pd.read_sql(query, mariadb_engine.raw_connection())\n",
    "# data.shape"
   ]
  },
  {
   "source": [
    "---"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATASETS_PATH = '../data/NL2ML_ structure - data_structure.csv'\n",
    "# datasets = pd.read_csv(DATASETS_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTEBOOKS_PATH = '../data/NL2ML_ structure - levin.csv'\n",
    "# notebooks = pd.read_csv(NOTEBOOKS_PATH, skiprows=1, nrows=96)\n",
    "# notebooks.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Index(['graph_vertex_id', 'graph_vertex', 'graph_vertex_subclass'], dtype='object')"
      ]
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "source": [
    "graph_path = '../data/actual_graph_2021-04-18.csv'\n",
    "graph = pd.read_csv(graph_path)\n",
    "graph.rename({'id':'graph_vertex_id'}, axis=1, inplace=True)\n",
    "graph.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(183, 10)"
      ]
     },
     "metadata": {},
     "execution_count": 27
    }
   ],
   "source": [
    "COMPETITIONS_PATH = \"../data/competitions_2021-04-18.csv\" #./data/competitions_info_cleaned.csv\n",
    "competitions = pd.read_csv(COMPETITIONS_PATH)\n",
    "competitions.drop_duplicates(inplace=True)\n",
    "competitions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   id                                ref                           comp_name  \\\n",
       "0   3              c/us-census-challenge   U.S. Census Return Rate Challenge   \n",
       "1  14                      c/facebook-ii  Facebook II - Mapping the Internet   \n",
       "2  16  c/galaxy-zoo-the-galaxy-challenge   Galaxy Zoo - The Galaxy Challenge   \n",
       "3  22               c/RxVolumePrediction      Prescription Volume Prediction   \n",
       "4  23                  c/yelp-recruiting         Yelp Recruiting Competition   \n",
       "\n",
       "     comp_type                                        description metric  \\\n",
       "0     featured  <p><strong>Note: The prediction phase of this ...  nwmae   \n",
       "1  recruitment  <p><span>For this challenge, potential Faceboo...    auc   \n",
       "2     research  <p>Understanding how and why we are here is on...   rmse   \n",
       "3      masters  <p>This is a private, invitation-only competit...   mcap   \n",
       "4  recruitment  <p>Here at Yelp, we really love the quality of...  rmsle   \n",
       "\n",
       "  datatype subject problemtype            insert_ts  \n",
       "0      NaN     NaN         NaN  2021-03-24 12:07:50  \n",
       "1      NaN     NaN         NaN  2021-03-24 12:07:50  \n",
       "2      NaN     NaN         NaN  2021-03-24 12:07:50  \n",
       "3      NaN     NaN         NaN  2021-03-24 12:07:50  \n",
       "4      NaN     NaN         NaN  2021-03-24 12:07:50  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>ref</th>\n      <th>comp_name</th>\n      <th>comp_type</th>\n      <th>description</th>\n      <th>metric</th>\n      <th>datatype</th>\n      <th>subject</th>\n      <th>problemtype</th>\n      <th>insert_ts</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>3</td>\n      <td>c/us-census-challenge</td>\n      <td>U.S. Census Return Rate Challenge</td>\n      <td>featured</td>\n      <td>&lt;p&gt;&lt;strong&gt;Note: The prediction phase of this ...</td>\n      <td>nwmae</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2021-03-24 12:07:50</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>14</td>\n      <td>c/facebook-ii</td>\n      <td>Facebook II - Mapping the Internet</td>\n      <td>recruitment</td>\n      <td>&lt;p&gt;&lt;span&gt;For this challenge, potential Faceboo...</td>\n      <td>auc</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2021-03-24 12:07:50</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>16</td>\n      <td>c/galaxy-zoo-the-galaxy-challenge</td>\n      <td>Galaxy Zoo - The Galaxy Challenge</td>\n      <td>research</td>\n      <td>&lt;p&gt;Understanding how and why we are here is on...</td>\n      <td>rmse</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2021-03-24 12:07:50</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>22</td>\n      <td>c/RxVolumePrediction</td>\n      <td>Prescription Volume Prediction</td>\n      <td>masters</td>\n      <td>&lt;p&gt;This is a private, invitation-only competit...</td>\n      <td>mcap</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2021-03-24 12:07:50</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>23</td>\n      <td>c/yelp-recruiting</td>\n      <td>Yelp Recruiting Competition</td>\n      <td>recruitment</td>\n      <td>&lt;p&gt;Here at Yelp, we really love the quality of...</td>\n      <td>rmsle</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2021-03-24 12:07:50</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 28
    }
   ],
   "source": [
    "competitions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   code_block_id                                         code_block  \\\n",
       "0         570367  `# My forecasting COVID-19 confirmed cases and...   \n",
       "1         570367  `# My forecasting COVID-19 confirmed cases and...   \n",
       "2         570368  `# load training and testing data \\nsubm = pd....   \n",
       "3         570369                                             `subm`   \n",
       "4         570367  `# My forecasting COVID-19 confirmed cases and...   \n",
       "\n",
       "  data_format  graph_vertex_id errors  marks  kaggle_id  competition_id  \n",
       "0       Table               45     No      2    8591010            4368  \n",
       "1       Table               45     No      2    8591010            4368  \n",
       "2       Table               45     No      5    8591010            4368  \n",
       "3       Table               41     No      5    8591010            4368  \n",
       "4       Table               45     No      2    8591010            4368  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>code_block_id</th>\n      <th>code_block</th>\n      <th>data_format</th>\n      <th>graph_vertex_id</th>\n      <th>errors</th>\n      <th>marks</th>\n      <th>kaggle_id</th>\n      <th>competition_id</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>570367</td>\n      <td>`# My forecasting COVID-19 confirmed cases and...</td>\n      <td>Table</td>\n      <td>45</td>\n      <td>No</td>\n      <td>2</td>\n      <td>8591010</td>\n      <td>4368</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>570367</td>\n      <td>`# My forecasting COVID-19 confirmed cases and...</td>\n      <td>Table</td>\n      <td>45</td>\n      <td>No</td>\n      <td>2</td>\n      <td>8591010</td>\n      <td>4368</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>570368</td>\n      <td>`# load training and testing data \\nsubm = pd....</td>\n      <td>Table</td>\n      <td>45</td>\n      <td>No</td>\n      <td>5</td>\n      <td>8591010</td>\n      <td>4368</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>570369</td>\n      <td>`subm`</td>\n      <td>Table</td>\n      <td>41</td>\n      <td>No</td>\n      <td>5</td>\n      <td>8591010</td>\n      <td>4368</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>570367</td>\n      <td>`# My forecasting COVID-19 confirmed cases and...</td>\n      <td>Table</td>\n      <td>45</td>\n      <td>No</td>\n      <td>2</td>\n      <td>8591010</td>\n      <td>4368</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 22
    }
   ],
   "source": [
    "NOTEBOOKS_PATH = '../data/markup_data_2021-04-18.csv'\n",
    "notebooks = pd.read_csv(NOTEBOOKS_PATH)\n",
    "notebooks.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Index(['code_block_id', 'code_block', 'data_format', 'graph_vertex_id',\n",
       "       'errors', 'marks', 'kaggle_id', 'competition_id', 'graph_vertex',\n",
       "       'graph_vertex_subclass'],\n",
       "      dtype='object')"
      ]
     },
     "metadata": {},
     "execution_count": 23
    }
   ],
   "source": [
    "notebooks = notebooks.merge(graph, on='graph_vertex_id', how='left')\n",
    "notebooks.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   code_block_id                                         code_block  \\\n",
       "0         570367  `# My forecasting COVID-19 confirmed cases and...   \n",
       "1         570367  `# My forecasting COVID-19 confirmed cases and...   \n",
       "\n",
       "  data_format  graph_vertex_id errors  marks  kaggle_id  competition_id  \\\n",
       "0       Table               45     No      2    8591010            4368   \n",
       "1       Table               45     No      2    8591010            4368   \n",
       "\n",
       "      graph_vertex graph_vertex_subclass    id  \\\n",
       "0  Data_Extraction         load_from_csv  4368   \n",
       "1  Data_Extraction         load_from_csv  4368   \n",
       "\n",
       "                                   ref                            comp_name  \\\n",
       "0  c/covid19-global-forecasting-week-2  COVID19 Global Forecasting (Week 2)   \n",
       "1  c/covid19-global-forecasting-week-2  COVID19 Global Forecasting (Week 2)   \n",
       "\n",
       "  comp_type                                        description   metric  \\\n",
       "0  research  **[This week 2 forecasting task is now closed ...  mcrmsle   \n",
       "1  research  **[This week 2 forecasting task is now closed ...  mcrmsle   \n",
       "\n",
       "       datatype   subject problemtype            insert_ts  \n",
       "0  tabular data   covid19         NaN  2021-03-24 12:07:50  \n",
       "1  tabular data   covid19         NaN  2021-03-24 12:07:50  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>code_block_id</th>\n      <th>code_block</th>\n      <th>data_format</th>\n      <th>graph_vertex_id</th>\n      <th>errors</th>\n      <th>marks</th>\n      <th>kaggle_id</th>\n      <th>competition_id</th>\n      <th>graph_vertex</th>\n      <th>graph_vertex_subclass</th>\n      <th>id</th>\n      <th>ref</th>\n      <th>comp_name</th>\n      <th>comp_type</th>\n      <th>description</th>\n      <th>metric</th>\n      <th>datatype</th>\n      <th>subject</th>\n      <th>problemtype</th>\n      <th>insert_ts</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>570367</td>\n      <td>`# My forecasting COVID-19 confirmed cases and...</td>\n      <td>Table</td>\n      <td>45</td>\n      <td>No</td>\n      <td>2</td>\n      <td>8591010</td>\n      <td>4368</td>\n      <td>Data_Extraction</td>\n      <td>load_from_csv</td>\n      <td>4368</td>\n      <td>c/covid19-global-forecasting-week-2</td>\n      <td>COVID19 Global Forecasting (Week 2)</td>\n      <td>research</td>\n      <td>**[This week 2 forecasting task is now closed ...</td>\n      <td>mcrmsle</td>\n      <td>tabular data</td>\n      <td>covid19</td>\n      <td>NaN</td>\n      <td>2021-03-24 12:07:50</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>570367</td>\n      <td>`# My forecasting COVID-19 confirmed cases and...</td>\n      <td>Table</td>\n      <td>45</td>\n      <td>No</td>\n      <td>2</td>\n      <td>8591010</td>\n      <td>4368</td>\n      <td>Data_Extraction</td>\n      <td>load_from_csv</td>\n      <td>4368</td>\n      <td>c/covid19-global-forecasting-week-2</td>\n      <td>COVID19 Global Forecasting (Week 2)</td>\n      <td>research</td>\n      <td>**[This week 2 forecasting task is now closed ...</td>\n      <td>mcrmsle</td>\n      <td>tabular data</td>\n      <td>covid19</td>\n      <td>NaN</td>\n      <td>2021-03-24 12:07:50</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 29
    }
   ],
   "source": [
    "nl2ml = notebooks.merge(competitions, left_on=['competition_id'], right_on=['id'], how='left')\n",
    "nl2ml.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nl2ml = notebooks.merge(datasets, on=['dataset_id'], how='left')\n",
    "# nl2ml.head(2)"
   ]
  },
  {
   "source": [
    "### Vertices Preprocessing"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Data_Transform          786\n",
       "EDA                     596\n",
       "Model_Train             255\n",
       "Visualization           199\n",
       "Environment             185\n",
       "Data_Extraction         152\n",
       "Hyperparam_Tuning       126\n",
       "Other                   122\n",
       "Data_Export              98\n",
       "Model_Evaluation         68\n",
       "Model_Interpretation     20\n",
       "Hypothesis                3\n",
       "Name: graph_vertex, dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 30
    }
   ],
   "source": [
    "nl2ml['graph_vertex'].apply(lambda x: x.split(';')[0].split('.')[0]).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Index(['code_block_id', 'code_block', 'data_format', 'graph_vertex_id',\n",
       "       'errors', 'marks', 'kaggle_id', 'competition_id', 'graph_vertex',\n",
       "       'graph_vertex_subclass', 'id', 'ref', 'comp_name', 'comp_type',\n",
       "       'description', 'metric', 'datatype', 'subject', 'problemtype',\n",
       "       'insert_ts'],\n",
       "      dtype='object')"
      ]
     },
     "metadata": {},
     "execution_count": 31
    }
   ],
   "source": [
    "nl2ml.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "nl2ml['vertex_l1'], nl2ml['vertex_l2'] = nl2ml['graph_vertex'].apply(lambda x: x.split(';')[0].split('.')[0]), nl2ml['graph_vertex_subclass']#.apply(lambda x: x.split(';')[0].split('.')[1])"
   ]
  },
  {
   "source": [
    "### Missing Values"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "nl2ml.replace('-', -1, inplace=True)\n",
    "nl2ml.fillna(-1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "TASK_FEATURES = ['comp_name', 'comp_type', 'description',\n",
    "                'metric', 'datatype', 'subject', 'problemtype']\n",
    "# TASK_FEATURES = ['ProblemType',\n",
    "#                 'number of columns (for tabular)', 'number of entries',\n",
    "#                 'LabelType', 'Number of classes', 'Loss Function/Metrics',\n",
    "#                 'Target Column(s) Name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET_COLUMN = 'vertex_l2'"
   ]
  },
  {
   "source": [
    "### Grouping chunks by notebooks"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "notebook_id_col = 'kaggle_id'\n",
    "def group_by_notebooks(data:pd.DataFrame, vertex_col:str='vertex_l1') -> pd.DataFrame:\n",
    "    notebook_cols = [[notebook_id_col, vertex_col] + TASK_FEATURES]\n",
    "    df = pd.DataFrame(columns=notebook_cols)\n",
    "    for i, notebook_id in enumerate(data[notebook_id_col].unique()):\n",
    "        notebook = data[data[notebook_id_col] == notebook_id].reset_index(drop=True)\n",
    "        vertices_seq = \" \".join(notebook[vertex_col])\n",
    "        task_features = notebook[TASK_FEATURES].loc[0]\n",
    "        row = [notebook_id, vertices_seq] + task_features.tolist()\n",
    "        df.loc[i] = row\n",
    "        print('notebook #{} done'.format(notebook_id))\n",
    "    return df"
   ]
  },
  {
   "source": [
    "### Taking Train Features"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "notebook #8591010 done\n",
      "notebook #8592598 done\n",
      "notebook #8596735 done\n",
      "notebook #8606894 done\n",
      "notebook #8609050 done\n",
      "notebook #8611767 done\n",
      "notebook #8630977 done\n",
      "notebook #8634286 done\n",
      "notebook #8640194 done\n",
      "notebook #8660923 done\n",
      "notebook #8667455 done\n",
      "notebook #8668446 done\n",
      "notebook #8678201 done\n",
      "notebook #8687334 done\n",
      "notebook #8689318 done\n",
      "notebook #8699382 done\n",
      "notebook #8705213 done\n",
      "notebook #8706858 done\n",
      "notebook #8708118 done\n",
      "notebook #8710137 done\n",
      "notebook #8710362 done\n",
      "notebook #138832 done\n",
      "notebook #2637869 done\n",
      "notebook #5466844 done\n",
      "notebook #5729566 done\n",
      "notebook #6470191 done\n",
      "notebook #8382140 done\n",
      "notebook #9655329 done\n",
      "notebook #10424951 done\n",
      "notebook #10522332 done\n",
      "notebook #10702707 done\n",
      "notebook #10913030 done\n",
      "notebook #11097956 done\n",
      "notebook #11410370 done\n",
      "notebook #11611498 done\n",
      "notebook #11656525 done\n",
      "notebook #12034947 done\n",
      "notebook #12343159 done\n",
      "notebook #13503938 done\n",
      "notebook #14177670 done\n",
      "notebook #8604602 done\n",
      "notebook #8617043 done\n",
      "notebook #8620454 done\n",
      "notebook #8625834 done\n",
      "notebook #8628909 done\n",
      "notebook #8658083 done\n",
      "notebook #8663175 done\n",
      "notebook #8671133 done\n",
      "notebook #8679319 done\n",
      "notebook #8682800 done\n",
      "notebook #8687249 done\n",
      "notebook #8693806 done\n",
      "notebook #8701862 done\n",
      "notebook #8702904 done\n",
      "notebook #8706295 done\n",
      "notebook #8711165 done\n",
      "notebook #9326374 done\n",
      "notebook #9349764 done\n",
      "notebook #9463384 done\n",
      "notebook #171635 done\n",
      "notebook #2843645 done\n",
      "notebook #2846432 done\n",
      "notebook #2874738 done\n",
      "notebook #2894439 done\n",
      "notebook #2895967 done\n",
      "notebook #2897818 done\n",
      "notebook #2942474 done\n",
      "notebook #3001116 done\n",
      "notebook #3065122 done\n",
      "notebook #3127294 done\n",
      "notebook #3155308 done\n",
      "notebook #3308267 done\n",
      "notebook #3338077 done\n",
      "notebook #3412975 done\n",
      "notebook #3424825 done\n",
      "notebook #3544896 done\n",
      "notebook #3577796 done\n",
      "notebook #3640289 done\n",
      "notebook #3663832 done\n",
      "notebook #11400829 done\n",
      "notebook #24315 done\n",
      "notebook #242408 done\n",
      "notebook #243149 done\n",
      "notebook #244547 done\n",
      "notebook #244742 done\n",
      "notebook #244890 done\n",
      "notebook #244905 done\n",
      "notebook #244962 done\n",
      "notebook #245675 done\n",
      "notebook #460165 done\n",
      "notebook #465088 done\n",
      "notebook #481205 done\n",
      "notebook #493112 done\n",
      "notebook #502587 done\n",
      "notebook #505287 done\n",
      "notebook #510995 done\n",
      "notebook #524817 done\n",
      "notebook #541325 done\n",
      "notebook #548489 done\n",
      "notebook #567131 done\n",
      "notebook #582222 done\n",
      "notebook #874590 done\n",
      "notebook #1140262 done\n"
     ]
    }
   ],
   "source": [
    "train = group_by_notebooks(nl2ml, TARGET_COLUMN)\n",
    "X, y = train[TASK_FEATURES], train[TARGET_COLUMN]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "  kaggle_id                                          vertex_l2  \\\n",
       "0   8591010  load_from_csv load_from_csv load_from_csv show...   \n",
       "1   8592598  import_modules compute_train_metric load_from_csv   \n",
       "2   8596735  import_modules import_modules load_from_csv sh...   \n",
       "3   8606894                       import_modules load_from_csv   \n",
       "4   8609050  import_modules load_from_csv something_strange...   \n",
       "\n",
       "                             comp_name comp_type  \\\n",
       "0  COVID19 Global Forecasting (Week 2)  research   \n",
       "1  COVID19 Global Forecasting (Week 2)  research   \n",
       "2  COVID19 Global Forecasting (Week 2)  research   \n",
       "3  COVID19 Global Forecasting (Week 2)  research   \n",
       "4  COVID19 Global Forecasting (Week 2)  research   \n",
       "\n",
       "                                         description   metric      datatype  \\\n",
       "0  **[This week 2 forecasting task is now closed ...  mcrmsle  tabular data   \n",
       "1  **[This week 2 forecasting task is now closed ...  mcrmsle  tabular data   \n",
       "2  **[This week 2 forecasting task is now closed ...  mcrmsle  tabular data   \n",
       "3  **[This week 2 forecasting task is now closed ...  mcrmsle  tabular data   \n",
       "4  **[This week 2 forecasting task is now closed ...  mcrmsle  tabular data   \n",
       "\n",
       "    subject problemtype  \n",
       "0   covid19          -1  \n",
       "1   covid19          -1  \n",
       "2   covid19          -1  \n",
       "3   covid19          -1  \n",
       "4   covid19          -1  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead tr th {\n        text-align: left;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr>\n      <th></th>\n      <th>kaggle_id</th>\n      <th>vertex_l2</th>\n      <th>comp_name</th>\n      <th>comp_type</th>\n      <th>description</th>\n      <th>metric</th>\n      <th>datatype</th>\n      <th>subject</th>\n      <th>problemtype</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>8591010</td>\n      <td>load_from_csv load_from_csv load_from_csv show...</td>\n      <td>COVID19 Global Forecasting (Week 2)</td>\n      <td>research</td>\n      <td>**[This week 2 forecasting task is now closed ...</td>\n      <td>mcrmsle</td>\n      <td>tabular data</td>\n      <td>covid19</td>\n      <td>-1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>8592598</td>\n      <td>import_modules compute_train_metric load_from_csv</td>\n      <td>COVID19 Global Forecasting (Week 2)</td>\n      <td>research</td>\n      <td>**[This week 2 forecasting task is now closed ...</td>\n      <td>mcrmsle</td>\n      <td>tabular data</td>\n      <td>covid19</td>\n      <td>-1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>8596735</td>\n      <td>import_modules import_modules load_from_csv sh...</td>\n      <td>COVID19 Global Forecasting (Week 2)</td>\n      <td>research</td>\n      <td>**[This week 2 forecasting task is now closed ...</td>\n      <td>mcrmsle</td>\n      <td>tabular data</td>\n      <td>covid19</td>\n      <td>-1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>8606894</td>\n      <td>import_modules load_from_csv</td>\n      <td>COVID19 Global Forecasting (Week 2)</td>\n      <td>research</td>\n      <td>**[This week 2 forecasting task is now closed ...</td>\n      <td>mcrmsle</td>\n      <td>tabular data</td>\n      <td>covid19</td>\n      <td>-1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>8609050</td>\n      <td>import_modules load_from_csv something_strange...</td>\n      <td>COVID19 Global Forecasting (Week 2)</td>\n      <td>research</td>\n      <td>**[This week 2 forecasting task is now closed ...</td>\n      <td>mcrmsle</td>\n      <td>tabular data</td>\n      <td>covid19</td>\n      <td>-1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 58
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(103, 9)"
      ]
     },
     "metadata": {},
     "execution_count": 51
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "source": [
    "### Converting Dtypes"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_encodings = {}\n",
    "for i, col in enumerate(X.columns):\n",
    "    try:\n",
    "        X[col] =  X[col].astype('float32')\n",
    "    except:\n",
    "        X[col] = pd.Categorical(X[col])\n",
    "        cat_encodings.update({i:dict(enumerate(X[col].cat.categories))})\n",
    "        X[col] = X[col].cat.codes"
   ]
  },
  {
   "source": [
    "### Target Preprocessing: Encoding Vertices"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "lang = {vertice:i+2 for i, vertice in enumerate(nl2ml[TARGET_COLUMN].unique())} #TODO: save the dict as a local file\n",
    "lang.update({'<start>':1, '<end>':max(lang.values())+1})\n",
    "def encode_vertices(vertices_seq, lang:dict=lang):\n",
    "    encoded = np.append(np.flip(np.array([lang[vertex] for vertex in vertices_seq[0].split(' ')] + [lang['<end>']])), lang['<start>'])\n",
    "    return encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0      [54, 4, 3, 16, 15, 13, 15, 15, 11, 12, 15, 13,...\n",
       "1                                       [54, 2, 7, 5, 1]\n",
       "2      [54, 16, 3, 21, 26, 26, 3, 3, 7, 15, 14, 3, 4,...\n",
       "3                                          [54, 2, 5, 1]\n",
       "4      [54, 16, 8, 26, 11, 30, 5, 17, 17, 29, 25, 17,...\n",
       "                             ...                        \n",
       "98              [54, 3, 3, 22, 22, 22, 22, 22, 44, 5, 1]\n",
       "99           [54, 3, 16, 22, 22, 22, 22, 7, 22, 5, 5, 1]\n",
       "100    [54, 16, 3, 34, 3, 3, 28, 11, 12, 9, 23, 8, 19...\n",
       "101    [54, 17, 17, 16, 15, 36, 35, 11, 14, 14, 17, 3...\n",
       "102               [54, 42, 4, 3, 3, 4, 3, 3, 2, 8, 5, 1]\n",
       "Length: 103, dtype: object"
      ]
     },
     "metadata": {},
     "execution_count": 61
    }
   ],
   "source": [
    "y.apply(encode_vertices, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X['vertex_l2'] = y.apply(encode_vertices, axis=1)\n",
    "# X.to_csv('../data/nl2ml_train_example.csv', index=False)"
   ]
  },
  {
   "source": [
    "### Target Preprocessing: Padding Sequences"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = tf.keras.preprocessing.sequence.pad_sequences(y.apply(encode_vertices, axis=1))"
   ]
  },
  {
   "source": [
    "### Defining Constants"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BUFFER_SIZE = len(input_tensor_train)\n",
    "BATCH_SIZE = 1\n",
    "steps_per_epoch = len(X)//BATCH_SIZE\n",
    "embedding_dim = 128\n",
    "units = 512\n",
    "# vocab_inp_size = len(inp_lang.word_index) + 1\n",
    "# vocab_tar_size = len(targ_lang.word_index) + 1"
   ]
  },
  {
   "source": [
    "### Creating tf.Dataset"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices((X.values, Y))\n",
    "dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length_targ, max_length_feat = Y.shape[1], X.values.shape[1]"
   ]
  },
  {
   "source": [
    "### Building the Model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://machinelearningmastery.com/text-generation-lstm-recurrent-neural-networks-python-keras/\n",
    "# https://www.tensorflow.org/tutorials/text/text_generation\n",
    "# https://www.tensorflow.org/guide/keras/rnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.Model):\n",
    "  def __init__(self, vocab_size, embedding_dim, dec_units, batch_sz):\n",
    "    super(Decoder, self).__init__()\n",
    "    self.batch_sz = batch_sz\n",
    "    self.dec_units = dec_units\n",
    "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "    # self.hidden_embedding = tf.keras.layers.Embedding(vocab_size, 1)\n",
    "    self.gru = tf.keras.layers.GRU(self.dec_units,\n",
    "                                   return_sequences=True,\n",
    "                                   return_state=True,\n",
    "                                   recurrent_initializer='glorot_uniform')\n",
    "    self.fc = tf.keras.layers.Dense(vocab_size)\n",
    "\n",
    "    # used for attention\n",
    "    # self.attention = BahdanauAttention(self.dec_units)\n",
    "\n",
    "  def call(self, x, hidden):#, enc_output):\n",
    "    # enc_output shape == (batch_size, max_length, hidden_size)\n",
    "    # context_vector, attention_weights = self.attention(hidden, enc_output)\n",
    "    attention_weights = tf.ones(x.shape)\n",
    "    # context_vector = tf.ones(x.shape)\n",
    "    # print(\"X Vector has {} type and {} shape\".format(type(x), x.shape))\n",
    "    # print(\"Context Vector has {} type and {} shape\".format(type(context_vector), context_vector.shape))\n",
    "    # print(\"Attention Vector has {} type and {} shape\".format(type(context_vector), context_vector.shape))\n",
    "    # x shape after passing through embedding == (batch_size, 1, embedding_dim)\n",
    "    x = self.embedding(x)\n",
    "    # x = tf.squeeze(self.hidden_embedding(x), axis=-1)\n",
    "    # x shape after concatenation == (batch_size, 1, embedding_dim + hidden_size)\n",
    "    # x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1)\n",
    "\n",
    "    # passing the concatenated vector to the GRU\n",
    "    output, state = self.gru(x, initial_state=hidden)\n",
    "\n",
    "    # output shape == (batch_size * 1, hidden_size)\n",
    "    output = tf.reshape(output, (-1, output.shape[2]))\n",
    "\n",
    "    # output shape == (batch_size, vocab)\n",
    "    x = self.fc(output)\n",
    "\n",
    "    return x, state, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Decoder output shape: (batch_size, vocab size) (1, 56)\nModel: \"decoder\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nembedding (Embedding)        multiple                  7168      \n_________________________________________________________________\ngru (GRU)                    multiple                  986112    \n_________________________________________________________________\ndense (Dense)                multiple                  28728     \n=================================================================\nTotal params: 1,022,008\nTrainable params: 1,022,008\nNon-trainable params: 0\n_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "decoder = Decoder(len(lang)+2, embedding_dim, units, BATCH_SIZE)\n",
    "sample_hidden = tf.zeros((BATCH_SIZE, units))\n",
    "sample_decoder_output, _, _ = decoder(tf.random.uniform((BATCH_SIZE, 1))\n",
    "                                      , sample_hidden\n",
    "                                    #   , sample_output\n",
    "                                    )\n",
    "print ('Decoder output shape: (batch_size, vocab size) {}'.format(sample_decoder_output.shape))\n",
    "decoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam()\n",
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "                  from_logits=True, reduction='none')\n",
    "\n",
    "def loss_function(real, pred):\n",
    "  mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "  loss_ = loss_object(real, pred)\n",
    "\n",
    "  mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "  loss_ *= mask\n",
    "\n",
    "  return tf.reduce_mean(loss_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def compute_bleu(reference_corpus, translation_corpus, max_order=4,\n",
    "#                  smooth=False):\n",
    "#   \"\"\"Computes BLEU score of translated segments against one or more references.\n",
    "#   Args:\n",
    "#     reference_corpus: list of lists of references for each translation. Each\n",
    "#         reference should be tokenized into a list of tokens.\n",
    "#     translation_corpus: list of translations to score. Each translation\n",
    "#         should be tokenized into a list of tokens.\n",
    "#     max_order: Maximum n-gram order to use when computing BLEU score.\n",
    "#     smooth: Whether or not to apply Lin et al. 2004 smoothing.\n",
    "#   Returns:\n",
    "#     3-Tuple with the BLEU score, n-gram precisions, geometric mean of n-gram\n",
    "#     precisions and brevity penalty.\n",
    "#   \"\"\"\n",
    "#   matches_by_order = [0] * max_order\n",
    "#   possible_matches_by_order = [0] * max_order\n",
    "#   reference_length = 0\n",
    "#   translation_length = 0\n",
    "#   for (references, translation) in zip(reference_corpus,\n",
    "#                                        translation_corpus):\n",
    "#     reference_length += min(len(r) for r in references)\n",
    "#     translation_length += len(translation)\n",
    "\n",
    "#     merged_ref_ngram_counts = collections.Counter()\n",
    "#     for reference in references:\n",
    "#       merged_ref_ngram_counts |= _get_ngrams(reference, max_order)\n",
    "#     translation_ngram_counts = _get_ngrams(translation, max_order)\n",
    "#     overlap = translation_ngram_counts & merged_ref_ngram_counts\n",
    "#     for ngram in overlap:\n",
    "#       matches_by_order[len(ngram)-1] += overlap[ngram]\n",
    "#     for order in range(1, max_order+1):\n",
    "#       possible_matches = len(translation) - order + 1\n",
    "#       if possible_matches > 0:\n",
    "#         possible_matches_by_order[order-1] += possible_matches\n",
    "\n",
    "#   precisions = [0] * max_order\n",
    "#   for i in range(0, max_order):\n",
    "#     if smooth:\n",
    "#       precisions[i] = ((matches_by_order[i] + 1.) /\n",
    "#                        (possible_matches_by_order[i] + 1.))\n",
    "#     else:\n",
    "#       if possible_matches_by_order[i] > 0:\n",
    "#         precisions[i] = (float(matches_by_order[i]) /\n",
    "#                          possible_matches_by_order[i])\n",
    "#       else:\n",
    "#         precisions[i] = 0.0\n",
    "\n",
    "#   if min(precisions) > 0:\n",
    "#     p_log_sum = sum((1. / max_order) * math.log(p) for p in precisions)\n",
    "#     geo_mean = math.exp(p_log_sum)\n",
    "#   else:\n",
    "#     geo_mean = 0\n",
    "\n",
    "#   ratio = float(translation_length) / reference_length\n",
    "\n",
    "#   if ratio > 1.0:\n",
    "#     bp = 1.\n",
    "#   else:\n",
    "#     bp = math.exp(1 - 1. / ratio)\n",
    "\n",
    "#   bleu = geo_mean * bp\n",
    "\n",
    "#   return (bleu, precisions, bp, ratio, translation_length, reference_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class PerplexityMetric(tf.keras.metrics.Metric):\n",
    "#     ##TODO: calculate perplexity for one example\n",
    "#     # average for batch\n",
    "#     # average for epoch\n",
    "#     \"\"\"\n",
    "#     USAGE NOTICE: this metric accepts only logits for now (i.e. expect the same behaviour as from tf.keras.losses.SparseCategoricalCrossentropy with the a provided argument \"from_logits=True\", \n",
    "# \t\there the same loss is used with \"from_logits=True\" enforced so you need to provide it in such a format)\n",
    "#     METRIC DESCRIPTION:\n",
    "#     Popular metric for evaluating language modelling architectures.\n",
    "#     More info: http://cs224d.stanford.edu/lecture_notes/LectureNotes4.pdf.\n",
    "#     DISCLAIMER: Original function created by Kirill Mavreshko in https://github.com/kpot/keras-transformer/blob/b9d4e76c535c0c62cadc73e37416e4dc18b635ca/example/run_gpt.py#L106. \n",
    "#     My \"contribution\": I converted Kirill method's logic (and added a padding masking to to it) into this new Tensorflow 2.0 way of doing things via a stateful \"Metric\" object. This required making the metric a fully-fledged object by subclassing      the Metric class. \n",
    "#     \"\"\"\n",
    "#     def __init__(self, name='perplexity', **kwargs):\n",
    "#       super(PerplexityMetric, self).__init__(name=name, **kwargs)\n",
    "#       self.cross_entropy = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False, reduction='none')\n",
    "#       # self.cross_entropy = tf.keras.losses.CategoricalCrossentropy(from_logits=False, reduction='none')\n",
    "#       self.perplexity = self.add_weight(name='tp', initializer='ones') #tf.math.multiply(1, 1)\n",
    "# \t\t# Consider uncommenting the decorator for a performance boost (?)  \t\t\n",
    "#     # @tf.function\n",
    "#     def _calculate_perplexity(self, real, pred):\n",
    "# \t\t\t# The next 4 lines zero-out the padding from loss calculations, \n",
    "# \t\t\t# this follows the logic from: https://www.tensorflow.org/beta/tutorials/text/transformer#loss_and_metrics \t\t\t\n",
    "#       mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "#       loss_ = self.cross_entropy(real, pred)\n",
    "#       mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "#       loss_ *= mask\n",
    "# \t\t\t# Calculating the perplexity steps:\n",
    "#       step1 = K.mean(loss_, axis=0)#axis=-1)\n",
    "#       step2 = K.exp(step1)\n",
    "#       perplexity = K.mean(step2)\n",
    "#       return perplexity\n",
    "\n",
    "#     def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "#       # TODO:FIXME: handle sample_weight !\n",
    "#       if sample_weight is not None:\n",
    "#           print(\"WARNING! Provided 'sample_weight' argument to the perplexity metric. Currently this is not handled and won't do anything differently..\")\n",
    "#       cur_perplexity = self._calculate_perplexity(y_true, y_pred)\n",
    "# \t\t\t# Remember self.perplexity is a tensor (tf.Variable), so using simply \"self.perplexity = perplexity\" will result in error because of mixing EagerTensor and Graph operations \n",
    "#       # self.perplexity.assign_add(cur_perplexity)\n",
    "#       # print('cur_perplexity: {}'.format(cur_perplexity))\n",
    "#       # print('self.perplexity: {}'.format(self.perplexity))\n",
    "#       # print('mul : {}'.format(tf.math.multiply(self.perplexity, cur_perplexity)))\n",
    "#       self.perplexity.assign(tf.math.multiply(self.perplexity, cur_perplexity))\n",
    "#       # self.perplexity = tf.math.multiply(self.perplexity, cur_perplexity) ##TODO\n",
    "#       # print('current perplexity is: {}'.format(self.perplexity))\n",
    "\n",
    "#     def result(self):\n",
    "#       return self.perplexity\n",
    "\n",
    "#     def reset_states(self):\n",
    "#       # The state of the metric will be reset at the start of each epoch.\n",
    "#       self.perplexity.assign(1.0) # = tf.math.multiply(1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(inp, targ):#, enc_hidden):\n",
    "  loss = 0\n",
    "  batch_perplexity = 1\n",
    "  with tf.GradientTape() as tape:\n",
    "    # enc_output, enc_hidden = encoder(inp, enc_hidden)\n",
    "\n",
    "    dec_hidden = tf.zeros((BATCH_SIZE, units)) #enc_hidden\n",
    "\n",
    "    dec_input = tf.expand_dims([1] * BATCH_SIZE, 1)\n",
    "    \n",
    "    # Teacher forcing - feeding the target as the next input\n",
    "    for t in range(1, targ.shape[1]): # for each vertex (token) from solution (sequence)\n",
    "      # passing enc_output to the decoder\n",
    "      predictions, dec_hidden, _ = decoder(dec_input, dec_hidden)#, enc_output)\n",
    "      loss += loss_function(targ[:, t], predictions)\n",
    "      batch_perplexity *= tf.exp(loss)      \n",
    "\n",
    "      # using teacher forcing\n",
    "      dec_input = tf.expand_dims(targ[:, t], 1)\n",
    "\n",
    "  batch_loss = (loss / int(targ.shape[1]))\n",
    "  variables = decoder.trainable_variables # + encoder.trainable_variables\n",
    "\n",
    "  gradients = tape.gradient(loss, variables)\n",
    "\n",
    "  optimizer.apply_gradients(zip(gradients, variables))\n",
    "  return batch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_dir = './task2seq_checkpoints/'\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
    "checkpoint = tf.train.Checkpoint(optimizer=optimizer\n",
    "                                # , metrics=perplexity_metric\n",
    "                                #  , encoder=encoder\n",
    "                                 , decoder=decoder)"
   ]
  },
  {
   "source": [
    "### Model Training"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "EPOCHS = 50\n",
    "for epoch in range(EPOCHS):\n",
    "  start = time.time()\n",
    "  # enc_hidden = encoder.initialize_hidden_state()\n",
    "  total_loss = 0\n",
    "  total_batch_perplexity = 0\n",
    "  for (batch, (feat, targ)) in enumerate(dataset.take(steps_per_epoch)):\n",
    "    # print ('Features: {}, Target: {}'.format(feat, targ))\n",
    "    batch_loss = train_step(feat, targ)#, enc_hidden)\n",
    "    batch_perplexity = tf.exp(batch_loss)\n",
    "\n",
    "    total_loss += batch_loss\n",
    "    total_batch_perplexity += batch_perplexity #perplexity_metric.result()\n",
    "\n",
    "    if batch % 100 == 0:\n",
    "      print('Epoch {} Batch {} Loss {:.4f}'.format(epoch + 1,\n",
    "                                                    batch,\n",
    "                                                    batch_loss.numpy()), end=' ')\n",
    "      print('Perplexity {:.4f}'.format(batch_perplexity))\n",
    "if (epoch + 1) % 2 == 0:\n",
    "  print('saving')\n",
    "  checkpoint.save(file_prefix = checkpoint_prefix)\n",
    "  print('saved')\n",
    "\n",
    "print('Time taken for 1 epoch {} sec\\n'.format(time.time() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "OpError",
     "evalue": "",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\tensorflow\\python\\training\\py_checkpoint_reader.py\u001b[0m in \u001b[0;36mNewCheckpointReader\u001b[1;34m(filepattern)\u001b[0m\n\u001b[0;32m     94\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 95\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mCheckpointReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_bytes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepattern\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     96\u001b[0m   \u001b[1;31m# TODO(b/143319754): Remove the RuntimeError casting logic once we resolve the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mOpError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-78-cd533d7dff1a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mcheckpoint\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'./task2seq/task2seq_checkpoints/'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\util.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, save_path, options)\u001b[0m\n\u001b[0;32m   2146\u001b[0m     \"\"\"\n\u001b[0;32m   2147\u001b[0m     \u001b[0moptions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moptions\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mcheckpoint_options\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCheckpointOptions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2148\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_saver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrestore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msave_path\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msave_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2149\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2150\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mrestore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msave_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\util.py\u001b[0m in \u001b[0;36mrestore\u001b[1;34m(self, save_path, options)\u001b[0m\n\u001b[0;32m   1290\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0msave_path\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1291\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mInitializationOnlyStatus\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_graph_view\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1292\u001b[1;33m     \u001b[0mreader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpy_checkpoint_reader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mNewCheckpointReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msave_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1293\u001b[0m     \u001b[0mgraph_building\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1294\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mgraph_building\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\tensorflow\\python\\training\\py_checkpoint_reader.py\u001b[0m in \u001b[0;36mNewCheckpointReader\u001b[1;34m(filepattern)\u001b[0m\n\u001b[0;32m     97\u001b[0m   \u001b[1;31m# issue with throwing python exceptions from C++.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     98\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mRuntimeError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 99\u001b[1;33m     \u001b[0merror_translator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\tensorflow\\python\\training\\py_checkpoint_reader.py\u001b[0m in \u001b[0;36merror_translator\u001b[1;34m(e)\u001b[0m\n\u001b[0;32m     46\u001b[0m     \u001b[1;32mraise\u001b[0m \u001b[0merrors_impl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mInternalError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merror_message\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m   \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 48\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0merrors_impl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merror_message\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors_impl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mUNKNOWN\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     49\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mOpError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# checkpoint.read('./task2seq/task2seq_checkpoints/')"
   ]
  },
  {
   "source": [
    "### Model Evaluation"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_task(task_vector):\n",
    "    # either convert to float32 or encode to categoricals\n",
    "    for i, el in enumerate(task_vector):\n",
    "        try:\n",
    "            task_vector[i] = float(task_vector[i])\n",
    "        except:\n",
    "            task_vector[i] = get_key(cat_encodings[i], task_vector[i])\n",
    "    return task_vector.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_task_vector = X.loc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(task_vector):\n",
    "  attention_plot = np.zeros((max_length_targ, max_length_feat))\n",
    "\n",
    "  task_vector = preprocess_task(task_vector)\n",
    "\n",
    "  # inputs = [inp_lang.word_index[i] for i in task_vector.split(' ')]\n",
    "  # inputs = tf.keras.preprocessing.sequence.pad_sequences([inputs],\n",
    "  #                                                        maxlen=max_length_feat,\n",
    "  #                                                        padding='post')\n",
    "  inputs = tf.convert_to_tensor(task_vector) #inputs)\n",
    "\n",
    "  result = ''\n",
    "\n",
    "  # hidden = [tf.zeros((1, units))]\n",
    "  # enc_out, enc_hidden = encoder(inputs, hidden)\n",
    "\n",
    "  dec_hidden = tf.zeros((BATCH_SIZE, units)) #enc_hidden\n",
    "  dec_input = tf.expand_dims([1], 0)\n",
    "\n",
    "  for t in range(max_length_targ):\n",
    "    # print(t, max_length_targ)\n",
    "    predictions, dec_hidden, attention_weights = decoder(dec_input\n",
    "                                                         , dec_hidden,\n",
    "                                                        #  , enc_out\n",
    "                                                         )\n",
    "    \n",
    "    # storing the attention weights to plot later on\n",
    "    attention_weights = tf.reshape(attention_weights, (-1, ))\n",
    "    attention_plot[t] = attention_weights.numpy()\n",
    "    predicted_id = tf.argmax(predictions[0]).numpy()\n",
    "\n",
    "    result = get_key(lang, predicted_id) + ' ' + result #targ_lang.index_word[predicted_id] + ' '\n",
    "\n",
    "    if get_key(lang, predicted_id) == '<start>':\n",
    "      print('Evaluation: found start, ending')\n",
    "      return result, task_vector, attention_plot\n",
    "\n",
    "    # the predicted ID is fed back into the model\n",
    "    dec_input = tf.expand_dims([predicted_id], 0)\n",
    "\n",
    "  return result, task_vector, attention_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "result, task_vector, attention_plot = evaluate(example_task_vector)\n",
    "print('The number of vertices is: {} \\n'.format(len(result.split(' '))))\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_FILE = './task2seq/outputs/output.py'\n",
    "with open(OUTPUT_FILE, 'w') as f:\n",
    "    last_vertice = ''\n",
    "    for vertice in result.split(' '):\n",
    "        if vertice:\n",
    "            if (vertice!='<start>')&(vertice!='<end>')&(vertice!=last_vertice):\n",
    "                line = '#@ {} \\n\\n'.format(vertice)\n",
    "                f.write(line)\n",
    "                last_vertice = vertice"
   ]
  },
  {
   "source": [
    "### Metrics"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_scores()"
   ]
  }
 ]
}