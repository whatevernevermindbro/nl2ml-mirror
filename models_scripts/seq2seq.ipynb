{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.6 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "0de36b31320ba4c88b4f85a74724f3d16c36a44df48581253710b1065e752d9e"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import backend as K\n",
    "# from sklearn.preprocessing import LabelEncoder "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.set_option('mode.chained_assignment', None)"
   ]
  },
  {
   "source": [
    "### Defining Methods"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_key(my_dict, val):\n",
    "    for key, value in my_dict.items():\n",
    "         if val == value:\n",
    "             return key\n",
    " \n",
    "    return \"key doesn't exist\""
   ]
  },
  {
   "source": [
    "### Reading Data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "NOTEBOOKS_PATH = '../data/NL2ML_ structure - levin.csv'\n",
    "DATASETS_PATH = '../data/NL2ML_ structure - data_structure.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "notebooks = pd.read_csv(NOTEBOOKS_PATH, skiprows=1, nrows=96)\n",
    "datasets = pd.read_csv(DATASETS_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   chunk_id   dataset_id  notebook_id  splitting_id  \\\n",
       "0         1  jane_street            1             1   \n",
       "1         2  jane_street            1             1   \n",
       "\n",
       "                                          code_block data_format  \\\n",
       "0  import os\\nimport numpy as np\\nimport matplotl...        None   \n",
       "1  print('Reading datasets...', end='')\\n\\ntrain_...       Table   \n",
       "\n",
       "                    graph_vertex  errors  graph_vertex_m1  graph_vertex_m2  \\\n",
       "0     Environment.import_modules   False              NaN              NaN   \n",
       "1  Data_Extraction.load_from_csv   False              NaN              NaN   \n",
       "\n",
       "   ...  python_methods_m3  python_methods_p1  python_methods_p2  \\\n",
       "0  ...                NaN                NaN                NaN   \n",
       "1  ...                NaN                NaN                NaN   \n",
       "\n",
       "   python_methods_p3  kaggle_link  kaggle_comments  kaggle_upvotes  \\\n",
       "0                NaN          NaN              NaN             NaN   \n",
       "1                NaN          NaN              NaN             NaN   \n",
       "\n",
       "   kaggle_section  kaggle_section_overview  kaggle_score  \n",
       "0             NaN                      NaN           NaN  \n",
       "1             NaN                      NaN           NaN  \n",
       "\n",
       "[2 rows x 32 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>chunk_id</th>\n      <th>dataset_id</th>\n      <th>notebook_id</th>\n      <th>splitting_id</th>\n      <th>code_block</th>\n      <th>data_format</th>\n      <th>graph_vertex</th>\n      <th>errors</th>\n      <th>graph_vertex_m1</th>\n      <th>graph_vertex_m2</th>\n      <th>...</th>\n      <th>python_methods_m3</th>\n      <th>python_methods_p1</th>\n      <th>python_methods_p2</th>\n      <th>python_methods_p3</th>\n      <th>kaggle_link</th>\n      <th>kaggle_comments</th>\n      <th>kaggle_upvotes</th>\n      <th>kaggle_section</th>\n      <th>kaggle_section_overview</th>\n      <th>kaggle_score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>jane_street</td>\n      <td>1</td>\n      <td>1</td>\n      <td>import os\\nimport numpy as np\\nimport matplotl...</td>\n      <td>None</td>\n      <td>Environment.import_modules</td>\n      <td>False</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>jane_street</td>\n      <td>1</td>\n      <td>1</td>\n      <td>print('Reading datasets...', end='')\\n\\ntrain_...</td>\n      <td>Table</td>\n      <td>Data_Extraction.load_from_csv</td>\n      <td>False</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n<p>2 rows × 32 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "notebooks.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "  dataset_id                                                url  \\\n",
       "0        NaN              https://www.kaggle.com/c/titanic/data   \n",
       "1        NaN  https://www.kaggle.com/c/competitive-data-scie...   \n",
       "\n",
       "                                         Name  TL;DR (In plain English)  \\\n",
       "0  Titanic - Machine Learning from Disaster\\n                       NaN   \n",
       "1                        Predict Future Sales                       NaN   \n",
       "\n",
       "      ProblemType number of columns (for tabular) number of entries  \\\n",
       "0  classification                              25                 -   \n",
       "1      regression                              18                 -   \n",
       "\n",
       "  image resolution number of images Data Format  LabelType Number of classes  \\\n",
       "0                -                -         csv        NaN                 2   \n",
       "1                -                -         csv        NaN                 -   \n",
       "\n",
       "    Loss Function/Metrics Target Column(s) Name  \\\n",
       "0  categorizationaccuracy              Survived   \n",
       "1                    rmse          item_cnt_day   \n",
       "\n",
       "                    Columns DTypes  \n",
       "0  String, Integer, Decimal, Other  \n",
       "1       String, Decimal, Id, Other  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>dataset_id</th>\n      <th>url</th>\n      <th>Name</th>\n      <th>TL;DR (In plain English)</th>\n      <th>ProblemType</th>\n      <th>number of columns (for tabular)</th>\n      <th>number of entries</th>\n      <th>image resolution</th>\n      <th>number of images</th>\n      <th>Data Format</th>\n      <th>LabelType</th>\n      <th>Number of classes</th>\n      <th>Loss Function/Metrics</th>\n      <th>Target Column(s) Name</th>\n      <th>Columns DTypes</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>NaN</td>\n      <td>https://www.kaggle.com/c/titanic/data</td>\n      <td>Titanic - Machine Learning from Disaster\\n</td>\n      <td>NaN</td>\n      <td>classification</td>\n      <td>25</td>\n      <td>-</td>\n      <td>-</td>\n      <td>-</td>\n      <td>csv</td>\n      <td>NaN</td>\n      <td>2</td>\n      <td>categorizationaccuracy</td>\n      <td>Survived</td>\n      <td>String, Integer, Decimal, Other</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>NaN</td>\n      <td>https://www.kaggle.com/c/competitive-data-scie...</td>\n      <td>Predict Future Sales</td>\n      <td>NaN</td>\n      <td>regression</td>\n      <td>18</td>\n      <td>-</td>\n      <td>-</td>\n      <td>-</td>\n      <td>csv</td>\n      <td>NaN</td>\n      <td>-</td>\n      <td>rmse</td>\n      <td>item_cnt_day</td>\n      <td>String, Decimal, Id, Other</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "datasets.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "nl2ml = notebooks.merge(datasets, on=['dataset_id'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   chunk_id   dataset_id  notebook_id  splitting_id  \\\n",
       "0         1  jane_street            1             1   \n",
       "1         2  jane_street            1             1   \n",
       "\n",
       "                                          code_block data_format  \\\n",
       "0  import os\\nimport numpy as np\\nimport matplotl...        None   \n",
       "1  print('Reading datasets...', end='')\\n\\ntrain_...       Table   \n",
       "\n",
       "                    graph_vertex  errors  graph_vertex_m1  graph_vertex_m2  \\\n",
       "0     Environment.import_modules   False              NaN              NaN   \n",
       "1  Data_Extraction.load_from_csv   False              NaN              NaN   \n",
       "\n",
       "   ...  number of columns (for tabular)  number of entries  image resolution  \\\n",
       "0  ...                              303                  -                 -   \n",
       "1  ...                              303                  -                 -   \n",
       "\n",
       "   number of images  Data Format  LabelType  Number of classes  \\\n",
       "0                 -          csv        NaN                  2   \n",
       "1                 -          csv        NaN                  2   \n",
       "\n",
       "   Loss Function/Metrics  Target Column(s) Name  \\\n",
       "0         custom metrics                 action   \n",
       "1         custom metrics                 action   \n",
       "\n",
       "                     Columns DTypes  \n",
       "0  Decimal, Boolean, Integer, Other  \n",
       "1  Decimal, Boolean, Integer, Other  \n",
       "\n",
       "[2 rows x 46 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>chunk_id</th>\n      <th>dataset_id</th>\n      <th>notebook_id</th>\n      <th>splitting_id</th>\n      <th>code_block</th>\n      <th>data_format</th>\n      <th>graph_vertex</th>\n      <th>errors</th>\n      <th>graph_vertex_m1</th>\n      <th>graph_vertex_m2</th>\n      <th>...</th>\n      <th>number of columns (for tabular)</th>\n      <th>number of entries</th>\n      <th>image resolution</th>\n      <th>number of images</th>\n      <th>Data Format</th>\n      <th>LabelType</th>\n      <th>Number of classes</th>\n      <th>Loss Function/Metrics</th>\n      <th>Target Column(s) Name</th>\n      <th>Columns DTypes</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>jane_street</td>\n      <td>1</td>\n      <td>1</td>\n      <td>import os\\nimport numpy as np\\nimport matplotl...</td>\n      <td>None</td>\n      <td>Environment.import_modules</td>\n      <td>False</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>303</td>\n      <td>-</td>\n      <td>-</td>\n      <td>-</td>\n      <td>csv</td>\n      <td>NaN</td>\n      <td>2</td>\n      <td>custom metrics</td>\n      <td>action</td>\n      <td>Decimal, Boolean, Integer, Other</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>jane_street</td>\n      <td>1</td>\n      <td>1</td>\n      <td>print('Reading datasets...', end='')\\n\\ntrain_...</td>\n      <td>Table</td>\n      <td>Data_Extraction.load_from_csv</td>\n      <td>False</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>303</td>\n      <td>-</td>\n      <td>-</td>\n      <td>-</td>\n      <td>csv</td>\n      <td>NaN</td>\n      <td>2</td>\n      <td>custom metrics</td>\n      <td>action</td>\n      <td>Decimal, Boolean, Integer, Other</td>\n    </tr>\n  </tbody>\n</table>\n<p>2 rows × 46 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "nl2ml.head(2)"
   ]
  },
  {
   "source": [
    "### Vertices Preprocessing"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Data_Transform       32\n",
       "EDA                  20\n",
       "Model_Train          14\n",
       "Visualization        11\n",
       "Environment           7\n",
       "Hyperparam_Tuning     4\n",
       "Data_Extraction       4\n",
       "Exporatory_DA         3\n",
       "Data_Export           1\n",
       "Name: graph_vertex, dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "nl2ml['graph_vertex'].apply(lambda x: x.split(';')[0].split('.')[0]).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Index(['chunk_id', 'dataset_id', 'notebook_id', 'splitting_id', 'code_block',\n",
       "       'data_format', 'graph_vertex', 'errors', 'graph_vertex_m1',\n",
       "       'graph_vertex_m2', 'graph_vertex_m3', 'graph_vertex_p1',\n",
       "       'graph_vertex_p2', 'graph_vertex_p3', 'comments', 'libraries', 'ast',\n",
       "       'graph_vertex_regex', 'python_methods', 'docstrings',\n",
       "       'python_methods_m1', 'python_methods_m2', 'python_methods_m3',\n",
       "       'python_methods_p1', 'python_methods_p2', 'python_methods_p3',\n",
       "       'kaggle_link', 'kaggle_comments', 'kaggle_upvotes', 'kaggle_section',\n",
       "       'kaggle_section_overview', 'kaggle_score', 'url', 'Name',\n",
       "       'TL;DR (In plain English)', 'ProblemType',\n",
       "       'number of columns (for tabular)', 'number of entries',\n",
       "       'image resolution', 'number of images', 'Data Format', 'LabelType',\n",
       "       'Number of classes', 'Loss Function/Metrics', 'Target Column(s) Name',\n",
       "       'Columns DTypes'],\n",
       "      dtype='object')"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "nl2ml.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "nl2ml['vertex_l1'], nl2ml['vertex_l2'] = nl2ml['graph_vertex'].apply(lambda x: x.split(';')[0].split('.')[0]), nl2ml['graph_vertex'].apply(lambda x: x.split(';')[0].split('.')[1])"
   ]
  },
  {
   "source": [
    "### Missing Values"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "nl2ml.replace('-', -1, inplace=True)\n",
    "nl2ml.fillna(-1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "TASK_FEATURES = ['ProblemType',\n",
    "                'number of columns (for tabular)', 'number of entries',\n",
    "                'LabelType', 'Number of classes', 'Loss Function/Metrics',\n",
    "                'Target Column(s) Name']\n",
    "TARGET_COLUMN = 'vertex_l1'"
   ]
  },
  {
   "source": [
    "### Grouping chunks by notebooks"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_by_notebooks(data:pd.DataFrame, vertex_col:str='vertex_l1') -> pd.DataFrame:\n",
    "    notebook_cols = [['notebook_id', vertex_col] + TASK_FEATURES]\n",
    "    df = pd.DataFrame(columns=notebook_cols)\n",
    "    for i, notebook_id in enumerate(data['notebook_id'].unique()):\n",
    "        notebook = data[data['notebook_id'] == notebook_id].reset_index(drop=True)\n",
    "        vertices_seq = \" \".join(notebook[vertex_col])\n",
    "        task_features = notebook[TASK_FEATURES].loc[0]\n",
    "        row = [notebook_id, vertices_seq] + task_features.tolist()\n",
    "        df.loc[i] = row\n",
    "        print('notebook #{} done'.format(notebook_id))\n",
    "    return df"
   ]
  },
  {
   "source": [
    "### Taking Train Features"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "notebook #1 done\nnotebook #7 done\nnotebook #9 done\n"
     ]
    }
   ],
   "source": [
    "train = group_by_notebooks(nl2ml, TARGET_COLUMN)\n",
    "X, y = train[TASK_FEATURES], train[TARGET_COLUMN]"
   ]
  },
  {
   "source": [
    "### Converting Dtypes"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_encodings = {}\n",
    "for i, col in enumerate(X.columns):\n",
    "    try:\n",
    "        X[col] =  X[col].astype('float32')\n",
    "    except:\n",
    "        X[col] = pd.Categorical(X[col])\n",
    "        cat_encodings.update({i:dict(enumerate(X[col].cat.categories))})\n",
    "        X[col] = X[col].cat.codes"
   ]
  },
  {
   "source": [
    "### Target Preprocessing: Encoding Vertices"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [],
   "source": [
    "lang = {vertice:i+2 for i, vertice in enumerate(nl2ml[TARGET_COLUMN].unique())} #TODO: save the dict as a local file\n",
    "lang.update({'<start>':1, '<end>':max(lang.values())+1})\n",
    "def encode_vertices(vertices_seq, lang:dict=lang):\n",
    "    encoded = np.flip(np.array([lang[vertex] for vertex in vertices_seq[0].split(' ')]))\n",
    "    return encoded"
   ]
  },
  {
   "source": [
    "### Target Preprocessing: Padding Sequences"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = tf.keras.preprocessing.sequence.pad_sequences(y.apply(encode_vertices, axis=1))"
   ]
  },
  {
   "source": [
    "### Defining Constants"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BUFFER_SIZE = len(input_tensor_train)\n",
    "BATCH_SIZE = 1\n",
    "steps_per_epoch = len(X)//BATCH_SIZE\n",
    "embedding_dim = 256\n",
    "units = 1024\n",
    "# vocab_inp_size = len(inp_lang.word_index)+1\n",
    "# vocab_tar_size = len(targ_lang.word_index)+1"
   ]
  },
  {
   "source": [
    "### Creating tf.Dataset"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices((X.values, Y))\n",
    "dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length_targ, max_length_feat = Y.shape[1], X.values.shape[1]"
   ]
  },
  {
   "source": [
    "### Building the Model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.Model):\n",
    "  def __init__(self, vocab_size, embedding_dim, dec_units, batch_sz):\n",
    "    super(Decoder, self).__init__()\n",
    "    self.batch_sz = batch_sz\n",
    "    self.dec_units = dec_units\n",
    "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "    self.gru = tf.keras.layers.GRU(self.dec_units,\n",
    "                                   return_sequences=True,\n",
    "                                   return_state=True,\n",
    "                                   recurrent_initializer='glorot_uniform')\n",
    "    self.fc = tf.keras.layers.Dense(vocab_size)\n",
    "\n",
    "    # used for attention\n",
    "    # self.attention = BahdanauAttention(self.dec_units)\n",
    "\n",
    "  def call(self, x): #, hidden):#, enc_output):\n",
    "    # enc_output shape == (batch_size, max_length, hidden_size)\n",
    "    # context_vector, attention_weights = self.attention(hidden, enc_output)\n",
    "    attention_weights = tf.ones(x.shape)\n",
    "    context_vector = tf.ones(x.shape)\n",
    "    # print(\"X Vector has {} type and {} shape\".format(type(x), x.shape))\n",
    "    # print(\"Context Vector has {} type and {} shape\".format(type(context_vector), context_vector.shape))\n",
    "    # print(\"Attention Vector has {} type and {} shape\".format(type(context_vector), context_vector.shape))\n",
    "    # x shape after passing through embedding == (batch_size, 1, embedding_dim)\n",
    "    x = self.embedding(x)\n",
    " \n",
    "    # x shape after concatenation == (batch_size, 1, embedding_dim + hidden_size)\n",
    "    x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1)\n",
    "\n",
    "    # passing the concatenated vector to the GRU\n",
    "    output, state = self.gru(x)\n",
    "\n",
    "    # output shape == (batch_size * 1, hidden_size)\n",
    "    output = tf.reshape(output, (-1, output.shape[2]))\n",
    "\n",
    "    # output shape == (batch_size, vocab)\n",
    "    x = self.fc(output)\n",
    "\n",
    "    return x, state, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample_hidden = tf.zeros((BATCH_SIZE, units))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Decoder output shape: (batch_size, vocab size) (1, 13)\n"
     ]
    }
   ],
   "source": [
    "decoder = Decoder(len(lang)+2, embedding_dim, units, BATCH_SIZE)\n",
    "\n",
    "sample_decoder_output, _, _ = decoder(tf.random.uniform((BATCH_SIZE, 1)))\n",
    "                                      #, sample_hidden)\n",
    "                                      #, sample_output)\n",
    "\n",
    "print ('Decoder output shape: (batch_size, vocab size) {}'.format(sample_decoder_output.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam()\n",
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "    from_logits=True, reduction='none')\n",
    "\n",
    "def loss_function(real, pred):\n",
    "  mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "  loss_ = loss_object(real, pred)\n",
    "\n",
    "  mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "  loss_ *= mask\n",
    "\n",
    "  return tf.reduce_mean(loss_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(inp, targ):#, enc_hidden):\n",
    "  loss = 0\n",
    "  perplexity = 0\n",
    "\n",
    "  with tf.GradientTape() as tape:\n",
    "    # enc_output, enc_hidden = encoder(inp, enc_hidden)\n",
    "\n",
    "    dec_hidden = tf.zeros((BATCH_SIZE, units)) #enc_hidden\n",
    "\n",
    "    dec_input = tf.expand_dims([1] * BATCH_SIZE, 1)\n",
    "\n",
    "    # Teacher forcing - feeding the target as the next input\n",
    "    for t in range(1, targ.shape[1]):\n",
    "      # passing enc_output to the decoder\n",
    "      predictions, dec_hidden, _ = decoder(dec_input)#, dec_hidden, enc_output)\n",
    "\n",
    "      loss += loss_function(targ[:, t], predictions)\n",
    "\n",
    "      perplexity += perplexity_metric(targ[:, t], predictions)\n",
    "      # using teacher forcing\n",
    "      dec_input = tf.expand_dims(targ[:, t], 1)\n",
    "\n",
    "  batch_loss = (loss / int(targ.shape[1]))\n",
    "\n",
    "  variables = decoder.trainable_variables # + encoder.trainable_variables\n",
    "\n",
    "  gradients = tape.gradient(loss, variables)\n",
    "\n",
    "  optimizer.apply_gradients(zip(gradients, variables))\n",
    "  return batch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_bleu(reference_corpus, translation_corpus, max_order=4,\n",
    "                 smooth=False):\n",
    "  \"\"\"Computes BLEU score of translated segments against one or more references.\n",
    "  Args:\n",
    "    reference_corpus: list of lists of references for each translation. Each\n",
    "        reference should be tokenized into a list of tokens.\n",
    "    translation_corpus: list of translations to score. Each translation\n",
    "        should be tokenized into a list of tokens.\n",
    "    max_order: Maximum n-gram order to use when computing BLEU score.\n",
    "    smooth: Whether or not to apply Lin et al. 2004 smoothing.\n",
    "  Returns:\n",
    "    3-Tuple with the BLEU score, n-gram precisions, geometric mean of n-gram\n",
    "    precisions and brevity penalty.\n",
    "  \"\"\"\n",
    "  matches_by_order = [0] * max_order\n",
    "  possible_matches_by_order = [0] * max_order\n",
    "  reference_length = 0\n",
    "  translation_length = 0\n",
    "  for (references, translation) in zip(reference_corpus,\n",
    "                                       translation_corpus):\n",
    "    reference_length += min(len(r) for r in references)\n",
    "    translation_length += len(translation)\n",
    "\n",
    "    merged_ref_ngram_counts = collections.Counter()\n",
    "    for reference in references:\n",
    "      merged_ref_ngram_counts |= _get_ngrams(reference, max_order)\n",
    "    translation_ngram_counts = _get_ngrams(translation, max_order)\n",
    "    overlap = translation_ngram_counts & merged_ref_ngram_counts\n",
    "    for ngram in overlap:\n",
    "      matches_by_order[len(ngram)-1] += overlap[ngram]\n",
    "    for order in range(1, max_order+1):\n",
    "      possible_matches = len(translation) - order + 1\n",
    "      if possible_matches > 0:\n",
    "        possible_matches_by_order[order-1] += possible_matches\n",
    "\n",
    "  precisions = [0] * max_order\n",
    "  for i in range(0, max_order):\n",
    "    if smooth:\n",
    "      precisions[i] = ((matches_by_order[i] + 1.) /\n",
    "                       (possible_matches_by_order[i] + 1.))\n",
    "    else:\n",
    "      if possible_matches_by_order[i] > 0:\n",
    "        precisions[i] = (float(matches_by_order[i]) /\n",
    "                         possible_matches_by_order[i])\n",
    "      else:\n",
    "        precisions[i] = 0.0\n",
    "\n",
    "  if min(precisions) > 0:\n",
    "    p_log_sum = sum((1. / max_order) * math.log(p) for p in precisions)\n",
    "    geo_mean = math.exp(p_log_sum)\n",
    "  else:\n",
    "    geo_mean = 0\n",
    "\n",
    "  ratio = float(translation_length) / reference_length\n",
    "\n",
    "  if ratio > 1.0:\n",
    "    bp = 1.\n",
    "  else:\n",
    "    bp = math.exp(1 - 1. / ratio)\n",
    "\n",
    "  bleu = geo_mean * bp\n",
    "\n",
    "  return (bleu, precisions, bp, ratio, translation_length, reference_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PerplexityMetric(tf.keras.metrics.Metric):\n",
    "    \"\"\"\n",
    "    USAGE NOTICE: this metric accepts only logits for now (i.e. expect the same behaviour as from tf.keras.losses.SparseCategoricalCrossentropy with the a provided argument \"from_logits=True\", \n",
    "\t\there the same loss is used with \"from_logits=True\" enforced so you need to provide it in such a format)\n",
    "    METRIC DESCRIPTION:\n",
    "    Popular metric for evaluating language modelling architectures.\n",
    "    More info: http://cs224d.stanford.edu/lecture_notes/LectureNotes4.pdf.\n",
    "    DISCLAIMER: Original function created by Kirill Mavreshko in https://github.com/kpot/keras-transformer/blob/b9d4e76c535c0c62cadc73e37416e4dc18b635ca/example/run_gpt.py#L106. \n",
    "    My \"contribution\": I converted Kirill method's logic (and added a padding masking to to it) into this new Tensorflow 2.0 way of doing things via a stateful \"Metric\" object. This required making the metric a fully-fledged object by subclassing the Metric class. \n",
    "    \"\"\"\n",
    "    def __init__(self, name='perplexity', **kwargs):\n",
    "      super(PerplexityMetric, self).__init__(name=name, **kwargs)\n",
    "      self.cross_entropy = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, reduction='none')\n",
    "      self.perplexity = self.add_weight(name='tp', initializer='zeros')\n",
    "\n",
    "\t\t# Consider uncommenting the decorator for a performance boost (?)  \t\t\n",
    "    # @tf.function\n",
    "    def _calculate_perplexity(self, real, pred):\n",
    "\t\t\t# The next 4 lines zero-out the padding from loss calculations, \n",
    "\t\t\t# this follows the logic from: https://www.tensorflow.org/beta/tutorials/text/transformer#loss_and_metrics \t\t\t\n",
    "      mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "      loss_ = self.cross_entropy(real, pred)\n",
    "      mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "      loss_ *= mask\n",
    "\t\t\t# Calculating the perplexity steps: \t\t\t\n",
    "      step1 = K.mean(loss_, axis=-1)\n",
    "      step2 = K.exp(step1)\n",
    "      perplexity = K.mean(step2)\n",
    "\n",
    "      return perplexity\n",
    "\n",
    "\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "      # TODO:FIXME: handle sample_weight !\n",
    "      if sample_weight is not None:\n",
    "          print(\"WARNING! Provided 'sample_weight' argument to the perplexity metric. Currently this is not handled and won't do anything differently..\")\n",
    "      perplexity = self._calculate_perplexity(y_true, y_pred)\n",
    "\t\t\t# Remember self.perplexity is a tensor (tf.Variable), so using simply \"self.perplexity = perplexity\" will result in error because of mixing EagerTensor and Graph operations \n",
    "      self.perplexity.assign_add(perplexity)\n",
    "        \n",
    "    def result(self):\n",
    "      return self.perplexity\n",
    "\n",
    "    def reset_states(self):\n",
    "      # The state of the metric will be reset at the start of each epoch.\n",
    "      self.perplexity.assign(0.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [],
   "source": [
    "perplexity_metric = PerplexityMetric()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_dir = './decoder_training_checkpoints/'\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
    "checkpoint = tf.train.Checkpoint(optimizer=optimizer\n",
    "                                , metrics=perplexity_metric\n",
    "                                #  , encoder=encoder\n",
    "                                 , decoder=decoder)"
   ]
  },
  {
   "source": [
    "### Model Training"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Initial Perplexity: 15846.841796875 \n",
      "Epoch 1 Batch 0 Loss 0.1103 Perplexity 15931.3838\n",
      "Epoch 2 Batch 0 Loss 0.1112 Perplexity 16471.0898\n",
      "Epoch 3 Batch 0 Loss 0.1124 Perplexity 17010.4805\n",
      "Epoch 4 Batch 0 Loss 0.1134 Perplexity 17549.8965\n",
      "Epoch 5 Batch 0 Loss 0.1141 Perplexity 18087.2676\n",
      "Epoch 6 Batch 0 Loss 0.1144 Perplexity 18620.1055\n",
      "Epoch 7 Batch 0 Loss 0.1145 Perplexity 19148.0020\n",
      "Epoch 8 Batch 0 Loss 0.1146 Perplexity 19672.3184\n",
      "Epoch 9 Batch 0 Loss 0.1147 Perplexity 20194.8574\n",
      "Epoch 10 Batch 0 Loss 0.1148 Perplexity 20716.8555\n",
      "Epoch 11 Batch 0 Loss 0.1150 Perplexity 21238.7773\n",
      "Epoch 12 Batch 0 Loss 0.1152 Perplexity 21760.3633\n",
      "Epoch 13 Batch 0 Loss 0.1154 Perplexity 22281.5840\n",
      "Epoch 14 Batch 0 Loss 0.1157 Perplexity 22802.6641\n",
      "Epoch 15 Batch 0 Loss 0.1160 Perplexity 23323.6367\n",
      "Epoch 16 Batch 0 Loss 0.1162 Perplexity 23844.1934\n",
      "Epoch 17 Batch 0 Loss 0.1162 Perplexity 24363.8262\n",
      "Epoch 18 Batch 0 Loss 0.1163 Perplexity 24882.2344\n",
      "Epoch 19 Batch 0 Loss 0.1163 Perplexity 25399.5723\n",
      "Epoch 20 Batch 0 Loss 0.1163 Perplexity 25916.3320\n",
      "Epoch 21 Batch 0 Loss 0.1163 Perplexity 26432.9004\n",
      "Epoch 22 Batch 0 Loss 0.1163 Perplexity 26949.3184\n",
      "Epoch 23 Batch 0 Loss 0.1163 Perplexity 27465.4336\n",
      "Epoch 24 Batch 0 Loss 0.1163 Perplexity 27981.1426\n",
      "Epoch 25 Batch 0 Loss 0.1163 Perplexity 28496.4805\n",
      "Epoch 25 Loss 0.6006 Perplexity 28914.2520\n",
      "Time taken for 1 epoch 2.5961484909057617 sec\n",
      "\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 25\n",
    "\n",
    "print('Initial Perplexity: {} '.format(perplexity_metric.result()))\n",
    "for epoch in range(EPOCHS):\n",
    "  start = time.time()\n",
    "\n",
    "  # enc_hidden = encoder.initialize_hidden_state()\n",
    "  total_loss = 0\n",
    "  for (batch, (feat, targ)) in enumerate(dataset.take(steps_per_epoch)):\n",
    "    # print ('Features: {}, Target: {}'.format(feat, targ))\n",
    "    batch_loss = train_step(feat, targ)#, enc_hidden)\n",
    "    total_loss += batch_loss\n",
    "\n",
    "    if batch % 100 == 0:\n",
    "      print('Epoch {} Batch {} Loss {:.4f} Perplexity {:.4f}'.format(epoch + 1,\n",
    "                                                    batch,\n",
    "                                                    batch_loss.numpy(),\n",
    "                                                    perplexity_metric.result()))\n",
    "if (epoch + 1) % 2 == 0:\n",
    "  print('saving')\n",
    "  checkpoint.save(file_prefix = checkpoint_prefix)\n",
    "  print('saved')\n",
    "\n",
    "print('Epoch {} Loss {:.4f} Perplexity {:.4f}'.format(epoch + 1,\n",
    "                                    total_loss / steps_per_epoch,\n",
    "                                    perplexity_metric.result()))\n",
    "print('Time taken for 1 epoch {} sec\\n'.format(time.time() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_task(task_vector):\n",
    "    # either convert to float32 or encode to categoricals\n",
    "    for i, el in enumerate(task_vector):\n",
    "        try:\n",
    "            task_vector[i] = float(task_vector[i])\n",
    "        except:\n",
    "            task_vector[i] = get_key(cat_encodings[i], task_vector[i])\n",
    "    return task_vector.astype('float32')"
   ]
  },
  {
   "source": [
    "### Model Evaluation"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example_task_vector = X.loc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(task_vector):\n",
    "  attention_plot = np.zeros((max_length_targ, max_length_feat))\n",
    "\n",
    "  task_vector = preprocess_task(task_vector)\n",
    "\n",
    "  # inputs = [inp_lang.word_index[i] for i in task_vector.split(' ')]\n",
    "  # inputs = tf.keras.preprocessing.sequence.pad_sequences([inputs],\n",
    "  #                                                        maxlen=max_length_feat,\n",
    "  #                                                        padding='post')\n",
    "  inputs = tf.convert_to_tensor(task_vector) #inputs)\n",
    "\n",
    "  result = ''\n",
    "\n",
    "  # hidden = [tf.zeros((1, units))]\n",
    "  # enc_out, enc_hidden = encoder(inputs, hidden)\n",
    "\n",
    "  dec_hidden = tf.zeros((BATCH_SIZE, units)) #enc_hidden\n",
    "  dec_input = tf.expand_dims([1], 0)\n",
    "\n",
    "  for t in range(max_length_targ):\n",
    "    # print(t, max_length_targ)\n",
    "    predictions, dec_hidden, attention_weights = decoder(dec_input\n",
    "                                                        #  , dec_hidden,\n",
    "                                                        #  , enc_out\n",
    "                                                         )\n",
    "    \n",
    "    # storing the attention weights to plot later on\n",
    "    attention_weights = tf.reshape(attention_weights, (-1, ))\n",
    "    attention_plot[t] = attention_weights.numpy()\n",
    "\n",
    "    predicted_id = tf.argmax(predictions[0]).numpy()\n",
    "\n",
    "    result = get_key(lang, predicted_id) + ' ' + result #targ_lang.index_word[predicted_id] + ' '\n",
    "\n",
    "    if get_key(lang, predicted_id) == '<end>':\n",
    "      return result, task_vector, attention_plot\n",
    "\n",
    "    # the predicted ID is fed back into the model\n",
    "    dec_input = tf.expand_dims([predicted_id], 0)\n",
    "\n",
    "  return result, task_vector, attention_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perplexity_metric(Y[0], result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "('Model_Train Model_Train Model_Train Model_Train Model_Train Model_Train Model_Train Model_Train Model_Train Model_Train Model_Train Model_Train Model_Train Model_Train Model_Train Model_Train Model_Train Model_Train Model_Train Model_Train Model_Train Model_Train Model_Train Model_Train Model_Train Model_Train Model_Train Model_Train Model_Train Model_Train Model_Train Model_Train Model_Train Model_Train Model_Train Model_Train Model_Train Model_Train Model_Train Model_Train Model_Train Model_Train Model_Train Model_Train Model_Train Model_Train Model_Train Model_Train Model_Train Model_Train Model_Train Model_Train Model_Train Model_Train Model_Train Model_Train Model_Train Model_Train Data_Export ',\n",
       " ProblemType                          0.0\n",
       " number of columns (for tabular)    303.0\n",
       " number of entries                   -1.0\n",
       " LabelType                           -1.0\n",
       " Number of classes                    2.0\n",
       " Loss Function/Metrics                0.0\n",
       " Target Column(s) Name                1.0\n",
       " Name: 0, dtype: float32,\n",
       " array([[1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1.]]))"
      ]
     },
     "metadata": {},
     "execution_count": 359
    }
   ],
   "source": [
    "evaluate(example_task_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "result, task_vector, attention_plot = evaluate(example_task_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "('Data_Extraction EDA Data_Transform Data_Transform Data_Transform Data_Transform Data_Transform Data_Transform Data_Transform Data_Transform Data_Transform Data_Transform Data_Transform Data_Transform Data_Transform Data_Transform Data_Transform Data_Transform Data_Transform Data_Transform Data_Transform Data_Transform Data_Transform Data_Transform Data_Transform Data_Transform Data_Transform Data_Transform Data_Transform Data_Transform Data_Transform Data_Transform Data_Transform Data_Transform Data_Transform Data_Transform Data_Transform Data_Transform Data_Transform Data_Transform Data_Transform Data_Transform Data_Transform Data_Transform Data_Transform Data_Transform Data_Transform Data_Transform Data_Transform Data_Transform Data_Transform Data_Transform Data_Transform Data_Transform Data_Transform Data_Transform Data_Transform Data_Transform Data_Transform ',\n",
       " ProblemType                          0.0\n",
       " number of columns (for tabular)    303.0\n",
       " number of entries                   -1.0\n",
       " LabelType                           -1.0\n",
       " Number of classes                    2.0\n",
       " Loss Function/Metrics                0.0\n",
       " Target Column(s) Name                1.0\n",
       " Name: 0, dtype: float32,\n",
       " array([[1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1.]]))"
      ]
     },
     "metadata": {},
     "execution_count": 209
    }
   ],
   "source": []
  },
  {
   "source": [
    "### Metrics"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_scores()"
   ]
  },
  {
   "source": [
    "## Текущие вопросы\n",
    "1. Мы решаем seq2seq element-wise или отображение из задачи в последовательность вершин?\n",
    "\n",
    "    1.1 А что если сначала обучить unsupervised-сеть на последовательностях вершин (предсказывать следующую вершину)? То есть инициализация весов\n",
    "\n",
    "2. Как измерить \"правильность\" сгенерированных последовательностей вершин?\n",
    "\n",
    "3. Что если обучать последовательность вершин от конца к началу?\n",
    "\n",
    "--4. Какие фичи мы берём для первой версии модели?\n",
    "\n",
    "5. Какие есть референс-архитектуры, на которые можно обратить внимание?\n",
    "\n",
    "    5.1 Как должна выглядеть архитектура нашей нейросети\n",
    "\n",
    "6. Что генерить: верхнеуровневые вершины/конкатенацию уровней вершин/верхнеуровневые + низкоуровневые вершины по отдельности?"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}