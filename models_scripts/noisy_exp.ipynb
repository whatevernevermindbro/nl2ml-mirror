{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dagshub\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.svm import SVC\n",
    "from enum import Enum\n",
    "\n",
    "from common.tools import *\n",
    "\n",
    "import svm_for_semi as sfs\n",
    "\n",
    "TARGET_COLUMN = 'graph_vertex_id'\n",
    "FEATURE_COLUMN = 'code_block'\n",
    "RANDOM_STATE = 42\n",
    "GRAPH_VER = \"7\"\n",
    "\n",
    "\n",
    "MODEL_DIR = \"../models/hyper_noisy_regex_graph_v{}.sav\".format(GRAPH_VER)\n",
    "TFIDF_DIR = \"../models/tfidf_hyper_noisy_graph_v{}.pickle\".format(GRAPH_VER)\n",
    "DATA_PATH = \"../data/markup_data_2021-05-06.csv\"\n",
    "UNMARKED_DATA_PATH = \"../data/not_yet_markup_data_2021-05-06.csv\"\n",
    "SEMI_ITER = 3\n",
    "\n",
    "kfold_params = {\n",
    "    \"n_splits\": 9,\n",
    "    \"random_state\": RANDOM_STATE,\n",
    "    \"shuffle\": True,\n",
    "}\n",
    "\n",
    "data = pd.read_csv(DATA_PATH)\n",
    "unlabeled_data = pd.read_csv(UNMARKED_DATA_PATH)\n",
    "\n",
    "class SemiType(Enum):\n",
    "    RANDOM = 1\n",
    "    MOST_ACCURATE = 2\n",
    "    LEAST_ACCURATE = 3\n",
    "\n",
    "def find_hyperparams(pseudo_df, data, kfold_params, TFIDF_DIR, MODEL_DIR, use_proba=False):\n",
    "    return sfs.select_hyperparams(pseudo_df, data, kfold_params, TFIDF_DIR, MODEL_DIR, use_proba)\n",
    "\n",
    "def get_idxs(data, rate, target=None, flag=False):\n",
    "    idx = np.array(list(range(data.shape[0])))\n",
    "    np.random.shuffle(idx)\n",
    "    idx = idx[:int(data.shape[0] *rate)]\n",
    "    \n",
    "    new_blocks =  pd.DataFrame(data.iloc[idx][FEATURE_COLUMN], columns=[FEATURE_COLUMN])\n",
    "    if flag:\n",
    "        new_blocks[TARGET_COLUMN] = target[idx]\n",
    "    else:\n",
    "        new_blocks[TARGET_COLUMN] = data.iloc[idx][TARGET_COLUMN]\n",
    "    return idx, new_blocks\n",
    "\n",
    "def get_idxs_most_accurate(data, rate, target, target_proba, reverse=False):\n",
    "    max_proba = target_proba.max(axis=1)\n",
    "    args = (-max_proba).argsort()\n",
    "    if reverse:\n",
    "        args = (max_proba).argsort()\n",
    "    idx = args[:int(data.shape[0] *rate)]\n",
    "    \n",
    "    new_blocks =  pd.DataFrame(data.iloc[idx][FEATURE_COLUMN], columns=[FEATURE_COLUMN])\n",
    "    new_blocks[TARGET_COLUMN] = target[idx]\n",
    "    return idx, new_blocks\n",
    "\n",
    "def get_pseudo(data, unlabeled_data, best_tfidf_params, best_svm_params, use_proba=False):\n",
    "    clf = SVC(**best_svm_params)\n",
    "    code_blocks_tfidf = tfidf_fit_transform(data[FEATURE_COLUMN], best_tfidf_params, TFIDF_DIR)\n",
    "    X, y = code_blocks_tfidf, data[TARGET_COLUMN].values\n",
    "    \n",
    "    clf.fit(X, y) \n",
    "    unl_tfidf = tfidf_transform(unlabeled_data[FEATURE_COLUMN], best_tfidf_params, TFIDF_DIR)\n",
    "    if use_proba:\n",
    "        return clf.predict(unl_tfidf), clf.predict_proba(unl_tfidf)\n",
    "    return clf.predict(unl_tfidf)\n",
    "\n",
    "def semi_baseline():\n",
    "    real_idx, temp_pseudo = get_idxs(data, 0.001)\n",
    "    train_data = data.drop(real_idx)\n",
    "    return find_hyperparams(temp_pseudo, train_data, kfold_params, tfidf_path, model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def semi_experiments(best_tfidf_params, best_svm_params, \n",
    "                data, unlabeled_data, \n",
    "                type_name = SemiType.RANDOM\n",
    "                tfidf_dir_name, model_dir_name, metrics_path, params_path,\n",
    "                tfidf_dir_base, model_dir_base,\n",
    "                iter_number = 2, rate = 0.2):\n",
    "    best_tfidf_params, best_svm_params, metrics = semi_baseline(tfidf_dir_base, model_dir_base)\n",
    "    pseudo_idx = []\n",
    "    pseudo_blocks = None\n",
    "    for i in range(iter_number):\n",
    "        print('Iteration ', i)\n",
    "        print('create new pseudo targets')\n",
    "        if type_name.name == RANDOM:\n",
    "            pseudo_target = get_pseudo(data, unlabeled_data.drop(pseudo_idx), best_tfidf_params, best_svm_params)\n",
    "            new_idx, new_blocks = get_idxs(unlabeled_data.drop(pseudo_idx), rate, pseudo_target, True)\n",
    "        else if type_name.name == MOST_ACCURATE:\n",
    "            pseudo_target, pseudo_target_proba = get_pseudo(data, unlabeled_data, best_tfidf_params, best_svm_params, True)\n",
    "            new_idx, new_blocks = get_idxs_most_accurate(unlabeled_data, 0.2, pseudo_target, pseudo_target_proba)\n",
    "        else:\n",
    "            pseudo_target, pseudo_target_proba = get_pseudo(data, unlabeled_data, best_tfidf_params, best_svm_params, True)\n",
    "            new_idx, new_blocks = get_idxs_most_accurate(unlabeled_data, 0.2, pseudo_target, pseudo_target_proba, True)\n",
    "            \n",
    "        pseudo_idx = np.append(pseudo_idx, new_idx)\n",
    "        if pseudo_blocks != None:\n",
    "            pseudo_blocks = pd.concat([pseudo_blocks, new_blocks])\n",
    "        else:\n",
    "            pseudo_blocks = new_blocks\n",
    "        print('start hyperparam search')\n",
    "        best_tfidf_params, best_svm_params, metrics = find_hyperparams(pseudo_blocks, \n",
    "                                                                       data, kfold_params, tfidf_dir_name, model_dir_name)\n",
    "        print('finish search')\n",
    "        print('Metrics are', metrics, '\\n')\n",
    "    \n",
    "    kfold_params = {\n",
    "    \"n_splits\": 9,\n",
    "    \"random_state\": RANDOM_STATE,\n",
    "    \"shuffle\": True,\n",
    "    }\n",
    "    data_meta = {\n",
    "        \"DATASET_PATH\": DATA_PATH,\n",
    "        \"nrows\": data.shape[0],\n",
    "        \"label\": '',\n",
    "        \"model\": model_dir_name,\n",
    "        \"script_dir\": 'nl2ml/models_scripts/semi_experiment.ipynb',\n",
    "    }\n",
    "\n",
    "    with dagshub.dagshub_logger(metrics_path=metrics_path, hparams_path=params_path) as logger:\n",
    "        print(\"logging the results\")\n",
    "        logger.log_hyperparams({\"data\": data_meta})\n",
    "        logger.log_hyperparams({\"tfidf\": best_tfidf_params_least_accurate})\n",
    "        logger.log_hyperparams({\"model\": best_svm_params_least_accurate})\n",
    "        logger.log_hyperparams({\"kfold\": kf})\n",
    "        logger.log_metrics(metrics_least_accurate_2)\n",
    "    return best_tfidf_params, best_svm_params, metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
