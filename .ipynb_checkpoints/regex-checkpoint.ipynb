{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PWhsBC6njw8W"
   },
   "source": [
    "# Regex Labeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QPPqGHrljw8Z"
   },
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VDXoZ7h3o7a2"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import csv\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "a_CklmUL35at"
   },
   "outputs": [],
   "source": [
    "GRAPH_VER = 6\n",
    "\n",
    "DATASET_PATH = './data_mini/code_blocks_raw.csv' ## CODE_COLUMN = 'code_block'\n",
    "OUTPUT_DATASET_PATH = './data_mini/code_blocks_regex_graph_v{}.csv'.format(GRAPH_VER)\n",
    "CODE_COLUMN = 'code_block'\n",
    "GRAPH_DIR = './graph/graph_v{}.txt'.format(GRAPH_VER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 475
    },
    "colab_type": "code",
    "id": "hGfSdj5Ajw9B",
    "outputId": "1ff38a33-c3aa-4d80-e508-288a22df37ca"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(DATASET_PATH, encoding='utf-8', sep='\\t')#, error_bad_lines=False, sep=',')#quoting=csv.QUOTE_NONE,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = df[[CODE_COLUMN, 'tag']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bv-ZljZASnW4",
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(df.isna().sum())\n",
    "df = df.dropna(subset=[CODE_COLUMN]).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lUXaQ1wpjw9U"
   },
   "outputs": [],
   "source": [
    "# def wordListToFreqDict(wordlist):\n",
    "#     def sortFreqDict(freqdict):\n",
    "#         aux = [(freqdict[key], key) for key in freqdict]\n",
    "#         aux.sort()\n",
    "#         aux.reverse()\n",
    "#         return aux\n",
    "#     wordfreq = [wordlist.count(p) for p in wordlist]\n",
    "#     return sortFreqDict(dict(list(zip(wordlist,wordfreq))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XiRkUliHlpWx"
   },
   "outputs": [],
   "source": [
    "# tokens = (\" \".join(\" \".join(df['Code'].to_list()).split('\\n')).split('.'))#.split('')\n",
    "# wordListToFreqDict(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GNbO3HXwjw9f"
   },
   "outputs": [],
   "source": [
    "# %%time\n",
    "# wordListToFreqDict(df.code.to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "h7-lyPQDjw9o"
   },
   "outputs": [],
   "source": [
    "# %%time\n",
    "# nl2ml = pd.read_csv(KK_PATH + 'nl2ml.csv')\n",
    "# nl2ml = nl2ml.rename({'':'code_block', '':'method_tag'})\n",
    "# nl2ml_vis = nl2ml[nl2ml['method_tag'] == 'Visualization']\n",
    "# tokens_visualization = wordListToFreqDict(nl2ml_vis.code_block.to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8DdGpT3GwvWo"
   },
   "outputs": [],
   "source": [
    "def tokens_search(df, tokens, new_column_name):\n",
    "    df[new_column_name] = 0\n",
    "    for i in range(len(df)):\n",
    "        percents = str(round(100*i/len(df),1))\n",
    "        print(percents + '%\\r', end='')\n",
    "        row = df[CODE_COLUMN][i]\n",
    "        for token in tokens:\n",
    "            result = re.search(token.replace('(','\\('), row)\n",
    "            if result!=None:\n",
    "                df[new_column_name][i] = 1\n",
    "                break\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BssLlwj4jw9-"
   },
   "source": [
    "## Regex Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(GRAPH_DIR, \"r\") as graph_file:\n",
    "    graph = json.load(graph_file)\n",
    "    # exec(graph_file.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 228
    },
    "colab_type": "code",
    "id": "1TlTFwwHjw-t",
    "outputId": "3766230b-ab98-4e48-c72c-4667c5fd229a",
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "for i in range(0, len(graph)):\n",
    "    vertice = list(graph.keys())[i]\n",
    "    print('\\n' + vertice)\n",
    "    tokens = graph[vertice]\n",
    "    df = tokens_search(df, tokens, vertice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['preprocessing'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zQuwy7Exjw_D"
   },
   "outputs": [],
   "source": [
    "df.to_csv(OUTPUT_DATASET_PATH, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xWYhQybHUZEj"
   },
   "outputs": [],
   "source": [
    "# for col in list(graph.keys()):\n",
    "#     display(df[df['Data format'] == 'Table'][col].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print('finished')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regex Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "import dagshub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GRAPH_VER = 5\n",
    "REGEXED_DATA_PATH = \"./data/golden_884_set.csv\"\n",
    "TAGS = ['import', 'data_import', 'data_export', 'preprocessing',\n",
    "                    'visualization', 'model', 'deep_learning_model', 'train', 'predict']\n",
    "REGEX_TAGS = [el+'_regex_v{}'.format(GRAPH_VER) for el in TAGS]\n",
    "regexed_data = pd.read_csv(REGEXED_DATA_PATH)\n",
    "regexed_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test, Y_pred = regexed_data[TAGS], regexed_data[REGEX_TAGS]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_f1 = f1_score(Y_test, Y_pred, average='weighted')\n",
    "base_precision = precision_score(Y_test, Y_pred, average='weighted')\n",
    "base_recall = recall_score(Y_test, Y_pred, average='weighted')\n",
    "regex_results = {'test_f1_score': base_f1\n",
    "                , 'test_precision': base_precision\n",
    "                , 'test_recall': base_recall}\n",
    "regex_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for i, tag in enumerate(TAGS):\n",
    "    tag_results = (round(f1_score(Y_test.iloc[:, i], Y_pred.iloc[:, i], average='weighted'),4),\\\n",
    "                    round(precision_score(Y_test.iloc[:, i], Y_pred.iloc[:, i], average='weighted'),4),\\\n",
    "                    round(recall_score(Y_test.iloc[:, i], Y_pred.iloc[:, i], average='weighted'),4))\n",
    "    print(tag)\n",
    "    print(tag_results)\n",
    "    print('------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_meta = {'DATASET_PATH': REGEXED_DATA_PATH\n",
    "            ,'nrows': regexed_data.shape[0]\n",
    "            ,'graph_ver': GRAPH_VER\n",
    "            ,'label': TAGS\n",
    "            ,'model': 'regex_v{}'.format(GRAPH_VER)\n",
    "            ,'script_dir': './regex.ipynb'\n",
    "            ,'task': 'regex evaluation'}\n",
    "\n",
    "with dagshub.dagshub_logger() as logger:\n",
    "    logger.log_hyperparams(data_meta)\n",
    "    logger.log_metrics(regex_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "NL2ML: Regex Labeling.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python (true)",
   "language": "python",
   "name": "python-true"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
