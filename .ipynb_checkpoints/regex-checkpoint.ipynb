{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PWhsBC6njw8W"
   },
   "source": [
    "# Regex Labeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QPPqGHrljw8Z"
   },
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VDXoZ7h3o7a2"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import csv\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "a_CklmUL35at"
   },
   "outputs": [],
   "source": [
    "GRAPH_VER = 6\n",
    "\n",
    "DATASET_PATH = './data/code_blocks_clean.csv' ## CODE_COLUMN = 'code_block'\n",
    "OUTPUT_DATASET_PATH = './data/code_blocks_regex_graph_v{}.csv'.format(GRAPH_VER)\n",
    "CODE_COLUMN = 'code_block'\n",
    "GRAPH_DIR = './graph/graph_v{}.txt'.format(GRAPH_VER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 475
    },
    "colab_type": "code",
    "id": "hGfSdj5Ajw9B",
    "outputId": "1ff38a33-c3aa-4d80-e508-288a22df37ca"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(DATASET_PATH, encoding='utf-8', sep='\\t')#, error_bad_lines=False, sep=',')#quoting=csv.QUOTE_NONE,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = df[[CODE_COLUMN, 'tag']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bv-ZljZASnW4",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "code_block      1\n",
      "tag           488\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df.isna().sum())\n",
    "df = df.dropna(subset=[CODE_COLUMN]).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lUXaQ1wpjw9U"
   },
   "outputs": [],
   "source": [
    "# def wordListToFreqDict(wordlist):\n",
    "#     def sortFreqDict(freqdict):\n",
    "#         aux = [(freqdict[key], key) for key in freqdict]\n",
    "#         aux.sort()\n",
    "#         aux.reverse()\n",
    "#         return aux\n",
    "#     wordfreq = [wordlist.count(p) for p in wordlist]\n",
    "#     return sortFreqDict(dict(list(zip(wordlist,wordfreq))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XiRkUliHlpWx"
   },
   "outputs": [],
   "source": [
    "# tokens = (\" \".join(\" \".join(df['Code'].to_list()).split('\\n')).split('.'))#.split('')\n",
    "# wordListToFreqDict(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GNbO3HXwjw9f"
   },
   "outputs": [],
   "source": [
    "# %%time\n",
    "# wordListToFreqDict(df.code.to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "h7-lyPQDjw9o"
   },
   "outputs": [],
   "source": [
    "# %%time\n",
    "# nl2ml = pd.read_csv(KK_PATH + 'nl2ml.csv')\n",
    "# nl2ml = nl2ml.rename({'':'code_block', '':'method_tag'})\n",
    "# nl2ml_vis = nl2ml[nl2ml['method_tag'] == 'Visualization']\n",
    "# tokens_visualization = wordListToFreqDict(nl2ml_vis.code_block.to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8DdGpT3GwvWo"
   },
   "outputs": [],
   "source": [
    "def tokens_search(df, tokens, new_column_name):\n",
    "    df[new_column_name] = 0\n",
    "    for i in range(len(df)):\n",
    "        percents = str(round(100*i/len(df),1))\n",
    "        print(percents + '%\\r', end='')\n",
    "        row = df[CODE_COLUMN][i]\n",
    "        for token in tokens:\n",
    "            result = re.search(token.replace('(','\\('), row)\n",
    "            if result!=None:\n",
    "                df[new_column_name][i] = 1\n",
    "                break\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BssLlwj4jw9-"
   },
   "source": [
    "## Regex Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "JSONDecodeError",
     "evalue": "Expecting ',' delimiter: line 4 column 41 (char 204)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-dfc4f5f37367>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mGRAPH_DIR\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"r\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mgraph_file\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mgraph\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgraph_file\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[1;31m# graph = graph_file.read()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\json\\__init__.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(fp, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[0;32m    294\u001b[0m         \u001b[0mcls\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcls\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobject_hook\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mobject_hook\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    295\u001b[0m         \u001b[0mparse_float\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mparse_float\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparse_int\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mparse_int\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 296\u001b[1;33m         parse_constant=parse_constant, object_pairs_hook=object_pairs_hook, **kw)\n\u001b[0m\u001b[0;32m    297\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    298\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\json\\__init__.py\u001b[0m in \u001b[0;36mloads\u001b[1;34m(s, encoding, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[0;32m    346\u001b[0m             \u001b[0mparse_int\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mparse_float\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    347\u001b[0m             parse_constant is None and object_pairs_hook is None and not kw):\n\u001b[1;32m--> 348\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_default_decoder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    349\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    350\u001b[0m         \u001b[0mcls\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mJSONDecoder\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\json\\decoder.py\u001b[0m in \u001b[0;36mdecode\u001b[1;34m(self, s, _w)\u001b[0m\n\u001b[0;32m    335\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    336\u001b[0m         \"\"\"\n\u001b[1;32m--> 337\u001b[1;33m         \u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraw_decode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0midx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0m_w\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    338\u001b[0m         \u001b[0mend\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_w\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    339\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mend\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\json\\decoder.py\u001b[0m in \u001b[0;36mraw_decode\u001b[1;34m(self, s, idx)\u001b[0m\n\u001b[0;32m    351\u001b[0m         \"\"\"\n\u001b[0;32m    352\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 353\u001b[1;33m             \u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscan_once\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0midx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    354\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    355\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mJSONDecodeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Expecting value\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mJSONDecodeError\u001b[0m: Expecting ',' delimiter: line 4 column 41 (char 204)"
     ]
    }
   ],
   "source": [
    "with open(GRAPH_DIR, \"r\") as graph_file:\n",
    "    graph = json.load(graph_file)\n",
    "    # graph = graph_file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 228
    },
    "colab_type": "code",
    "id": "1TlTFwwHjw-t",
    "outputId": "3766230b-ab98-4e48-c72c-4667c5fd229a",
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "for i in range(0, len(graph)):\n",
    "    vertice = list(graph.keys())[i]\n",
    "    print('\\n' + vertice)\n",
    "    tokens = graph[vertice]\n",
    "    df = tokens_search(df, tokens, vertice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['preprocessing'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zQuwy7Exjw_D"
   },
   "outputs": [],
   "source": [
    "df.to_csv(OUTPUT_DATASET_PATH, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xWYhQybHUZEj"
   },
   "outputs": [],
   "source": [
    "# for col in list(graph.keys()):\n",
    "#     display(df[df['Data format'] == 'Table'][col].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print('finished')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regex Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "import dagshub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>code_block</th>\n",
       "      <th>import</th>\n",
       "      <th>data_import</th>\n",
       "      <th>data_export</th>\n",
       "      <th>preprocessing</th>\n",
       "      <th>visualization</th>\n",
       "      <th>model</th>\n",
       "      <th>deep_learning_model</th>\n",
       "      <th>train</th>\n",
       "      <th>predict</th>\n",
       "      <th>import_regex</th>\n",
       "      <th>data_import_regex_v5</th>\n",
       "      <th>data_export_regex_v5</th>\n",
       "      <th>preprocessing_regex_v5</th>\n",
       "      <th>visualization_regex_v5</th>\n",
       "      <th>model_regex_v5</th>\n",
       "      <th>deep_learning_model_regex_v5</th>\n",
       "      <th>train_regex_v5</th>\n",
       "      <th>predict_regex_v5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\\nprint(f())    \\n\\nx = 5\\ndef f():\\n    y = 2...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\\nprint(int('807') + 1),\\n\\nimport numpy as np...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\\nimport numpy as np \\nimport pandas as pd \\ni...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\\n Average Precision-Recall Score ={0:0.2f}'.f...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\\nplot_confusion_matrix(actual_cm, labels, tit...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          code_block  import  data_import  \\\n",
       "0  \\nprint(f())    \\n\\nx = 5\\ndef f():\\n    y = 2...       1            0   \n",
       "1  \\nprint(int('807') + 1),\\n\\nimport numpy as np...       1            0   \n",
       "2  \\nimport numpy as np \\nimport pandas as pd \\ni...       1            0   \n",
       "3  \\n Average Precision-Recall Score ={0:0.2f}'.f...       1            0   \n",
       "4  \\nplot_confusion_matrix(actual_cm, labels, tit...       1            0   \n",
       "\n",
       "   data_export  preprocessing  visualization  model  deep_learning_model  \\\n",
       "0            0              0              0      0                    0   \n",
       "1            0              0              0      0                    0   \n",
       "2            0              0              0      0                    0   \n",
       "3            0              0              0      0                    0   \n",
       "4            0              0              1      0                    0   \n",
       "\n",
       "   train  predict  import_regex  data_import_regex_v5  data_export_regex_v5  \\\n",
       "0      0        0             1                     0                     0   \n",
       "1      0        0             1                     0                     0   \n",
       "2      0        0             1                     0                     0   \n",
       "3      0        1             1                     0                     0   \n",
       "4      0        0             1                     0                     0   \n",
       "\n",
       "   preprocessing_regex_v5  visualization_regex_v5  model_regex_v5  \\\n",
       "0                       0                       0               0   \n",
       "1                       0                       0               0   \n",
       "2                       0                       0               0   \n",
       "3                       0                       0               0   \n",
       "4                       0                       0               0   \n",
       "\n",
       "   deep_learning_model_regex_v5  train_regex_v5  predict_regex_v5  \n",
       "0                             0               0                 0  \n",
       "1                             0               0                 0  \n",
       "2                             0               0                 0  \n",
       "3                             0               0                 0  \n",
       "4                             0               0                 0  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GRAPH_VER = 5\n",
    "REGEXED_DATA_PATH = \"./data/golden_884_set.csv\"\n",
    "TAGS = ['import', 'data_import', 'data_export', 'preprocessing',\n",
    "                    'visualization', 'model', 'deep_learning_model', 'train', 'predict']\n",
    "REGEX_TAGS = [el+'_regex_v{}'.format(GRAPH_VER) for el in TAGS]\n",
    "regexed_data = pd.read_csv(REGEXED_DATA_PATH)\n",
    "regexed_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test, Y_pred = regexed_data[TAGS], regexed_data[REGEX_TAGS]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'test_f1_score': 0.7568760919796619,\n",
       " 'test_precision': 0.9258695652173914,\n",
       " 'test_recall': 0.6784420289855072}"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_f1 = f1_score(Y_test, Y_pred, average='weighted')\n",
    "base_precision = precision_score(Y_test, Y_pred, average='weighted')\n",
    "base_recall = recall_score(Y_test, Y_pred, average='weighted')\n",
    "regex_results = {'test_f1_score': base_f1\n",
    "                , 'test_precision': base_precision\n",
    "                , 'test_recall': base_recall}\n",
    "regex_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import\n",
      "(1.0, 1.0, 1.0)\n",
      "------\n",
      "data_import\n",
      "(0.9767, 0.9772, 0.9774)\n",
      "------\n",
      "data_export\n",
      "(0.9931, 0.9933, 0.9932)\n",
      "------\n",
      "preprocessing\n",
      "(0.8392, 0.8781, 0.8597)\n",
      "------\n",
      "visualization\n",
      "(0.8773, 0.9047, 0.8914)\n",
      "------\n",
      "model\n",
      "(0.9127, 0.9258, 0.9208)\n",
      "------\n",
      "deep_learning_model\n",
      "(0.918, 0.9516, 0.8948)\n",
      "------\n",
      "train\n",
      "(0.9683, 0.9683, 0.9683)\n",
      "------\n",
      "predict\n",
      "(0.9425, 0.9463, 0.94)\n",
      "------\n"
     ]
    }
   ],
   "source": [
    "for i, tag in enumerate(TAGS):\n",
    "    tag_results = (round(f1_score(Y_test.iloc[:, i], Y_pred.iloc[:, i], average='weighted'),4),\\\n",
    "                    round(precision_score(Y_test.iloc[:, i], Y_pred.iloc[:, i], average='weighted'),4),\\\n",
    "                    round(recall_score(Y_test.iloc[:, i], Y_pred.iloc[:, i], average='weighted'),4))\n",
    "    print(tag)\n",
    "    print(tag_results)\n",
    "    print('------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_meta = {'DATASET_PATH': REGEXED_DATA_PATH\n",
    "            ,'nrows': regexed_data.shape[0]\n",
    "            ,'graph_ver': GRAPH_VER\n",
    "            ,'label': TAGS\n",
    "            ,'model': 'regex_v{}'.format(GRAPH_VER)\n",
    "            ,'script_dir': './regex.ipynb'\n",
    "            ,'task': 'regex evaluation'}\n",
    "\n",
    "with dagshub.dagshub_logger() as logger:\n",
    "    logger.log_hyperparams(data_meta)\n",
    "    logger.log_metrics(regex_results)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "NL2ML: Regex Labeling.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
