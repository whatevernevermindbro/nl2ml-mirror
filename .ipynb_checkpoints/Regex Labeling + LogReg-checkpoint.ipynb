{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regex Labeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VDXoZ7h3o7a2"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "a_CklmUL35at"
   },
   "outputs": [],
   "source": [
    "KK_PATH = './'\n",
    "# DATASET_PATH = 'code_blocks_final_clean.csv'\n",
    "DATASET_PATH = 'chunks_30_final.csv'\n",
    "NEW_DATASET_PATH = DATASET_PATH[:-4] + '_regex.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 98
    },
    "colab_type": "code",
    "id": "uNMxMypsx63n",
    "outputId": "36fdf85e-bfd4-4376-dd7f-3caa38663b21"
   },
   "outputs": [],
   "source": [
    "# df = pd.read_csv(KK_PATH + 'code_blocks.csv', sep='\\t')\n",
    "# df = df.dropna()\n",
    "# df = df.drop_duplicates()\n",
    "# df = df.reset_index(drop=True)\n",
    "# df['code_block_length'] = np.zeros(len(df))\n",
    "# for i in range(len(df)):\n",
    "#     df['code_block_length'][i] = len(df['code_block'][i])\n",
    "#     print(str(i)+'\\r', end='')\n",
    "# df = df.drop(df[df['code_block_length'] > 512].index)\n",
    "# df.shape\n",
    "# df.to_csv(KK_PATH + 'code_blocks_prepared.csv', sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 33
    },
    "colab_type": "code",
    "id": "cvyM07BJsvwg",
    "outputId": "1cbe1cd9-6d97-44d4-b0d8-c00b1e6e9a78"
   },
   "outputs": [],
   "source": [
    "# df = pd.read_csv(KK_PATH + 'code_blocks_prepared.csv', sep='\\t')\n",
    "# df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(KK_PATH + DATASET_PATH, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(76243, 1)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wordListToFreqDict(wordlist):\n",
    "    def sortFreqDict(freqdict):\n",
    "        aux = [(freqdict[key], key) for key in freqdict]\n",
    "        aux.sort()\n",
    "        aux.reverse()\n",
    "        return aux\n",
    "    wordfreq = [wordlist.count(p) for p in wordlist]\n",
    "    return sortFreqDict(dict(list(zip(wordlist,wordfreq))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# wordListToFreqDict(df.code.to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# nl2ml = pd.read_csv(KK_PATH + 'nl2ml.csv')\n",
    "# nl2ml = nl2ml.rename({'':'code_block', '':'method_tag'})\n",
    "# nl2ml_vis = nl2ml[nl2ml['method_tag'] == 'Visualization']\n",
    "# tokens_visualization = wordListToFreqDict(nl2ml_vis.code_block.to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "8DdGpT3GwvWo",
    "outputId": "14357c6e-c7c9-4572-a157-c166a2f02bb8"
   },
   "outputs": [],
   "source": [
    "def tokens_search(df, tokens, new_column_name):\n",
    "    df[new_column_name] = 0\n",
    "    for i in range(len(df)):\n",
    "        percents = str(round(100*i/len(df),1))\n",
    "        print(percents + '%\\r', end='')\n",
    "        row = df['code'][i]\n",
    "        for token in tokens:\n",
    "            result = re.search(token, row)\n",
    "            if result!=None:\n",
    "                df[new_column_name][i] = 1\n",
    "                break\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regex Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = {'imports':['import', 'from']#, 'as']\n",
    "          ,'load_data':['load', 'csv', 'glob', 'pickle', 'read', 'download', 'txt']\n",
    "          ,'preprocessing':['preprocess', 'plot', 'heatmap', 'figure', 'encode', 'fill', 'merge', 'vectorize', 'generation', 'augmentation', 'stemming', 'lemmatization', 'scale', 'normalize', 'crop', 'convert', 'resize']\n",
    "          ,'model':['LinearRegression', 'RandomForest', 'Ridge', 'Lasso', 'SGD', 'LogisticRegression', 'SVM', 'SVC', 'Layer', 'xgboost', 'LGBM', 'CatBoost']\n",
    "          ,'train': ['train', 'fit', 'epoch', 'loss', 'learn', 'optimizer']\n",
    "          ,'predict':['predict', 'error', 'evaluation', 'MSE', 'Test']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0%\r",
      "0.0%\r",
      "0.0%\r",
      "0.0%\r",
      "0.0%\r",
      "0.0%\r",
      "0.0%\r",
      "0.0%\r",
      "0.0%\r",
      "0.0%\r",
      "0.0%\r",
      "0.0%\r",
      "0.0%\r",
      "0.0%\r",
      "0.0%\r",
      "0.0%\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Alex\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46.2%%\r"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for i in range(0, len(graph)):\n",
    "    print(i)\n",
    "    vertice = list(graph.keys())[i]\n",
    "    tokens = graph[vertice]\n",
    "    df = tokens_search(df, tokens, vertice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(NEW_DATASET_PATH, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tag: Import-Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1VhsSVhWj1Wx"
   },
   "outputs": [],
   "source": [
    "# # TAG: input_output\n",
    "# tokens_io = ['read', 'csv' , 'sql' , 'json' , 'png' , 'jpg' ,\n",
    "#           'tsv' , 'write' , 'open' , 'print' , 'output' ,\n",
    "#           'stdin' , 'stdout' , 'path' , 'dir'\n",
    "# #            , 'import'\n",
    "#           ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# %%time\n",
    "# df = tokens_search(df, tokens_io, 'tag_import_output')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.to_csv(KK_PATH + 'chunks_30_tag_io.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tag: Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokens_visualization = ['plot', 'hist', 'sns.', 'plt.']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# df = tokens_search(df, tokens_visualization, 'tag_visualization')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.to_csv(KK_PATH + 'chunks_30_tags.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF + Log Reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(NEW_DATASET_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = df['code']\n",
    "train_corpus = df['code'][0:30000]\n",
    "test_corpus = df['code'][30000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf = TfidfVectorizer(min_df=5\n",
    "                        , max_df = 0.3\n",
    "                        , ngram_range = (1,2)\n",
    "                        , smooth_idf = True\n",
    "                       )\n",
    "features = tfidf.fit_transform(corpus)\n",
    "# for_pred = tfidf.transform(test_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(features[0:len(df['tag_import_output'])], df['tag_import_output'], test_size=0.25)\n",
    "clf = LogisticRegression(random_state=4321).fit(X_train, y_train)\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "accuracy = clf.score(X_test, y_test)\n",
    "print(f'Mean Accuracy {round(accuracy*100, 2)}%')\n",
    "print(f'F1-score {round(metrics.f1_score(y_pred, y_test)*100, 2)}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.plot_precision_recall_curve(clf, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "metrics.plot_confusion_matrix(clf, X_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
