{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from comment_parser import comment_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"../data/NL2ML_ structure - levin.csv\"\n",
    "\n",
    "df = pd.read_csv(filename, skiprows=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chunk_id</th>\n",
       "      <th>notebook_id</th>\n",
       "      <th>splitting_id</th>\n",
       "      <th>code_block</th>\n",
       "      <th>data_format</th>\n",
       "      <th>graph_vertex</th>\n",
       "      <th>errors</th>\n",
       "      <th>graph_vertex_m1</th>\n",
       "      <th>graph_vertex_m2</th>\n",
       "      <th>graph_vertex_m3</th>\n",
       "      <th>...</th>\n",
       "      <th>python_methods_m3</th>\n",
       "      <th>python_methods_p1</th>\n",
       "      <th>python_methods_p2</th>\n",
       "      <th>python_methods_p3</th>\n",
       "      <th>kaggle_link</th>\n",
       "      <th>kaggle_comments</th>\n",
       "      <th>kaggle_upvotes</th>\n",
       "      <th>kaggle_section</th>\n",
       "      <th>kaggle_section_overview</th>\n",
       "      <th>kaggle_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>import os\\nimport numpy as np\\nimport matplotl...</td>\n",
       "      <td>None</td>\n",
       "      <td>Environment.import_modules</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>print('Reading datasets...', end='')\\n\\ntrain_...</td>\n",
       "      <td>Table</td>\n",
       "      <td>Data: extraction.Load from CSV</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>print('Preprocessing data...', end='')\\n\\nfeat...</td>\n",
       "      <td>Table</td>\n",
       "      <td>Data: transform.filter;Data: transform.data ty...</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>print('Creating classifier...', end='')\\nclf =...</td>\n",
       "      <td>None</td>\n",
       "      <td>Model: train.choose model class</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>print('Training classifier...', end='')\\r\\n%ti...</td>\n",
       "      <td>Table</td>\n",
       "      <td>Model: train.train model</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   chunk_id  notebook_id  splitting_id  \\\n",
       "0       1.0          1.0           1.0   \n",
       "1       2.0          1.0           1.0   \n",
       "2       3.0          1.0           1.0   \n",
       "3       4.0          1.0           1.0   \n",
       "4       5.0          1.0           1.0   \n",
       "\n",
       "                                          code_block data_format  \\\n",
       "0  import os\\nimport numpy as np\\nimport matplotl...        None   \n",
       "1  print('Reading datasets...', end='')\\n\\ntrain_...       Table   \n",
       "2  print('Preprocessing data...', end='')\\n\\nfeat...       Table   \n",
       "3  print('Creating classifier...', end='')\\nclf =...        None   \n",
       "4  print('Training classifier...', end='')\\r\\n%ti...       Table   \n",
       "\n",
       "                                        graph_vertex  errors  graph_vertex_m1  \\\n",
       "0                         Environment.import_modules   False              NaN   \n",
       "1                     Data: extraction.Load from CSV   False              NaN   \n",
       "2  Data: transform.filter;Data: transform.data ty...   False              NaN   \n",
       "3                    Model: train.choose model class   False              NaN   \n",
       "4                           Model: train.train model   False              NaN   \n",
       "\n",
       "   graph_vertex_m2  graph_vertex_m3  ...  python_methods_m3  \\\n",
       "0              NaN              NaN  ...                NaN   \n",
       "1              NaN              NaN  ...                NaN   \n",
       "2              NaN              NaN  ...                NaN   \n",
       "3              NaN              NaN  ...                NaN   \n",
       "4              NaN              NaN  ...                NaN   \n",
       "\n",
       "   python_methods_p1  python_methods_p2  python_methods_p3  kaggle_link  \\\n",
       "0                NaN                NaN                NaN          NaN   \n",
       "1                NaN                NaN                NaN          NaN   \n",
       "2                NaN                NaN                NaN          NaN   \n",
       "3                NaN                NaN                NaN          NaN   \n",
       "4                NaN                NaN                NaN          NaN   \n",
       "\n",
       "   kaggle_comments  kaggle_upvotes  kaggle_section  kaggle_section_overview  \\\n",
       "0              NaN             NaN             NaN                      NaN   \n",
       "1              NaN             NaN             NaN                      NaN   \n",
       "2              NaN             NaN             NaN                      NaN   \n",
       "3              NaN             NaN             NaN                      NaN   \n",
       "4              NaN             NaN             NaN                      NaN   \n",
       "\n",
       "   kaggle_score  \n",
       "0           NaN  \n",
       "1           NaN  \n",
       "2           NaN  \n",
       "3           NaN  \n",
       "4           NaN  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the column names from the original markup file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HEADER = df.columns\n",
    "# HEADER = [col if (\"Unnamed:\" not in col) else \"\" for col in HEADER ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.columns = df.iloc[0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = df.drop(index=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions for parsing libraries and comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dict(str_arr):\n",
    "    name_lib_import = {}\n",
    "    name_lib_from = {}\n",
    "    str_arr = [[line.strip() for line in text.split(\"\\n\")] for text in str_arr]\n",
    "    # delete all double spaces in all lines\n",
    "    for line_array in str_arr:\n",
    "        for ind in range(len(line_array)):\n",
    "            prev_len = -1\n",
    "            while prev_len != len(line_array[ind]):\n",
    "                prev_len = len(line_array[ind])\n",
    "                line_array[ind] = line_array[ind].replace(\"  \", \" \")\n",
    "    # now get libraries if line start with \"import\" or \"from\"\n",
    "    for line_array in str_arr:\n",
    "        for line in line_array:\n",
    "            if line.startswith(\"import\"):\n",
    "                split_arr = line.split(\" \")\n",
    "                # if we have \"import ... as ...\"\"\n",
    "                if len(split_arr) > 2 and split_arr[2] == \"as\":\n",
    "                    name_lib_import[split_arr[-1]] = split_arr[1].split(\".\")[0]\n",
    "            \n",
    "            if line.startswith(\"from\"):\n",
    "                split_arr = line.split(\" \")\n",
    "                # if we have \"from ... import ...\"\"\n",
    "                if len(split_arr) > 2 and split_arr[2] == \"import\":\n",
    "                    name_lib_from[split_arr[-1]] = split_arr[1].split(\".\")[0]\n",
    "    return (name_lib_import, name_lib_from)\n",
    "    \n",
    "    \n",
    "def get_libraries(text: str, dicts: tuple):\n",
    "    name_lib_import = dicts[0]\n",
    "    name_lib_from = dicts[1]\n",
    "    text = str(text)\n",
    "    libs = []\n",
    "    line_array = [line.strip() for line in text.split(\"\\n\")]\n",
    "    # delete all double spaces in all lines\n",
    "    for ind in range(len(line_array)):\n",
    "        \n",
    "        prev_len = -1\n",
    "        while prev_len != len(line_array[ind]):\n",
    "            prev_len = len(line_array[ind])\n",
    "            line_array[ind] = line_array[ind].replace(\"  \", \" \")\n",
    "    # now get libraries if line start with \"import\" or \"from\"\n",
    "    for line in line_array:\n",
    "        if line.startswith(\"import\") or line.startswith(\"from\"):\n",
    "            libs.append(line.split(\" \")[1].split(\".\")[0])\n",
    "    for name in name_lib_from.keys():\n",
    "        for line in line_array:\n",
    "            if name in line:\n",
    "                libs.append(name_lib_from[name])\n",
    "                \n",
    "    for name in name_lib_import.keys():\n",
    "        for line in line_array:\n",
    "            if name + \".\" in line:\n",
    "                libs.append(name_lib_import[name])\n",
    "        \n",
    "    return \"\\n\".join(list(set(libs)))\n",
    "\n",
    "\n",
    "def get_comments(text: str):\n",
    "    text = str(text)\n",
    "#     comments = comment_parser.extract_comments_from_str(text, mime=\"text/x-python\")\n",
    "#     return \"\\n\".join([line.text() for line in comments])\n",
    "\n",
    "    comments = []\n",
    "    line_array = [line.strip() for line in text.split(\"\\n\")]\n",
    "    # now get libraries if line start with \"#\"\n",
    "    for line_ind in range(len(line_array)):\n",
    "        if line_array[line_ind].startswith(\"#\"):\n",
    "            comments.append(line_array[line_ind][1:])\n",
    "        elif line_array[line_ind].startswith(\"'''\"):\n",
    "            multi_comm = str()\n",
    "            multi_comm += line_array[line_ind][3:] + \"\\n\"\n",
    "            if \"'''\" in multi_comm:\n",
    "                multi_comm = multi_comm.replace(\"'''\", \"\")\n",
    "                line_ind += 1\n",
    "                comments.append(multi_comm)\n",
    "                continue\n",
    "            line_ind += 1\n",
    "            while line_ind < len(line_array):\n",
    "                multi_comm += line_array[line_ind] + \"\\n\"\n",
    "                if \"'''\" in multi_comm:\n",
    "                    multi_comm = multi_comm.replace(\"'''\", \"\")\n",
    "                    line_ind += 1\n",
    "                    break\n",
    "                line_ind += 1\n",
    "            comments.append(multi_comm)\n",
    "        elif line_array[line_ind].startswith('\"\"\"'):\n",
    "            multi_comm = str()\n",
    "            multi_comm += line_array[line_ind][3:] + \"\\n\"\n",
    "            if '\"\"\"' in multi_comm:\n",
    "                multi_comm = multi_comm.replace('\"\"\"', \"\")\n",
    "                line_ind += 1\n",
    "                comments.append(multi_comm)\n",
    "                continue\n",
    "            line_ind += 1\n",
    "            while line_ind < len(line_array):\n",
    "                multi_comm += line_array[line_ind] + \"\\n\"\n",
    "                if '\"\"\"' in multi_comm:\n",
    "                    multi_comm = multi_comm.replace('\"\"\"', \"\")\n",
    "                    line_ind += 1\n",
    "                    break\n",
    "                line_ind += 1\n",
    "            comments.append(multi_comm)\n",
    "            pass\n",
    "    return \"\\n\".join([line for line in comments])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['libraries'] = df.code_block.apply(get_libraries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['comments'] = df.code_block.apply(get_comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                                       \n",
       "1                                                       \n",
       "2                           train = train.fillna(-99999)\n",
       "3      sampling_method='gradient_based',\\neval_metric...\n",
       "4                                                       \n",
       "                             ...                        \n",
       "994                                                     \n",
       "995                                                     \n",
       "996                                                     \n",
       "997                                                     \n",
       "998                                                     \n",
       "Name: comments, Length: 999, dtype: object"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['comments']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For each 'notebook_id' do cell shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Alex\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  app.launch_new_instance()\n",
      "C:\\Users\\Alex\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\Alex\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\Alex\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  app.launch_new_instance()\n",
      "C:\\Users\\Alex\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\Alex\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\Alex\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  app.launch_new_instance()\n",
      "C:\\Users\\Alex\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\Alex\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chunk_id</th>\n",
       "      <th>notebook_id</th>\n",
       "      <th>splitting_id</th>\n",
       "      <th>code_block</th>\n",
       "      <th>data_format</th>\n",
       "      <th>graph_vertex</th>\n",
       "      <th>errors</th>\n",
       "      <th>graph_vertex_m1</th>\n",
       "      <th>graph_vertex_m2</th>\n",
       "      <th>graph_vertex_m3</th>\n",
       "      <th>...</th>\n",
       "      <th>python_methods_m3</th>\n",
       "      <th>python_methods_p1</th>\n",
       "      <th>python_methods_p2</th>\n",
       "      <th>python_methods_p3</th>\n",
       "      <th>kaggle_link</th>\n",
       "      <th>kaggle_comments</th>\n",
       "      <th>kaggle_upvotes</th>\n",
       "      <th>kaggle_section</th>\n",
       "      <th>kaggle_section_overview</th>\n",
       "      <th>kaggle_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>import os\\nimport numpy as np\\nimport matplotl...</td>\n",
       "      <td>None</td>\n",
       "      <td>Environment.import_modules</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>print('Reading datasets...', end='')\\n\\ntrain_...</td>\n",
       "      <td>Table</td>\n",
       "      <td>Data: extraction.Load from CSV</td>\n",
       "      <td>False</td>\n",
       "      <td>Environment.import_modules</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>print('Preprocessing data...', end='')\\n\\nfeat...</td>\n",
       "      <td>Table</td>\n",
       "      <td>Data: transform.filter;Data: transform.data ty...</td>\n",
       "      <td>False</td>\n",
       "      <td>Data: extraction.Load from CSV</td>\n",
       "      <td>Environment.import_modules</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>print('Creating classifier...', end='')\\nclf =...</td>\n",
       "      <td>None</td>\n",
       "      <td>Model: train.choose model class</td>\n",
       "      <td>False</td>\n",
       "      <td>Data: transform.filter;Data: transform.data ty...</td>\n",
       "      <td>Data: extraction.Load from CSV</td>\n",
       "      <td>Environment.import_modules</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>print('Training classifier...', end='')\\r\\n%ti...</td>\n",
       "      <td>Table</td>\n",
       "      <td>Model: train.train model</td>\n",
       "      <td>False</td>\n",
       "      <td>Model: train.choose model class</td>\n",
       "      <td>Data: transform.filter;Data: transform.data ty...</td>\n",
       "      <td>Data: extraction.Load from CSV</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   chunk_id  notebook_id  splitting_id  \\\n",
       "0         1            1           1.0   \n",
       "1         2            1           1.0   \n",
       "2         3            1           1.0   \n",
       "3         4            1           1.0   \n",
       "4         5            1           1.0   \n",
       "\n",
       "                                          code_block data_format  \\\n",
       "0  import os\\nimport numpy as np\\nimport matplotl...        None   \n",
       "1  print('Reading datasets...', end='')\\n\\ntrain_...       Table   \n",
       "2  print('Preprocessing data...', end='')\\n\\nfeat...       Table   \n",
       "3  print('Creating classifier...', end='')\\nclf =...        None   \n",
       "4  print('Training classifier...', end='')\\r\\n%ti...       Table   \n",
       "\n",
       "                                        graph_vertex  errors  \\\n",
       "0                         Environment.import_modules   False   \n",
       "1                     Data: extraction.Load from CSV   False   \n",
       "2  Data: transform.filter;Data: transform.data ty...   False   \n",
       "3                    Model: train.choose model class   False   \n",
       "4                           Model: train.train model   False   \n",
       "\n",
       "                                     graph_vertex_m1  \\\n",
       "0                                                NaN   \n",
       "1                         Environment.import_modules   \n",
       "2                     Data: extraction.Load from CSV   \n",
       "3  Data: transform.filter;Data: transform.data ty...   \n",
       "4                    Model: train.choose model class   \n",
       "\n",
       "                                     graph_vertex_m2  \\\n",
       "0                                                NaN   \n",
       "1                                                NaN   \n",
       "2                         Environment.import_modules   \n",
       "3                     Data: extraction.Load from CSV   \n",
       "4  Data: transform.filter;Data: transform.data ty...   \n",
       "\n",
       "                  graph_vertex_m3  ... python_methods_m3 python_methods_p1  \\\n",
       "0                             NaN  ...               NaN               NaN   \n",
       "1                             NaN  ...               NaN               NaN   \n",
       "2                             NaN  ...               NaN               NaN   \n",
       "3      Environment.import_modules  ...               NaN               NaN   \n",
       "4  Data: extraction.Load from CSV  ...               NaN               NaN   \n",
       "\n",
       "  python_methods_p2 python_methods_p3 kaggle_link  kaggle_comments  \\\n",
       "0               NaN               NaN         NaN              NaN   \n",
       "1               NaN               NaN         NaN              NaN   \n",
       "2               NaN               NaN         NaN              NaN   \n",
       "3               NaN               NaN         NaN              NaN   \n",
       "4               NaN               NaN         NaN              NaN   \n",
       "\n",
       "   kaggle_upvotes  kaggle_section  kaggle_section_overview  kaggle_score  \n",
       "0             NaN             NaN                      NaN           NaN  \n",
       "1             NaN             NaN                      NaN           NaN  \n",
       "2             NaN             NaN                      NaN           NaN  \n",
       "3             NaN             NaN                      NaN           NaN  \n",
       "4             NaN             NaN                      NaN           NaN  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "notebooks_ids = set([i for i in df['notebook_id'].values if str(i) != 'nan'])\n",
    "SHIFT_RANGE = 3\n",
    "all_temp_dfs = []\n",
    "\n",
    "# print(notebooks_ids)\n",
    "for not_id in notebooks_ids:\n",
    "    # get rows for one notebook_id\n",
    "    temp_df = df[df['notebook_id'] == not_id]\n",
    "    buf_graph_vertex = list(temp_df.graph_vertex.values)\n",
    "    dicts = get_dict(temp_df.code_block.values)\n",
    "#     print(dicts)\n",
    "    buf_arr = []\n",
    "    for code in temp_df.code_block.values:\n",
    "#         print(get_libraries(code, dicts))\n",
    "        buf_arr.append(get_libraries(code, dicts))\n",
    "    temp_df['libraries'] = buf_arr\n",
    "    # shift down\n",
    "    for i in range(1, SHIFT_RANGE + 1):\n",
    "        temp_df['graph_vertex_m' + str(i)] = [np.NaN] * i + buf_graph_vertex[0: -i]\n",
    "    # shift up\n",
    "    for i in range(1, SHIFT_RANGE + 1):\n",
    "        temp_df['graph_vertex_p' + str(i)] = buf_graph_vertex[i:] + [np.NaN] * i\n",
    "    all_temp_dfs.append(temp_df)\n",
    "    \n",
    "# concatenate all shifted notebooks\n",
    "final_df = pd.concat(all_temp_dfs)\n",
    "final_df['notebook_id'] = final_df['notebook_id'].apply(int)\n",
    "final_df['chunk_id'] = final_df['chunk_id'].apply(int)\n",
    "\n",
    "final_df.sort_values(['notebook_id', 'chunk_id'], inplace=True)\n",
    "final_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>code_block</th>\n",
       "      <th>libraries</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>import os\\nimport numpy as np\\nimport matplotlib.pyplot as plt\\n\\nimport cudf\\n\\nfrom sklearn import preprocessing\\nfrom sklearn.model_selection import GridSearchCV\\nfrom sklearn.model_selection import StratifiedKFold\\n\\nimport pandas as pd\\npd.set_option('display.max_columns', 500)\\n\\nimport xgboost as xgb\\nprint(\"XGBoost version:\", xgb.__version__)\\n\\nimport warnings\\nwarnings.filterwarnings(\"ignore\")\\n\\nimport janestreet\\nprint('Creating competition environment...', end='')\\nenv = janestr...</td>\n",
       "      <td>xgboost\\nmatplotlib\\npandas\\ncudf\\nos\\njanestreet\\nsklearn\\nwarnings\\nnumpy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>print('Reading datasets...', end='')\\n\\ntrain_cudf = cudf.read_csv('/kaggle/input/jane-street-market-prediction/train.csv')\\ntrain = train_cudf.to_pandas()\\ndel train_cudf\\n\\nfeatures_meta_cudf = cudf.read_csv('/kaggle/input/jane-street-market-prediction/features.csv')\\nfeatures_meta = features_meta_cudf.to_pandas()\\ndel features_meta_cudf\\n\\nprint('Finished.')\\n\\nprint(f'train shape: {format(train.shape)}')\\nprint(f'features_meta shape: {format(features_meta.shape)}')</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>print('Preprocessing data...', end='')\\n\\nfeatures = [col for col in list(train.columns) if 'feature' in col]\\n\\ntrain = train[train['weight'] != 0]\\n\\ntrain['action'] = (train['resp'].values &gt; 0).astype(int)\\n\\n#train = train.fillna(-99999)\\ntrain.fillna(f_mean)\\n\\nX_train = train.loc[:, features]\\ny_train = train.loc[:, 'action']\\ndel train\\n\\nprint('Finished.')</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>print('Creating classifier...', end='')\\nclf = xgb.XGBClassifier(\\n    n_estimators=400,\\n    max_depth=7,\\n    eta=0.5, # learning_rate\\n    missing=None,\\n    random_state=42,\\n    tree_method='gpu_hist',\\n    subsample=0.8,\\n    colsample_bytree=1,\\n    #sampling_method='gradient_based',\\n    #eval_metric='logloss',\\n    verbosity=2   # info\\n)\\nprint('Finished.')</td>\n",
       "      <td>xgboost</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>print('Training classifier...', end='')\\r\\n%time clf.fit(X_train, y_train)\\r\\nprint('Finished.')</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>print('Creating submissions file...', end='')\\nrcount = 0\\nfor (test_df, prediction_df) in env.iter_test():\\n    X_test = test_df.loc[:, features]\\n    y_preds = clf.predict(X_test)\\n    prediction_df.action = y_preds\\n    env.predict(prediction_df)\\n    rcount += len(test_df.index)\\nprint(f'Finished processing {rcount} rows.')</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>import numpy as np\\nimport pandas as pd\\nimport matplotlib.pyplot as plt\\nimport seaborn as sns\\nfrom sklearn.linear_model import Lasso\\nfrom sklearn.linear_model import ElasticNet\\nfrom sklearn.ensemble import RandomForestRegressor\\nimport xgboost\\nfrom sklearn.preprocessing import StandardScaler\\nfrom sklearn.model_selection import RandomizedSearchCV\\nfrom sklearn.model_selection import GridSearchCV\\nimport warnings\\nwarnings.filterwarnings('ignore')</td>\n",
       "      <td>xgboost\\nmatplotlib\\npandas\\nseaborn\\nsklearn\\nwarnings\\nnumpy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>train=pd.read_csv(r'../input/house-prices-advanced-regression-techniques/train.csv')</td>\n",
       "      <td>pandas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>train.head()\\r</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>train.shape</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>test=pd.read_csv(r'../input/house-prices-advanced-regression-techniques/test.csv')</td>\n",
       "      <td>pandas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>test.shape</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>train.describe()</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>train.dtypes</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>train.dtypes.value_counts()</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>train['SalePrice'].describe()</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>unique=len(set(train['Id']))\\ntotal=len(train['Id'])\\ndup=total - unique\\nprint(\"No of duplicate ID values in train dataset :\",dup)\\n\\nunique_t=len(set(test['Id']))\\ntotal_t=len(test['Id'])\\ndup_t=total_t - unique_t\\nprint(\"No of duplicate ID values in test dataset :\",dup_t)</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>submission=pd.DataFrame()\\nsubmission['Id']=test['Id']\\ntrain.drop(['Id'],axis=1,inplace=True)\\ntest.drop(['Id'],axis=1,inplace=True)</td>\n",
       "      <td>pandas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>misval=train.isnull().sum()\\r\\nmisval=misval[misval&gt;0]\\r\\nprint(misval)</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>train.drop(['Alley','FireplaceQu','PoolQC','Fence','MiscFeature'],axis=1,inplace=True)</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>num_feat=train.select_dtypes(exclude=[object]).columns\\r\\ncat_feat=train.select_dtypes(include=[object]).columns\\r\\nprint(\"No. of numerical features:\",len(num_feat))\\r\\nprint(num_feat)\\r\\nprint(\"No. of categorical features:\",len(cat_feat))\\r\\nprint(cat_feat)</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>train=train.fillna(train.median())\\nsns.heatmap(train.isnull(),cbar=False)</td>\n",
       "      <td>seaborn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>misval=train.isnull().sum()\\r\\nmisval=misval[misval&gt;0]\\r\\nprint(misval)</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>train['BsmtQual']=train['BsmtQual'].fillna(train['BsmtQual'].mode()[0])</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>train['BsmtCond']=train['BsmtCond'].fillna(train['BsmtCond'].mode()[0])</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>train['BsmtExposure']=train['BsmtExposure'].fillna(train['BsmtExposure'].mode()[0])</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>train['BsmtFinType1']=train['BsmtFinType1'].fillna(train['BsmtFinType1'].mode()[0])</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>train['BsmtFinType2']=train['BsmtFinType2'].fillna(train['BsmtFinType2'].mode()[0])</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>train['GarageType']=train['GarageType'].fillna(train['GarageType'].mode()[0])</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>train['GarageFinish']=train['GarageFinish'].fillna(train['GarageFinish'].mode()[0])</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>train['GarageQual']=train['GarageQual'].fillna(train['GarageQual'].mode()[0])</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>train['GarageCond']=train['GarageCond'].fillna(train['GarageCond'].mode()[0])</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>train['MasVnrType']=train['MasVnrType'].fillna(train['MasVnrType'].mode()[0])</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>train['Electrical']=train['Electrical'].fillna(train['Electrical'].mode()[0])</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>sns.heatmap(train.isnull(),cbar=False)</td>\n",
       "      <td>seaborn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>misval_t=test.isnull().sum()\\r\\nmisval_t=misval_t[misval_t&gt;0]\\r\\nprint(misval_t)</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>test.drop(['Alley','FireplaceQu','PoolQC','Fence','MiscFeature'],axis=1,inplace=True)</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>num_feat_test= test.select_dtypes(exclude='object').columns\\ncat_feat_test= test.select_dtypes(include='object').columns\\nprint(\"No. of numerical features in test dataset:\",len(num_feat_test))\\nprint(num_feat_test)\\nprint(\"No. of categorical features in test dataset:\",len(cat_feat_test))\\nprint(cat_feat_test)</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>test=test.fillna(test.median())\\r\\nsns.heatmap(test.isnull(),cbar=False)</td>\n",
       "      <td>seaborn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>test['BsmtQual']=test['BsmtQual'].fillna(test['BsmtQual'].mode()[0])\\r\\ntest['BsmtCond']=test['BsmtCond'].fillna(test['BsmtCond'].mode()[0])\\r\\ntest['BsmtExposure']=test['BsmtExposure'].fillna(test['BsmtExposure'].mode()[0])\\r\\ntest['BsmtFinType1']=test['BsmtFinType1'].fillna(test['BsmtFinType1'].mode()[0])\\r\\ntest['BsmtFinType2']=test['BsmtFinType2'].fillna(test['BsmtFinType2'].mode()[0])\\r\\ntest['GarageType']=test['GarageType'].fillna(test['GarageType'].mode()[0])\\r\\ntest['GarageFinish']=t...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>misval_t=test.isnull().sum()\\r\\nmisval_t=misval_t[misval_t&gt;0]\\r\\nprint(misval_t)</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>test['MSZoning']=test['MSZoning'].fillna(test['MSZoning'].mode()[0])\\r\\ntest['Utilities']=test['Utilities'].fillna(test['Utilities'].mode()[0])\\r\\ntest['Exterior1st']=test['Exterior1st'].fillna(test['Exterior1st'].mode()[0])\\r\\ntest['Exterior2nd']=test['Exterior2nd'].fillna(test['Exterior2nd'].mode()[0])\\r\\ntest['KitchenQual']=test['KitchenQual'].fillna(test['KitchenQual'].mode()[0])\\r\\ntest['Functional']=test['Functional'].fillna(test['Functional'].mode()[0])\\r\\ntest['SaleType']=test['SaleT...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>sns.heatmap(test.isnull(),cbar=False)</td>\n",
       "      <td>seaborn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>test.shape</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>train.shape</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>file=pd.concat([train,test],axis=0)\\r\\nfile.shape</td>\n",
       "      <td>pandas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>file=pd.get_dummies(file)\\r\\nfile.shape</td>\n",
       "      <td>pandas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>file.head()</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>mis_file=file.isnull().sum()\\r\\nmis_file=mis_file[mis_file&gt;0]\\r\\nprint(mis_file)</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>traindata=file.iloc[:1460]\\ntraindata.shape</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>traindata.head()</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>testdata=file.iloc[1460:]\\n\\ntestdata.drop(['SalePrice'],axis=1,inplace=True)\\ntestdata.shape</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>sns.distplot(traindata['SalePrice'])</td>\n",
       "      <td>seaborn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>traindata['SalePrice']= np.log(traindata['SalePrice'])\\r\\nsns.distplot(traindata['SalePrice'])</td>\n",
       "      <td>seaborn\\nnumpy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>x_train=traindata.drop(['SalePrice'],axis=1)\\r\\ny_train=traindata['SalePrice']</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>scaler=StandardScaler()\\r\\nscaler.fit_transform(x_train)</td>\n",
       "      <td>sklearn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>model=Lasso()\\n\\nparam_grid={'alpha':[1e-4,1e-2,1,10,100]}\\ngrid_search=GridSearchCV(model,param_grid,scoring='neg_mean_squared_error',cv=5)\\nresult=grid_search.fit(x_train,y_train)\\nprint(\"Best score using Lasso: %f with %s\"%(result.best_score_,result.best_params_))\\n</td>\n",
       "      <td>sklearn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>model=ElasticNet()\\r\\n\\r\\nparam_grid={'alpha':[1e-4,1e-2,1,10],'l1_ratio':[0,0.5,1]}\\r\\ngrid_search=GridSearchCV(model,param_grid,scoring='neg_mean_squared_error',cv=5)\\r\\nresult=grid_search.fit(x_train,y_train)\\r\\nprint(\"Best score using ElasticNet: %f with %s\"%(result.best_score_,result.best_params_))</td>\n",
       "      <td>sklearn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>model=RandomForestRegressor()\\n\\nn_estimators=[10,50,100,150,200,250,300]\\nmax_features=['sqrt','log2']\\nparam_grid=dict(n_estimators=n_estimators,max_features=max_features)\\nrandom_search=RandomizedSearchCV(model,param_grid,scoring='neg_mean_squared_error',n_jobs=-1,cv=5)\\nresult=random_search.fit(x_train,y_train)\\nprint(\"Best score using RandomForest: %f with %s\"%(result.best_score_,result.best_params_))</td>\n",
       "      <td>sklearn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>model=xgboost.XGBRegressor()\\r\\n\\r\\nbooster=['gbtree','gblinear']\\r\\nlearning_rate=[0.001,0.01,0.1,0.2,0.5]\\r\\nn_estimators=[50,100,150,200,250,300]\\r\\nmax_depth=[2,4,6,8]\\r\\nparam_grid=dict(booster=booster,max_depth=max_depth,n_estimators=n_estimators,learning_rate=learning_rate)\\r\\n\\r\\nrandom_search=RandomizedSearchCV(model,param_grid,scoring='neg_mean_squared_error',n_jobs=-1,cv=5)\\r\\nresult=random_search.fit(x_train,y_train)\\r\\nprint(\"Best score using XGBoost: %f with %s\"%(result.best_sc...</td>\n",
       "      <td>sklearn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>print(result.best_estimator_)</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>f_model=xgboost.XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\\r\\n             colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\\r\\n             importance_type='gain', interaction_constraints='',\\r\\n             learning_rate=0.1, max_delta_step=0, max_depth=8,\\r\\n             min_child_weight=1, monotone_constraints='()',\\r\\n             n_estimators=300, n_jobs=0, num_parallel_tree=1, random_state=0,\\r\\n             reg_alpha=0, reg_lambda=1, scale_pos_weigh...</td>\n",
       "      <td>interaction_constraints='',</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>y_pred=f_model.predict(testdata)\\r\\npredictions=np.exp(y_pred)\\r\\nprint(predictions)</td>\n",
       "      <td>numpy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>submission['SalePrice']=predictions\\r\\nsubmission.to_csv(r\"C:\\Users\\Dipanjan Dey Sarkar\\OneDrive\\Documents\\sampleSubmission.csv\",index=False)</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>sns.distplot(predictions)</td>\n",
       "      <td>seaborn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>import os\\r\\nfor dirname, _, filenames in os.walk('/kaggle/input'):\\r\\n    for filename in filenames:\\r\\n        print(os.path.join(dirname, filename))</td>\n",
       "      <td>os</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>import matplotlib.pyplot as plt\\nfrom sklearn.ensemble import GradientBoostingRegressor as GBR\\nfrom sklearn.model_selection import train_test_split\\nimport warnings\\nwarnings.filterwarnings(\"ignore\")</td>\n",
       "      <td>matplotlib\\nsklearn\\nwarnings</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>train = pd.read_csv('../input/house-prices-advanced-regression-techniques/train.csv')\\ntrain_size = int(len(train)*0.8)\\ntrain = train.sort_values(['YrSold', 'MoSold'], axis=0).reset_index(drop=True)\\ntrain_X = train.drop(['SalePrice', 'Id'], axis=1).loc[:train_size-1, :]\\nvalid_X = train.drop(['SalePrice', 'Id'], axis=1).loc[train_size:, :]\\ntrain_y = train['SalePrice'][:train_size]\\nvalid_y = train['SalePrice'][train_size:]\\ntest_X = pd.read_csv('../input/house-prices-advanced-regression-t...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>train_X.head()</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>train_X.info()</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>class CustomImputer:\\n    def __init__(self):\\n        pass\\n    \\n    def fit(self, data):\\n        cat_cols = data.columns[data.dtypes == 'object']\\n        self.impute_cols = cat_cols[data[cat_cols].isna().sum() &gt; 0] \\n    \\n    def transform(self, data):\\n        for column in self.impute_cols:\\n            if data[column].isin(['None', 'No', 'Othr']).sum() &gt; 0:\\n                replace_value = data.loc[data[column].isin(['None', 'No', 'Othr']), column].unique()[0]\\n                data[...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>na_cols = train_X.columns[(train_X.isna().sum() &gt; 0).values]\\nprint(f'Columns with NA: {na_cols}')\\ntrain_X.loc[:, na_cols] = CustomImputer().fit_transform(train_X.loc[:, na_cols])\\ntest_X.loc[:, na_cols] = CustomImputer().fit_transform(test_X.loc[:, na_cols])\\nvalid_X.loc[:, na_cols] = CustomImputer().fit_transform(valid_X.loc[:, na_cols])\\ntrain_X.loc[:, na_cols[train_X.loc[:, na_cols].dtypes == 'float64']] = train_X.loc[:, na_cols[train_X.loc[:, na_cols].dtypes == 'float64']].fillna(0)</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>train_X.columns[train_X.isna().sum() &gt; 0]</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>def get_sold_last_mnth(df):\\n    \"\"\" Generates sold houses lats month feature \"\"\"\\n    timeline = pd.to_datetime(df['YrSold'].astype('str') + '-' + df['MoSold'].astype('str'), format='%Y-%m')\\n    tm_ln_indexed = pd.Series(data=timeline.index ,index=timeline.values)\\n    tm_ln_sold_last_mnth = tm_ln_indexed.rolling('62d').count() - tm_ln_indexed.rolling('31d').count()\\n    sold_lst_mnth = pd.Series(data=tm_ln_sold_last_mnth.values, index=tm_ln_indexed.values).reindex(df.index)\\n    return so...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>train_X = train_X.assign(Sold_Lst_Mnth=lambda df: get_sold_last_mnth(df))\\nvalid_X = valid_X.assign(Sold_Lst_Mnth=lambda df: get_sold_last_mnth(df))\\ntest_X = test_X.assign(Sold_Lst_Mnth=lambda df: get_sold_last_mnth(df))\\ntrain_X = train_X.assign(FireplacesPerRm=lambda df: get_fireplaces_per_room(df))\\nvalid_X = valid_X.assign(FireplacesPerRm=lambda df: get_fireplaces_per_room(df))\\ntest_X = test_X.assign(FireplacesPerRm=lambda df: get_fireplaces_per_room(df))\\ntrain_X = train_X.assign(Qual...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>ta_leakage_cols = ['YrSold', 'MoSold']\\r\\ntrain_X = train_X.drop(ta_leakage_cols, axis=1)\\r\\nvalid_X = valid_X.drop(ta_leakage_cols, axis=1)\\r\\ntest_X =test_X.drop(ta_leakage_cols, axis=1)</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>cat_features = train_X.columns[train_X.dtypes == 'object']\\nnum_features = train_X.columns[(train_X.dtypes == 'int64') | (train_X.dtypes == 'float64')]</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>train_X[num_features].hist(bins=15, figsize=(20, 20))</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>fig, ax = plt.subplots(len(cat_features)//5 + 1, 5)\\nfig.set_size_inches(20, 30)\\nfor idx, feature in enumerate(cat_features):\\n    sns.countplot(data=train_X, x=feature, ax=ax[idx//5, idx%5])\\nplt.tight_layout()</td>\n",
       "      <td>matplotlib</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>plt.figure(figsize=(30, 18))\\r\\nsns.heatmap(pd.concat([train_X[num_features], train_y], axis=1).corr(), annot=True)</td>\n",
       "      <td>matplotlib</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>fig, ax = plt.subplots(len(cat_features)//3+1, 3, figsize=(20, len(cat_features)*2))\\r\\nfor idx, feature in enumerate(cat_features):\\r\\n    sns.violinplot(x=feature, y=train_y, data=train_X, ax=ax[idx//3, idx%3])\\r\\n    ax[idx//3, idx%3].set_title(f'Violin plot of {feature} x SalePrice')\\r\\n    ax[idx//3, idx%3].xaxis.set_tick_params(rotation=45)\\r\\n    \\r\\nplt.tight_layout()</td>\n",
       "      <td>matplotlib</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>plt.style.use('seaborn-darkgrid')\\r\\nfig, ax = plt.subplots(len(num_features)//3+1, 3, figsize=(36, len(cat_features)*3))\\r\\nfor idx, num_feature in enumerate(num_features):\\r\\n    sns.scatterplot(data=train_X, x=num_feature, y=train_y, ax=ax[idx//3, idx%3])\\r\\n    ax[idx//3, idx%3].set_title(f'Regplot of Sale Price x {num_feature}', size=24)\\r\\n    ax[idx//3, idx%3].set_xlabel(num_feature, size=20)\\r\\n    ax[idx//3, idx%3].set_ylabel('Sale Price', size=20)\\r\\n    \\r\\nplt.tight_layout()</td>\n",
       "      <td>matplotlib</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>from sklearn import pipeline\\r\\nfrom sklearn.compose import ColumnTransformer\\r\\nfrom sklearn.preprocessing import StandardScaler\\r\\nfrom sklearn.impute import SimpleImputer\\r\\nfrom category_encoders import CatBoostEncoder, OrdinalEncoder</td>\n",
       "      <td>category_encoders\\nsklearn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>ordinal_features = [\\n    'LandSlope',\\n    'Condition1',\\n    'Condition2',\\n    'ExterQual',\\n    'ExterCond',\\n    'BsmtQual',\\n    'BsmtCond',\\n    'BsmtFinType1',\\n    'BsmtFinType2',\\n    'HeatingQC',\\n    'KitchenQual',\\n    'FireplaceQu',\\n    'GarageQual',\\n    'GarageCond',\\n    'PoolQC'\\n]\\nnominal_features = cat_features.drop(ordinal_features)\\n# Next define transformer of nominal features\\nnominal_transformer = pipeline.Pipeline(steps=[\\n    ('cat_boost', CatBoostEncoder()),\\n  ...</td>\n",
       "      <td>category_encoders\\nsklearn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>from sklearn.model_selection import GridSearchCV, TimeSeriesSplit\\r\\nfrom xgboost import XGBRegressor\\r\\nfrom sklearn.metrics import mean_absolute_error</td>\n",
       "      <td>xgboost\\nsklearn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>params = {\\n    'learning_rate': np.arange(0.01, 0.11, 0.01)\\n}\\noptimizer = GridSearchCV(XGBRegressor(n_estimators=500, tree_method='gpu_hist', max_depth=4, min_child_weight=3, gamma=0, colsample_bytree=0.4, subsample=0.7, learning_rate=0.05), params, cv=TimeSeriesSplit(n_splits=3), n_jobs=-1)\\noptimizer.fit(train_X_transformed, train_y)\\nvalid_score = mean_absolute_error(valid_y, optimizer.predict(valid_X_transformed))</td>\n",
       "      <td>xgboost\\nsklearn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>optimizer.best_params_</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>pd.DataFrame(optimizer.cv_results_)</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>print(f'Mean validation score is {valid_score}')</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>xgb_params = {\\n    'colsample_bytree': 0.4,\\n    'n_estimators': 1000,\\n    'min_child_weight': 3,\\n    'max_depth': 6,\\n    'subsample': 0.4,\\n    'learning_rate': 0.01,\\n    'gamma': 0,\\n    'reg_lambda': 0.02\\n}\\nmodel = XGBRegressor(tree_method='gpu_hist', **xgb_params).fit(train_X_transformed, train_y)</td>\n",
       "      <td>xgboost\\nsklearn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>train_score = mean_absolute_error(train_y, model.predict(train_X_transformed))\\nprint(f'Mean train score is {train_score}')\\n</td>\n",
       "      <td>sklearn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>valid_score = mean_absolute_error(valid_y, model.predict(valid_X_transformed))\\r\\nprint(f'Mean validation score is {valid_score}')</td>\n",
       "      <td>sklearn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>from sklearn.model_selection import learning_curve\\r\\n\\r\\ndef plot_learning_curve(estimator, X_train, y_train, cv, train_sizes=np.linspace(0.1, 1, 10)):\\r\\n    plt.style.use('seaborn-darkgrid')\\r\\n    train_sizes, train_scores, test_scores = learning_curve(estimator, X_train, y_train, cv=cv, n_jobs=-1, train_sizes=train_sizes)\\r\\n    train_mean_scores = np.mean(train_scores, axis=1)\\r\\n    test_mean_scores = np.mean(test_scores, axis=1)\\r\\n    plt.title('Learning curve')\\r\\n    plt.plot(trai...</td>\n",
       "      <td>matplotlib\\nsklearn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>plot_learning_curve(model, train_X_transformed, train_y, TimeSeriesSplit(n_splits=3))</td>\n",
       "      <td>sklearn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>features = nominal_features.values.tolist() + ordinal_features + num_features.values.tolist() \\r\\nplt.figure(figsize=(25, 20))\\r\\nsns.barplot(y=features, x=model.feature_importances_)</td>\n",
       "      <td>matplotlib</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>preds_test = model.predict(test_X_transformed)\\r\\noutput = pd.DataFrame({'Id': test_X.index,\\r\\n                       'SalePrice': preds_test})\\r\\noutput.to_csv('submission.csv', index=False)</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             code_block  \\\n",
       "0   import os\\nimport numpy as np\\nimport matplotlib.pyplot as plt\\n\\nimport cudf\\n\\nfrom sklearn import preprocessing\\nfrom sklearn.model_selection import GridSearchCV\\nfrom sklearn.model_selection import StratifiedKFold\\n\\nimport pandas as pd\\npd.set_option('display.max_columns', 500)\\n\\nimport xgboost as xgb\\nprint(\"XGBoost version:\", xgb.__version__)\\n\\nimport warnings\\nwarnings.filterwarnings(\"ignore\")\\n\\nimport janestreet\\nprint('Creating competition environment...', end='')\\nenv = janestr...   \n",
       "1                             print('Reading datasets...', end='')\\n\\ntrain_cudf = cudf.read_csv('/kaggle/input/jane-street-market-prediction/train.csv')\\ntrain = train_cudf.to_pandas()\\ndel train_cudf\\n\\nfeatures_meta_cudf = cudf.read_csv('/kaggle/input/jane-street-market-prediction/features.csv')\\nfeatures_meta = features_meta_cudf.to_pandas()\\ndel features_meta_cudf\\n\\nprint('Finished.')\\n\\nprint(f'train shape: {format(train.shape)}')\\nprint(f'features_meta shape: {format(features_meta.shape)}')   \n",
       "2                                                                                                                                        print('Preprocessing data...', end='')\\n\\nfeatures = [col for col in list(train.columns) if 'feature' in col]\\n\\ntrain = train[train['weight'] != 0]\\n\\ntrain['action'] = (train['resp'].values > 0).astype(int)\\n\\n#train = train.fillna(-99999)\\ntrain.fillna(f_mean)\\n\\nX_train = train.loc[:, features]\\ny_train = train.loc[:, 'action']\\ndel train\\n\\nprint('Finished.')   \n",
       "3                                                                                                                                     print('Creating classifier...', end='')\\nclf = xgb.XGBClassifier(\\n    n_estimators=400,\\n    max_depth=7,\\n    eta=0.5, # learning_rate\\n    missing=None,\\n    random_state=42,\\n    tree_method='gpu_hist',\\n    subsample=0.8,\\n    colsample_bytree=1,\\n    #sampling_method='gradient_based',\\n    #eval_metric='logloss',\\n    verbosity=2   # info\\n)\\nprint('Finished.')   \n",
       "4                                                                                                                                                                                                                                                                                                                                                                                                                      print('Training classifier...', end='')\\r\\n%time clf.fit(X_train, y_train)\\r\\nprint('Finished.')   \n",
       "5                                                                                                                                                                             print('Creating submissions file...', end='')\\nrcount = 0\\nfor (test_df, prediction_df) in env.iter_test():\\n    X_test = test_df.loc[:, features]\\n    y_preds = clf.predict(X_test)\\n    prediction_df.action = y_preds\\n    env.predict(prediction_df)\\n    rcount += len(test_df.index)\\nprint(f'Finished processing {rcount} rows.')   \n",
       "6                                              import numpy as np\\nimport pandas as pd\\nimport matplotlib.pyplot as plt\\nimport seaborn as sns\\nfrom sklearn.linear_model import Lasso\\nfrom sklearn.linear_model import ElasticNet\\nfrom sklearn.ensemble import RandomForestRegressor\\nimport xgboost\\nfrom sklearn.preprocessing import StandardScaler\\nfrom sklearn.model_selection import RandomizedSearchCV\\nfrom sklearn.model_selection import GridSearchCV\\nimport warnings\\nwarnings.filterwarnings('ignore')   \n",
       "7                                                                                                                                                                                                                                                                                                                                                                                                                                  train=pd.read_csv(r'../input/house-prices-advanced-regression-techniques/train.csv')   \n",
       "8                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        train.head()\\r   \n",
       "9                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           train.shape   \n",
       "10                                                                                                                                                                                                                                                                                                                                                                                                                                   test=pd.read_csv(r'../input/house-prices-advanced-regression-techniques/test.csv')   \n",
       "11                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           test.shape   \n",
       "12                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     train.describe()   \n",
       "13                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         train.dtypes   \n",
       "14                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          train.dtypes.value_counts()   \n",
       "15                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        train['SalePrice'].describe()   \n",
       "16                                                                                                                                                                                                                                  unique=len(set(train['Id']))\\ntotal=len(train['Id'])\\ndup=total - unique\\nprint(\"No of duplicate ID values in train dataset :\",dup)\\n\\nunique_t=len(set(test['Id']))\\ntotal_t=len(test['Id'])\\ndup_t=total_t - unique_t\\nprint(\"No of duplicate ID values in test dataset :\",dup_t)   \n",
       "17                                                                                                                                                                                                                                                                                                                                                                                submission=pd.DataFrame()\\nsubmission['Id']=test['Id']\\ntrain.drop(['Id'],axis=1,inplace=True)\\ntest.drop(['Id'],axis=1,inplace=True)   \n",
       "18                                                                                                                                                                                                                                                                                                                                                                                                                                              misval=train.isnull().sum()\\r\\nmisval=misval[misval>0]\\r\\nprint(misval)   \n",
       "19                                                                                                                                                                                                                                                                                                                                                                                                                               train.drop(['Alley','FireplaceQu','PoolQC','Fence','MiscFeature'],axis=1,inplace=True)   \n",
       "20                                                                                                                                                                                                                                                   num_feat=train.select_dtypes(exclude=[object]).columns\\r\\ncat_feat=train.select_dtypes(include=[object]).columns\\r\\nprint(\"No. of numerical features:\",len(num_feat))\\r\\nprint(num_feat)\\r\\nprint(\"No. of categorical features:\",len(cat_feat))\\r\\nprint(cat_feat)   \n",
       "21                                                                                                                                                                                                                                                                                                                                                                                                                                           train=train.fillna(train.median())\\nsns.heatmap(train.isnull(),cbar=False)   \n",
       "22                                                                                                                                                                                                                                                                                                                                                                                                                                              misval=train.isnull().sum()\\r\\nmisval=misval[misval>0]\\r\\nprint(misval)   \n",
       "23                                                                                                                                                                                                                                                                                                                                                                                                                                              train['BsmtQual']=train['BsmtQual'].fillna(train['BsmtQual'].mode()[0])   \n",
       "24                                                                                                                                                                                                                                                                                                                                                                                                                                              train['BsmtCond']=train['BsmtCond'].fillna(train['BsmtCond'].mode()[0])   \n",
       "25                                                                                                                                                                                                                                                                                                                                                                                                                                  train['BsmtExposure']=train['BsmtExposure'].fillna(train['BsmtExposure'].mode()[0])   \n",
       "26                                                                                                                                                                                                                                                                                                                                                                                                                                  train['BsmtFinType1']=train['BsmtFinType1'].fillna(train['BsmtFinType1'].mode()[0])   \n",
       "27                                                                                                                                                                                                                                                                                                                                                                                                                                  train['BsmtFinType2']=train['BsmtFinType2'].fillna(train['BsmtFinType2'].mode()[0])   \n",
       "28                                                                                                                                                                                                                                                                                                                                                                                                                                        train['GarageType']=train['GarageType'].fillna(train['GarageType'].mode()[0])   \n",
       "29                                                                                                                                                                                                                                                                                                                                                                                                                                  train['GarageFinish']=train['GarageFinish'].fillna(train['GarageFinish'].mode()[0])   \n",
       "30                                                                                                                                                                                                                                                                                                                                                                                                                                        train['GarageQual']=train['GarageQual'].fillna(train['GarageQual'].mode()[0])   \n",
       "31                                                                                                                                                                                                                                                                                                                                                                                                                                        train['GarageCond']=train['GarageCond'].fillna(train['GarageCond'].mode()[0])   \n",
       "32                                                                                                                                                                                                                                                                                                                                                                                                                                        train['MasVnrType']=train['MasVnrType'].fillna(train['MasVnrType'].mode()[0])   \n",
       "33                                                                                                                                                                                                                                                                                                                                                                                                                                        train['Electrical']=train['Electrical'].fillna(train['Electrical'].mode()[0])   \n",
       "34                                                                                                                                                                                                                                                                                                                                                                                                                                                                               sns.heatmap(train.isnull(),cbar=False)   \n",
       "35                                                                                                                                                                                                                                                                                                                                                                                                                                     misval_t=test.isnull().sum()\\r\\nmisval_t=misval_t[misval_t>0]\\r\\nprint(misval_t)   \n",
       "36                                                                                                                                                                                                                                                                                                                                                                                                                                test.drop(['Alley','FireplaceQu','PoolQC','Fence','MiscFeature'],axis=1,inplace=True)   \n",
       "37                                                                                                                                                                                               num_feat_test= test.select_dtypes(exclude='object').columns\\ncat_feat_test= test.select_dtypes(include='object').columns\\nprint(\"No. of numerical features in test dataset:\",len(num_feat_test))\\nprint(num_feat_test)\\nprint(\"No. of categorical features in test dataset:\",len(cat_feat_test))\\nprint(cat_feat_test)   \n",
       "38                                                                                                                                                                                                                                                                                                                                                                                                                                             test=test.fillna(test.median())\\r\\nsns.heatmap(test.isnull(),cbar=False)   \n",
       "39  test['BsmtQual']=test['BsmtQual'].fillna(test['BsmtQual'].mode()[0])\\r\\ntest['BsmtCond']=test['BsmtCond'].fillna(test['BsmtCond'].mode()[0])\\r\\ntest['BsmtExposure']=test['BsmtExposure'].fillna(test['BsmtExposure'].mode()[0])\\r\\ntest['BsmtFinType1']=test['BsmtFinType1'].fillna(test['BsmtFinType1'].mode()[0])\\r\\ntest['BsmtFinType2']=test['BsmtFinType2'].fillna(test['BsmtFinType2'].mode()[0])\\r\\ntest['GarageType']=test['GarageType'].fillna(test['GarageType'].mode()[0])\\r\\ntest['GarageFinish']=t...   \n",
       "40                                                                                                                                                                                                                                                                                                                                                                                                                                     misval_t=test.isnull().sum()\\r\\nmisval_t=misval_t[misval_t>0]\\r\\nprint(misval_t)   \n",
       "41  test['MSZoning']=test['MSZoning'].fillna(test['MSZoning'].mode()[0])\\r\\ntest['Utilities']=test['Utilities'].fillna(test['Utilities'].mode()[0])\\r\\ntest['Exterior1st']=test['Exterior1st'].fillna(test['Exterior1st'].mode()[0])\\r\\ntest['Exterior2nd']=test['Exterior2nd'].fillna(test['Exterior2nd'].mode()[0])\\r\\ntest['KitchenQual']=test['KitchenQual'].fillna(test['KitchenQual'].mode()[0])\\r\\ntest['Functional']=test['Functional'].fillna(test['Functional'].mode()[0])\\r\\ntest['SaleType']=test['SaleT...   \n",
       "42                                                                                                                                                                                                                                                                                                                                                                                                                                                                                sns.heatmap(test.isnull(),cbar=False)   \n",
       "43                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           test.shape   \n",
       "44                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          train.shape   \n",
       "45                                                                                                                                                                                                                                                                                                                                                                                                                                                                    file=pd.concat([train,test],axis=0)\\r\\nfile.shape   \n",
       "46                                                                                                                                                                                                                                                                                                                                                                                                                                                                              file=pd.get_dummies(file)\\r\\nfile.shape   \n",
       "47                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          file.head()   \n",
       "48                                                                                                                                                                                                                                                                                                                                                                                                                                     mis_file=file.isnull().sum()\\r\\nmis_file=mis_file[mis_file>0]\\r\\nprint(mis_file)   \n",
       "49                                                                                                                                                                                                                                                                                                                                                                                                                                                                          traindata=file.iloc[:1460]\\ntraindata.shape   \n",
       "50                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     traindata.head()   \n",
       "51                                                                                                                                                                                                                                                                                                                                                                                                                        testdata=file.iloc[1460:]\\n\\ntestdata.drop(['SalePrice'],axis=1,inplace=True)\\ntestdata.shape   \n",
       "52                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 sns.distplot(traindata['SalePrice'])   \n",
       "53                                                                                                                                                                                                                                                                                                                                                                                                                       traindata['SalePrice']= np.log(traindata['SalePrice'])\\r\\nsns.distplot(traindata['SalePrice'])   \n",
       "54                                                                                                                                                                                                                                                                                                                                                                                                                                       x_train=traindata.drop(['SalePrice'],axis=1)\\r\\ny_train=traindata['SalePrice']   \n",
       "55                                                                                                                                                                                                                                                                                                                                                                                                                                                             scaler=StandardScaler()\\r\\nscaler.fit_transform(x_train)   \n",
       "56                                                                                                                                                                                                                                        model=Lasso()\\n\\nparam_grid={'alpha':[1e-4,1e-2,1,10,100]}\\ngrid_search=GridSearchCV(model,param_grid,scoring='neg_mean_squared_error',cv=5)\\nresult=grid_search.fit(x_train,y_train)\\nprint(\"Best score using Lasso: %f with %s\"%(result.best_score_,result.best_params_))\\n   \n",
       "57                                                                                                                                                                                                     model=ElasticNet()\\r\\n\\r\\nparam_grid={'alpha':[1e-4,1e-2,1,10],'l1_ratio':[0,0.5,1]}\\r\\ngrid_search=GridSearchCV(model,param_grid,scoring='neg_mean_squared_error',cv=5)\\r\\nresult=grid_search.fit(x_train,y_train)\\r\\nprint(\"Best score using ElasticNet: %f with %s\"%(result.best_score_,result.best_params_))   \n",
       "58                                                                                            model=RandomForestRegressor()\\n\\nn_estimators=[10,50,100,150,200,250,300]\\nmax_features=['sqrt','log2']\\nparam_grid=dict(n_estimators=n_estimators,max_features=max_features)\\nrandom_search=RandomizedSearchCV(model,param_grid,scoring='neg_mean_squared_error',n_jobs=-1,cv=5)\\nresult=random_search.fit(x_train,y_train)\\nprint(\"Best score using RandomForest: %f with %s\"%(result.best_score_,result.best_params_))   \n",
       "59  model=xgboost.XGBRegressor()\\r\\n\\r\\nbooster=['gbtree','gblinear']\\r\\nlearning_rate=[0.001,0.01,0.1,0.2,0.5]\\r\\nn_estimators=[50,100,150,200,250,300]\\r\\nmax_depth=[2,4,6,8]\\r\\nparam_grid=dict(booster=booster,max_depth=max_depth,n_estimators=n_estimators,learning_rate=learning_rate)\\r\\n\\r\\nrandom_search=RandomizedSearchCV(model,param_grid,scoring='neg_mean_squared_error',n_jobs=-1,cv=5)\\r\\nresult=random_search.fit(x_train,y_train)\\r\\nprint(\"Best score using XGBoost: %f with %s\"%(result.best_sc...   \n",
       "60                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        print(result.best_estimator_)   \n",
       "61  f_model=xgboost.XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\\r\\n             colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\\r\\n             importance_type='gain', interaction_constraints='',\\r\\n             learning_rate=0.1, max_delta_step=0, max_depth=8,\\r\\n             min_child_weight=1, monotone_constraints='()',\\r\\n             n_estimators=300, n_jobs=0, num_parallel_tree=1, random_state=0,\\r\\n             reg_alpha=0, reg_lambda=1, scale_pos_weigh...   \n",
       "62                                                                                                                                                                                                                                                                                                                                                                                                                                 y_pred=f_model.predict(testdata)\\r\\npredictions=np.exp(y_pred)\\r\\nprint(predictions)   \n",
       "63                                                                                                                                                                                                                                                                                                                                                                        submission['SalePrice']=predictions\\r\\nsubmission.to_csv(r\"C:\\Users\\Dipanjan Dey Sarkar\\OneDrive\\Documents\\sampleSubmission.csv\",index=False)   \n",
       "64                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            sns.distplot(predictions)   \n",
       "65                                                                                                                                                                                                                                                                                                                                                              import os\\r\\nfor dirname, _, filenames in os.walk('/kaggle/input'):\\r\\n    for filename in filenames:\\r\\n        print(os.path.join(dirname, filename))   \n",
       "66                                                                                                                                                                                                                                                                                                             import matplotlib.pyplot as plt\\nfrom sklearn.ensemble import GradientBoostingRegressor as GBR\\nfrom sklearn.model_selection import train_test_split\\nimport warnings\\nwarnings.filterwarnings(\"ignore\")   \n",
       "67  train = pd.read_csv('../input/house-prices-advanced-regression-techniques/train.csv')\\ntrain_size = int(len(train)*0.8)\\ntrain = train.sort_values(['YrSold', 'MoSold'], axis=0).reset_index(drop=True)\\ntrain_X = train.drop(['SalePrice', 'Id'], axis=1).loc[:train_size-1, :]\\nvalid_X = train.drop(['SalePrice', 'Id'], axis=1).loc[train_size:, :]\\ntrain_y = train['SalePrice'][:train_size]\\nvalid_y = train['SalePrice'][train_size:]\\ntest_X = pd.read_csv('../input/house-prices-advanced-regression-t...   \n",
       "68                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       train_X.head()   \n",
       "69                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       train_X.info()   \n",
       "70  class CustomImputer:\\n    def __init__(self):\\n        pass\\n    \\n    def fit(self, data):\\n        cat_cols = data.columns[data.dtypes == 'object']\\n        self.impute_cols = cat_cols[data[cat_cols].isna().sum() > 0] \\n    \\n    def transform(self, data):\\n        for column in self.impute_cols:\\n            if data[column].isin(['None', 'No', 'Othr']).sum() > 0:\\n                replace_value = data.loc[data[column].isin(['None', 'No', 'Othr']), column].unique()[0]\\n                data[...   \n",
       "71        na_cols = train_X.columns[(train_X.isna().sum() > 0).values]\\nprint(f'Columns with NA: {na_cols}')\\ntrain_X.loc[:, na_cols] = CustomImputer().fit_transform(train_X.loc[:, na_cols])\\ntest_X.loc[:, na_cols] = CustomImputer().fit_transform(test_X.loc[:, na_cols])\\nvalid_X.loc[:, na_cols] = CustomImputer().fit_transform(valid_X.loc[:, na_cols])\\ntrain_X.loc[:, na_cols[train_X.loc[:, na_cols].dtypes == 'float64']] = train_X.loc[:, na_cols[train_X.loc[:, na_cols].dtypes == 'float64']].fillna(0)   \n",
       "72                                                                                                                                                                                                                                                                                                                                                                                                                                                                            train_X.columns[train_X.isna().sum() > 0]   \n",
       "73  def get_sold_last_mnth(df):\\n    \"\"\" Generates sold houses lats month feature \"\"\"\\n    timeline = pd.to_datetime(df['YrSold'].astype('str') + '-' + df['MoSold'].astype('str'), format='%Y-%m')\\n    tm_ln_indexed = pd.Series(data=timeline.index ,index=timeline.values)\\n    tm_ln_sold_last_mnth = tm_ln_indexed.rolling('62d').count() - tm_ln_indexed.rolling('31d').count()\\n    sold_lst_mnth = pd.Series(data=tm_ln_sold_last_mnth.values, index=tm_ln_indexed.values).reindex(df.index)\\n    return so...   \n",
       "74  train_X = train_X.assign(Sold_Lst_Mnth=lambda df: get_sold_last_mnth(df))\\nvalid_X = valid_X.assign(Sold_Lst_Mnth=lambda df: get_sold_last_mnth(df))\\ntest_X = test_X.assign(Sold_Lst_Mnth=lambda df: get_sold_last_mnth(df))\\ntrain_X = train_X.assign(FireplacesPerRm=lambda df: get_fireplaces_per_room(df))\\nvalid_X = valid_X.assign(FireplacesPerRm=lambda df: get_fireplaces_per_room(df))\\ntest_X = test_X.assign(FireplacesPerRm=lambda df: get_fireplaces_per_room(df))\\ntrain_X = train_X.assign(Qual...   \n",
       "75                                                                                                                                                                                                                                                                                                                         ta_leakage_cols = ['YrSold', 'MoSold']\\r\\ntrain_X = train_X.drop(ta_leakage_cols, axis=1)\\r\\nvalid_X = valid_X.drop(ta_leakage_cols, axis=1)\\r\\ntest_X =test_X.drop(ta_leakage_cols, axis=1)   \n",
       "76                                                                                                                                                                                                                                                                                                                                                              cat_features = train_X.columns[train_X.dtypes == 'object']\\nnum_features = train_X.columns[(train_X.dtypes == 'int64') | (train_X.dtypes == 'float64')]   \n",
       "77                                                                                                                                                                                                                                                                                                                                                                                                                                                                train_X[num_features].hist(bins=15, figsize=(20, 20))   \n",
       "78                                                                                                                                                                                                                                                                                                 fig, ax = plt.subplots(len(cat_features)//5 + 1, 5)\\nfig.set_size_inches(20, 30)\\nfor idx, feature in enumerate(cat_features):\\n    sns.countplot(data=train_X, x=feature, ax=ax[idx//5, idx%5])\\nplt.tight_layout()   \n",
       "79                                                                                                                                                                                                                                                                                                                                                                                                  plt.figure(figsize=(30, 18))\\r\\nsns.heatmap(pd.concat([train_X[num_features], train_y], axis=1).corr(), annot=True)   \n",
       "80                                                                                                                           fig, ax = plt.subplots(len(cat_features)//3+1, 3, figsize=(20, len(cat_features)*2))\\r\\nfor idx, feature in enumerate(cat_features):\\r\\n    sns.violinplot(x=feature, y=train_y, data=train_X, ax=ax[idx//3, idx%3])\\r\\n    ax[idx//3, idx%3].set_title(f'Violin plot of {feature} x SalePrice')\\r\\n    ax[idx//3, idx%3].xaxis.set_tick_params(rotation=45)\\r\\n    \\r\\nplt.tight_layout()   \n",
       "81          plt.style.use('seaborn-darkgrid')\\r\\nfig, ax = plt.subplots(len(num_features)//3+1, 3, figsize=(36, len(cat_features)*3))\\r\\nfor idx, num_feature in enumerate(num_features):\\r\\n    sns.scatterplot(data=train_X, x=num_feature, y=train_y, ax=ax[idx//3, idx%3])\\r\\n    ax[idx//3, idx%3].set_title(f'Regplot of Sale Price x {num_feature}', size=24)\\r\\n    ax[idx//3, idx%3].set_xlabel(num_feature, size=20)\\r\\n    ax[idx//3, idx%3].set_ylabel('Sale Price', size=20)\\r\\n    \\r\\nplt.tight_layout()   \n",
       "82                                                                                                                                                                                                                                                                       from sklearn import pipeline\\r\\nfrom sklearn.compose import ColumnTransformer\\r\\nfrom sklearn.preprocessing import StandardScaler\\r\\nfrom sklearn.impute import SimpleImputer\\r\\nfrom category_encoders import CatBoostEncoder, OrdinalEncoder   \n",
       "83  ordinal_features = [\\n    'LandSlope',\\n    'Condition1',\\n    'Condition2',\\n    'ExterQual',\\n    'ExterCond',\\n    'BsmtQual',\\n    'BsmtCond',\\n    'BsmtFinType1',\\n    'BsmtFinType2',\\n    'HeatingQC',\\n    'KitchenQual',\\n    'FireplaceQu',\\n    'GarageQual',\\n    'GarageCond',\\n    'PoolQC'\\n]\\nnominal_features = cat_features.drop(ordinal_features)\\n# Next define transformer of nominal features\\nnominal_transformer = pipeline.Pipeline(steps=[\\n    ('cat_boost', CatBoostEncoder()),\\n  ...   \n",
       "84                                                                                                                                                                                                                                                                                                                                                             from sklearn.model_selection import GridSearchCV, TimeSeriesSplit\\r\\nfrom xgboost import XGBRegressor\\r\\nfrom sklearn.metrics import mean_absolute_error   \n",
       "85                                                                             params = {\\n    'learning_rate': np.arange(0.01, 0.11, 0.01)\\n}\\noptimizer = GridSearchCV(XGBRegressor(n_estimators=500, tree_method='gpu_hist', max_depth=4, min_child_weight=3, gamma=0, colsample_bytree=0.4, subsample=0.7, learning_rate=0.05), params, cv=TimeSeriesSplit(n_splits=3), n_jobs=-1)\\noptimizer.fit(train_X_transformed, train_y)\\nvalid_score = mean_absolute_error(valid_y, optimizer.predict(valid_X_transformed))   \n",
       "86                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               optimizer.best_params_   \n",
       "87                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  pd.DataFrame(optimizer.cv_results_)   \n",
       "88                                                                                                                                                                                                                                                                                                                                                                                                                                                                     print(f'Mean validation score is {valid_score}')   \n",
       "89                                                                                                                                                                                                xgb_params = {\\n    'colsample_bytree': 0.4,\\n    'n_estimators': 1000,\\n    'min_child_weight': 3,\\n    'max_depth': 6,\\n    'subsample': 0.4,\\n    'learning_rate': 0.01,\\n    'gamma': 0,\\n    'reg_lambda': 0.02\\n}\\nmodel = XGBRegressor(tree_method='gpu_hist', **xgb_params).fit(train_X_transformed, train_y)   \n",
       "90                                                                                                                                                                                                                                                                                                                                                                                        train_score = mean_absolute_error(train_y, model.predict(train_X_transformed))\\nprint(f'Mean train score is {train_score}')\\n   \n",
       "91                                                                                                                                                                                                                                                                                                                                                                                   valid_score = mean_absolute_error(valid_y, model.predict(valid_X_transformed))\\r\\nprint(f'Mean validation score is {valid_score}')   \n",
       "92  from sklearn.model_selection import learning_curve\\r\\n\\r\\ndef plot_learning_curve(estimator, X_train, y_train, cv, train_sizes=np.linspace(0.1, 1, 10)):\\r\\n    plt.style.use('seaborn-darkgrid')\\r\\n    train_sizes, train_scores, test_scores = learning_curve(estimator, X_train, y_train, cv=cv, n_jobs=-1, train_sizes=train_sizes)\\r\\n    train_mean_scores = np.mean(train_scores, axis=1)\\r\\n    test_mean_scores = np.mean(test_scores, axis=1)\\r\\n    plt.title('Learning curve')\\r\\n    plt.plot(trai...   \n",
       "93                                                                                                                                                                                                                                                                                                                                                                                                                                plot_learning_curve(model, train_X_transformed, train_y, TimeSeriesSplit(n_splits=3))   \n",
       "94                                                                                                                                                                                                                                                                                                                              features = nominal_features.values.tolist() + ordinal_features + num_features.values.tolist() \\r\\nplt.figure(figsize=(25, 20))\\r\\nsns.barplot(y=features, x=model.feature_importances_)   \n",
       "95                                                                                                                                                                                                                                                                                                                     preds_test = model.predict(test_X_transformed)\\r\\noutput = pd.DataFrame({'Id': test_X.index,\\r\\n                       'SalePrice': preds_test})\\r\\noutput.to_csv('submission.csv', index=False)   \n",
       "\n",
       "                                                                      libraries  \n",
       "0   xgboost\\nmatplotlib\\npandas\\ncudf\\nos\\njanestreet\\nsklearn\\nwarnings\\nnumpy  \n",
       "1                                                                                \n",
       "2                                                                                \n",
       "3                                                                       xgboost  \n",
       "4                                                                                \n",
       "5                                                                                \n",
       "6                xgboost\\nmatplotlib\\npandas\\nseaborn\\nsklearn\\nwarnings\\nnumpy  \n",
       "7                                                                        pandas  \n",
       "8                                                                                \n",
       "9                                                                                \n",
       "10                                                                       pandas  \n",
       "11                                                                               \n",
       "12                                                                               \n",
       "13                                                                               \n",
       "14                                                                               \n",
       "15                                                                               \n",
       "16                                                                               \n",
       "17                                                                       pandas  \n",
       "18                                                                               \n",
       "19                                                                               \n",
       "20                                                                               \n",
       "21                                                                      seaborn  \n",
       "22                                                                               \n",
       "23                                                                               \n",
       "24                                                                               \n",
       "25                                                                               \n",
       "26                                                                               \n",
       "27                                                                               \n",
       "28                                                                               \n",
       "29                                                                               \n",
       "30                                                                               \n",
       "31                                                                               \n",
       "32                                                                               \n",
       "33                                                                               \n",
       "34                                                                      seaborn  \n",
       "35                                                                               \n",
       "36                                                                               \n",
       "37                                                                               \n",
       "38                                                                      seaborn  \n",
       "39                                                                               \n",
       "40                                                                               \n",
       "41                                                                               \n",
       "42                                                                      seaborn  \n",
       "43                                                                               \n",
       "44                                                                               \n",
       "45                                                                       pandas  \n",
       "46                                                                       pandas  \n",
       "47                                                                               \n",
       "48                                                                               \n",
       "49                                                                               \n",
       "50                                                                               \n",
       "51                                                                               \n",
       "52                                                                      seaborn  \n",
       "53                                                               seaborn\\nnumpy  \n",
       "54                                                                               \n",
       "55                                                                      sklearn  \n",
       "56                                                                      sklearn  \n",
       "57                                                                      sklearn  \n",
       "58                                                                      sklearn  \n",
       "59                                                                      sklearn  \n",
       "60                                                                               \n",
       "61                                                  interaction_constraints='',  \n",
       "62                                                                        numpy  \n",
       "63                                                                               \n",
       "64                                                                      seaborn  \n",
       "65                                                                           os  \n",
       "66                                                matplotlib\\nsklearn\\nwarnings  \n",
       "67                                                                               \n",
       "68                                                                               \n",
       "69                                                                               \n",
       "70                                                                               \n",
       "71                                                                               \n",
       "72                                                                               \n",
       "73                                                                               \n",
       "74                                                                               \n",
       "75                                                                               \n",
       "76                                                                               \n",
       "77                                                                               \n",
       "78                                                                   matplotlib  \n",
       "79                                                                   matplotlib  \n",
       "80                                                                   matplotlib  \n",
       "81                                                                   matplotlib  \n",
       "82                                                   category_encoders\\nsklearn  \n",
       "83                                                   category_encoders\\nsklearn  \n",
       "84                                                             xgboost\\nsklearn  \n",
       "85                                                             xgboost\\nsklearn  \n",
       "86                                                                               \n",
       "87                                                                               \n",
       "88                                                                               \n",
       "89                                                             xgboost\\nsklearn  \n",
       "90                                                                      sklearn  \n",
       "91                                                                      sklearn  \n",
       "92                                                          matplotlib\\nsklearn  \n",
       "93                                                                      sklearn  \n",
       "94                                                                   matplotlib  \n",
       "95                                                                               "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df[['code_block', 'libraries']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Returning the original header markup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add columns names \n",
    "final_df.loc[-1] = final_df.columns\n",
    "# add original HEADER\n",
    "final_df.columns = HEADER\n",
    "final_df.index = final_df.index + 1\n",
    "final_df.sort_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PK</th>\n",
       "      <th>Manually</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Automatically</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>...</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>chunk_id</td>\n",
       "      <td>notebook_id</td>\n",
       "      <td>splitting_id</td>\n",
       "      <td>code_block</td>\n",
       "      <td>data_format</td>\n",
       "      <td>graph_vertex</td>\n",
       "      <td>errors</td>\n",
       "      <td>graph_vertex_m1</td>\n",
       "      <td>graph_vertex_m2</td>\n",
       "      <td>graph_vertex_m3</td>\n",
       "      <td>...</td>\n",
       "      <td>python_methods_m3</td>\n",
       "      <td>python_methods_p1</td>\n",
       "      <td>python_methods_p2</td>\n",
       "      <td>python_methods_p3</td>\n",
       "      <td>kaggle_link</td>\n",
       "      <td>kaggle_comments</td>\n",
       "      <td>kaggle_upvotes</td>\n",
       "      <td>kaggle_section</td>\n",
       "      <td>kaggle_section_overview</td>\n",
       "      <td>kaggle_score</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>import os\\nimport numpy as np\\nimport matplotlib.pyplot as plt\\n\\nimport cudf\\n\\nfrom sklearn import preprocessing\\nfrom sklearn.model_selection import GridSearchCV\\nfrom sklearn.model_selection import StratifiedKFold\\n\\nimport pandas as pd\\npd.set_option('display.max_columns', 500)\\n\\nimport xgboost as xgb\\nprint(\"XGBoost version:\", xgb.__version__)\\n\\nimport warnings\\nwarnings.filterwarnings(\"ignore\")\\n\\nimport janestreet\\nprint('Creating competition environment...', end='')\\nenv = janestr...</td>\n",
       "      <td>None</td>\n",
       "      <td>Environment.import_modules</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>print('Reading datasets...', end='')\\n\\ntrain_cudf = cudf.read_csv('/kaggle/input/jane-street-market-prediction/train.csv')\\ntrain = train_cudf.to_pandas()\\ndel train_cudf\\n\\nfeatures_meta_cudf = cudf.read_csv('/kaggle/input/jane-street-market-prediction/features.csv')\\nfeatures_meta = features_meta_cudf.to_pandas()\\ndel features_meta_cudf\\n\\nprint('Finished.')\\n\\nprint(f'train shape: {format(train.shape)}')\\nprint(f'features_meta shape: {format(features_meta.shape)}')</td>\n",
       "      <td>Table</td>\n",
       "      <td>Data: extraction.Load from CSV</td>\n",
       "      <td>False</td>\n",
       "      <td>Environment.import_modules</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>print('Preprocessing data...', end='')\\n\\nfeatures = [col for col in list(train.columns) if 'feature' in col]\\n\\ntrain = train[train['weight'] != 0]\\n\\ntrain['action'] = (train['resp'].values &gt; 0).astype(int)\\n\\n#train = train.fillna(-99999)\\ntrain.fillna(f_mean)\\n\\nX_train = train.loc[:, features]\\ny_train = train.loc[:, 'action']\\ndel train\\n\\nprint('Finished.')</td>\n",
       "      <td>Table</td>\n",
       "      <td>Data: transform.filter;Data: transform.data type conversions;Data: transform.correct missing values;Data: transform.split</td>\n",
       "      <td>False</td>\n",
       "      <td>Data: extraction.Load from CSV</td>\n",
       "      <td>Environment.import_modules</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>print('Creating classifier...', end='')\\nclf = xgb.XGBClassifier(\\n    n_estimators=400,\\n    max_depth=7,\\n    eta=0.5, # learning_rate\\n    missing=None,\\n    random_state=42,\\n    tree_method='gpu_hist',\\n    subsample=0.8,\\n    colsample_bytree=1,\\n    #sampling_method='gradient_based',\\n    #eval_metric='logloss',\\n    verbosity=2   # info\\n)\\nprint('Finished.')</td>\n",
       "      <td>None</td>\n",
       "      <td>Model: train.choose model class</td>\n",
       "      <td>False</td>\n",
       "      <td>Data: transform.filter;Data: transform.data type conversions;Data: transform.correct missing values;Data: transform.split</td>\n",
       "      <td>Data: extraction.Load from CSV</td>\n",
       "      <td>Environment.import_modules</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>print('Training classifier...', end='')\\r\\n%time clf.fit(X_train, y_train)\\r\\nprint('Finished.')</td>\n",
       "      <td>Table</td>\n",
       "      <td>Model: train.train model</td>\n",
       "      <td>False</td>\n",
       "      <td>Model: train.choose model class</td>\n",
       "      <td>Data: transform.filter;Data: transform.data type conversions;Data: transform.correct missing values;Data: transform.split</td>\n",
       "      <td>Data: extraction.Load from CSV</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>print('Creating submissions file...', end='')\\nrcount = 0\\nfor (test_df, prediction_df) in env.iter_test():\\n    X_test = test_df.loc[:, features]\\n    y_preds = clf.predict(X_test)\\n    prediction_df.action = y_preds\\n    env.predict(prediction_df)\\n    rcount += len(test_df.index)\\nprint(f'Finished processing {rcount} rows.')</td>\n",
       "      <td>Table</td>\n",
       "      <td>Model: train.predict</td>\n",
       "      <td>False</td>\n",
       "      <td>Model: train.train model</td>\n",
       "      <td>Model: train.choose model class</td>\n",
       "      <td>Data: transform.filter;Data: transform.data type conversions;Data: transform.correct missing values;Data: transform.split</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>import numpy as np\\nimport pandas as pd\\nimport matplotlib.pyplot as plt\\nimport seaborn as sns\\nfrom sklearn.linear_model import Lasso\\nfrom sklearn.linear_model import ElasticNet\\nfrom sklearn.ensemble import RandomForestRegressor\\nimport xgboost\\nfrom sklearn.preprocessing import StandardScaler\\nfrom sklearn.model_selection import RandomizedSearchCV\\nfrom sklearn.model_selection import GridSearchCV\\nimport warnings\\nwarnings.filterwarnings('ignore')</td>\n",
       "      <td>None</td>\n",
       "      <td>Environment.import_modules; Environment.set_options</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>train=pd.read_csv(r'../input/house-prices-advanced-regression-techniques/train.csv')</td>\n",
       "      <td>Table</td>\n",
       "      <td>Data: extraction.Load from CSV</td>\n",
       "      <td>False</td>\n",
       "      <td>Environment.import_modules; Environment.set_options</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>train.head()\\r</td>\n",
       "      <td>Table</td>\n",
       "      <td>Exploratory_DA.show_table</td>\n",
       "      <td>False</td>\n",
       "      <td>Data: extraction.Load from CSV</td>\n",
       "      <td>Environment.import_modules; Environment.set_options</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>train.shape</td>\n",
       "      <td>Table</td>\n",
       "      <td>Exploratory_DA.show_table_attributes</td>\n",
       "      <td>False</td>\n",
       "      <td>Exploratory_DA.show_table</td>\n",
       "      <td>Data: extraction.Load from CSV</td>\n",
       "      <td>Environment.import_modules; Environment.set_options</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>test=pd.read_csv(r'../input/house-prices-advanced-regression-techniques/test.csv')</td>\n",
       "      <td>Table</td>\n",
       "      <td>Data: extraction.Load from CSV</td>\n",
       "      <td>False</td>\n",
       "      <td>Exploratory_DA.show_table_attributes</td>\n",
       "      <td>Exploratory_DA.show_table</td>\n",
       "      <td>Data: extraction.Load from CSV</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>test.shape</td>\n",
       "      <td>Table</td>\n",
       "      <td>Exploratory_DA.show_table</td>\n",
       "      <td>False</td>\n",
       "      <td>Data: extraction.Load from CSV</td>\n",
       "      <td>Exploratory_DA.show_table_attributes</td>\n",
       "      <td>Exploratory_DA.show_table</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>train.describe()</td>\n",
       "      <td>Table</td>\n",
       "      <td>Exploratory_DA.show_table_attributes</td>\n",
       "      <td>False</td>\n",
       "      <td>Exploratory_DA.show_table</td>\n",
       "      <td>Data: extraction.Load from CSV</td>\n",
       "      <td>Exploratory_DA.show_table_attributes</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>train.dtypes</td>\n",
       "      <td>Table</td>\n",
       "      <td>Exploratory_DA.show_table_attributes</td>\n",
       "      <td>False</td>\n",
       "      <td>Exploratory_DA.show_table_attributes</td>\n",
       "      <td>Exploratory_DA.show_table</td>\n",
       "      <td>Data: extraction.Load from CSV</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>train.dtypes.value_counts()</td>\n",
       "      <td>Table</td>\n",
       "      <td>Exploratory_DA.show_table_attributes</td>\n",
       "      <td>False</td>\n",
       "      <td>Exploratory_DA.show_table_attributes</td>\n",
       "      <td>Exploratory_DA.show_table_attributes</td>\n",
       "      <td>Exploratory_DA.show_table</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>train['SalePrice'].describe()</td>\n",
       "      <td>Table</td>\n",
       "      <td>Exploratory_DA.show_table_attributes</td>\n",
       "      <td>False</td>\n",
       "      <td>Exploratory_DA.show_table_attributes</td>\n",
       "      <td>Exploratory_DA.show_table_attributes</td>\n",
       "      <td>Exploratory_DA.show_table_attributes</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>unique=len(set(train['Id']))\\ntotal=len(train['Id'])\\ndup=total - unique\\nprint(\"No of duplicate ID values in train dataset :\",dup)\\n\\nunique_t=len(set(test['Id']))\\ntotal_t=len(test['Id'])\\ndup_t=total_t - unique_t\\nprint(\"No of duplicate ID values in test dataset :\",dup_t)</td>\n",
       "      <td>Table</td>\n",
       "      <td>Exploratory_DA.count_duplicates</td>\n",
       "      <td>False</td>\n",
       "      <td>Exploratory_DA.show_table_attributes</td>\n",
       "      <td>Exploratory_DA.show_table_attributes</td>\n",
       "      <td>Exploratory_DA.show_table_attributes</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>submission=pd.DataFrame()\\nsubmission['Id']=test['Id']\\ntrain.drop(['Id'],axis=1,inplace=True)\\ntest.drop(['Id'],axis=1,inplace=True)</td>\n",
       "      <td>Table</td>\n",
       "      <td>Data: transform.create dataframe</td>\n",
       "      <td>False</td>\n",
       "      <td>Exploratory_DA.count_duplicates</td>\n",
       "      <td>Exploratory_DA.show_table_attributes</td>\n",
       "      <td>Exploratory_DA.show_table_attributes</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>misval=train.isnull().sum()\\r\\nmisval=misval[misval&gt;0]\\r\\nprint(misval)</td>\n",
       "      <td>Table</td>\n",
       "      <td>Exploratory_DA.count_missing_values</td>\n",
       "      <td>False</td>\n",
       "      <td>Data: transform.create dataframe</td>\n",
       "      <td>Exploratory_DA.count_duplicates</td>\n",
       "      <td>Exploratory_DA.show_table_attributes</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>train.drop(['Alley','FireplaceQu','PoolQC','Fence','MiscFeature'],axis=1,inplace=True)</td>\n",
       "      <td>Table</td>\n",
       "      <td>Data: transform.correct missing values</td>\n",
       "      <td>False</td>\n",
       "      <td>Exploratory_DA.count_missing_values</td>\n",
       "      <td>Data: transform.create dataframe</td>\n",
       "      <td>Exploratory_DA.count_duplicates</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>num_feat=train.select_dtypes(exclude=[object]).columns\\r\\ncat_feat=train.select_dtypes(include=[object]).columns\\r\\nprint(\"No. of numerical features:\",len(num_feat))\\r\\nprint(num_feat)\\r\\nprint(\"No. of categorical features:\",len(cat_feat))\\r\\nprint(cat_feat)</td>\n",
       "      <td>Table</td>\n",
       "      <td>Exploratory_DA.count_data_types</td>\n",
       "      <td>False</td>\n",
       "      <td>Data: transform.correct missing values</td>\n",
       "      <td>Exploratory_DA.count_missing_values</td>\n",
       "      <td>Data: transform.create dataframe</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>train=train.fillna(train.median())\\nsns.heatmap(train.isnull(),cbar=False)</td>\n",
       "      <td>Table</td>\n",
       "      <td>Data: transform.correct missing values; Visualize.missing_values</td>\n",
       "      <td>False</td>\n",
       "      <td>Exploratory_DA.count_data_types</td>\n",
       "      <td>Data: transform.correct missing values</td>\n",
       "      <td>Exploratory_DA.count_missing_values</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>23</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>misval=train.isnull().sum()\\r\\nmisval=misval[misval&gt;0]\\r\\nprint(misval)</td>\n",
       "      <td>Table</td>\n",
       "      <td>Exploratory_DA.count_missing_values</td>\n",
       "      <td>False</td>\n",
       "      <td>Data: transform.correct missing values; Visualize.missing_values</td>\n",
       "      <td>Exploratory_DA.count_data_types</td>\n",
       "      <td>Data: transform.correct missing values</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>24</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>train['BsmtQual']=train['BsmtQual'].fillna(train['BsmtQual'].mode()[0])</td>\n",
       "      <td>Table</td>\n",
       "      <td>Data: transform.correct missing values</td>\n",
       "      <td>False</td>\n",
       "      <td>Exploratory_DA.count_missing_values</td>\n",
       "      <td>Data: transform.correct missing values; Visualize.missing_values</td>\n",
       "      <td>Exploratory_DA.count_data_types</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          PK     Manually                \\\n",
       "0   chunk_id  notebook_id  splitting_id   \n",
       "1          1            1             1   \n",
       "2          2            1             1   \n",
       "3          3            1             1   \n",
       "4          4            1             1   \n",
       "5          5            1             1   \n",
       "6          6            1             1   \n",
       "7          7            7             1   \n",
       "8          8            7             1   \n",
       "9          9            7             1   \n",
       "10        10            7             1   \n",
       "11        11            7             1   \n",
       "12        12            7             1   \n",
       "13        13            7             1   \n",
       "14        14            7             1   \n",
       "15        15            7             1   \n",
       "16        16            7             1   \n",
       "17        17            7             1   \n",
       "18        18            7             1   \n",
       "19        19            7             1   \n",
       "20        20            7             1   \n",
       "21        21            7             1   \n",
       "22        22            7             1   \n",
       "23        23            7             1   \n",
       "24        24            7             1   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         \\\n",
       "0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            code_block   \n",
       "1   import os\\nimport numpy as np\\nimport matplotlib.pyplot as plt\\n\\nimport cudf\\n\\nfrom sklearn import preprocessing\\nfrom sklearn.model_selection import GridSearchCV\\nfrom sklearn.model_selection import StratifiedKFold\\n\\nimport pandas as pd\\npd.set_option('display.max_columns', 500)\\n\\nimport xgboost as xgb\\nprint(\"XGBoost version:\", xgb.__version__)\\n\\nimport warnings\\nwarnings.filterwarnings(\"ignore\")\\n\\nimport janestreet\\nprint('Creating competition environment...', end='')\\nenv = janestr...   \n",
       "2                             print('Reading datasets...', end='')\\n\\ntrain_cudf = cudf.read_csv('/kaggle/input/jane-street-market-prediction/train.csv')\\ntrain = train_cudf.to_pandas()\\ndel train_cudf\\n\\nfeatures_meta_cudf = cudf.read_csv('/kaggle/input/jane-street-market-prediction/features.csv')\\nfeatures_meta = features_meta_cudf.to_pandas()\\ndel features_meta_cudf\\n\\nprint('Finished.')\\n\\nprint(f'train shape: {format(train.shape)}')\\nprint(f'features_meta shape: {format(features_meta.shape)}')   \n",
       "3                                                                                                                                        print('Preprocessing data...', end='')\\n\\nfeatures = [col for col in list(train.columns) if 'feature' in col]\\n\\ntrain = train[train['weight'] != 0]\\n\\ntrain['action'] = (train['resp'].values > 0).astype(int)\\n\\n#train = train.fillna(-99999)\\ntrain.fillna(f_mean)\\n\\nX_train = train.loc[:, features]\\ny_train = train.loc[:, 'action']\\ndel train\\n\\nprint('Finished.')   \n",
       "4                                                                                                                                     print('Creating classifier...', end='')\\nclf = xgb.XGBClassifier(\\n    n_estimators=400,\\n    max_depth=7,\\n    eta=0.5, # learning_rate\\n    missing=None,\\n    random_state=42,\\n    tree_method='gpu_hist',\\n    subsample=0.8,\\n    colsample_bytree=1,\\n    #sampling_method='gradient_based',\\n    #eval_metric='logloss',\\n    verbosity=2   # info\\n)\\nprint('Finished.')   \n",
       "5                                                                                                                                                                                                                                                                                                                                                                                                                      print('Training classifier...', end='')\\r\\n%time clf.fit(X_train, y_train)\\r\\nprint('Finished.')   \n",
       "6                                                                                                                                                                             print('Creating submissions file...', end='')\\nrcount = 0\\nfor (test_df, prediction_df) in env.iter_test():\\n    X_test = test_df.loc[:, features]\\n    y_preds = clf.predict(X_test)\\n    prediction_df.action = y_preds\\n    env.predict(prediction_df)\\n    rcount += len(test_df.index)\\nprint(f'Finished processing {rcount} rows.')   \n",
       "7                                              import numpy as np\\nimport pandas as pd\\nimport matplotlib.pyplot as plt\\nimport seaborn as sns\\nfrom sklearn.linear_model import Lasso\\nfrom sklearn.linear_model import ElasticNet\\nfrom sklearn.ensemble import RandomForestRegressor\\nimport xgboost\\nfrom sklearn.preprocessing import StandardScaler\\nfrom sklearn.model_selection import RandomizedSearchCV\\nfrom sklearn.model_selection import GridSearchCV\\nimport warnings\\nwarnings.filterwarnings('ignore')   \n",
       "8                                                                                                                                                                                                                                                                                                                                                                                                                                  train=pd.read_csv(r'../input/house-prices-advanced-regression-techniques/train.csv')   \n",
       "9                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        train.head()\\r   \n",
       "10                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          train.shape   \n",
       "11                                                                                                                                                                                                                                                                                                                                                                                                                                   test=pd.read_csv(r'../input/house-prices-advanced-regression-techniques/test.csv')   \n",
       "12                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           test.shape   \n",
       "13                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     train.describe()   \n",
       "14                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         train.dtypes   \n",
       "15                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          train.dtypes.value_counts()   \n",
       "16                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        train['SalePrice'].describe()   \n",
       "17                                                                                                                                                                                                                                  unique=len(set(train['Id']))\\ntotal=len(train['Id'])\\ndup=total - unique\\nprint(\"No of duplicate ID values in train dataset :\",dup)\\n\\nunique_t=len(set(test['Id']))\\ntotal_t=len(test['Id'])\\ndup_t=total_t - unique_t\\nprint(\"No of duplicate ID values in test dataset :\",dup_t)   \n",
       "18                                                                                                                                                                                                                                                                                                                                                                                submission=pd.DataFrame()\\nsubmission['Id']=test['Id']\\ntrain.drop(['Id'],axis=1,inplace=True)\\ntest.drop(['Id'],axis=1,inplace=True)   \n",
       "19                                                                                                                                                                                                                                                                                                                                                                                                                                              misval=train.isnull().sum()\\r\\nmisval=misval[misval>0]\\r\\nprint(misval)   \n",
       "20                                                                                                                                                                                                                                                                                                                                                                                                                               train.drop(['Alley','FireplaceQu','PoolQC','Fence','MiscFeature'],axis=1,inplace=True)   \n",
       "21                                                                                                                                                                                                                                                   num_feat=train.select_dtypes(exclude=[object]).columns\\r\\ncat_feat=train.select_dtypes(include=[object]).columns\\r\\nprint(\"No. of numerical features:\",len(num_feat))\\r\\nprint(num_feat)\\r\\nprint(\"No. of categorical features:\",len(cat_feat))\\r\\nprint(cat_feat)   \n",
       "22                                                                                                                                                                                                                                                                                                                                                                                                                                           train=train.fillna(train.median())\\nsns.heatmap(train.isnull(),cbar=False)   \n",
       "23                                                                                                                                                                                                                                                                                                                                                                                                                                              misval=train.isnull().sum()\\r\\nmisval=misval[misval>0]\\r\\nprint(misval)   \n",
       "24                                                                                                                                                                                                                                                                                                                                                                                                                                              train['BsmtQual']=train['BsmtQual'].fillna(train['BsmtQual'].mode()[0])   \n",
       "\n",
       "                 \\\n",
       "0   data_format   \n",
       "1          None   \n",
       "2         Table   \n",
       "3         Table   \n",
       "4          None   \n",
       "5         Table   \n",
       "6         Table   \n",
       "7          None   \n",
       "8         Table   \n",
       "9         Table   \n",
       "10        Table   \n",
       "11        Table   \n",
       "12        Table   \n",
       "13        Table   \n",
       "14        Table   \n",
       "15        Table   \n",
       "16        Table   \n",
       "17        Table   \n",
       "18        Table   \n",
       "19        Table   \n",
       "20        Table   \n",
       "21        Table   \n",
       "22        Table   \n",
       "23        Table   \n",
       "24        Table   \n",
       "\n",
       "                                                                                                                               \\\n",
       "0                                                                                                                graph_vertex   \n",
       "1                                                                                                  Environment.import_modules   \n",
       "2                                                                                              Data: extraction.Load from CSV   \n",
       "3   Data: transform.filter;Data: transform.data type conversions;Data: transform.correct missing values;Data: transform.split   \n",
       "4                                                                                             Model: train.choose model class   \n",
       "5                                                                                                    Model: train.train model   \n",
       "6                                                                                                        Model: train.predict   \n",
       "7                                                                         Environment.import_modules; Environment.set_options   \n",
       "8                                                                                              Data: extraction.Load from CSV   \n",
       "9                                                                                                   Exploratory_DA.show_table   \n",
       "10                                                                                       Exploratory_DA.show_table_attributes   \n",
       "11                                                                                             Data: extraction.Load from CSV   \n",
       "12                                                                                                  Exploratory_DA.show_table   \n",
       "13                                                                                       Exploratory_DA.show_table_attributes   \n",
       "14                                                                                       Exploratory_DA.show_table_attributes   \n",
       "15                                                                                       Exploratory_DA.show_table_attributes   \n",
       "16                                                                                       Exploratory_DA.show_table_attributes   \n",
       "17                                                                                            Exploratory_DA.count_duplicates   \n",
       "18                                                                                           Data: transform.create dataframe   \n",
       "19                                                                                        Exploratory_DA.count_missing_values   \n",
       "20                                                                                     Data: transform.correct missing values   \n",
       "21                                                                                            Exploratory_DA.count_data_types   \n",
       "22                                                           Data: transform.correct missing values; Visualize.missing_values   \n",
       "23                                                                                        Exploratory_DA.count_missing_values   \n",
       "24                                                                                     Data: transform.correct missing values   \n",
       "\n",
       "            \\\n",
       "0   errors   \n",
       "1    False   \n",
       "2    False   \n",
       "3    False   \n",
       "4    False   \n",
       "5    False   \n",
       "6    False   \n",
       "7    False   \n",
       "8    False   \n",
       "9    False   \n",
       "10   False   \n",
       "11   False   \n",
       "12   False   \n",
       "13   False   \n",
       "14   False   \n",
       "15   False   \n",
       "16   False   \n",
       "17   False   \n",
       "18   False   \n",
       "19   False   \n",
       "20   False   \n",
       "21   False   \n",
       "22   False   \n",
       "23   False   \n",
       "24   False   \n",
       "\n",
       "                                                                                                                Automatically  \\\n",
       "0                                                                                                             graph_vertex_m1   \n",
       "1                                                                                                                         NaN   \n",
       "2                                                                                                  Environment.import_modules   \n",
       "3                                                                                              Data: extraction.Load from CSV   \n",
       "4   Data: transform.filter;Data: transform.data type conversions;Data: transform.correct missing values;Data: transform.split   \n",
       "5                                                                                             Model: train.choose model class   \n",
       "6                                                                                                    Model: train.train model   \n",
       "7                                                                                                                         NaN   \n",
       "8                                                                         Environment.import_modules; Environment.set_options   \n",
       "9                                                                                              Data: extraction.Load from CSV   \n",
       "10                                                                                                  Exploratory_DA.show_table   \n",
       "11                                                                                       Exploratory_DA.show_table_attributes   \n",
       "12                                                                                             Data: extraction.Load from CSV   \n",
       "13                                                                                                  Exploratory_DA.show_table   \n",
       "14                                                                                       Exploratory_DA.show_table_attributes   \n",
       "15                                                                                       Exploratory_DA.show_table_attributes   \n",
       "16                                                                                       Exploratory_DA.show_table_attributes   \n",
       "17                                                                                       Exploratory_DA.show_table_attributes   \n",
       "18                                                                                            Exploratory_DA.count_duplicates   \n",
       "19                                                                                           Data: transform.create dataframe   \n",
       "20                                                                                        Exploratory_DA.count_missing_values   \n",
       "21                                                                                     Data: transform.correct missing values   \n",
       "22                                                                                            Exploratory_DA.count_data_types   \n",
       "23                                                           Data: transform.correct missing values; Visualize.missing_values   \n",
       "24                                                                                        Exploratory_DA.count_missing_values   \n",
       "\n",
       "                                                                                                                               \\\n",
       "0                                                                                                             graph_vertex_m2   \n",
       "1                                                                                                                         NaN   \n",
       "2                                                                                                                         NaN   \n",
       "3                                                                                                  Environment.import_modules   \n",
       "4                                                                                              Data: extraction.Load from CSV   \n",
       "5   Data: transform.filter;Data: transform.data type conversions;Data: transform.correct missing values;Data: transform.split   \n",
       "6                                                                                             Model: train.choose model class   \n",
       "7                                                                                                                         NaN   \n",
       "8                                                                                                                         NaN   \n",
       "9                                                                         Environment.import_modules; Environment.set_options   \n",
       "10                                                                                             Data: extraction.Load from CSV   \n",
       "11                                                                                                  Exploratory_DA.show_table   \n",
       "12                                                                                       Exploratory_DA.show_table_attributes   \n",
       "13                                                                                             Data: extraction.Load from CSV   \n",
       "14                                                                                                  Exploratory_DA.show_table   \n",
       "15                                                                                       Exploratory_DA.show_table_attributes   \n",
       "16                                                                                       Exploratory_DA.show_table_attributes   \n",
       "17                                                                                       Exploratory_DA.show_table_attributes   \n",
       "18                                                                                       Exploratory_DA.show_table_attributes   \n",
       "19                                                                                            Exploratory_DA.count_duplicates   \n",
       "20                                                                                           Data: transform.create dataframe   \n",
       "21                                                                                        Exploratory_DA.count_missing_values   \n",
       "22                                                                                     Data: transform.correct missing values   \n",
       "23                                                                                            Exploratory_DA.count_data_types   \n",
       "24                                                           Data: transform.correct missing values; Visualize.missing_values   \n",
       "\n",
       "                                                                                                                               \\\n",
       "0                                                                                                             graph_vertex_m3   \n",
       "1                                                                                                                         NaN   \n",
       "2                                                                                                                         NaN   \n",
       "3                                                                                                                         NaN   \n",
       "4                                                                                                  Environment.import_modules   \n",
       "5                                                                                              Data: extraction.Load from CSV   \n",
       "6   Data: transform.filter;Data: transform.data type conversions;Data: transform.correct missing values;Data: transform.split   \n",
       "7                                                                                                                         NaN   \n",
       "8                                                                                                                         NaN   \n",
       "9                                                                                                                         NaN   \n",
       "10                                                                        Environment.import_modules; Environment.set_options   \n",
       "11                                                                                             Data: extraction.Load from CSV   \n",
       "12                                                                                                  Exploratory_DA.show_table   \n",
       "13                                                                                       Exploratory_DA.show_table_attributes   \n",
       "14                                                                                             Data: extraction.Load from CSV   \n",
       "15                                                                                                  Exploratory_DA.show_table   \n",
       "16                                                                                       Exploratory_DA.show_table_attributes   \n",
       "17                                                                                       Exploratory_DA.show_table_attributes   \n",
       "18                                                                                       Exploratory_DA.show_table_attributes   \n",
       "19                                                                                       Exploratory_DA.show_table_attributes   \n",
       "20                                                                                            Exploratory_DA.count_duplicates   \n",
       "21                                                                                           Data: transform.create dataframe   \n",
       "22                                                                                        Exploratory_DA.count_missing_values   \n",
       "23                                                                                     Data: transform.correct missing values   \n",
       "24                                                                                            Exploratory_DA.count_data_types   \n",
       "\n",
       "    ...                                                           \\\n",
       "0   ...  python_methods_m3  python_methods_p1  python_methods_p2   \n",
       "1   ...                NaN                NaN                NaN   \n",
       "2   ...                NaN                NaN                NaN   \n",
       "3   ...                NaN                NaN                NaN   \n",
       "4   ...                NaN                NaN                NaN   \n",
       "5   ...                NaN                NaN                NaN   \n",
       "6   ...                NaN                NaN                NaN   \n",
       "7   ...                NaN                NaN                NaN   \n",
       "8   ...                NaN                NaN                NaN   \n",
       "9   ...                NaN                NaN                NaN   \n",
       "10  ...                NaN                NaN                NaN   \n",
       "11  ...                NaN                NaN                NaN   \n",
       "12  ...                NaN                NaN                NaN   \n",
       "13  ...                NaN                NaN                NaN   \n",
       "14  ...                NaN                NaN                NaN   \n",
       "15  ...                NaN                NaN                NaN   \n",
       "16  ...                NaN                NaN                NaN   \n",
       "17  ...                NaN                NaN                NaN   \n",
       "18  ...                NaN                NaN                NaN   \n",
       "19  ...                NaN                NaN                NaN   \n",
       "20  ...                NaN                NaN                NaN   \n",
       "21  ...                NaN                NaN                NaN   \n",
       "22  ...                NaN                NaN                NaN   \n",
       "23  ...                NaN                NaN                NaN   \n",
       "24  ...                NaN                NaN                NaN   \n",
       "\n",
       "                                                                     \\\n",
       "0   python_methods_p3  kaggle_link  kaggle_comments  kaggle_upvotes   \n",
       "1                 NaN          NaN              NaN             NaN   \n",
       "2                 NaN          NaN              NaN             NaN   \n",
       "3                 NaN          NaN              NaN             NaN   \n",
       "4                 NaN          NaN              NaN             NaN   \n",
       "5                 NaN          NaN              NaN             NaN   \n",
       "6                 NaN          NaN              NaN             NaN   \n",
       "7                 NaN          NaN              NaN             NaN   \n",
       "8                 NaN          NaN              NaN             NaN   \n",
       "9                 NaN          NaN              NaN             NaN   \n",
       "10                NaN          NaN              NaN             NaN   \n",
       "11                NaN          NaN              NaN             NaN   \n",
       "12                NaN          NaN              NaN             NaN   \n",
       "13                NaN          NaN              NaN             NaN   \n",
       "14                NaN          NaN              NaN             NaN   \n",
       "15                NaN          NaN              NaN             NaN   \n",
       "16                NaN          NaN              NaN             NaN   \n",
       "17                NaN          NaN              NaN             NaN   \n",
       "18                NaN          NaN              NaN             NaN   \n",
       "19                NaN          NaN              NaN             NaN   \n",
       "20                NaN          NaN              NaN             NaN   \n",
       "21                NaN          NaN              NaN             NaN   \n",
       "22                NaN          NaN              NaN             NaN   \n",
       "23                NaN          NaN              NaN             NaN   \n",
       "24                NaN          NaN              NaN             NaN   \n",
       "\n",
       "                                                           \n",
       "0   kaggle_section  kaggle_section_overview  kaggle_score  \n",
       "1              NaN                      NaN           NaN  \n",
       "2              NaN                      NaN           NaN  \n",
       "3              NaN                      NaN           NaN  \n",
       "4              NaN                      NaN           NaN  \n",
       "5              NaN                      NaN           NaN  \n",
       "6              NaN                      NaN           NaN  \n",
       "7              NaN                      NaN           NaN  \n",
       "8              NaN                      NaN           NaN  \n",
       "9              NaN                      NaN           NaN  \n",
       "10             NaN                      NaN           NaN  \n",
       "11             NaN                      NaN           NaN  \n",
       "12             NaN                      NaN           NaN  \n",
       "13             NaN                      NaN           NaN  \n",
       "14             NaN                      NaN           NaN  \n",
       "15             NaN                      NaN           NaN  \n",
       "16             NaN                      NaN           NaN  \n",
       "17             NaN                      NaN           NaN  \n",
       "18             NaN                      NaN           NaN  \n",
       "19             NaN                      NaN           NaN  \n",
       "20             NaN                      NaN           NaN  \n",
       "21             NaN                      NaN           NaN  \n",
       "22             NaN                      NaN           NaN  \n",
       "23             NaN                      NaN           NaN  \n",
       "24             NaN                      NaN           NaN  \n",
       "\n",
       "[25 rows x 31 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df[['code_block', 'graph_vertex'.head(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.to_csv(filename[:-4] + \"graph_vertex_shift.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.6 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "0de36b31320ba4c88b4f85a74724f3d16c36a44df48581253710b1065e752d9e"
    }
   }
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}