{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python386jvsc74a57bd00de36b31320ba4c88b4f85a74724f3d16c36a44df48581253710b1065e752d9e",
   "display_name": "Python 3.8.6 64-bit"
  },
  "metadata": {
   "interpreter": {
    "hash": "0de36b31320ba4c88b4f85a74724f3d16c36a44df48581253710b1065e752d9e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from methods_parse.methods_parse import UsedMethods, shift_methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('mode.chained_assignment', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# comp_path = '../../data_mini/competitions_info_cleaned.csv'\n",
    "# competitions = pd.read_csv(comp_path)\n",
    "# competitions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_path = '../../data/actual_graph_2021-05-06.csv'\n",
    "graph = pd.read_csv(graph_path)\n",
    "graph.rename({'id':'graph_vertex_id'}, axis=1, inplace=True)\n",
    "# graph.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(4748, 8)"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "markup_path = '../../data/markup_data_2021-05-06.csv'\n",
    "markup_data = pd.read_csv(markup_path)\n",
    "markup_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(4748, 10)"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "markup_data = markup_data.merge(graph, on='graph_vertex_id', how='left')\n",
    "markup_data.shape"
   ]
  },
  {
   "source": [
    "---\n",
    "For Row"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def remove_comments(code_block:str) -> str:\n",
    "    \n",
    "#     return cleaned_code_block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_code_by_regex(code_block, regex_graph_version:int=6):\n",
    "    regex_graph_dir = '../../graph/graph_v{}.txt'.format(regex_graph_version)\n",
    "    with open(regex_graph_dir, \"r\") as regex_graph_file:\n",
    "        regex_graph = json.load(regex_graph_file)\n",
    "    found_vertices = []\n",
    "    for i, vertex in enumerate(regex_graph):\n",
    "        tokens = regex_graph[vertex]\n",
    "        for token in tokens:\n",
    "            result = re.search(token.replace('(','\\('), code_block)\n",
    "            if result!=None:\n",
    "                found_vertices.append(vertex)\n",
    "                break\n",
    "    return found_vertices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_comments(text: str):\n",
    "    text = str(text)\n",
    "#     comments = comment_parser.extract_comments_from_str(text, mime=\"text/x-python\")\n",
    "#     return \"\\n\".join([line.text() for line in comments])\n",
    "\n",
    "    comments = []\n",
    "    line_array = [line.strip() for line in text.split(\"\\n\")]\n",
    "    # now get libraries if line start with \"#\"\n",
    "    for line_ind in range(len(line_array)):\n",
    "        if line_array[line_ind].startswith(\"#\"):\n",
    "            comments.append(line_array[line_ind][1:])\n",
    "        elif line_array[line_ind].startswith(\"'''\"):\n",
    "            multi_comm = str()\n",
    "            multi_comm += line_array[line_ind][3:] + \"\\n\"\n",
    "            if \"'''\" in multi_comm:\n",
    "                multi_comm = multi_comm.replace(\"'''\", \"\")\n",
    "                line_ind += 1\n",
    "                comments.append(multi_comm)\n",
    "                continue\n",
    "            line_ind += 1\n",
    "            while line_ind < len(line_array):\n",
    "                multi_comm += line_array[line_ind] + \"\\n\"\n",
    "                if \"'''\" in multi_comm:\n",
    "                    multi_comm = multi_comm.replace(\"'''\", \"\")\n",
    "                    line_ind += 1\n",
    "                    break\n",
    "                line_ind += 1\n",
    "            comments.append(multi_comm)\n",
    "        elif line_array[line_ind].startswith('\"\"\"'):\n",
    "            multi_comm = str()\n",
    "            multi_comm += line_array[line_ind][3:] + \"\\n\"\n",
    "            if '\"\"\"' in multi_comm:\n",
    "                multi_comm = multi_comm.replace('\"\"\"', \"\")\n",
    "                line_ind += 1\n",
    "                comments.append(multi_comm)\n",
    "                continue\n",
    "            line_ind += 1\n",
    "            while line_ind < len(line_array):\n",
    "                multi_comm += line_array[line_ind] + \"\\n\"\n",
    "                if '\"\"\"' in multi_comm:\n",
    "                    multi_comm = multi_comm.replace('\"\"\"', \"\")\n",
    "                    line_ind += 1\n",
    "                    break\n",
    "                line_ind += 1\n",
    "            comments.append(multi_comm)\n",
    "            pass\n",
    "    return \"\\n\".join([line for line in comments])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "##TODO: FIXME 4k rows -> 200k\n",
    "def get_libraries(text: str, dicts: tuple):\n",
    "    name_lib_import = dicts[0]\n",
    "    name_lib_from = dicts[1]\n",
    "    text = str(text)\n",
    "    libs = []\n",
    "    line_array = [line.strip() for line in text.split(\"\\n\")]\n",
    "    # delete all double spaces in all lines\n",
    "    for ind in range(len(line_array)):\n",
    "        \n",
    "        prev_len = -1\n",
    "        while prev_len != len(line_array[ind]):\n",
    "            prev_len = len(line_array[ind])\n",
    "            line_array[ind] = line_array[ind].replace(\"  \", \" \")\n",
    "    # now get libraries if line start with \"import\" or \"from\"\n",
    "    for line in line_array:\n",
    "        if line.startswith(\"import\") or line.startswith(\"from\"):\n",
    "            libs.append(line.split(\" \")[1].split(\".\")[0])\n",
    "    for name in name_lib_from.keys():\n",
    "        for line in line_array:\n",
    "            if name in line:\n",
    "                libs.append(name_lib_from[name])\n",
    "                \n",
    "    for name in name_lib_import.keys():\n",
    "        for line in line_array:\n",
    "            if name + \".\" in line:\n",
    "                libs.append(name_lib_import[name])\n",
    "        \n",
    "    return \"\\n\".join(list(set(libs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dict(str_arr):\n",
    "    name_lib_import = {}\n",
    "    name_lib_from = {}\n",
    "    str_arr = [[line.strip() for line in text.split(\"\\n\")] for text in str_arr]\n",
    "    # delete all double spaces in all lines\n",
    "    for line_array in str_arr:\n",
    "        for ind in range(len(line_array)):\n",
    "            prev_len = -1\n",
    "            while prev_len != len(line_array[ind]):\n",
    "                prev_len = len(line_array[ind])\n",
    "                line_array[ind] = line_array[ind].replace(\"  \", \" \")\n",
    "    # now get libraries if line start with \"import\" or \"from\"\n",
    "    for line_array in str_arr:\n",
    "        for line in line_array:\n",
    "            if line.startswith(\"import\"):\n",
    "                split_arr = line.split(\" \")\n",
    "                # if we have \"import ... as ...\"\"\n",
    "                if len(split_arr) > 2 and split_arr[2] == \"as\":\n",
    "                    name_lib_import[split_arr[-1]] = split_arr[1].split(\".\")[0]\n",
    "            \n",
    "            if line.startswith(\"from\"):\n",
    "                split_arr = line.split(\" \")\n",
    "                # if we have \"from ... import ...\"\"\n",
    "                if len(split_arr) > 2 and split_arr[2] == \"import\":\n",
    "                    name_lib_from[split_arr[-1]] = split_arr[1].split(\".\")[0]\n",
    "    return (name_lib_import, name_lib_from)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_row(row):\n",
    "    '''\n",
    "    from methods_parse.py: python_methods, python_methods_m1, python_methods_m2, python_methods_m3, python_methods_p1, python_methods_p2, python_methods_p3\n",
    "    from models_scripts/regex.py: graph_vertex_regexs\n",
    "    '''\n",
    "    row['python_methods'] = UsedMethods(row['code_block'])\n",
    "    row['graph_vertex_regex'] = label_code_by_regex(row['code_block'])\n",
    "    row['comments'] = get_comments(row['code_block'])\n",
    "    return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(4748, 13)"
      ]
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "source": [
    "markup_data = markup_data.apply(process_row, axis=1)\n",
    "markup_data.shape"
   ]
  },
  {
   "source": [
    "---\n",
    "For Dataset"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(4748, 13)"
      ]
     },
     "metadata": {},
     "execution_count": 21
    }
   ],
   "source": [
    "markup_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_libraries_df(df):\n",
    "    all_temp_dfs = []\n",
    "    notebooks_ids = df['kaggle_id'].tolist()\n",
    "    for not_id in notebooks_ids:\n",
    "        # print('notebook id {}'.format(not_id))\n",
    "        # get rows for one kaggle_id\n",
    "        temp_df = df[df['kaggle_id'] == not_id]\n",
    "        buf_graph_vertex = list(temp_df.graph_vertex.values)\n",
    "        dicts = get_dict(temp_df.code_block.values)\n",
    "    #     print(dicts)\n",
    "        buf_arr = []\n",
    "        for code in temp_df.code_block.values:\n",
    "    #         print(get_libraries(code, dicts))\n",
    "            buf_arr.append(get_libraries(code, dicts))\n",
    "        temp_df['libraries'] = buf_arr\n",
    "        all_temp_dfs.append(temp_df)\n",
    "    return pd.concat(all_temp_dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(202804, 14)"
      ]
     },
     "metadata": {},
     "execution_count": 23
    }
   ],
   "source": [
    "get_libraries_df(markup_data).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "markup_data = get_libraries_df(markup_data)\n",
    "markup_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "markup_data = shift_methods(markup_data, shift_range=5)\n",
    "markup_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}