{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Alex\\Anaconda3\\lib\\site-packages\\ipykernel\\parentpoller.py:116: UserWarning: Parent poll failed.  If the frontend dies,\n",
      "                the kernel may be left running.  Please let us know\n",
      "                about your system (bitness, Python, etc.) at\n",
      "                ipython-dev@scipy.org\n",
      "  ipython-dev@scipy.org\"\"\")\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import keyword\n",
    "from IPython.display import clear_output\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "# from catboost import CatBoostClassifier\n",
    "import numpy as np\n",
    "from sklearn.metrics import f1_score\n",
    "import itertools\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import svm, datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing code samples\n",
    "\n",
    "Extracting code chunks with comments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>code_block</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50</td>\n",
       "      <td>\\nimport numpy as np \\nimport pandas as pd \\ni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>86</td>\n",
       "      <td>'''\\nThis is my implementation for this tutori...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>168</td>\n",
       "      <td>\\nimport numpy as np \\nimport pandas as pd \\np...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>216</td>\n",
       "      <td>\\nimport numpy as np \\nimport pandas as pd \\ni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>278</td>\n",
       "      <td>\\nimport numpy as np \\nimport pandas as pd \\ni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>293</td>\n",
       "      <td>\\nimport numpy as np \\nimport pandas as pd \\n'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>419</td>\n",
       "      <td>class LinearActiv(chainer.Chain):\\n    '''line...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>469</td>\n",
       "      <td>class Head(torch.nn.Module):\\n    def __init__...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>916</td>\n",
       "      <td>three_tables_query = '''\\n                    ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>917</td>\n",
       "      <td>all_users_query = '''\\n                  SELEC...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>918</td>\n",
       "      <td>max_commits_query = '''\\n                    S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>919</td>\n",
       "      <td>pop_lang_query = '''\\n                 SELECT ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>920</td>\n",
       "      <td>all_langs_query = '''\\n                  SELEC...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>922</td>\n",
       "      <td>def wants_all_toppings(ketchup, mustard, onion...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>923</td>\n",
       "      <td>def wants_plain_hotdog(ketchup, mustard, onion...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>924</td>\n",
       "      <td>def exactly_one_sauce(ketchup, mustard, onion)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>925</td>\n",
       "      <td>def exactly_one_topping(ketchup, mustard, onio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>928</td>\n",
       "      <td>def is_valid_zip(zip_code):\\n    '''Returns wh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>929</td>\n",
       "      <td>def multi_word_search(documents, keywords):\\n ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>959</td>\n",
       "      <td>def wants_all_toppings(ketchup, mustard, onion...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>960</td>\n",
       "      <td>def wants_plain_hotdog(ketchup, mustard, onion...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>961</td>\n",
       "      <td>def exactly_one_sauce(ketchup, mustard, onion)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>962</td>\n",
       "      <td>def exactly_one_topping(ketchup, mustard, onio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>963</td>\n",
       "      <td>def blackjack_hand_greater_than(hand_1, hand_2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>964</td>\n",
       "      <td>def is_valid_zip(zip_code):\\n    '''Returns wh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>965</td>\n",
       "      <td>def multi_word_search(doc_list, keywords):\\n  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>966</td>\n",
       "      <td>def blackjack_hand_greater_than(hand_1, hand_2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>970</td>\n",
       "      <td>def get_score(n_estimators):\\n    '''Return th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>973</td>\n",
       "      <td>def losing_team_captain(teams):\\n    '''Given ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>974</td>\n",
       "      <td>def purple_shell(racers):\\n    '''Given a list...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4920</th>\n",
       "      <td>221204</td>\n",
       "      <td>def mapl(f, l):\\n  '''\\n  Function that applie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4921</th>\n",
       "      <td>221206</td>\n",
       "      <td>def split_at_s(text, s):\\n  '''Function that s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4922</th>\n",
       "      <td>221209</td>\n",
       "      <td>import string\\ndef remove_punctuations_and_low...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4923</th>\n",
       "      <td>221211</td>\n",
       "      <td>def counter(l, f):\\n  '''\\n  Function that ret...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4924</th>\n",
       "      <td>221216</td>\n",
       "      <td>def predict(text, dict_prob_spam, dict_prob_ha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4925</th>\n",
       "      <td>221238</td>\n",
       "      <td>from sklearn.pipeline import make_pipeline\\nfr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4926</th>\n",
       "      <td>221265</td>\n",
       "      <td>def bar_plot(variable):\\n    '''\\n    inputlar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4927</th>\n",
       "      <td>221303</td>\n",
       "      <td>\\ncountry_spend_pct_query = '''\\n             ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4928</th>\n",
       "      <td>221377</td>\n",
       "      <td>from sklearn.model_selection import KFold \\ncl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4929</th>\n",
       "      <td>221505</td>\n",
       "      <td>class Apriori:\\n    \\n    def __init__(self, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4930</th>\n",
       "      <td>221509</td>\n",
       "      <td>answers_query = '''\\n                SELECT a....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4931</th>\n",
       "      <td>221510</td>\n",
       "      <td>\\nbigquery_experts_query = '''\\n              ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4932</th>\n",
       "      <td>221515</td>\n",
       "      <td>\\nrides_per_month_query = '''SELECT EXTRACT(MO...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4933</th>\n",
       "      <td>221516</td>\n",
       "      <td>\\nspeeds_query = '''\\n               WITH Rele...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4934</th>\n",
       "      <td>221522</td>\n",
       "      <td>\\nprolific_commenters_query = '''SELECT delete...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4935</th>\n",
       "      <td>221525</td>\n",
       "      <td>\\n'''\\nCreated on Sat Apr 11 22:02:11 2020\\n@a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4936</th>\n",
       "      <td>221539</td>\n",
       "      <td>def word_search(doc_list, keyword):\\n    '''\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4937</th>\n",
       "      <td>221544</td>\n",
       "      <td>PATTERN = r'([*]{2,})'\\ndef format_style(style...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4938</th>\n",
       "      <td>221596</td>\n",
       "      <td>REPLACE_BY_SPACE_RE = re.compile('[/(){}[]|@,;...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4939</th>\n",
       "      <td>221600</td>\n",
       "      <td>\\nWORDS_TO_INDEX = w \\nINDEX_TO_WORDS = ind_w\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4940</th>\n",
       "      <td>221603</td>\n",
       "      <td>def tfidf_features(X_train, X_val, X_test):\\n ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4941</th>\n",
       "      <td>221606</td>\n",
       "      <td>def train_classifier(X_train, y_train):\\n    '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4942</th>\n",
       "      <td>221646</td>\n",
       "      <td>def conv2d(layer_input, filters, f_size=4, bn=...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4943</th>\n",
       "      <td>221780</td>\n",
       "      <td>def solve(a, b, r):\\n    '''\\n    Solves the C...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4944</th>\n",
       "      <td>221783</td>\n",
       "      <td>\\ndef hprint(string):\\n    '''used to print he...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4945</th>\n",
       "      <td>221787</td>\n",
       "      <td>def create_corpus(text_data):\\n    ''' Create ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4946</th>\n",
       "      <td>221789</td>\n",
       "      <td>def clean_and_tokenise(text, stop_words=False,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4947</th>\n",
       "      <td>221797</td>\n",
       "      <td>def multi_model_cross_validation(clf_tuple_lis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4948</th>\n",
       "      <td>221799</td>\n",
       "      <td>def test_set_performances(clf_tuple_list, X_tr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4949</th>\n",
       "      <td>221801</td>\n",
       "      <td>def plot_confusion_matrix(true_y, pred_y, titl...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4950 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       index                                         code_block\n",
       "0         50  \\nimport numpy as np \\nimport pandas as pd \\ni...\n",
       "1         86  '''\\nThis is my implementation for this tutori...\n",
       "2        168  \\nimport numpy as np \\nimport pandas as pd \\np...\n",
       "3        216  \\nimport numpy as np \\nimport pandas as pd \\ni...\n",
       "4        278  \\nimport numpy as np \\nimport pandas as pd \\ni...\n",
       "5        293  \\nimport numpy as np \\nimport pandas as pd \\n'...\n",
       "6        419  class LinearActiv(chainer.Chain):\\n    '''line...\n",
       "7        469  class Head(torch.nn.Module):\\n    def __init__...\n",
       "8        916  three_tables_query = '''\\n                    ...\n",
       "9        917  all_users_query = '''\\n                  SELEC...\n",
       "10       918  max_commits_query = '''\\n                    S...\n",
       "11       919  pop_lang_query = '''\\n                 SELECT ...\n",
       "12       920  all_langs_query = '''\\n                  SELEC...\n",
       "13       922  def wants_all_toppings(ketchup, mustard, onion...\n",
       "14       923  def wants_plain_hotdog(ketchup, mustard, onion...\n",
       "15       924  def exactly_one_sauce(ketchup, mustard, onion)...\n",
       "16       925  def exactly_one_topping(ketchup, mustard, onio...\n",
       "17       928  def is_valid_zip(zip_code):\\n    '''Returns wh...\n",
       "18       929  def multi_word_search(documents, keywords):\\n ...\n",
       "19       959  def wants_all_toppings(ketchup, mustard, onion...\n",
       "20       960  def wants_plain_hotdog(ketchup, mustard, onion...\n",
       "21       961  def exactly_one_sauce(ketchup, mustard, onion)...\n",
       "22       962  def exactly_one_topping(ketchup, mustard, onio...\n",
       "23       963  def blackjack_hand_greater_than(hand_1, hand_2...\n",
       "24       964  def is_valid_zip(zip_code):\\n    '''Returns wh...\n",
       "25       965  def multi_word_search(doc_list, keywords):\\n  ...\n",
       "26       966  def blackjack_hand_greater_than(hand_1, hand_2...\n",
       "27       970  def get_score(n_estimators):\\n    '''Return th...\n",
       "28       973  def losing_team_captain(teams):\\n    '''Given ...\n",
       "29       974  def purple_shell(racers):\\n    '''Given a list...\n",
       "...      ...                                                ...\n",
       "4920  221204  def mapl(f, l):\\n  '''\\n  Function that applie...\n",
       "4921  221206  def split_at_s(text, s):\\n  '''Function that s...\n",
       "4922  221209  import string\\ndef remove_punctuations_and_low...\n",
       "4923  221211  def counter(l, f):\\n  '''\\n  Function that ret...\n",
       "4924  221216  def predict(text, dict_prob_spam, dict_prob_ha...\n",
       "4925  221238  from sklearn.pipeline import make_pipeline\\nfr...\n",
       "4926  221265  def bar_plot(variable):\\n    '''\\n    inputlar...\n",
       "4927  221303  \\ncountry_spend_pct_query = '''\\n             ...\n",
       "4928  221377  from sklearn.model_selection import KFold \\ncl...\n",
       "4929  221505  class Apriori:\\n    \\n    def __init__(self, t...\n",
       "4930  221509  answers_query = '''\\n                SELECT a....\n",
       "4931  221510  \\nbigquery_experts_query = '''\\n              ...\n",
       "4932  221515  \\nrides_per_month_query = '''SELECT EXTRACT(MO...\n",
       "4933  221516  \\nspeeds_query = '''\\n               WITH Rele...\n",
       "4934  221522  \\nprolific_commenters_query = '''SELECT delete...\n",
       "4935  221525  \\n'''\\nCreated on Sat Apr 11 22:02:11 2020\\n@a...\n",
       "4936  221539  def word_search(doc_list, keyword):\\n    '''\\n...\n",
       "4937  221544  PATTERN = r'([*]{2,})'\\ndef format_style(style...\n",
       "4938  221596  REPLACE_BY_SPACE_RE = re.compile('[/(){}[]|@,;...\n",
       "4939  221600  \\nWORDS_TO_INDEX = w \\nINDEX_TO_WORDS = ind_w\\...\n",
       "4940  221603  def tfidf_features(X_train, X_val, X_test):\\n ...\n",
       "4941  221606  def train_classifier(X_train, y_train):\\n    '...\n",
       "4942  221646  def conv2d(layer_input, filters, f_size=4, bn=...\n",
       "4943  221780  def solve(a, b, r):\\n    '''\\n    Solves the C...\n",
       "4944  221783  \\ndef hprint(string):\\n    '''used to print he...\n",
       "4945  221787  def create_corpus(text_data):\\n    ''' Create ...\n",
       "4946  221789  def clean_and_tokenise(text, stop_words=False,...\n",
       "4947  221797  def multi_model_cross_validation(clf_tuple_lis...\n",
       "4948  221799  def test_set_performances(clf_tuple_list, X_tr...\n",
       "4949  221801  def plot_confusion_matrix(true_y, pred_y, titl...\n",
       "\n",
       "[4950 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "code = pd.read_csv('code_blocks_final_clean.csv')\n",
    "code = code['code_block'].to_frame()\n",
    "idx = code['code_block'].str.contains(\"#\") | (code['code_block'].str.contains(\"'''\") & (code['code_block'].str.count(\"'''\") % 2 == 0))\n",
    "commented_code = code[idx].reset_index()\n",
    "commented_code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def digits_portion(x):\n",
    "    digits = ['0','1','2','3','4','5','6','7','8','9']\n",
    "    s = 0\n",
    "    for d in digits:\n",
    "        s += x.count(d)\n",
    "    return s / len(x)\n",
    "\n",
    "def keywords_num(x):\n",
    "    s = 0\n",
    "    words = x.split()\n",
    "    for k in keyword.kwlist:\n",
    "        s += words.count(k)\n",
    "    return s\n",
    "\n",
    "def num_words(x):\n",
    "    return len(x.split())\n",
    "\n",
    "def escape_sequence(x):\n",
    "    seqs = ['\\n','\\t']\n",
    "    s = 0\n",
    "    for i in seqs:\n",
    "        s += x.count(i)\n",
    "    return s\n",
    "    \n",
    "def can_compile(x):\n",
    "    try:\n",
    "        compile(x, \"bogusfile.py\", \"exec\")\n",
    "        return 1\n",
    "    except Exception as e:\n",
    "        return 0\n",
    "\n",
    "def brackets_num(x):\n",
    "    symbols = ['(',')','[',']','{','}']\n",
    "    s = 0\n",
    "    for i in symbols:\n",
    "        s += x.count(i)\n",
    "    return s\n",
    "\n",
    "def special_symbols(x):\n",
    "    symbols = ['!','@','$','%','^','&','*','-','+','~','/','|','\\\\']\n",
    "    s = 0\n",
    "    for i in symbols:\n",
    "        s += x.count(i)\n",
    "    return s\n",
    "\n",
    "def uppercase_partion(x):\n",
    "    s = 0\n",
    "    for i in x:\n",
    "        s += 1 if (('A' <= i) and (i <='Z')) else 0\n",
    "    return s / len(x)\n",
    "\n",
    "def lowercase_partion(x):\n",
    "    s = 0\n",
    "    for i in x:\n",
    "        s += 1 if (('a' <= i) and (i <='z')) else 0\n",
    "    return s / len(x)\n",
    "    \n",
    "vdp = np.vectorize(digits_portion)\n",
    "vlen = np.vectorize(len)\n",
    "vkn = np.vectorize(keywords_num)\n",
    "vnw = np.vectorize(num_words)\n",
    "vcc = np.vectorize(can_compile)\n",
    "ves = np.vectorize(escape_sequence)\n",
    "vbn = np.vectorize(brackets_num)\n",
    "vss = np.vectorize(special_symbols)\n",
    "vup = np.vectorize(uppercase_partion)\n",
    "vlp = np.vectorize(lowercase_partion)\n",
    "\n",
    "def preprocess_comments(ar):\n",
    "    prepr_funcs = [vdp, vlen, vkn, vnw, vcc, ves, vbn, vss, vup, vlp]\n",
    "    num = ar.shape[0]\n",
    "\n",
    "    prepr_columns = []\n",
    "\n",
    "    for f in prepr_funcs:\n",
    "        prepr_columns.append(f(ar).reshape([1,num]))\n",
    "\n",
    "    return np.concatenate(prepr_columns).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = CatBoostClassifier()\n",
    "# model.load_model(\"is_comment.cbm\")\n",
    "\n",
    "def all_occur(text, substr):\n",
    "    return [m.start() for m in re.finditer(substr, text)]\n",
    "\n",
    "def greater_than_in(value ,l, if_none):\n",
    "    try:\n",
    "        return next(y[1] for y in enumerate(l) if y[1] > value)\n",
    "    except:\n",
    "        return if_none\n",
    "\n",
    "def max_less(value ,l, if_none):\n",
    "    try:\n",
    "        return max([x for x in l if x < value])\n",
    "    except:\n",
    "        return if_none\n",
    "\n",
    "# проверка строки на наличие комментария\n",
    "def is_comment(text):\n",
    "    return True\n",
    "#     comment = preprocess_comments(np.array([text]))\n",
    "#     pred = model.predict(comment)\n",
    "#     return pred[0] == 1\n",
    "\n",
    "def change_position(code, code_new, ar):\n",
    "    dif = len(code) - len(code_new)\n",
    "    ar = [pos - dif for pos in ar]\n",
    "    return ar\n",
    "\n",
    "def trim_symbols(code_chunk):\n",
    "    code = code_chunk['code_block']\n",
    "    \n",
    "    patern1 = r\"(#\\s*)+\"\n",
    "    patern2 = r\"[#]+\"\n",
    "    \n",
    "    p1 = re.compile(patern1)\n",
    "    p2 = re.compile(patern2)\n",
    "    \n",
    "    code = p2.sub('#', p1.sub('#', code))\n",
    "    \n",
    "    # исправляем неправильно заданные многострочные комментарии\n",
    "    code = code.replace(\"''''\", \"'''\")\n",
    "    \n",
    "    # убираем последний символ - ','\n",
    "    code = code[:-1]\n",
    "    \n",
    "    # для случаев '''code_chunk''' убираем скобочки\n",
    "    if code.strip()[:3] == code.strip()[-3:]:\n",
    "        code = code.strip()[3:-3]\n",
    "    \n",
    "    code_chunk['code_block'] = code\n",
    "    return code_chunk\n",
    "    \n",
    "def single_lines(code_chunk):\n",
    "    code = code_chunk['code_block']\n",
    "    \n",
    "    singles = all_occur(code, '#')\n",
    "    newlines = all_occur(code, \"\\n\")\n",
    "    code_new = \"\"\n",
    "    \n",
    "    while len(singles) != 0:\n",
    "        codelen = len(code)\n",
    "        comment_start = singles.pop(0)\n",
    "        \n",
    "        comment_end = greater_than_in(comment_start, newlines, codelen)\n",
    "        comment = code[comment_start:comment_end]\n",
    "        \n",
    "        prev_newline = max_less(comment_start, newlines, 0)\n",
    "        before = code[prev_newline:comment_start]\n",
    "        before_indent = before[:(len(before) - len(before.lstrip()))]\n",
    "        before = before.strip()\n",
    "\n",
    "        comment = code[comment_start:comment_end]\n",
    "        \n",
    "        # перемещаем однострочные комментарии, перед которыми есть код\n",
    "        if (before != \"\"):\n",
    "            # проверяем, чтобы # не содержался внутри строки\n",
    "            # проверяем, чтобы # не был закоментирован\n",
    "            if ((before.count(\"'\") % 2 != 1) and\n",
    "                (before.count('\"') % 2 != 1) and\n",
    "                (code[:comment_start].count(\"'''\") %  2 != 1)):\n",
    "                \n",
    "                code_new = code[:prev_newline] + \"\\n'''\\n\" + comment[1:] + \"\\n'''\" + \\\n",
    "                           before_indent + before + code[comment_end:]\n",
    "                \n",
    "                singles = change_position(code, code_new, singles)\n",
    "                newlines = change_position(code, code_new, newlines)\n",
    "                \n",
    "                code = code_new\n",
    "    \n",
    "        # превращаем однострочные комментарии в начале строки в многострочные\n",
    "        else:\n",
    "            # проверяем, чтобы # не был закоментирован\n",
    "            if (code[:comment_start].count(\"'''\") %  2 != 1):\n",
    "                code_new = code[:prev_newline] + \"\\n'''\\n\" + comment[1:] + \"\\n'''\" + \\\n",
    "                               before_indent + before + code[comment_end:]\n",
    "                singles = change_position(code, code_new, singles)\n",
    "                newlines = change_position(code, code_new, newlines)\n",
    "                code = code_new\n",
    "\n",
    "    code_chunk['code_block'] = code\n",
    "    return code_chunk\n",
    "\n",
    "def multiple_lines(code_chunk):\n",
    "    code = code_chunk['code_block']\n",
    "    \n",
    "    code_new = \"\"\n",
    "    \n",
    "    multiples = all_occur(code, \"'''\")\n",
    "    \n",
    "    # объединение соседних комментов\n",
    "#     patern3 = r\"'''(\\n)*'''\"\n",
    "#     p3 = re.compile(patern3)\n",
    "#     code = p3.sub('\\n', code)\n",
    "    \n",
    "    code_chunk['code_block'] = code\n",
    "    return code_chunk\n",
    "\n",
    "def extract_comments(code_chunk):\n",
    "    code = code_chunk['code_block']\n",
    "\n",
    "    # добавляем комментарии в отдельный столбец\n",
    "    comments = []\n",
    "    multiples = all_occur(code, \"'''\")\n",
    "    \n",
    "    while len(multiples) > 0:\n",
    "        comment_start = multiples.pop(0)\n",
    "        comment_end = multiples.pop(0)\n",
    "        comment = code[comment_start + 3:comment_end]\n",
    "        \n",
    "        code_new = code[:comment_start] + code[comment_end + 3:]\n",
    "        multiples = change_position(code, code_new, multiples)\n",
    "        code = code_new\n",
    "        \n",
    "        if (len(comment) > 0) and (is_comment(comment)):\n",
    "            comments.append((comment_start, comment))\n",
    "    \n",
    "    code_chunk['code_block'] = code\n",
    "    code_chunk['comments'] = comments\n",
    "    \n",
    "    return code_chunk\n",
    "\n",
    "def purify(code_chunk):\n",
    "    comments = code_chunk['comments']\n",
    "    comments_new = []\n",
    "    for com in comments:\n",
    "        comment = com[1].replace('\\n','')\n",
    "        comment = comment.replace('\\t',' ')\n",
    "        comment = comment.strip()\n",
    "        \n",
    "        patern1 = r\"\\s+\"\n",
    "        p1 = re.compile(patern1)\n",
    "    \n",
    "        comment = p1.sub(' ', comment)\n",
    "        if len(comment) > 0:\n",
    "            comments_new.append((com[0], comment))\n",
    "    code_chunk['comments'] = comments_new\n",
    "    return code_chunk \n",
    "\n",
    "def create_description(code_chunk):\n",
    "    description = \"\"\n",
    "    description += \"\\n\".join([com[1] for com in code_chunk['comments']])\n",
    "    code_chunk['description'] = description\n",
    "    return code_chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "commented_code['comments'] = [[] for i in range(commented_code.shape[0])]\n",
    "preprocessed = commented_code.apply(trim_symbols, axis=1)\n",
    "preprocessed = preprocessed.apply(single_lines, axis=1)\n",
    "preprocessed = preprocessed.apply(multiple_lines, axis=1)\n",
    "# preprocessed = preprocessed.apply(purify, axis=1)\n",
    "preprocessed = preprocessed.apply(extract_comments, axis=1)\n",
    "descripted = preprocessed.apply(create_description, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "descripted = descripted[descripted['description'] != ''].reset_index().drop(columns=['level_0', 'comments'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "descripted.to_csv('code_blocks_descripted_check.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Разметка комментарием для обучения модели\n",
    "\n",
    "y - хороший коммент, n - плохой, b - остановить разметку"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "comments = []\n",
    "code_blocks = []\n",
    "comments_pure = []\n",
    "\n",
    "for i in range(preprocessed.shape[0]):\n",
    "    code_blocks.append(preprocessed['code_block'][i])\n",
    "    for com in preprocessed['comments'][i]:\n",
    "        comments.append(com)\n",
    "        comments_pure.append(com[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17\n",
      "done 30 of 8045\n",
      "____________________\n",
      "\n",
      "                  SELECT q.owner_user_id \n",
      "                  FROM `bigquery-public-data.stackoverflow.posts_questions` AS q\n",
      "                  WHERE EXTRACT(DATE FROM q.creation_date) = '2019-01-01'\n",
      "                  UNION DISTINCT\n",
      "                  SELECT a.owner_user_id\n",
      "                  FROM `bigquery-public-data.stackoverflow.posts_answers` AS a\n",
      "                  WHERE EXTRACT(DATE FROM a.creation_date) = '2019-01-01'\n",
      "                  \n",
      "____________________\n",
      "is comment? y/n?\n",
      "b\n"
     ]
    }
   ],
   "source": [
    "num = len(comments_pure)\n",
    "is_comment = [-1 for i in range(num)]\n",
    "\n",
    "done = 0\n",
    "for i in range(num):\n",
    "    if (is_comment[i] == -1):\n",
    "        comment = comments_pure[i]\n",
    "        print(i)\n",
    "        print('done',done,'of',num)\n",
    "        print(20*'_')\n",
    "        print(comment)\n",
    "        print(20*'_')\n",
    "        print('is comment? y/n?')\n",
    "        inp = input()[0]\n",
    "        if (inp == 'b'):\n",
    "            break\n",
    "        inp = 1 if inp == 'y' else 0\n",
    "        idxs = [j for j, x in enumerate(comments_pure) if x == comment]\n",
    "        done += len(idxs)\n",
    "        for idx in idxs:\n",
    "            is_comment[idx] = inp\n",
    "        clear_output()\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Хороший комментарий это:\n",
    "1. Кратко описывает одно, возможно сложное, действие\n",
    "2. Не содержит ссылок\n",
    "3. Не содержит кода или объяснения работы использованных функций\n",
    "4. Не описывает входные и выходные переменные\n",
    "5. Не является кодом\n",
    "6. На английском языке"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сохранение полученной разметки и предобработанных комментов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-8b3ed3143b0f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mis_comment\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_comment\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mcomments\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcomments\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"is_comment.npy\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"wb\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "is_comment = np.array(is_comment)\n",
    "comments = np.array(comments)\n",
    "\n",
    "with open(\"is_comment.npy\", \"wb\")as f:\n",
    "    np.save(f, is_comment)\n",
    "    \n",
    "# with open(\"comments.npy\", \"wb\")as f:\n",
    "#     np.save(f, comments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загрузка разметки и предобработанных комментов из файла."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"is_comment.npy\", \"rb\")as f:\n",
    "    is_comment = np.load(f)\n",
    "    \n",
    "# with open(\"comments.npy\", \"rb\")as f:\n",
    "#     comments = np.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8045,)\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-258ca7f67056>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_comment\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mcomments\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcomments\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcomments\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print(is_comment.shape)\n",
    "comments = np.array(comments)\n",
    "print(comments.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обучение модели, определяющей хорошие комментарии"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# число размеченных комментариев в выборке\n",
    "num = 1062\n",
    "X = preprocess_comments(np.array(comments_pure[:num]))\n",
    "y = is_comment[:num]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_unknown = preprocess_comments(np.array(comments_pure[num:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostClassifier at 0x1a21015f10>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = X_train\n",
    "train_labels = y_train\n",
    "\n",
    "model = CatBoostClassifier(iterations=150)\n",
    "model.fit(train_data,\n",
    "          train_labels,\n",
    "          verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 score: 0.9242416128255508\n",
      "accuracy: 0.9287749287749287\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "print('f1 score:', f1)\n",
    "print('accuracy:', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix, without normalization\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "\n",
    "cnf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "class_names = ['not comment', 'comment']\n",
    "\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix, classes=class_names,\n",
    "                      title='Confusion matrix')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_unknown_pred = model.predict(X_unknown)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All the students are grouped in five due to race/ethnicity. The data includes the parental level of education of the whole students. Also math, reading, writing scores are listed for each individual. \n",
      "____________________\n",
      "\n",
      "    Show chlonological change of the data.\n",
      "    \n",
      "____________________\n",
      "\n",
      "    Remove all special character from text string\n",
      "    \n",
      "____________________\n",
      "\n",
      "    Tokenize with NLTK\n",
      "    Rules:\n",
      "        - drop all words of 1 and 2 characters\n",
      "        - drop all stopwords\n",
      "        - drop all numbers\n",
      "    \n",
      "____________________\n",
      "\n",
      "    Clean and tokenize text input\n",
      "    \n",
      "____________________\n",
      "Grouping by match and groups\n",
      "____________________\n",
      "match rank\n",
      "____________________\n",
      "How dangerous is the coronavirus?\n",
      "Covid-19 is deadly, although fatality rates skyrocket for the elderly and those with compromised immune systems.\n",
      "How has the coronavirus affected you?\n",
      "Well if you ask me personally, the outbreak of novel Coronavirus, has affected me significantly. Both in respect of career and in respect of mental health.\n",
      "Is there a treatment for the Coronavirus?\n",
      "They are experimenting with various medicines and it seems some anti-malarial drugs show promise. However, they help only a little bit, as evidenced by the mortality rate in places like Italy or Spain. They are best if administered early, before the lungs are damaged.\n",
      "Is there a vaccine for the coronavirus?\n",
      "We don’t “find” vaccines. That’s the language yellow media uses, but it’s far from the truth.\n",
      "We know the virus, and we know what it looks like. Now we need to produce a sufficient amount of attenuated virii. For that, we inject the virus into a foreign host, like a chicken embryo in an egg. Most viruses will die, because the host is so different from humans, that it can not work. Some will mutate to work, and those multiply.\n",
      "How did coronaviruses get their name?\n",
      "The coronavirus family was discovered first in 1960s but we don’t know where they come from. They get the name given their crown-like (“corona”) shape. Following a December 2019 outbreak in China, the World Health Organization identified a new type called 2019 novel coronavirus (2019-nCoV).\n",
      "What are coronaviruses?\n",
      "Coronavirus is a name for a group of viruses that target mammals, including cats, dogs, and humans. They’re well known for causing potentially fatal conditions like kidney failure, pneumonia but also mundane things like some instances of the common cold.\n",
      "Does coronavirus cause death?\n",
      "Statistically speaking, you have a 98% chance of survival, and 80% chance that you won’t need medical care at all even if you get infected, so stay positive, stay at home as much as possible, eat healthy, treat everyone as if they are infected, treat other as if you are infected. Many people get infected and get better without even knowing they had it.\n",
      " \n",
      "What can one do to prepare for the coronavirus? What should one buy or do regularly?\n",
      "So, one thing you might do before it hits your region is to buy enough food for your freezer as well as canned goods and stock it so that, when the Virus hits, you won’t be running out into a store crowded with infected people. When it hits, stay home for work and school and strictly avoid crowded places. Stock up on real bar soap (like Ivory Gold) and wash hands frequently. Avoid sanitizers. Try to avoid clinics or EDs unless your symptoms become an issue as you don’t want to spread the disease beyond your home. Stock up on jello, G-Zero, plain decongestants like Mucinex, Bouillon or clear soups, lots of Kleenex and avoid solids and dairy products while you are symptomatic. The rest is just common sense.\n",
      "What should I buy to prepare for a coronavirus epidemic if I had to stay in my home for a very long time?\n",
      "So, one thing you might do before it hits your region is to buy enough food for your freezer as well as canned goods and stock it so that, when the Virus hits, you won’t be running out into a store crowded with infected people. When it hits, stay home for work and school and strictly avoid crowded places. Stock up on real bar soap (like Ivory Gold) and wash hands frequently. Avoid sanitizers. Try to avoid clinics or EDs unless your symptoms become an issue as you don’t want to spread the disease beyond your home. Stock up on jello, G-Zero, plain decongestants like Mucinex, Bouillon or clear soups, lots of Kleenex and avoid solids and dairy products while you are symptomatic. The rest is just common sense.\n",
      "What are the symptoms of Coronavirus?\n",
      "The symptoms of this virus include high fever, respiratory problems, shortness of breath and coughing. In extreme cases, it can even lead to pneumonia, kidney failure and death.\n",
      "To prevent infection from spreading, one should wash hands regularly, cover mouth and nose while coughing and sneezing and eat properly cook meat and eggs.\n",
      "____________________\n",
      "Helper to apply fitter to dataframe groups\n",
      "____________________\n",
      " For the given the source word, capture all the topn words\n",
      "____________________\n",
      "For all the words provided in the keyword list, capture the topn similar words\n",
      "____________________\n",
      "Load the Word2Vec model\n",
      "____________________\n",
      "\n",
      "Ratings distribution - The ratings are very unevenly distributed, and the vast majority of ratings are 0.\n",
      "\n",
      "____________________\n",
      "\n",
      "Age distribution - The most active users are among those in their 20–30s.\n",
      "\n",
      "____________________\n",
      "\n",
      "    Accepts the total_acc and mort_acc values for the row.\n",
      "    Checks if the mort_acc is NaN , if so, it returns the avg mort_acc value\n",
      "    for the corresponding total_acc value for that row.\n",
      "    \n",
      "    total_acc_avg here should be a Series or dictionary containing the mapping of the\n",
      "    groupby averages of mort_acc per total_acc values.\n",
      "    \n",
      "____________________\n",
      "Function creates bar chart with the ratio of correlated pairs for both groups\n",
      "____________________\n",
      "\n",
      "    Funtion takes the stimulus parameter and channel number and returns the p-value from Mann Whitney U-test (Alcoholic vs Control).\n",
      "    \n",
      "____________________\n",
      " Other maybe interestung POS: VERB, NOUN, PROPN\n",
      "    \n",
      "____________________\n",
      "plots new cases on each day\n",
      "____________________\n",
      " return defined t tuble\n",
      "____________________\n",
      " print key and value of dictionary\n",
      "____________________\n",
      " print key and value of dictionary\n",
      "____________________\n",
      "\n",
      "    Plot importances returned by a model. This can work with any measure of\n",
      "    feature importance provided that higher importance is better. \n",
      "    \n",
      "    Args:\n",
      "        df (dataframe): feature importances. Must have the features in a column\n",
      "        called `features` and the importances in a column called `importance\n",
      "        \n",
      "    Returns:\n",
      "        shows a plot of the 15 most importance features\n",
      "        \n",
      "        df (dataframe): feature importances sorted by importance (highest to lowest) \n",
      "        with a column for normalized importance\n",
      "        \n",
      "____________________\n",
      "\n",
      "    Plot importances returned by a model. This can work with any measure of\n",
      "    feature importance provided that higher importance is better. \n",
      "    \n",
      "    Parameters\n",
      "    --------\n",
      "        df : dataframe\n",
      "            feature importances. Must have the features in a column\n",
      "            called `features` and the importances in a column called `importance\n",
      "        \n",
      "    Return\n",
      "    -------\n",
      "        shows a plot of the 15 most importance features\n",
      "        \n",
      "        df : dataframe\n",
      "            feature importances sorted by importance (highest to lowest) \n",
      "            with a column for normalized importance\n",
      "        \n",
      "____________________\n",
      "Train and test a light gradient boosting model using\n",
      "    cross validation. \n",
      "    \n",
      "    Parameters\n",
      "    --------\n",
      "        features (pd.DataFrame): \n",
      "            dataframe of training features to use \n",
      "            for training a model. Must include the TARGET column.\n",
      "        test_features (pd.DataFrame): \n",
      "            dataframe of testing features to use\n",
      "            for making predictions with the model. \n",
      "        encoding (str, default = 'ohe'): \n",
      "            method for encoding categorical variables. Either 'ohe' for one-hot encoding or 'le' for integer label encoding\n",
      "            n_folds (int, default = 5): number of folds to use for cross validation\n",
      "        \n",
      "    Return\n",
      "    --------\n",
      "        submission (pd.DataFrame): \n",
      "            dataframe with `SK_ID_CURR` and `TARGET` probabilities\n",
      "            predicted by the model.\n",
      "        feature_importances (pd.DataFrame): \n",
      "            dataframe with the feature importances from the model.\n",
      "        valid_metrics (pd.DataFrame): \n",
      "            dataframe with training and validation metrics (ROC AUC) for each fold and overall.\n",
      "        \n",
      "    \n",
      "____________________\n"
     ]
    }
   ],
   "source": [
    "j = 0\n",
    "for i in range(num, len(comments_pure) - 1, 1):\n",
    "    if y_unknown_pred[i - num] == 1:\n",
    "        print(comments_pure[i + 1])\n",
    "        print(20 * \"_\")\n",
    "        j += 1\n",
    "    if j >= 25:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_model('is_comment.cbm')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
